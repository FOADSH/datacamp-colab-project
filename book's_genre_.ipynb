{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install Required Libraries"
      ],
      "metadata": {
        "id": "yPLVohPE8WA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODqIjFtA8NbP"
      },
      "outputs": [],
      "source": [
        "pip install pandas scikit-learn nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Load and Explore the Dataset"
      ],
      "metadata": {
        "id": "qt49R2jC8rxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('books.csv')\n",
        "\n",
        "# Explore the dataset\n",
        "print(df.head())\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "7VA5ynFt8qvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Clean the Dataset\n",
        "\n",
        "Handle missing values and clean the text data."
      ],
      "metadata": {
        "id": "Xt8jmp1R9AYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values in title/description\n",
        "df.dropna(subset=['title', 'description'], inplace=True)\n",
        "\n",
        "# You can also perform further cleaning like lowercasing, removing punctuation, etc.\n",
        "df['description'] = df['description'].str.lower()"
      ],
      "metadata": {
        "id": "qx72cGoR8_eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Vectorization"
      ],
      "metadata": {
        "id": "0SpcuZ6Y9n7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Vectorize the descriptions\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(df['description'])"
      ],
      "metadata": {
        "id": "LJzoDfet9xFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: K-Means Clustering"
      ],
      "metadata": {
        "id": "3zhjOnrM-d3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Choose the number of clusters (genres)\n",
        "num_clusters = 5  # You can adjust this based on your dataset\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "kmeans.fit(X)\n",
        "df['cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "OCWaDM7G-gdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Evaluate using Silhouette Coefficient"
      ],
      "metadata": {
        "id": "gqYyFABw_JUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Calculate silhouette score\n",
        "silhouette_avg = silhouette_score(X, kmeans.labels_)\n",
        "print(f'Silhouette Coefficient: {silhouette_avg}')"
      ],
      "metadata": {
        "id": "Cniwau9L-6da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the count of books in each cluster\n",
        "print(df['cluster'].value_counts())"
      ],
      "metadata": {
        "id": "wexSKZgq_O9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Step: Visualize Clusters (Optional)\n",
        "If you want to visualize clusters, you might use PCA to reduce the dimensions to 2D."
      ],
      "metadata": {
        "id": "cH7233Un_TGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Dimensionality reduction\n",
        "pca = PCA(n_components=2)\n",
        "X_embedded = pca.fit_transform(X.toarray())\n",
        "\n",
        "# Plotting\n",
        "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=df['cluster'], cmap='viridis')\n",
        "plt.title('Book Clusters')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8-u4c0dw_VNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('books.csv')\n",
        "\n",
        "# Explore the dataset\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# Drop rows with missing values in title/description\n",
        "df.dropna(subset=['title', 'description'], inplace=True)\n",
        "\n",
        "# Clean the description text\n",
        "df['description'] = df['description'].str.lower()\n",
        "\n",
        "# Define a custom list of stop words (optional)\n",
        "custom_stop_words = [\"book\", \"novel\", \"story\", \"read\", \"readers\"] # Add more as needed\n",
        "\n",
        "# Combine custom stop words with default English stop words\n",
        "from sklearn.feature_extraction import text\n",
        "stop_words = text.ENGLISH_STOP_WORDS.union(custom_stop_words)\n",
        "\n",
        "# Vectorize the descriptions, using the stop words\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
        "X = vectorizer.fit_transform(df['description'])\n",
        "\n",
        "# Choose the number of clusters (genres)\n",
        "num_clusters = 5  # You can adjust this based on your dataset\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "kmeans.fit(X)\n",
        "df['cluster'] = kmeans.labels_\n",
        "\n",
        "# Calculate silhouette score\n",
        "silhouette_avg = silhouette_score(X, kmeans.labels_)\n",
        "print(f'Silhouette Coefficient: {silhouette_avg}')\n",
        "\n",
        "# Display the count of books in each cluster\n",
        "print(df['cluster'].value_counts())\n",
        "\n",
        "# Dimensionality reduction for visualization\n",
        "pca = PCA(n_components=2)\n",
        "X_embedded = pca.fit_transform(X.toarray())\n",
        "\n",
        "# Plotting the clusters\n",
        "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=df['cluster'], cmap='viridis')\n",
        "plt.title('Book Clusters')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "41dp9vIFAaSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}