{"cells":[{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.570110Z","iopub.status.busy":"2024-04-02T05:45:26.569152Z","iopub.status.idle":"2024-04-02T05:45:26.581333Z","shell.execute_reply":"2024-04-02T05:45:26.580134Z","shell.execute_reply.started":"2024-04-02T05:45:26.570058Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/heart-disease-data-compiled-from-uci/UCI_Heart_Disease_Dataset_Combined.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.584526Z","iopub.status.busy":"2024-04-02T05:45:26.584027Z","iopub.status.idle":"2024-04-02T05:45:26.601751Z","shell.execute_reply":"2024-04-02T05:45:26.600131Z","shell.execute_reply.started":"2024-04-02T05:45:26.584475Z"},"trusted":true},"outputs":[],"source":["df=pd.read_csv(\"/kaggle/input/heart-disease-data-compiled-from-uci/UCI_Heart_Disease_Dataset_Combined.csv\")"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.604146Z","iopub.status.busy":"2024-04-02T05:45:26.603715Z","iopub.status.idle":"2024-04-02T05:45:26.623074Z","shell.execute_reply":"2024-04-02T05:45:26.621673Z","shell.execute_reply.started":"2024-04-02T05:45:26.604112Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Sex</th>\n","      <th>ChestPainType</th>\n","      <th>RestingBP</th>\n","      <th>Cholesterol</th>\n","      <th>FastingBS</th>\n","      <th>RestingECG</th>\n","      <th>MaxHR</th>\n","      <th>ExerciseAngina</th>\n","      <th>Oldpeak</th>\n","      <th>HeartDisease</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>140</td>\n","      <td>289</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>49</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>160</td>\n","      <td>180</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>156</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>283</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>98</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>138</td>\n","      <td>214</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>108</td>\n","      <td>1</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>150</td>\n","      <td>195</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>122</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n","0   40    1              1        140          289          0           0   \n","1   49    0              2        160          180          0           0   \n","2   37    1              1        130          283          0           1   \n","3   48    0              3        138          214          0           0   \n","4   54    1              2        150          195          0           0   \n","\n","   MaxHR  ExerciseAngina  Oldpeak  HeartDisease  \n","0    172               0      0.0             0  \n","1    156               0      1.0             1  \n","2     98               0      0.0             0  \n","3    108               1      1.5             1  \n","4    122               0      0.0             0  "]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.625748Z","iopub.status.busy":"2024-04-02T05:45:26.625225Z","iopub.status.idle":"2024-04-02T05:45:26.634050Z","shell.execute_reply":"2024-04-02T05:45:26.632698Z","shell.execute_reply.started":"2024-04-02T05:45:26.625700Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(2943, 11)"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.638830Z","iopub.status.busy":"2024-04-02T05:45:26.638355Z","iopub.status.idle":"2024-04-02T05:45:26.653866Z","shell.execute_reply":"2024-04-02T05:45:26.652668Z","shell.execute_reply.started":"2024-04-02T05:45:26.638795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2943 entries, 0 to 2942\n","Data columns (total 11 columns):\n"," #   Column          Non-Null Count  Dtype  \n","---  ------          --------------  -----  \n"," 0   Age             2943 non-null   int64  \n"," 1   Sex             2943 non-null   int64  \n"," 2   ChestPainType   2943 non-null   int64  \n"," 3   RestingBP       2943 non-null   int64  \n"," 4   Cholesterol     2943 non-null   int64  \n"," 5   FastingBS       2943 non-null   int64  \n"," 6   RestingECG      2943 non-null   int64  \n"," 7   MaxHR           2943 non-null   int64  \n"," 8   ExerciseAngina  2943 non-null   int64  \n"," 9   Oldpeak         2943 non-null   float64\n"," 10  HeartDisease    2943 non-null   int64  \n","dtypes: float64(1), int64(10)\n","memory usage: 253.0 KB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.656081Z","iopub.status.busy":"2024-04-02T05:45:26.655706Z","iopub.status.idle":"2024-04-02T05:45:26.668233Z","shell.execute_reply":"2024-04-02T05:45:26.666701Z","shell.execute_reply.started":"2024-04-02T05:45:26.656048Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS',\n","       'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'HeartDisease'],\n","      dtype='object')"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.670924Z","iopub.status.busy":"2024-04-02T05:45:26.670529Z","iopub.status.idle":"2024-04-02T05:45:26.689518Z","shell.execute_reply":"2024-04-02T05:45:26.687985Z","shell.execute_reply.started":"2024-04-02T05:45:26.670891Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Sex</th>\n","      <th>ChestPainType</th>\n","      <th>RestingBP</th>\n","      <th>Cholesterol</th>\n","      <th>FastingBS</th>\n","      <th>RestingECG</th>\n","      <th>MaxHR</th>\n","      <th>ExerciseAngina</th>\n","      <th>Oldpeak</th>\n","      <th>HeartDisease</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>140</td>\n","      <td>289</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>49</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>160</td>\n","      <td>180</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>156</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>283</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>98</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>138</td>\n","      <td>214</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>108</td>\n","      <td>1</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>150</td>\n","      <td>195</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>122</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n","0   40    1              1        140          289          0           0   \n","1   49    0              2        160          180          0           0   \n","2   37    1              1        130          283          0           1   \n","3   48    0              3        138          214          0           0   \n","4   54    1              2        150          195          0           0   \n","\n","   MaxHR  ExerciseAngina  Oldpeak  HeartDisease  \n","0    172               0      0.0             0  \n","1    156               0      1.0             1  \n","2     98               0      0.0             0  \n","3    108               1      1.5             1  \n","4    122               0      0.0             0  "]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.691650Z","iopub.status.busy":"2024-04-02T05:45:26.691239Z","iopub.status.idle":"2024-04-02T05:45:26.712981Z","shell.execute_reply":"2024-04-02T05:45:26.711727Z","shell.execute_reply.started":"2024-04-02T05:45:26.691617Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Duplicate Rows except the first occurrence based on all columns are:\n","      Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n","1933   34    0              1        118          210          0           1   \n","1949   50    0              1        120          244          0           1   \n","1961   46    1              0        120          249          0           0   \n","1973   55    1              0        140          217          0           1   \n","1979   66    0              2        146          278          0           0   \n","...   ...  ...            ...        ...          ...        ...         ...   \n","2938   59    1              1        140          221          0           1   \n","2939   60    1              0        125          258          0           0   \n","2940   47    1              0        110          275          0           0   \n","2941   50    0              0        110          254          0           0   \n","2942   54    1              0        120          188          0           1   \n","\n","      MaxHR  ExerciseAngina  Oldpeak  HeartDisease  \n","1933    192               0      0.7             1  \n","1949    162               0      1.1             1  \n","1961    144               0      0.8             0  \n","1973    111               1      5.6             0  \n","1979    152               0      0.0             1  \n","...     ...             ...      ...           ...  \n","2938    164               1      0.0             1  \n","2939    141               1      2.8             0  \n","2940    118               1      1.0             0  \n","2941    159               0      0.0             1  \n","2942    113               0      1.4             0  \n","\n","[723 rows x 11 columns]\n"]}],"source":["duplicate_rows_df = df[df.duplicated()]\n","print(\"\\nDuplicate Rows except the first occurrence based on all columns are:\")\n","print(duplicate_rows_df)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.716047Z","iopub.status.busy":"2024-04-02T05:45:26.715127Z","iopub.status.idle":"2024-04-02T05:45:26.731178Z","shell.execute_reply":"2024-04-02T05:45:26.729898Z","shell.execute_reply.started":"2024-04-02T05:45:26.716000Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","DataFrame after removing duplicates:\n","      Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n","0      40    1              1        140          289          0           0   \n","1      49    0              2        160          180          0           0   \n","2      37    1              1        130          283          0           1   \n","3      48    0              3        138          214          0           0   \n","4      54    1              2        150          195          0           0   \n","...   ...  ...            ...        ...          ...        ...         ...   \n","2641   68    0              2        120          211          0           0   \n","2651   44    0              2        108          141          0           1   \n","2657   52    1              0        128          255          0           1   \n","2761   59    1              3        160          273          0           0   \n","2796   54    1              0        120          188          0           1   \n","\n","      MaxHR  ExerciseAngina  Oldpeak  HeartDisease  \n","0       172               0      0.0             0  \n","1       156               0      1.0             1  \n","2        98               0      0.0             0  \n","3       108               1      1.5             1  \n","4       122               0      0.0             0  \n","...     ...             ...      ...           ...  \n","2641    115               0      1.5             1  \n","2651    175               0      0.6             1  \n","2657    161               1      0.0             0  \n","2761    125               0      0.0             0  \n","2796    113               0      1.4             0  \n","\n","[2220 rows x 11 columns]\n"]}],"source":["df = df.drop_duplicates()\n","print(\"\\nDataFrame after removing duplicates:\")\n","print(df)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:26.733171Z","iopub.status.busy":"2024-04-02T05:45:26.732620Z","iopub.status.idle":"2024-04-02T05:45:27.059253Z","shell.execute_reply":"2024-04-02T05:45:27.058392Z","shell.execute_reply.started":"2024-04-02T05:45:26.733139Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(array([ 968.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","        1252.]),\n"," array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n"," <BarContainer object of 10 artists>)"]},"execution_count":44,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt \n","plt.hist(df[\"HeartDisease\"])"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:27.063394Z","iopub.status.busy":"2024-04-02T05:45:27.062882Z","iopub.status.idle":"2024-04-02T05:45:27.086358Z","shell.execute_reply":"2024-04-02T05:45:27.085067Z","shell.execute_reply.started":"2024-04-02T05:45:27.063363Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Sex</th>\n","      <th>RestingBP</th>\n","      <th>Cholesterol</th>\n","      <th>FastingBS</th>\n","      <th>RestingECG</th>\n","      <th>MaxHR</th>\n","      <th>ExerciseAngina</th>\n","      <th>Oldpeak</th>\n","      <th>HeartDisease</th>\n","      <th>ChestPainType_0</th>\n","      <th>ChestPainType_1</th>\n","      <th>ChestPainType_2</th>\n","      <th>ChestPainType_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40</td>\n","      <td>1</td>\n","      <td>140</td>\n","      <td>289</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>49</td>\n","      <td>0</td>\n","      <td>160</td>\n","      <td>180</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>156</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>283</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>98</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>138</td>\n","      <td>214</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>108</td>\n","      <td>1</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54</td>\n","      <td>1</td>\n","      <td>150</td>\n","      <td>195</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>122</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Age  Sex  RestingBP  Cholesterol  FastingBS  RestingECG  MaxHR  \\\n","0   40    1        140          289          0           0    172   \n","1   49    0        160          180          0           0    156   \n","2   37    1        130          283          0           1     98   \n","3   48    0        138          214          0           0    108   \n","4   54    1        150          195          0           0    122   \n","\n","   ExerciseAngina  Oldpeak  HeartDisease  ChestPainType_0  ChestPainType_1  \\\n","0               0      0.0             0            False             True   \n","1               0      1.0             1            False            False   \n","2               0      0.0             0            False             True   \n","3               1      1.5             1            False            False   \n","4               0      0.0             0            False            False   \n","\n","   ChestPainType_2  ChestPainType_3  \n","0            False            False  \n","1             True            False  \n","2            False            False  \n","3            False             True  \n","4             True            False  "]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.get_dummies(df, columns=['ChestPainType'])\n","df.head()\n"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:27.088703Z","iopub.status.busy":"2024-04-02T05:45:27.088246Z","iopub.status.idle":"2024-04-02T05:45:30.725808Z","shell.execute_reply":"2024-04-02T05:45:30.724636Z","shell.execute_reply.started":"2024-04-02T05:45:27.088663Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"name":"stdout","output_type":"stream","text":["Logistic Regression test Accuracy: 0.7342342342342343, Precision: 0.75, Recall: 0.8244274809160306, F1 Score: 0.7854545454545455\n","Random Forest test Accuracy: 0.8198198198198198, Precision: 0.837037037037037, Recall: 0.8625954198473282, F1 Score: 0.849624060150376\n","XGBoost test Accuracy: 0.8063063063063063, Precision: 0.8333333333333334, Recall: 0.8396946564885496, F1 Score: 0.8365019011406843\n","[LightGBM] [Info] Number of positive: 992, number of negative: 784\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 623\n","[LightGBM] [Info] Number of data points in the train set: 1776, number of used features: 13\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558559 -> initscore=0.235314\n","[LightGBM] [Info] Start training from score 0.235314\n","LightGBM test Accuracy: 0.8018018018018018, Precision: 0.8270676691729323, Recall: 0.8396946564885496, F1 Score: 0.8333333333333333\n","CatBoost test Accuracy: 0.8378378378378378, Precision: 0.8518518518518519, Recall: 0.8778625954198473, F1 Score: 0.8646616541353385\n","GradientBoost test Accuracy: 0.8153153153153153, Precision: 0.8409090909090909, Recall: 0.8473282442748091, F1 Score: 0.8441064638783269\n","ExtraTrees test Accuracy: 0.8558558558558559, Precision: 0.8561151079136691, Recall: 0.9083969465648855, F1 Score: 0.8814814814814815\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier,ExtraTreesClassifier\n","from sklearn.svm import SVC\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier\n","\n","X = df.drop('HeartDisease', axis=1)\n","y = df['HeartDisease']\n","\n","X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1111, random_state=42)\n","\n","classifiers = {\n","    'Logistic Regression': LogisticRegression(),\n","    'Random Forest': RandomForestClassifier(),\n","#     'SVM': SVC(),\n","    'XGBoost': XGBClassifier(),\n","    'LightGBM': LGBMClassifier(),\n","    'CatBoost': CatBoostClassifier(silent=True),\n","    'GradientBoost':GradientBoostingClassifier(),\n","    'ExtraTrees':ExtraTreesClassifier()\n","}\n","\n","# Train and test each classifier\n","for name, clf in classifiers.items():\n","    clf.fit(X_train, y_train)\n","    test_predictions = clf.predict(X_test)\n","    test_accuracy = accuracy_score(y_test, test_predictions)\n","    test_precision = precision_score(y_test, test_predictions)\n","    test_recall = recall_score(y_test, test_predictions)\n","    test_f1 = f1_score(y_test, test_predictions)\n","    print(f'{name} test Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}')\n","    \n","    # val_predictions = clf.predict(X_val)\n","    # val_accuracy = accuracy_score(y_val, val_predictions)\n","    # val_precision = precision_score(y_val, val_predictions)\n","    # val_recall = recall_score(y_val, val_predictions)\n","    # val_f1 = f1_score(y_val, val_predictions)\n","    # print(f'{name} validation Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1 Score: {val_f1}')\n","\n"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T05:45:30.728354Z","iopub.status.busy":"2024-04-02T05:45:30.727657Z","iopub.status.idle":"2024-04-02T05:45:51.298635Z","shell.execute_reply":"2024-04-02T05:45:51.297415Z","shell.execute_reply.started":"2024-04-02T05:45:30.728311Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5353 - loss: 1.6042 - val_accuracy: 0.5766 - val_loss: 0.6678\n","Epoch 2/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5863 - loss: 0.6545 - val_accuracy: 0.5586 - val_loss: 0.7522\n","Epoch 3/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5760 - loss: 0.6888 - val_accuracy: 0.5856 - val_loss: 0.6688\n","Epoch 4/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6090 - loss: 0.6536 - val_accuracy: 0.6441 - val_loss: 0.6097\n","Epoch 5/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6125 - loss: 0.6373 - val_accuracy: 0.6802 - val_loss: 0.5940\n","Epoch 6/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6594 - loss: 0.6170 - val_accuracy: 0.6081 - val_loss: 0.6761\n","Epoch 7/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6383 - loss: 0.6272 - val_accuracy: 0.6577 - val_loss: 0.6116\n","Epoch 8/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5808 - loss: 0.6449 - val_accuracy: 0.6937 - val_loss: 0.6279\n","Epoch 9/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6638 - loss: 0.6188 - val_accuracy: 0.6036 - val_loss: 0.6469\n","Epoch 10/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6159 - loss: 0.6359 - val_accuracy: 0.6216 - val_loss: 0.6302\n","Epoch 11/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6457 - loss: 0.6032 - val_accuracy: 0.6396 - val_loss: 0.5878\n","Epoch 12/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6622 - loss: 0.5961 - val_accuracy: 0.6396 - val_loss: 0.5855\n","Epoch 13/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6923 - loss: 0.5631 - val_accuracy: 0.6261 - val_loss: 0.5962\n","Epoch 14/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6910 - loss: 0.5739 - val_accuracy: 0.7793 - val_loss: 0.5272\n","Epoch 15/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7389 - loss: 0.5228 - val_accuracy: 0.6306 - val_loss: 0.6067\n","Epoch 16/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6451 - loss: 0.6101 - val_accuracy: 0.7748 - val_loss: 0.5424\n","Epoch 17/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7278 - loss: 0.5463 - val_accuracy: 0.7477 - val_loss: 0.5000\n","Epoch 18/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7278 - loss: 0.5265 - val_accuracy: 0.7477 - val_loss: 0.5449\n","Epoch 19/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7646 - loss: 0.4984 - val_accuracy: 0.6577 - val_loss: 0.6208\n","Epoch 20/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6808 - loss: 0.5959 - val_accuracy: 0.7838 - val_loss: 0.4873\n","Epoch 21/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7345 - loss: 0.5190 - val_accuracy: 0.7658 - val_loss: 0.4957\n","Epoch 22/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7448 - loss: 0.5273 - val_accuracy: 0.7477 - val_loss: 0.5256\n","Epoch 23/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7299 - loss: 0.5142 - val_accuracy: 0.7613 - val_loss: 0.4927\n","Epoch 24/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.4987 - val_accuracy: 0.7838 - val_loss: 0.4987\n","Epoch 25/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7246 - loss: 0.5424 - val_accuracy: 0.7793 - val_loss: 0.4939\n","Epoch 26/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7438 - loss: 0.5194 - val_accuracy: 0.7613 - val_loss: 0.5214\n","Epoch 27/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7368 - loss: 0.5188 - val_accuracy: 0.7973 - val_loss: 0.4758\n","Epoch 28/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7649 - loss: 0.4878 - val_accuracy: 0.7297 - val_loss: 0.5230\n","Epoch 29/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7348 - loss: 0.5049 - val_accuracy: 0.7928 - val_loss: 0.4670\n","Epoch 30/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7564 - loss: 0.5064 - val_accuracy: 0.7342 - val_loss: 0.5172\n","Epoch 31/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7561 - loss: 0.5022 - val_accuracy: 0.7477 - val_loss: 0.5194\n","Epoch 32/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7449 - loss: 0.5035 - val_accuracy: 0.7568 - val_loss: 0.4773\n","Epoch 33/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.4745 - val_accuracy: 0.7703 - val_loss: 0.4766\n","Epoch 34/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7668 - loss: 0.4809 - val_accuracy: 0.7252 - val_loss: 0.5421\n","Epoch 35/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7515 - loss: 0.4980 - val_accuracy: 0.7568 - val_loss: 0.4926\n","Epoch 36/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7547 - loss: 0.4907 - val_accuracy: 0.7928 - val_loss: 0.4745\n","Epoch 37/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.4916 - val_accuracy: 0.7973 - val_loss: 0.4823\n","Epoch 38/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7488 - loss: 0.5037 - val_accuracy: 0.7793 - val_loss: 0.4957\n","Epoch 39/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.4673 - val_accuracy: 0.7703 - val_loss: 0.4621\n","Epoch 40/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7797 - loss: 0.4704 - val_accuracy: 0.7703 - val_loss: 0.4745\n","Epoch 41/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.4572 - val_accuracy: 0.7748 - val_loss: 0.4553\n","Epoch 42/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.4465 - val_accuracy: 0.7523 - val_loss: 0.5110\n","Epoch 43/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7697 - loss: 0.4651 - val_accuracy: 0.7928 - val_loss: 0.4765\n","Epoch 44/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.4589 - val_accuracy: 0.7838 - val_loss: 0.4563\n","Epoch 45/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7924 - loss: 0.4584 - val_accuracy: 0.7748 - val_loss: 0.4648\n","Epoch 46/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7754 - loss: 0.4592 - val_accuracy: 0.7658 - val_loss: 0.4581\n","Epoch 47/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7851 - loss: 0.4462 - val_accuracy: 0.7748 - val_loss: 0.4866\n","Epoch 48/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7799 - loss: 0.4633 - val_accuracy: 0.7883 - val_loss: 0.4426\n","Epoch 49/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7929 - loss: 0.4423 - val_accuracy: 0.7793 - val_loss: 0.4512\n","Epoch 50/50\n","\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7902 - loss: 0.4423 - val_accuracy: 0.7387 - val_loss: 0.5183\n","56/56 - 0s - 2ms/step - accuracy: 0.7280 - loss: 0.5212\n","\n","Train accuracy: 0.7280405163764954\n","7/7 - 0s - 5ms/step - accuracy: 0.7387 - loss: 0.5183\n","\n","Test accuracy: 0.7387387156486511\n"]}],"source":["import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","\n","X_train = X_train.astype('float32')\n","y_train = y_train.astype('float32')\n","X_test = X_test.astype('float32')\n","y_test = y_test.astype('float32')\n","# Define the model architecture\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n","    tf.keras.layers.Dense(256, activation='relu'),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')  # adjust this according to your problem\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # adjust this according to your problem\n","\n","# Define the checkpoint callback\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_model.keras\", save_best_only=True)\n","\n","# Train the model\n","history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[checkpoint_cb])\n","\n","# Evaluate the model on the train set\n","train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n","print('\\nTrain accuracy:', train_acc)\n","\n","# Evaluate the model on the test set\n","test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n","print('\\nTest accuracy:', test_acc)\n"]},{"cell_type":"code","execution_count":48,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-02T05:45:51.302701Z","iopub.status.busy":"2024-04-02T05:45:51.302348Z","iopub.status.idle":"2024-04-02T06:01:16.901077Z","shell.execute_reply":"2024-04-02T06:01:16.900059Z","shell.execute_reply.started":"2024-04-02T05:45:51.302672Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-04-02 05:45:51,315] A new study created in memory with name: no-name-a5460355-7484-4b9d-977a-b5569e1b486e\n","[I 2024-04-02 05:45:51,472] Trial 0 finished with value: 0.7851496251496252 and parameters: {'iterations': 59, 'depth': 7, 'learning_rate': 0.030741693620160732, 'random_strength': 25, 'bagging_temperature': 0.03283609827831237, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 0 with value: 0.7851496251496252.\n","[I 2024-04-02 05:45:52,245] Trial 1 finished with value: 0.8325398336824732 and parameters: {'iterations': 256, 'depth': 9, 'learning_rate': 0.2560118518698934, 'random_strength': 23, 'bagging_temperature': 0.35904735651483966, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 1 with value: 0.8325398336824732.\n","[I 2024-04-02 05:45:52,661] Trial 2 finished with value: 0.8044843469837604 and parameters: {'iterations': 280, 'depth': 4, 'learning_rate': 0.016252691919071225, 'random_strength': 79, 'bagging_temperature': 0.026918109075970673, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 1 with value: 0.8325398336824732.\n","[I 2024-04-02 05:45:52,801] Trial 3 finished with value: 0.7887697006185347 and parameters: {'iterations': 61, 'depth': 7, 'learning_rate': 0.013037433299730134, 'random_strength': 63, 'bagging_temperature': 0.05225098197717591, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 1 with value: 0.8325398336824732.\n","[I 2024-04-02 05:45:53,188] Trial 4 finished with value: 0.8057795541931729 and parameters: {'iterations': 268, 'depth': 4, 'learning_rate': 0.11864055096772173, 'random_strength': 67, 'bagging_temperature': 16.816413450813805, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 1 with value: 0.8325398336824732.\n","[I 2024-04-02 05:45:53,561] Trial 5 finished with value: 0.8087888675268976 and parameters: {'iterations': 226, 'depth': 5, 'learning_rate': 0.01617454046924788, 'random_strength': 92, 'bagging_temperature': 17.17460584278489, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 1 with value: 0.8325398336824732.\n","[I 2024-04-02 05:45:53,689] Trial 6 finished with value: 0.8144360319184163 and parameters: {'iterations': 69, 'depth': 6, 'learning_rate': 0.266472970624049, 'random_strength': 80, 'bagging_temperature': 0.8277268395799583, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 1 with value: 0.8325398336824732.\n","[I 2024-04-02 05:45:54,702] Trial 7 finished with value: 0.8321685254027262 and parameters: {'iterations': 275, 'depth': 9, 'learning_rate': 0.013712154760398223, 'random_strength': 50, 'bagging_temperature': 0.906012074899335, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 1 with value: 0.8325398336824732.\n","[I 2024-04-02 05:45:55,132] Trial 8 finished with value: 0.8006420599704182 and parameters: {'iterations': 273, 'depth': 4, 'learning_rate': 0.015803524231401467, 'random_strength': 52, 'bagging_temperature': 0.13346632506341563, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 1 with value: 0.8325398336824732.\n","[I 2024-04-02 05:45:55,561] Trial 9 finished with value: 0.8187655090640165 and parameters: {'iterations': 190, 'depth': 8, 'learning_rate': 0.13110464304517952, 'random_strength': 35, 'bagging_temperature': 51.9501241553113, 'od_type': 'Iter', 'od_wait': 12}. Best is trial 1 with value: 0.8325398336824732.\n","[I 2024-04-02 05:45:56,674] Trial 10 finished with value: 0.8375511875511874 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.2652496626898427, 'random_strength': 0, 'bagging_temperature': 2.740514252122648, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 10 with value: 0.8375511875511874.\n","[I 2024-04-02 05:45:57,465] Trial 11 finished with value: 0.817406070733679 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.2868449428271194, 'random_strength': 7, 'bagging_temperature': 3.5029902277054816, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 10 with value: 0.8375511875511874.\n","[I 2024-04-02 05:45:58,331] Trial 12 finished with value: 0.8506436354465302 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.1290850681440973, 'random_strength': 1, 'bagging_temperature': 0.2746596912270978, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:45:59,462] Trial 13 finished with value: 0.8378378378378378 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.1245686637213831, 'random_strength': 0, 'bagging_temperature': 4.254242477843952, 'od_type': 'Iter', 'od_wait': 20}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:00,036] Trial 14 finished with value: 0.8234879328004447 and parameters: {'iterations': 116, 'depth': 9, 'learning_rate': 0.08096404573559735, 'random_strength': 12, 'bagging_temperature': 4.36415863704649, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:00,853] Trial 15 finished with value: 0.8183470827148989 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.050899552923852065, 'random_strength': 18, 'bagging_temperature': 0.11959902112562812, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:01,128] Trial 16 finished with value: 0.8321685254027262 and parameters: {'iterations': 94, 'depth': 8, 'learning_rate': 0.1367006051134921, 'random_strength': 36, 'bagging_temperature': 0.01051337385032075, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:01,600] Trial 17 finished with value: 0.8281925585296372 and parameters: {'iterations': 177, 'depth': 8, 'learning_rate': 0.06429919119528145, 'random_strength': 3, 'bagging_temperature': 0.3634954352175309, 'od_type': 'Iter', 'od_wait': 10}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:02,544] Trial 18 finished with value: 0.8368889581576149 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.17591469622417039, 'random_strength': 34, 'bagging_temperature': 9.963027141946073, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:02,911] Trial 19 finished with value: 0.8044843469837604 and parameters: {'iterations': 92, 'depth': 9, 'learning_rate': 0.040873322892743064, 'random_strength': 14, 'bagging_temperature': 1.6579668831482972, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:03,270] Trial 20 finished with value: 0.8154661162009946 and parameters: {'iterations': 212, 'depth': 6, 'learning_rate': 0.09074916726210128, 'random_strength': 0, 'bagging_temperature': 0.35577247737841644, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:04,240] Trial 21 finished with value: 0.8285262535262534 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.19000370882273776, 'random_strength': 0, 'bagging_temperature': 2.4578935479032524, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:05,139] Trial 22 finished with value: 0.8238465724077614 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.19472441528551349, 'random_strength': 11, 'bagging_temperature': 7.800741718010296, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:05,549] Trial 23 finished with value: 0.8087888675268976 and parameters: {'iterations': 105, 'depth': 9, 'learning_rate': 0.0973620027768355, 'random_strength': 25, 'bagging_temperature': 73.76433975013639, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:06,467] Trial 24 finished with value: 0.8321685254027262 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.16576849591562845, 'random_strength': 11, 'bagging_temperature': 0.9575896230744229, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:07,046] Trial 25 finished with value: 0.8422065533382046 and parameters: {'iterations': 128, 'depth': 9, 'learning_rate': 0.07009839771675423, 'random_strength': 0, 'bagging_temperature': 28.79027199809312, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:07,516] Trial 26 finished with value: 0.8135780982868414 and parameters: {'iterations': 196, 'depth': 8, 'learning_rate': 0.031559971099938924, 'random_strength': 21, 'bagging_temperature': 33.362513663511564, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:07,852] Trial 27 finished with value: 0.8140245822030209 and parameters: {'iterations': 83, 'depth': 9, 'learning_rate': 0.06584900644099173, 'random_strength': 44, 'bagging_temperature': 24.73480981154147, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:08,128] Trial 28 finished with value: 0.8230965538028735 and parameters: {'iterations': 107, 'depth': 7, 'learning_rate': 0.07554538766310674, 'random_strength': 8, 'bagging_temperature': 98.03362916669332, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:08,580] Trial 29 finished with value: 0.8097037845172175 and parameters: {'iterations': 120, 'depth': 9, 'learning_rate': 0.04600890826893543, 'random_strength': 31, 'bagging_temperature': 8.367959478255838, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:09,031] Trial 30 finished with value: 0.8148130633004671 and parameters: {'iterations': 157, 'depth': 8, 'learning_rate': 0.10985978263975234, 'random_strength': 18, 'bagging_temperature': 0.1479463104190129, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:09,920] Trial 31 finished with value: 0.8462775523686227 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.2242363372536283, 'random_strength': 5, 'bagging_temperature': 1.857317722119785, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:10,744] Trial 32 finished with value: 0.8462775523686227 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.21007440991192614, 'random_strength': 6, 'bagging_temperature': 0.45269575939399004, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:11,094] Trial 33 finished with value: 0.8226718495899223 and parameters: {'iterations': 78, 'depth': 9, 'learning_rate': 0.21356191853118603, 'random_strength': 6, 'bagging_temperature': 0.46562322497110564, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:11,716] Trial 34 finished with value: 0.8234879328004447 and parameters: {'iterations': 107, 'depth': 10, 'learning_rate': 0.15115210018755762, 'random_strength': 16, 'bagging_temperature': 0.21470282184390635, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:12,415] Trial 35 finished with value: 0.8265357671969952 and parameters: {'iterations': 177, 'depth': 9, 'learning_rate': 0.22225858201184845, 'random_strength': 25, 'bagging_temperature': 0.04734222182989582, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 12 with value: 0.8506436354465302.\n","[I 2024-04-02 05:46:13,767] Trial 36 finished with value: 0.8553200492881156 and parameters: {'iterations': 243, 'depth': 10, 'learning_rate': 0.021434977109677206, 'random_strength': 6, 'bagging_temperature': 0.08456525745941089, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 36 with value: 0.8553200492881156.\n","[I 2024-04-02 05:46:15,037] Trial 37 finished with value: 0.8097037845172175 and parameters: {'iterations': 241, 'depth': 10, 'learning_rate': 0.025153853861948426, 'random_strength': 29, 'bagging_temperature': 0.061135683592202214, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 36 with value: 0.8553200492881156.\n","[I 2024-04-02 05:46:15,593] Trial 38 finished with value: 0.7905782834818402 and parameters: {'iterations': 235, 'depth': 6, 'learning_rate': 0.010847457532560145, 'random_strength': 7, 'bagging_temperature': 0.5742755776536792, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 36 with value: 0.8553200492881156.\n","[I 2024-04-02 05:46:16,722] Trial 39 finished with value: 0.8183470827148989 and parameters: {'iterations': 200, 'depth': 10, 'learning_rate': 0.025166721724212006, 'random_strength': 78, 'bagging_temperature': 0.017225500934270666, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 36 with value: 0.8553200492881156.\n","[I 2024-04-02 05:46:17,253] Trial 40 finished with value: 0.8187655090640165 and parameters: {'iterations': 259, 'depth': 5, 'learning_rate': 0.020406813642007204, 'random_strength': 57, 'bagging_temperature': 1.5741172525733462, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 36 with value: 0.8553200492881156.\n","[I 2024-04-02 05:46:17,855] Trial 41 finished with value: 0.8596955363285586 and parameters: {'iterations': 139, 'depth': 9, 'learning_rate': 0.22209239535939537, 'random_strength': 6, 'bagging_temperature': 0.07843175905960639, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:18,722] Trial 42 finished with value: 0.8285262535262534 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.23547264643043792, 'random_strength': 99, 'bagging_temperature': 0.08155119826160678, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:19,949] Trial 43 finished with value: 0.8506436354465302 and parameters: {'iterations': 285, 'depth': 10, 'learning_rate': 0.14785965229341896, 'random_strength': 21, 'bagging_temperature': 0.032608716432009396, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:20,340] Trial 44 finished with value: 0.817406070733679 and parameters: {'iterations': 295, 'depth': 7, 'learning_rate': 0.296177043273145, 'random_strength': 19, 'bagging_temperature': 0.0279550422716873, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:21,187] Trial 45 finished with value: 0.845595020307664 and parameters: {'iterations': 281, 'depth': 9, 'learning_rate': 0.1500337796373993, 'random_strength': 44, 'bagging_temperature': 0.03942646780890439, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:22,315] Trial 46 finished with value: 0.8234879328004447 and parameters: {'iterations': 297, 'depth': 10, 'learning_rate': 0.10608561335254929, 'random_strength': 12, 'bagging_temperature': 0.2237645091014658, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:22,955] Trial 47 finished with value: 0.827429728579154 and parameters: {'iterations': 253, 'depth': 9, 'learning_rate': 0.24865140491514148, 'random_strength': 4, 'bagging_temperature': 0.07508135059692032, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:23,274] Trial 48 finished with value: 0.8044843469837604 and parameters: {'iterations': 50, 'depth': 10, 'learning_rate': 0.13988403100000932, 'random_strength': 10, 'bagging_temperature': 0.019044960408541943, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:24,399] Trial 49 finished with value: 0.8368889581576149 and parameters: {'iterations': 215, 'depth': 10, 'learning_rate': 0.17114267181143208, 'random_strength': 23, 'bagging_temperature': 0.10373249014259173, 'od_type': 'Iter', 'od_wait': 46}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:25,204] Trial 50 finished with value: 0.8230965538028735 and parameters: {'iterations': 283, 'depth': 8, 'learning_rate': 0.08934185693266598, 'random_strength': 72, 'bagging_temperature': 0.1988706298565798, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:26,398] Trial 51 finished with value: 0.833469421937483 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.2095138200443023, 'random_strength': 4, 'bagging_temperature': 0.34338819737855175, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:27,120] Trial 52 finished with value: 0.827429728579154 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.2504388456229574, 'random_strength': 15, 'bagging_temperature': 1.3887509937812619, 'od_type': 'Iter', 'od_wait': 20}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:28,064] Trial 53 finished with value: 0.84191359062235 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.12512435381036394, 'random_strength': 4, 'bagging_temperature': 0.7349801872550206, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:28,624] Trial 54 finished with value: 0.8222131906342433 and parameters: {'iterations': 133, 'depth': 9, 'learning_rate': 0.19233108815032074, 'random_strength': 8, 'bagging_temperature': 0.03460688468143086, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:29,752] Trial 55 finished with value: 0.8328800815150558 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.15606817108694104, 'random_strength': 14, 'bagging_temperature': 0.2836827351086252, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:30,564] Trial 56 finished with value: 0.8183470827148989 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.2651877709255593, 'random_strength': 4, 'bagging_temperature': 0.14338742334404525, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:31,012] Trial 57 finished with value: 0.8230965538028735 and parameters: {'iterations': 91, 'depth': 9, 'learning_rate': 0.18048321077287366, 'random_strength': 9, 'bagging_temperature': 0.09452799936991478, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:32,288] Trial 58 finished with value: 0.8191500616101444 and parameters: {'iterations': 264, 'depth': 10, 'learning_rate': 0.11892787631442751, 'random_strength': 29, 'bagging_temperature': 0.01944337703103368, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:32,864] Trial 59 finished with value: 0.8140245822030209 and parameters: {'iterations': 159, 'depth': 9, 'learning_rate': 0.05720802896703759, 'random_strength': 20, 'bagging_temperature': 0.012135083780570302, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:33,831] Trial 60 finished with value: 0.8459506827044141 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.21078249315537792, 'random_strength': 2, 'bagging_temperature': 0.05459593456540448, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:34,768] Trial 61 finished with value: 0.836512374443409 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.2989012298925506, 'random_strength': 2, 'bagging_temperature': 0.05694886634762555, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:35,712] Trial 62 finished with value: 0.8183470827148989 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.20430701521876865, 'random_strength': 13, 'bagging_temperature': 0.025333147169542214, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:36,596] Trial 63 finished with value: 0.8509470997296442 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.2256519356620376, 'random_strength': 0, 'bagging_temperature': 0.5760570797015752, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:38,012] Trial 64 finished with value: 0.840859352196084 and parameters: {'iterations': 245, 'depth': 10, 'learning_rate': 0.03532630465000007, 'random_strength': 9, 'bagging_temperature': 0.5608033382146399, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:38,457] Trial 65 finished with value: 0.8459506827044141 and parameters: {'iterations': 100, 'depth': 9, 'learning_rate': 0.2328434595825208, 'random_strength': 6, 'bagging_temperature': 0.7321770357255324, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:39,225] Trial 66 finished with value: 0.8187655090640165 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.18133307737180893, 'random_strength': 16, 'bagging_temperature': 1.2263008569966074, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:39,843] Trial 67 finished with value: 0.8331897849575306 and parameters: {'iterations': 131, 'depth': 9, 'learning_rate': 0.13505062023204176, 'random_strength': 0, 'bagging_temperature': 2.1516006955836247, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:40,573] Trial 68 finished with value: 0.8351938895417155 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.16074216735001862, 'random_strength': 6, 'bagging_temperature': 0.45710379603039225, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:41,202] Trial 69 finished with value: 0.7948613738087422 and parameters: {'iterations': 170, 'depth': 9, 'learning_rate': 0.01369514979176785, 'random_strength': 11, 'bagging_temperature': 5.388189044364213, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:41,889] Trial 70 finished with value: 0.8281925585296372 and parameters: {'iterations': 99, 'depth': 10, 'learning_rate': 0.25757449919485664, 'random_strength': 39, 'bagging_temperature': 0.16484745719767893, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:42,929] Trial 71 finished with value: 0.8596955363285586 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.21771276069162473, 'random_strength': 2, 'bagging_temperature': 0.045073849602883964, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:43,778] Trial 72 finished with value: 0.8503124686024315 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.2330128065702064, 'random_strength': 2, 'bagging_temperature': 0.26102284350504046, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:43,991] Trial 73 finished with value: 0.8234879328004447 and parameters: {'iterations': 122, 'depth': 5, 'learning_rate': 0.27610598978062023, 'random_strength': 2, 'bagging_temperature': 0.31704751532588427, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:44,746] Trial 74 finished with value: 0.8499531034991649 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.23179155760099496, 'random_strength': 2, 'bagging_temperature': 0.10885306079397601, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:45,320] Trial 75 finished with value: 0.8238465724077614 and parameters: {'iterations': 85, 'depth': 10, 'learning_rate': 0.23953791953607567, 'random_strength': 9, 'bagging_temperature': 0.12290169424307498, 'od_type': 'Iter', 'od_wait': 11}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:46,162] Trial 76 finished with value: 0.8201060592364939 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.01892068995788342, 'random_strength': 0, 'bagging_temperature': 0.07143949806434323, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:47,116] Trial 77 finished with value: 0.8317656008930031 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.19250106309889975, 'random_strength': 2, 'bagging_temperature': 0.044699421180212286, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:47,741] Trial 78 finished with value: 0.8183470827148989 and parameters: {'iterations': 154, 'depth': 9, 'learning_rate': 0.27095358792449104, 'random_strength': 16, 'bagging_temperature': 0.24079176022073548, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:48,920] Trial 79 finished with value: 0.8462775523686227 and parameters: {'iterations': 228, 'depth': 10, 'learning_rate': 0.17162911484683313, 'random_strength': 7, 'bagging_temperature': 0.16624345966088316, 'od_type': 'Iter', 'od_wait': 13}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:49,480] Trial 80 finished with value: 0.833469421937483 and parameters: {'iterations': 290, 'depth': 8, 'learning_rate': 0.14550529088524186, 'random_strength': 13, 'bagging_temperature': 0.09034156228965785, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:50,345] Trial 81 finished with value: 0.8321685254027262 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.22890086529195347, 'random_strength': 4, 'bagging_temperature': 0.10930863408332624, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:51,376] Trial 82 finished with value: 0.8556010556010556 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.2238091277964269, 'random_strength': 0, 'bagging_temperature': 0.032541645151543404, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:52,400] Trial 83 finished with value: 0.8321685254027262 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.19567102668900668, 'random_strength': 0, 'bagging_temperature': 0.024801938553733402, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:54,157] Trial 84 finished with value: 0.8462775523686227 and parameters: {'iterations': 271, 'depth': 10, 'learning_rate': 0.010644848192133101, 'random_strength': 2, 'bagging_temperature': 0.03119471546028028, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:54,349] Trial 85 finished with value: 0.8010650677711588 and parameters: {'iterations': 111, 'depth': 4, 'learning_rate': 0.21769005033955888, 'random_strength': 11, 'bagging_temperature': 0.042557036679829865, 'od_type': 'Iter', 'od_wait': 12}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:55,422] Trial 86 finished with value: 0.8331897849575306 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.16781982673844592, 'random_strength': 7, 'bagging_temperature': 0.06470465526585405, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:55,984] Trial 87 finished with value: 0.8053841310363877 and parameters: {'iterations': 139, 'depth': 9, 'learning_rate': 0.24661371688936506, 'random_strength': 58, 'bagging_temperature': 0.014453623783683261, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:56,779] Trial 88 finished with value: 0.8187655090640165 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.27527373300316454, 'random_strength': 22, 'bagging_temperature': 0.03756072311574163, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:57,606] Trial 89 finished with value: 0.83723505544913 and parameters: {'iterations': 210, 'depth': 9, 'learning_rate': 0.10855414297335443, 'random_strength': 5, 'bagging_temperature': 0.26951390083724264, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:58,115] Trial 90 finished with value: 0.8415917345645018 and parameters: {'iterations': 73, 'depth': 10, 'learning_rate': 0.18328583801450093, 'random_strength': 3, 'bagging_temperature': 0.1912381915813343, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:58,949] Trial 91 finished with value: 0.827429728579154 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.22746111609555109, 'random_strength': 8, 'bagging_temperature': 0.08362181118053279, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:46:59,727] Trial 92 finished with value: 0.8452100356170124 and parameters: {'iterations': 101, 'depth': 10, 'learning_rate': 0.20144259561775923, 'random_strength': 5, 'bagging_temperature': 0.9712368097833504, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:00,634] Trial 93 finished with value: 0.8064644633327506 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.011850931993220138, 'random_strength': 0, 'bagging_temperature': 0.053379734754144315, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:01,494] Trial 94 finished with value: 0.8415917345645018 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.2572875838008406, 'random_strength': 3, 'bagging_temperature': 1.9707140012266826, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:02,475] Trial 95 finished with value: 0.8462775523686227 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.1612621494543935, 'random_strength': 9, 'bagging_temperature': 3.06423126051141, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:03,076] Trial 96 finished with value: 0.8135780982868414 and parameters: {'iterations': 146, 'depth': 9, 'learning_rate': 0.043314678596833654, 'random_strength': 11, 'bagging_temperature': 0.12649550622599046, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:03,880] Trial 97 finished with value: 0.8183470827148989 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.07834044492717752, 'random_strength': 17, 'bagging_temperature': 0.02141754324410448, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:05,051] Trial 98 finished with value: 0.8503124686024315 and parameters: {'iterations': 183, 'depth': 10, 'learning_rate': 0.221054257330871, 'random_strength': 6, 'bagging_temperature': 0.5821437274541966, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:06,027] Trial 99 finished with value: 0.8415917345645018 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.28590883568362124, 'random_strength': 13, 'bagging_temperature': 0.570982539878885, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:07,227] Trial 100 finished with value: 0.8230965538028735 and parameters: {'iterations': 191, 'depth': 10, 'learning_rate': 0.21633498912675378, 'random_strength': 6, 'bagging_temperature': 0.4132958518612738, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:08,436] Trial 101 finished with value: 0.8596955363285586 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.24529988217024842, 'random_strength': 1, 'bagging_temperature': 1.1708815427471513, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:09,450] Trial 102 finished with value: 0.8509470997296442 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.24772072352075217, 'random_strength': 2, 'bagging_temperature': 1.2049675444820194, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:10,533] Trial 103 finished with value: 0.8422065533382046 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.24466912756233186, 'random_strength': 1, 'bagging_temperature': 1.3051871941267228, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:11,486] Trial 104 finished with value: 0.8465761215761216 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.2996300303383585, 'random_strength': 4, 'bagging_temperature': 0.6725209138491441, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:12,527] Trial 105 finished with value: 0.8265357671969952 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.18262452673050691, 'random_strength': 8, 'bagging_temperature': 0.9204724692860917, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:13,500] Trial 106 finished with value: 0.8238465724077614 and parameters: {'iterations': 248, 'depth': 10, 'learning_rate': 0.2036688476129796, 'random_strength': 0, 'bagging_temperature': 1.1298537077686925, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:13,859] Trial 107 finished with value: 0.8101075646906518 and parameters: {'iterations': 171, 'depth': 7, 'learning_rate': 0.09527950623919976, 'random_strength': 5, 'bagging_temperature': 0.8613045620873355, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:14,408] Trial 108 finished with value: 0.8135780982868414 and parameters: {'iterations': 144, 'depth': 9, 'learning_rate': 0.015333770614936688, 'random_strength': 3, 'bagging_temperature': 0.03067717922696129, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:14,719] Trial 109 finished with value: 0.8234879328004447 and parameters: {'iterations': 187, 'depth': 6, 'learning_rate': 0.2614354014813402, 'random_strength': 11, 'bagging_temperature': 0.39885706603443366, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:15,563] Trial 110 finished with value: 0.827429728579154 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.023715828665390244, 'random_strength': 9, 'bagging_temperature': 1.6439794891772659, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 41 with value: 0.8596955363285586.\n","[I 2024-04-02 05:47:16,525] Trial 111 finished with value: 0.8599806088369385 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.23410397787899606, 'random_strength': 2, 'bagging_temperature': 0.5207584441067472, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:17,432] Trial 112 finished with value: 0.8269994515719551 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.22040045952328802, 'random_strength': 7, 'bagging_temperature': 0.7532443358681078, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:18,564] Trial 113 finished with value: 0.8596955363285586 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.24099243931431474, 'random_strength': 2, 'bagging_temperature': 0.5235126389011197, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:19,662] Trial 114 finished with value: 0.8412404970025789 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.24325250947201058, 'random_strength': 0, 'bagging_temperature': 0.4806487460726076, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:20,674] Trial 115 finished with value: 0.8317656008930031 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.2788232656672246, 'random_strength': 2, 'bagging_temperature': 0.2851786830089226, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:21,351] Trial 116 finished with value: 0.8135780982868414 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.03646275179811166, 'random_strength': 4, 'bagging_temperature': 0.35563030587387506, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:22,381] Trial 117 finished with value: 0.83723505544913 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.1917137082993907, 'random_strength': 2, 'bagging_temperature': 0.6658350831878534, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:22,991] Trial 118 finished with value: 0.8337194337194337 and parameters: {'iterations': 140, 'depth': 9, 'learning_rate': 0.05751452218344436, 'random_strength': 0, 'bagging_temperature': 0.4895426685763683, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:23,887] Trial 119 finished with value: 0.836512374443409 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.26108220517531333, 'random_strength': 47, 'bagging_temperature': 1.1493004440463848, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:24,925] Trial 120 finished with value: 0.8415917345645018 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.20320008720161528, 'random_strength': 6, 'bagging_temperature': 0.03928348804038469, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:25,840] Trial 121 finished with value: 0.8459506827044141 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.23425035546200912, 'random_strength': 5, 'bagging_temperature': 0.5388343576498998, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:26,844] Trial 122 finished with value: 0.8325398336824732 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.21463958410286438, 'random_strength': 3, 'bagging_temperature': 0.588624043565139, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:27,675] Trial 123 finished with value: 0.8140245822030209 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.1746402610692545, 'random_strength': 7, 'bagging_temperature': 0.33418503132320354, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:28,791] Trial 124 finished with value: 0.8049526106031681 and parameters: {'iterations': 259, 'depth': 10, 'learning_rate': 0.24343623604840392, 'random_strength': 10, 'bagging_temperature': 0.8325556347137618, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:29,841] Trial 125 finished with value: 0.8230965538028735 and parameters: {'iterations': 231, 'depth': 10, 'learning_rate': 0.22538549560690413, 'random_strength': 91, 'bagging_temperature': 0.06843556316962524, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:30,767] Trial 126 finished with value: 0.845595020307664 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.2805423066792038, 'random_strength': 2, 'bagging_temperature': 1.4786755500504942, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:31,856] Trial 127 finished with value: 0.8144360319184163 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.188784581947081, 'random_strength': 14, 'bagging_temperature': 2.3265176308879725, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:32,773] Trial 128 finished with value: 0.8321685254027262 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.258460640328596, 'random_strength': 27, 'bagging_temperature': 0.22650736406310853, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:33,642] Trial 129 finished with value: 0.8368889581576149 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.14359551658748643, 'random_strength': 38, 'bagging_temperature': 1.055003349362334, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:34,300] Trial 130 finished with value: 0.8238465724077614 and parameters: {'iterations': 216, 'depth': 9, 'learning_rate': 0.20922624857600913, 'random_strength': 5, 'bagging_temperature': 0.04705882497807572, 'od_type': 'Iter', 'od_wait': 50}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:35,227] Trial 131 finished with value: 0.8599806088369385 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.22890527847241257, 'random_strength': 2, 'bagging_temperature': 0.09766987915844418, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:36,155] Trial 132 finished with value: 0.8465761215761216 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.23874347625263573, 'random_strength': 0, 'bagging_temperature': 0.1847772201637282, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:37,048] Trial 133 finished with value: 0.8325398336824732 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.22539440507219835, 'random_strength': 3, 'bagging_temperature': 0.024135258730911702, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:37,955] Trial 134 finished with value: 0.8368889581576149 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.2051150948342642, 'random_strength': 7, 'bagging_temperature': 0.1510528643035494, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:38,828] Trial 135 finished with value: 0.84191359062235 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.125837995897415, 'random_strength': 4, 'bagging_temperature': 0.09343566062873349, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:40,084] Trial 136 finished with value: 0.8503124686024315 and parameters: {'iterations': 288, 'depth': 10, 'learning_rate': 0.08410543802210332, 'random_strength': 1, 'bagging_temperature': 0.05859551155034354, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:40,937] Trial 137 finished with value: 0.8368889581576149 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.2662819817943984, 'random_strength': 9, 'bagging_temperature': 0.01578022649195927, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:41,401] Trial 138 finished with value: 0.8135780982868414 and parameters: {'iterations': 239, 'depth': 8, 'learning_rate': 0.1966629665266127, 'random_strength': 6, 'bagging_temperature': 0.03423678616918458, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:42,507] Trial 139 finished with value: 0.8278272336108157 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.2478207201498601, 'random_strength': 65, 'bagging_temperature': 0.07970852632824207, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:43,426] Trial 140 finished with value: 0.8368889581576149 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.0496364822465773, 'random_strength': 2, 'bagging_temperature': 0.4025727831348433, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:44,598] Trial 141 finished with value: 0.8148130633004671 and parameters: {'iterations': 287, 'depth': 10, 'learning_rate': 0.08356787122793981, 'random_strength': 0, 'bagging_temperature': 0.06133953440407798, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:45,827] Trial 142 finished with value: 0.836512374443409 and parameters: {'iterations': 206, 'depth': 10, 'learning_rate': 0.06953266861205788, 'random_strength': 2, 'bagging_temperature': 0.04528744721414043, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:47,132] Trial 143 finished with value: 0.836512374443409 and parameters: {'iterations': 300, 'depth': 10, 'learning_rate': 0.10277679431994723, 'random_strength': 4, 'bagging_temperature': 0.07102958558398387, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:48,272] Trial 144 finished with value: 0.8288288288288288 and parameters: {'iterations': 292, 'depth': 10, 'learning_rate': 0.15356171989844042, 'random_strength': 0, 'bagging_temperature': 0.05481423350303389, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:49,280] Trial 145 finished with value: 0.8191500616101444 and parameters: {'iterations': 266, 'depth': 10, 'learning_rate': 0.2193567024647058, 'random_strength': 8, 'bagging_temperature': 0.6556207124177398, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:50,193] Trial 146 finished with value: 0.8361047435944837 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.11465824289938127, 'random_strength': 5, 'bagging_temperature': 0.09953082570626345, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:51,319] Trial 147 finished with value: 0.8226718495899223 and parameters: {'iterations': 275, 'depth': 10, 'learning_rate': 0.17632745972797859, 'random_strength': 3, 'bagging_temperature': 0.03508399075734806, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:52,204] Trial 148 finished with value: 0.8053841310363877 and parameters: {'iterations': 282, 'depth': 10, 'learning_rate': 0.23076097696108472, 'random_strength': 2, 'bagging_temperature': 0.2846908494777648, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:52,749] Trial 149 finished with value: 0.8057795541931729 and parameters: {'iterations': 277, 'depth': 6, 'learning_rate': 0.02868744771587927, 'random_strength': 12, 'bagging_temperature': 0.11729296426308289, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:53,728] Trial 150 finished with value: 0.8285262535262534 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.28222552493035613, 'random_strength': 6, 'bagging_temperature': 0.029233800606663186, 'od_type': 'Iter', 'od_wait': 20}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:54,492] Trial 151 finished with value: 0.8328800815150558 and parameters: {'iterations': 106, 'depth': 10, 'learning_rate': 0.24881942324680287, 'random_strength': 1, 'bagging_temperature': 0.1270836694751999, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:55,393] Trial 152 finished with value: 0.842916430236183 and parameters: {'iterations': 223, 'depth': 10, 'learning_rate': 0.23016003655575692, 'random_strength': 0, 'bagging_temperature': 0.054419476854335055, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:56,054] Trial 153 finished with value: 0.836512374443409 and parameters: {'iterations': 113, 'depth': 10, 'learning_rate': 0.062150183337651314, 'random_strength': 4, 'bagging_temperature': 0.07923891258233642, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:57,062] Trial 154 finished with value: 0.8183470827148989 and parameters: {'iterations': 286, 'depth': 10, 'learning_rate': 0.2124282003881285, 'random_strength': 2, 'bagging_temperature': 0.47529985034925576, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:57,686] Trial 155 finished with value: 0.83723505544913 and parameters: {'iterations': 94, 'depth': 10, 'learning_rate': 0.26302182408276437, 'random_strength': 8, 'bagging_temperature': 0.10283308905785937, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:58,417] Trial 156 finished with value: 0.83723505544913 and parameters: {'iterations': 109, 'depth': 10, 'learning_rate': 0.19532851115463637, 'random_strength': 5, 'bagging_temperature': 0.06578186421656494, 'od_type': 'Iter', 'od_wait': 13}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:47:59,231] Trial 157 finished with value: 0.8368889581576149 and parameters: {'iterations': 102, 'depth': 10, 'learning_rate': 0.2978871208196907, 'random_strength': 2, 'bagging_temperature': 0.7814558710745446, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:00,126] Trial 158 finished with value: 0.8140245822030209 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.0861977134239876, 'random_strength': 10, 'bagging_temperature': 0.2516343619749262, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:00,695] Trial 159 finished with value: 0.8375511875511874 and parameters: {'iterations': 121, 'depth': 9, 'learning_rate': 0.16652745074465058, 'random_strength': 0, 'bagging_temperature': 0.1432579738955735, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:01,726] Trial 160 finished with value: 0.827429728579154 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.23281599368632547, 'random_strength': 7, 'bagging_temperature': 1.249585483728817, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:02,721] Trial 161 finished with value: 0.8183470827148989 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.29674888337384286, 'random_strength': 4, 'bagging_temperature': 0.8966652003810318, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:03,774] Trial 162 finished with value: 0.8265357671969952 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.2712101589916292, 'random_strength': 4, 'bagging_temperature': 0.6538180959122204, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:04,794] Trial 163 finished with value: 0.83723505544913 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.24791792418454497, 'random_strength': 2, 'bagging_temperature': 0.5719932522380881, 'od_type': 'Iter', 'od_wait': 48}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:05,896] Trial 164 finished with value: 0.8361047435944837 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.21681141622681188, 'random_strength': 6, 'bagging_temperature': 0.7063509187257396, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:07,002] Trial 165 finished with value: 0.8465761215761216 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.25589739119808846, 'random_strength': 0, 'bagging_temperature': 0.3759508301338932, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:07,913] Trial 166 finished with value: 0.84191359062235 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.18576142554035305, 'random_strength': 33, 'bagging_temperature': 0.18608600048557591, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:08,779] Trial 167 finished with value: 0.83723505544913 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.2379037501402368, 'random_strength': 4, 'bagging_temperature': 1.0060386102004075, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:09,838] Trial 168 finished with value: 0.8556010556010556 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.20449975904875, 'random_strength': 2, 'bagging_temperature': 0.03978415844137299, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:10,647] Trial 169 finished with value: 0.8553200492881156 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.20274468111904234, 'random_strength': 2, 'bagging_temperature': 0.03902436168235747, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:11,635] Trial 170 finished with value: 0.8281925585296372 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.20246909718124428, 'random_strength': 7, 'bagging_temperature': 0.04536846889159539, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 111 with value: 0.8599806088369385.\n","[I 2024-04-02 05:48:12,526] Trial 171 finished with value: 0.8690141179442328 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.22006048511328638, 'random_strength': 2, 'bagging_temperature': 0.020531740826571318, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:13,330] Trial 172 finished with value: 0.8321685254027262 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.21231975028559266, 'random_strength': 2, 'bagging_temperature': 0.025400371800683528, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:14,164] Trial 173 finished with value: 0.836512374443409 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.13395057894235557, 'random_strength': 2, 'bagging_temperature': 0.01948158717070031, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:15,206] Trial 174 finished with value: 0.8512233217188787 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.18671071208606602, 'random_strength': 0, 'bagging_temperature': 0.030207377223380818, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:16,260] Trial 175 finished with value: 0.8415917345645018 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.184450235274924, 'random_strength': 0, 'bagging_temperature': 0.022180880901728556, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:17,183] Trial 176 finished with value: 0.8226718495899223 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.1979163354744067, 'random_strength': 5, 'bagging_temperature': 0.032872798971930635, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:18,219] Trial 177 finished with value: 0.8269994515719551 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.22015720162849808, 'random_strength': 3, 'bagging_temperature': 0.013884909436958968, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:19,006] Trial 178 finished with value: 0.8230965538028735 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.1759032269691319, 'random_strength': 9, 'bagging_temperature': 0.03122625034946357, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:20,064] Trial 179 finished with value: 0.8602400900995527 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.20701731518890715, 'random_strength': 0, 'bagging_temperature': 0.04037682866539347, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:21,092] Trial 180 finished with value: 0.8415917345645018 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.2070632079171587, 'random_strength': 0, 'bagging_temperature': 0.027945478778251168, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:22,111] Trial 181 finished with value: 0.8325398336824732 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.22543429801976736, 'random_strength': 3, 'bagging_temperature': 0.04149563075011449, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:23,064] Trial 182 finished with value: 0.8503124686024315 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.19713463853775964, 'random_strength': 5, 'bagging_temperature': 0.01837860312181938, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:24,033] Trial 183 finished with value: 0.8506436354465302 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.23755234929189578, 'random_strength': 0, 'bagging_temperature': 0.03968858535709028, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:25,102] Trial 184 finished with value: 0.8281925585296372 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.24382997684078297, 'random_strength': 0, 'bagging_temperature': 0.036225545147920174, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:25,920] Trial 185 finished with value: 0.8503124686024315 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.2330140198907436, 'random_strength': 2, 'bagging_temperature': 0.04612191546482211, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:26,796] Trial 186 finished with value: 0.8006420599704182 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.189945175619684, 'random_strength': 70, 'bagging_temperature': 0.02353842838894668, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:27,813] Trial 187 finished with value: 0.8553200492881156 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.16307521984586495, 'random_strength': 0, 'bagging_temperature': 0.038274773807992345, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:28,816] Trial 188 finished with value: 0.8375511875511874 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.15379177153026136, 'random_strength': 0, 'bagging_temperature': 0.03761410081584544, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:29,054] Trial 189 finished with value: 0.8191500616101444 and parameters: {'iterations': 148, 'depth': 4, 'learning_rate': 0.16499051282815713, 'random_strength': 4, 'bagging_temperature': 0.029585979037701868, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:30,181] Trial 190 finished with value: 0.8462775523686227 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.17920332405608957, 'random_strength': 2, 'bagging_temperature': 0.04453300158088331, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:31,261] Trial 191 finished with value: 0.84191359062235 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.20895301779116396, 'random_strength': 0, 'bagging_temperature': 0.05198059392839177, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:32,119] Trial 192 finished with value: 0.8459506827044141 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.22063191855024658, 'random_strength': 3, 'bagging_temperature': 0.010657548242022946, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:32,882] Trial 193 finished with value: 0.8424710748057271 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.2562079527697846, 'random_strength': 53, 'bagging_temperature': 0.02775472568615966, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:33,831] Trial 194 finished with value: 0.8278272336108157 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.2383702358659286, 'random_strength': 3, 'bagging_temperature': 0.03805579173889007, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:34,873] Trial 195 finished with value: 0.84191359062235 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.20093092533334742, 'random_strength': 0, 'bagging_temperature': 0.021599221004209322, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:35,758] Trial 196 finished with value: 0.8356654636603111 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.16144013492782058, 'random_strength': 6, 'bagging_temperature': 0.050012274791836765, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:36,531] Trial 197 finished with value: 0.8596955363285586 and parameters: {'iterations': 113, 'depth': 10, 'learning_rate': 0.21586219330496675, 'random_strength': 2, 'bagging_temperature': 0.03587761141287063, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:37,339] Trial 198 finished with value: 0.8596955363285586 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.21624269856758344, 'random_strength': 2, 'bagging_temperature': 0.03427047864712542, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:38,162] Trial 199 finished with value: 0.8325398336824732 and parameters: {'iterations': 105, 'depth': 10, 'learning_rate': 0.192377014312903, 'random_strength': 4, 'bagging_temperature': 0.03307480430984956, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:39,061] Trial 200 finished with value: 0.8230965538028735 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.17195642848188378, 'random_strength': 2, 'bagging_temperature': 0.02475567832171258, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:39,994] Trial 201 finished with value: 0.8285262535262534 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.14265029047611252, 'random_strength': 0, 'bagging_temperature': 0.037637066659117875, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:40,844] Trial 202 finished with value: 0.840859352196084 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.21473430597691928, 'random_strength': 2, 'bagging_temperature': 0.040935660094560934, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:41,575] Trial 203 finished with value: 0.8462775523686227 and parameters: {'iterations': 109, 'depth': 10, 'learning_rate': 0.22412032148696362, 'random_strength': 5, 'bagging_temperature': 0.02903297305827688, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:42,285] Trial 204 finished with value: 0.8368889581576149 and parameters: {'iterations': 100, 'depth': 10, 'learning_rate': 0.20861101762950515, 'random_strength': 2, 'bagging_temperature': 0.053054630623957766, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:43,331] Trial 205 finished with value: 0.8459506827044141 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.25074667546608187, 'random_strength': 0, 'bagging_temperature': 0.06431454090647547, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:43,825] Trial 206 finished with value: 0.8092644368506438 and parameters: {'iterations': 157, 'depth': 8, 'learning_rate': 0.1889377717688212, 'random_strength': 4, 'bagging_temperature': 0.03264485950126798, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:44,600] Trial 207 finished with value: 0.8230965538028735 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.23922223788141173, 'random_strength': 6, 'bagging_temperature': 1.7462093909774385, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:45,586] Trial 208 finished with value: 0.8462775523686227 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.2697163735327917, 'random_strength': 2, 'bagging_temperature': 0.038900067557781894, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:46,664] Trial 209 finished with value: 0.8226718495899223 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.20562020226030175, 'random_strength': 7, 'bagging_temperature': 0.017735457490028774, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:47,518] Trial 210 finished with value: 0.8459506827044141 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.22218183322584165, 'random_strength': 4, 'bagging_temperature': 0.04300476016774351, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:48,453] Trial 211 finished with value: 0.8558558558558559 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.23610069328188876, 'random_strength': 0, 'bagging_temperature': 0.03276611085683426, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:49,377] Trial 212 finished with value: 0.8321685254027262 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.2319639662475717, 'random_strength': 0, 'bagging_temperature': 0.027963850369118515, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:50,156] Trial 213 finished with value: 0.8328800815150558 and parameters: {'iterations': 103, 'depth': 10, 'learning_rate': 0.2517534434649119, 'random_strength': 2, 'bagging_temperature': 0.02310061793667806, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:51,093] Trial 214 finished with value: 0.833469421937483 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.021361013819639906, 'random_strength': 0, 'bagging_temperature': 0.033400419857420274, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:52,076] Trial 215 finished with value: 0.8140245822030209 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.21782476819069305, 'random_strength': 4, 'bagging_temperature': 0.049163246017451534, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:52,887] Trial 216 finished with value: 0.827429728579154 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.20088107771396518, 'random_strength': 2, 'bagging_temperature': 12.734599396692442, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:53,646] Trial 217 finished with value: 0.8422065533382046 and parameters: {'iterations': 106, 'depth': 10, 'learning_rate': 0.23861999850033175, 'random_strength': 0, 'bagging_temperature': 0.05831643086869888, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:54,543] Trial 218 finished with value: 0.8226718495899223 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.2685257011363211, 'random_strength': 4, 'bagging_temperature': 0.026678047129831902, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:55,517] Trial 219 finished with value: 0.8550124072512131 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.21509638124101466, 'random_strength': 2, 'bagging_temperature': 0.03427091223074508, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:56,543] Trial 220 finished with value: 0.8140245822030209 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.18393219203637862, 'random_strength': 7, 'bagging_temperature': 0.03200841530088233, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:57,498] Trial 221 finished with value: 0.8361047435944837 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.2123524393491757, 'random_strength': 2, 'bagging_temperature': 0.04027749838069329, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:58,464] Trial 222 finished with value: 0.8593844402022841 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.22584599699724858, 'random_strength': 2, 'bagging_temperature': 0.036013084708852165, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:59,434] Trial 223 finished with value: 0.827429728579154 and parameters: {'iterations': 251, 'depth': 10, 'learning_rate': 0.2197716824417523, 'random_strength': 3, 'bagging_temperature': 0.026457236489811683, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:48:59,832] Trial 224 finished with value: 0.8140245822030209 and parameters: {'iterations': 144, 'depth': 7, 'learning_rate': 0.19927500942554704, 'random_strength': 5, 'bagging_temperature': 0.03516190120199921, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:00,996] Trial 225 finished with value: 0.8328800815150558 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.22650834244576568, 'random_strength': 2, 'bagging_temperature': 0.020317410431056733, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:01,951] Trial 226 finished with value: 0.8328800815150558 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.20978510439280876, 'random_strength': 4, 'bagging_temperature': 1.346609607422431, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:02,886] Trial 227 finished with value: 0.8281925585296372 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.24832689122313817, 'random_strength': 42, 'bagging_temperature': 0.0769759149427867, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:04,056] Trial 228 finished with value: 0.836512374443409 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.17278525323602106, 'random_strength': 2, 'bagging_temperature': 0.046003470380678806, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:04,943] Trial 229 finished with value: 0.8325398336824732 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.1909542978380437, 'random_strength': 0, 'bagging_temperature': 0.03081758273058703, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:05,938] Trial 230 finished with value: 0.8690141179442328 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.22980766152151566, 'random_strength': 6, 'bagging_temperature': 0.051024394054539145, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:06,975] Trial 231 finished with value: 0.8234879328004447 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.23653481236965868, 'random_strength': 6, 'bagging_temperature': 0.05754172468713411, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:08,046] Trial 232 finished with value: 0.8596955363285586 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.22471781675559946, 'random_strength': 2, 'bagging_temperature': 0.04879102831259461, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:09,049] Trial 233 finished with value: 0.8234879328004447 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.01700792916947172, 'random_strength': 2, 'bagging_temperature': 0.04553888371414368, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:10,187] Trial 234 finished with value: 0.8462775523686227 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.22562419590618524, 'random_strength': 4, 'bagging_temperature': 0.0614665432450624, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:11,324] Trial 235 finished with value: 0.8317656008930031 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.2125273200225865, 'random_strength': 2, 'bagging_temperature': 0.07228098985322831, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:12,341] Trial 236 finished with value: 0.8415917345645018 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.2576326943470654, 'random_strength': 0, 'bagging_temperature': 0.04754756204117529, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:13,189] Trial 237 finished with value: 0.8415917345645018 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.22779309326674588, 'random_strength': 5, 'bagging_temperature': 0.0370785630996229, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:14,290] Trial 238 finished with value: 0.817406070733679 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.1982832970906955, 'random_strength': 8, 'bagging_temperature': 0.05322499341112485, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:15,209] Trial 239 finished with value: 0.8506436354465302 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.24431397063236282, 'random_strength': 3, 'bagging_temperature': 0.038493704573487955, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:16,250] Trial 240 finished with value: 0.8465761215761216 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.21314349715607314, 'random_strength': 88, 'bagging_temperature': 0.08539725027828299, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:17,413] Trial 241 finished with value: 0.8230965538028735 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.2317252582726479, 'random_strength': 0, 'bagging_temperature': 0.030595966387386417, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:18,136] Trial 242 finished with value: 0.840859352196084 and parameters: {'iterations': 113, 'depth': 10, 'learning_rate': 0.20114884977759134, 'random_strength': 24, 'bagging_temperature': 0.034046489474349254, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:19,095] Trial 243 finished with value: 0.8462775523686227 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.21958625451859096, 'random_strength': 2, 'bagging_temperature': 0.041615268845649526, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:19,724] Trial 244 finished with value: 0.8183470827148989 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.037364889974510186, 'random_strength': 4, 'bagging_temperature': 0.02574128745593649, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:20,611] Trial 245 finished with value: 0.8321685254027262 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.2572471994707908, 'random_strength': 2, 'bagging_temperature': 40.36649377616747, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:21,630] Trial 246 finished with value: 0.8415917345645018 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.23161595402653934, 'random_strength': 6, 'bagging_temperature': 0.04931020976204556, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:22,625] Trial 247 finished with value: 0.8512233217188787 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.2073201738277383, 'random_strength': 0, 'bagging_temperature': 1.0829664363744085, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:23,619] Trial 248 finished with value: 0.84191359062235 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.2074631668178689, 'random_strength': 0, 'bagging_temperature': 1.0270269684375906, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:24,511] Trial 249 finished with value: 0.8462775523686227 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.18837556125003496, 'random_strength': 2, 'bagging_temperature': 0.9027287559101453, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:25,573] Trial 250 finished with value: 0.8285262535262534 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.21814214346432345, 'random_strength': 0, 'bagging_temperature': 1.3734802901295213, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:26,508] Trial 251 finished with value: 0.8506436354465302 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.244249725474624, 'random_strength': 3, 'bagging_temperature': 1.0860471462004135, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:27,561] Trial 252 finished with value: 0.83723505544913 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.20260057618203056, 'random_strength': 5, 'bagging_temperature': 1.1577609339777741, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:28,434] Trial 253 finished with value: 0.8465761215761216 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.22534181226136127, 'random_strength': 0, 'bagging_temperature': 1.4902564642903717, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:29,486] Trial 254 finished with value: 0.84191359062235 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.2672732497404521, 'random_strength': 4, 'bagging_temperature': 0.0636656409524356, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:30,424] Trial 255 finished with value: 0.8331897849575306 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.183875856639437, 'random_strength': 77, 'bagging_temperature': 0.03297120636041061, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:31,431] Trial 256 finished with value: 0.8459506827044141 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.24256487539624455, 'random_strength': 2, 'bagging_temperature': 0.0423692890176284, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:31,676] Trial 257 finished with value: 0.8187655090640165 and parameters: {'iterations': 129, 'depth': 5, 'learning_rate': 0.030421184990554025, 'random_strength': 2, 'bagging_temperature': 0.8346038556500937, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:32,609] Trial 258 finished with value: 0.8412404970025789 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.2113915569551457, 'random_strength': 6, 'bagging_temperature': 0.023234820666251516, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:33,537] Trial 259 finished with value: 0.8648648648648649 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.19615190584775077, 'random_strength': 0, 'bagging_temperature': 0.03871964706569096, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:34,135] Trial 260 finished with value: 0.8375511875511874 and parameters: {'iterations': 97, 'depth': 10, 'learning_rate': 0.1959529333723666, 'random_strength': 100, 'bagging_temperature': 0.04960942670768554, 'od_type': 'IncToDec', 'od_wait': 21}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:34,939] Trial 261 finished with value: 0.8328800815150558 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.22623367237783043, 'random_strength': 0, 'bagging_temperature': 0.03760514275718392, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:35,752] Trial 262 finished with value: 0.8325398336824732 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.2083508039554713, 'random_strength': 4, 'bagging_temperature': 0.02877068124333355, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:36,505] Trial 263 finished with value: 0.8509470997296442 and parameters: {'iterations': 107, 'depth': 10, 'learning_rate': 0.19382137267789262, 'random_strength': 2, 'bagging_temperature': 6.772285807420938, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:37,333] Trial 264 finished with value: 0.8378378378378378 and parameters: {'iterations': 113, 'depth': 10, 'learning_rate': 0.2509523373794932, 'random_strength': 0, 'bagging_temperature': 0.03674670611509338, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:38,077] Trial 265 finished with value: 0.790016981343731 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.010125919039108342, 'random_strength': 8, 'bagging_temperature': 0.016859947728490438, 'od_type': 'IncToDec', 'od_wait': 22}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:39,002] Trial 266 finished with value: 0.8061394798155086 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.27640656139584874, 'random_strength': 60, 'bagging_temperature': 4.090995101233157, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:39,891] Trial 267 finished with value: 0.8415917345645018 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.2301313551009681, 'random_strength': 4, 'bagging_temperature': 0.05436563577481679, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:40,870] Trial 268 finished with value: 0.8599806088369385 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.21532795683614586, 'random_strength': 2, 'bagging_temperature': 0.04264524096608631, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:41,443] Trial 269 finished with value: 0.8265357671969952 and parameters: {'iterations': 134, 'depth': 9, 'learning_rate': 0.1814876043420199, 'random_strength': 6, 'bagging_temperature': 0.04526047734702443, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:42,573] Trial 270 finished with value: 0.8317656008930031 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.21254919849554615, 'random_strength': 2, 'bagging_temperature': 0.06770207963324024, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:43,556] Trial 271 finished with value: 0.83723505544913 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.19863996224944705, 'random_strength': 0, 'bagging_temperature': 0.027723645818657324, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:44,271] Trial 272 finished with value: 0.8087888675268976 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.012116114776176558, 'random_strength': 4, 'bagging_temperature': 0.04030649285310053, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:45,235] Trial 273 finished with value: 0.8550124072512131 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.2149529983918807, 'random_strength': 2, 'bagging_temperature': 0.03374544995445448, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:45,661] Trial 274 finished with value: 0.8328800815150558 and parameters: {'iterations': 141, 'depth': 8, 'learning_rate': 0.21308830997590777, 'random_strength': 6, 'bagging_temperature': 0.03224930074281471, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:46,269] Trial 275 finished with value: 0.8328800815150558 and parameters: {'iterations': 88, 'depth': 10, 'learning_rate': 0.1889813058902003, 'random_strength': 3, 'bagging_temperature': 0.03636954048934772, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:47,254] Trial 276 finished with value: 0.8503124686024315 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.2206551223052113, 'random_strength': 2, 'bagging_temperature': 0.022357950150497102, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:48,179] Trial 277 finished with value: 0.8356654636603111 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.20197303185849882, 'random_strength': 8, 'bagging_temperature': 0.052449831412886436, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:48,907] Trial 278 finished with value: 0.8144360319184163 and parameters: {'iterations': 104, 'depth': 10, 'learning_rate': 0.2356817162023387, 'random_strength': 4, 'bagging_temperature': 0.028970723022187363, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:49,987] Trial 279 finished with value: 0.8331897849575306 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.1729867718778264, 'random_strength': 0, 'bagging_temperature': 0.04360453804657204, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:51,223] Trial 280 finished with value: 0.8452100356170124 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.2172181418100326, 'random_strength': 2, 'bagging_temperature': 0.08447718682298352, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:52,131] Trial 281 finished with value: 0.8234879328004447 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.19725065058316743, 'random_strength': 5, 'bagging_temperature': 0.03379788952805972, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:52,816] Trial 282 finished with value: 0.8462775523686227 and parameters: {'iterations': 176, 'depth': 9, 'learning_rate': 0.23263162873418614, 'random_strength': 2, 'bagging_temperature': 0.06062084071436186, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:53,897] Trial 283 finished with value: 0.8424710748057271 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.20458730731124644, 'random_strength': 0, 'bagging_temperature': 0.042486149330708364, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:54,655] Trial 284 finished with value: 0.8278272336108157 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.18122257227713046, 'random_strength': 4, 'bagging_temperature': 0.025991810085450467, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:55,645] Trial 285 finished with value: 0.8356654636603111 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.24926414848450454, 'random_strength': 7, 'bagging_temperature': 0.04883489571675223, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:56,409] Trial 286 finished with value: 0.8503124686024315 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.22070442582034996, 'random_strength': 2, 'bagging_temperature': 0.020948751189796184, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:57,530] Trial 287 finished with value: 0.8328800815150558 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.23921283951369712, 'random_strength': 0, 'bagging_temperature': 0.033205496698066814, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:58,476] Trial 288 finished with value: 0.8375511875511874 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.20736751418751975, 'random_strength': 5, 'bagging_temperature': 0.037975940813800686, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:49:59,394] Trial 289 finished with value: 0.8281925585296372 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.1904684309609047, 'random_strength': 3, 'bagging_temperature': 0.05661106218197179, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:00,426] Trial 290 finished with value: 0.840859352196084 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.22294902403986597, 'random_strength': 9, 'bagging_temperature': 0.09927071675181932, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:01,477] Trial 291 finished with value: 0.833469421937483 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.26072489142366395, 'random_strength': 1, 'bagging_temperature': 0.028000825768402918, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:02,526] Trial 292 finished with value: 0.84191359062235 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.2369364265010521, 'random_strength': 6, 'bagging_temperature': 0.04547514602415103, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:03,230] Trial 293 finished with value: 0.8509470997296442 and parameters: {'iterations': 99, 'depth': 10, 'learning_rate': 0.20990295717277305, 'random_strength': 3, 'bagging_temperature': 0.07068933423292655, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:04,162] Trial 294 finished with value: 0.8556010556010556 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.2248414047192342, 'random_strength': 0, 'bagging_temperature': 0.03343645464427062, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:04,794] Trial 295 finished with value: 0.8230965538028735 and parameters: {'iterations': 103, 'depth': 10, 'learning_rate': 0.048243599224563546, 'random_strength': 4, 'bagging_temperature': 0.013094239188746108, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:05,485] Trial 296 finished with value: 0.8278272336108157 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.026440736724821355, 'random_strength': 2, 'bagging_temperature': 0.03436761901698186, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:06,293] Trial 297 finished with value: 0.8325398336824732 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.2548318264316558, 'random_strength': 6, 'bagging_temperature': 0.02416841333879818, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:07,026] Trial 298 finished with value: 0.8325398336824732 and parameters: {'iterations': 109, 'depth': 10, 'learning_rate': 0.22872711922622935, 'random_strength': 10, 'bagging_temperature': 0.040204262416242385, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:07,954] Trial 299 finished with value: 0.8288288288288288 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.2398782457056069, 'random_strength': 0, 'bagging_temperature': 0.03054403091574459, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:09,035] Trial 300 finished with value: 0.8512233217188787 and parameters: {'iterations': 196, 'depth': 10, 'learning_rate': 0.2775286928281052, 'random_strength': 4, 'bagging_temperature': 0.020012654658152055, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:09,602] Trial 301 finished with value: 0.8325398336824732 and parameters: {'iterations': 116, 'depth': 9, 'learning_rate': 0.22600109886643732, 'random_strength': 2, 'bagging_temperature': 20.350812586949836, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:10,119] Trial 302 finished with value: 0.84191359062235 and parameters: {'iterations': 58, 'depth': 10, 'learning_rate': 0.19845104276329892, 'random_strength': 0, 'bagging_temperature': 0.048026881558365, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:10,766] Trial 303 finished with value: 0.845595020307664 and parameters: {'iterations': 93, 'depth': 10, 'learning_rate': 0.21769063548525022, 'random_strength': 7, 'bagging_temperature': 0.03681543340489749, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:11,570] Trial 304 finished with value: 0.8325398336824732 and parameters: {'iterations': 113, 'depth': 10, 'learning_rate': 0.18555340567560286, 'random_strength': 4, 'bagging_temperature': 0.026678279786788606, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:12,344] Trial 305 finished with value: 0.8187655090640165 and parameters: {'iterations': 106, 'depth': 10, 'learning_rate': 0.015081355797683884, 'random_strength': 2, 'bagging_temperature': 0.03309163132689923, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:13,446] Trial 306 finished with value: 0.83723505544913 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.2513874456057454, 'random_strength': 2, 'bagging_temperature': 0.04198804121596024, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:13,733] Trial 307 finished with value: 0.8104763854763856 and parameters: {'iterations': 120, 'depth': 5, 'learning_rate': 0.21615178000827795, 'random_strength': 5, 'bagging_temperature': 0.06049681336525856, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:14,800] Trial 308 finished with value: 0.8288288288288288 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.2398710245038828, 'random_strength': 0, 'bagging_temperature': 0.02921310294397894, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:15,898] Trial 309 finished with value: 0.8462775523686227 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.2654004589144731, 'random_strength': 3, 'bagging_temperature': 0.0518438174088301, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:16,898] Trial 310 finished with value: 0.8144360319184163 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.19549462995750141, 'random_strength': 8, 'bagging_temperature': 0.07479119534137729, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:17,860] Trial 311 finished with value: 0.8285262535262534 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.17704288992940284, 'random_strength': 0, 'bagging_temperature': 0.016372773776853516, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:18,838] Trial 312 finished with value: 0.8187655090640165 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.22451369160597862, 'random_strength': 5, 'bagging_temperature': 0.03889442039335397, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:19,636] Trial 313 finished with value: 0.8462775523686227 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.21244930344068913, 'random_strength': 2, 'bagging_temperature': 0.023764719938037186, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:20,527] Trial 314 finished with value: 0.8154661162009946 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.24231851890973755, 'random_strength': 52, 'bagging_temperature': 0.0464346171336176, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:20,811] Trial 315 finished with value: 0.8325398336824732 and parameters: {'iterations': 98, 'depth': 7, 'learning_rate': 0.2008071793089616, 'random_strength': 4, 'bagging_temperature': 0.03101673260401312, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:21,859] Trial 316 finished with value: 0.8599806088369385 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.2297584229084123, 'random_strength': 2, 'bagging_temperature': 0.036553482476479195, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:22,831] Trial 317 finished with value: 0.8234879328004447 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.07468745959532207, 'random_strength': 7, 'bagging_temperature': 0.06146758197251222, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:23,747] Trial 318 finished with value: 0.8368889581576149 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.2706485767569802, 'random_strength': 3, 'bagging_temperature': 0.054036470220316435, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:24,015] Trial 319 finished with value: 0.8044843469837604 and parameters: {'iterations': 105, 'depth': 6, 'learning_rate': 0.23235019479669725, 'random_strength': 6, 'bagging_temperature': 0.04041702130472245, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:24,698] Trial 320 finished with value: 0.8459506827044141 and parameters: {'iterations': 141, 'depth': 9, 'learning_rate': 0.25461135189495643, 'random_strength': 2, 'bagging_temperature': 0.11843685100139757, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:25,584] Trial 321 finished with value: 0.8415917345645018 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.22355020192310282, 'random_strength': 4, 'bagging_temperature': 0.03511204862720226, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:26,687] Trial 322 finished with value: 0.827429728579154 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.2423610440057597, 'random_strength': 1, 'bagging_temperature': 0.04497097509410679, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:27,497] Trial 323 finished with value: 0.8269994515719551 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.21162115397406392, 'random_strength': 10, 'bagging_temperature': 0.08758280662130914, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:28,468] Trial 324 finished with value: 0.8278272336108157 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.2828443117991434, 'random_strength': 5, 'bagging_temperature': 0.050241975916135745, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:28,889] Trial 325 finished with value: 0.8234879328004447 and parameters: {'iterations': 132, 'depth': 8, 'learning_rate': 0.23128486069658888, 'random_strength': 2, 'bagging_temperature': 0.037067019958160384, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:29,938] Trial 326 finished with value: 0.8380954533128446 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.24784886881448104, 'random_strength': 49, 'bagging_temperature': 0.06698962321712475, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:31,014] Trial 327 finished with value: 0.8281925585296372 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.21684817682371693, 'random_strength': 0, 'bagging_temperature': 0.025791800250945622, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:31,914] Trial 328 finished with value: 0.8325398336824732 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.2629188447736132, 'random_strength': 3, 'bagging_temperature': 0.041179862045420915, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:33,042] Trial 329 finished with value: 0.8178941595494262 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.2063884303159513, 'random_strength': 7, 'bagging_temperature': 0.033386089999321564, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:34,162] Trial 330 finished with value: 0.8422065533382046 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.23214094897839274, 'random_strength': 0, 'bagging_temperature': 0.05760019439216635, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:35,277] Trial 331 finished with value: 0.8415917345645018 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.2235332470972927, 'random_strength': 4, 'bagging_temperature': 0.0461227492508833, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:36,249] Trial 332 finished with value: 0.8321685254027262 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.20213082070615054, 'random_strength': 2, 'bagging_temperature': 0.01974168512879604, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:37,041] Trial 333 finished with value: 0.8135780982868414 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.022159571770614096, 'random_strength': 6, 'bagging_temperature': 0.02999110483105044, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:37,910] Trial 334 finished with value: 0.8412404970025789 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.24766539288259998, 'random_strength': 4, 'bagging_temperature': 0.036798109198084884, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:38,913] Trial 335 finished with value: 0.8516957111551706 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.2186699597618966, 'random_strength': 0, 'bagging_temperature': 0.026628659420836226, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:39,758] Trial 336 finished with value: 0.8230965538028735 and parameters: {'iterations': 116, 'depth': 10, 'learning_rate': 0.1926010630625612, 'random_strength': 2, 'bagging_temperature': 0.04909924633545289, 'od_type': 'Iter', 'od_wait': 10}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:40,437] Trial 337 finished with value: 0.8144360319184163 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.056095766937808364, 'random_strength': 8, 'bagging_temperature': 0.04063651467964994, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:41,103] Trial 338 finished with value: 0.8424710748057271 and parameters: {'iterations': 101, 'depth': 10, 'learning_rate': 0.23434389172617248, 'random_strength': 84, 'bagging_temperature': 0.022602415644162228, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:42,100] Trial 339 finished with value: 0.8512233217188787 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.257934586747359, 'random_strength': 2, 'bagging_temperature': 1.9934880841193814, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:43,122] Trial 340 finished with value: 0.8191500616101444 and parameters: {'iterations': 220, 'depth': 10, 'learning_rate': 0.2114782767668831, 'random_strength': 5, 'bagging_temperature': 0.07587310292435766, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:44,073] Trial 341 finished with value: 0.8368889581576149 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.0435100619035555, 'random_strength': 2, 'bagging_temperature': 0.03351511905329563, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:44,897] Trial 342 finished with value: 0.8509470997296442 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.23043228950403521, 'random_strength': 0, 'bagging_temperature': 2.9421428200095523, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:45,863] Trial 343 finished with value: 0.8593844402022841 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.20389930586267893, 'random_strength': 4, 'bagging_temperature': 0.09446761853366366, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:46,782] Trial 344 finished with value: 0.827429728579154 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.19152766646461958, 'random_strength': 6, 'bagging_temperature': 0.1124079121718314, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:47,592] Trial 345 finished with value: 0.8317656008930031 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.17263002466494728, 'random_strength': 4, 'bagging_temperature': 0.14411165368457984, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:48,135] Trial 346 finished with value: 0.83723505544913 and parameters: {'iterations': 121, 'depth': 9, 'learning_rate': 0.20413493643269606, 'random_strength': 4, 'bagging_temperature': 0.11222505165208455, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:48,934] Trial 347 finished with value: 0.83723505544913 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.24151356651272962, 'random_strength': 8, 'bagging_temperature': 0.09815401582274179, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:49,561] Trial 348 finished with value: 0.8178941595494262 and parameters: {'iterations': 113, 'depth': 10, 'learning_rate': 0.03342204073575257, 'random_strength': 12, 'bagging_temperature': 0.06182001110999615, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:50,255] Trial 349 finished with value: 0.84191359062235 and parameters: {'iterations': 104, 'depth': 10, 'learning_rate': 0.18391444649206462, 'random_strength': 27, 'bagging_temperature': 0.08768945128520446, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:51,217] Trial 350 finished with value: 0.84191359062235 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.28116792828691256, 'random_strength': 0, 'bagging_temperature': 0.07548013713967153, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:51,963] Trial 351 finished with value: 0.8415917345645018 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.16300595297147177, 'random_strength': 6, 'bagging_temperature': 0.05557392134879617, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:52,806] Trial 352 finished with value: 0.8325398336824732 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.22376465125475672, 'random_strength': 97, 'bagging_temperature': 0.043724732214921125, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:53,576] Trial 353 finished with value: 0.8178941595494262 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.20212640851006725, 'random_strength': 3, 'bagging_temperature': 0.0922758795072365, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:54,404] Trial 354 finished with value: 0.8368889581576149 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.25719753050067506, 'random_strength': 9, 'bagging_temperature': 0.052659324310066154, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:55,406] Trial 355 finished with value: 0.83723505544913 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.2360069414240131, 'random_strength': 2, 'bagging_temperature': 0.16487330663183197, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:56,343] Trial 356 finished with value: 0.8226718495899223 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.21893714765914743, 'random_strength': 5, 'bagging_temperature': 0.028076731495281622, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:57,208] Trial 357 finished with value: 0.8108108108108109 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.017269241443098302, 'random_strength': 0, 'bagging_temperature': 0.039568089892840615, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:58,160] Trial 358 finished with value: 0.8006420599704182 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.20036448351864178, 'random_strength': 36, 'bagging_temperature': 0.0762360824801306, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:50:59,069] Trial 359 finished with value: 0.8230965538028735 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.24619749111370084, 'random_strength': 3, 'bagging_temperature': 0.06564230665137684, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:00,053] Trial 360 finished with value: 0.8368889581576149 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.21603002166240357, 'random_strength': 6, 'bagging_temperature': 0.010452248520144652, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:01,317] Trial 361 finished with value: 0.8234879328004447 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.18993212221695882, 'random_strength': 0, 'bagging_temperature': 0.046003487990216224, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:02,429] Trial 362 finished with value: 0.8001817909863886 and parameters: {'iterations': 259, 'depth': 10, 'learning_rate': 0.23330085324878602, 'random_strength': 4, 'bagging_temperature': 0.0316453096380399, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:03,256] Trial 363 finished with value: 0.8412404970025789 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.26923425369557635, 'random_strength': 2, 'bagging_temperature': 0.13390618559675216, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:04,143] Trial 364 finished with value: 0.8328800815150558 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.20659200313662532, 'random_strength': 2, 'bagging_temperature': 0.036586565196955204, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:04,780] Trial 365 finished with value: 0.8321685254027262 and parameters: {'iterations': 137, 'depth': 9, 'learning_rate': 0.17978175199931695, 'random_strength': 4, 'bagging_temperature': 0.02375816732465237, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:05,955] Trial 366 finished with value: 0.8462775523686227 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.22284579816335848, 'random_strength': 0, 'bagging_temperature': 0.015001902020716277, 'od_type': 'Iter', 'od_wait': 20}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:06,920] Trial 367 finished with value: 0.8328800815150558 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.2516996422645593, 'random_strength': 8, 'bagging_temperature': 0.052522079894154736, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:08,044] Trial 368 finished with value: 0.8317656008930031 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.19789274667164442, 'random_strength': 6, 'bagging_temperature': 0.042698004514857585, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:08,901] Trial 369 finished with value: 0.8646259896259897 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.2283032318161679, 'random_strength': 2, 'bagging_temperature': 0.029961532693089432, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:09,329] Trial 370 finished with value: 0.8001817909863886 and parameters: {'iterations': 117, 'depth': 8, 'learning_rate': 0.29597269975530893, 'random_strength': 4, 'bagging_temperature': 77.17139436221747, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:10,275] Trial 371 finished with value: 0.8331897849575306 and parameters: {'iterations': 113, 'depth': 10, 'learning_rate': 0.10009860822022151, 'random_strength': 0, 'bagging_temperature': 0.02739190901423065, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:11,855] Trial 372 finished with value: 0.8317656008930031 and parameters: {'iterations': 234, 'depth': 10, 'learning_rate': 0.061369947217753865, 'random_strength': 2, 'bagging_temperature': 0.019542840425469808, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:12,730] Trial 373 finished with value: 0.8415917345645018 and parameters: {'iterations': 109, 'depth': 10, 'learning_rate': 0.23848872110428615, 'random_strength': 4, 'bagging_temperature': 0.024105390382212988, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:13,713] Trial 374 finished with value: 0.8148130633004671 and parameters: {'iterations': 205, 'depth': 10, 'learning_rate': 0.2601965701915871, 'random_strength': 2, 'bagging_temperature': 0.031201346597046428, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:14,850] Trial 375 finished with value: 0.8321685254027262 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.228145634275479, 'random_strength': 10, 'bagging_temperature': 0.06078749931510489, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:15,570] Trial 376 finished with value: 0.8269994515719551 and parameters: {'iterations': 104, 'depth': 10, 'learning_rate': 0.21221394195146093, 'random_strength': 6, 'bagging_temperature': 0.03881932557459558, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:16,323] Trial 377 finished with value: 0.8241730165768567 and parameters: {'iterations': 97, 'depth': 10, 'learning_rate': 0.24362007580728748, 'random_strength': 0, 'bagging_temperature': 0.04843066802446187, 'od_type': 'Iter', 'od_wait': 13}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:17,211] Trial 378 finished with value: 0.8690141179442328 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.22355395346611476, 'random_strength': 2, 'bagging_temperature': 0.2062664701543687, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:18,112] Trial 379 finished with value: 0.827429728579154 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.22331734776972245, 'random_strength': 7, 'bagging_temperature': 0.3740524788179378, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:19,005] Trial 380 finished with value: 0.8230965538028735 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.27479857227146387, 'random_strength': 4, 'bagging_temperature': 0.30685213989789545, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:19,521] Trial 381 finished with value: 0.8092644368506438 and parameters: {'iterations': 111, 'depth': 9, 'learning_rate': 0.235785762750509, 'random_strength': 31, 'bagging_temperature': 0.21630516962620125, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:20,486] Trial 382 finished with value: 0.8550124072512131 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.20829847177909636, 'random_strength': 2, 'bagging_temperature': 0.189884748967033, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:21,269] Trial 383 finished with value: 0.836512374443409 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.25668050288750255, 'random_strength': 5, 'bagging_temperature': 0.09702166701913457, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:21,944] Trial 384 finished with value: 0.8321685254027262 and parameters: {'iterations': 105, 'depth': 10, 'learning_rate': 0.03881087795141264, 'random_strength': 3, 'bagging_temperature': 0.12340816711335323, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:22,234] Trial 385 finished with value: 0.8191500616101444 and parameters: {'iterations': 125, 'depth': 6, 'learning_rate': 0.23008631691435424, 'random_strength': 8, 'bagging_temperature': 0.4921680093611643, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:23,077] Trial 386 finished with value: 0.8462775523686227 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.20959431496606143, 'random_strength': 2, 'bagging_temperature': 0.08094173644069594, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:23,749] Trial 387 finished with value: 0.8144360319184163 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.1940033538657289, 'random_strength': 68, 'bagging_temperature': 0.06423848668975753, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:24,543] Trial 388 finished with value: 0.8503124686024315 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.2464564482817578, 'random_strength': 5, 'bagging_temperature': 0.03089182908033286, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:25,346] Trial 389 finished with value: 0.8375511875511874 and parameters: {'iterations': 100, 'depth': 10, 'learning_rate': 0.2235258287520298, 'random_strength': 0, 'bagging_temperature': 0.018238862316458285, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:26,142] Trial 390 finished with value: 0.84191359062235 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.2202217511087981, 'random_strength': 3, 'bagging_temperature': 0.16404898418059904, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:27,302] Trial 391 finished with value: 0.8321685254027262 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.24554569066003223, 'random_strength': 6, 'bagging_temperature': 0.10808109759783414, 'od_type': 'Iter', 'od_wait': 47}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:28,287] Trial 392 finished with value: 0.8465761215761216 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.09162109897982511, 'random_strength': 2, 'bagging_temperature': 0.051568365022026594, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:29,894] Trial 393 finished with value: 0.8462775523686227 and parameters: {'iterations': 241, 'depth': 10, 'learning_rate': 0.01924758262395672, 'random_strength': 4, 'bagging_temperature': 0.2600733040056625, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:30,148] Trial 394 finished with value: 0.8328800815150558 and parameters: {'iterations': 150, 'depth': 4, 'learning_rate': 0.20295703043258148, 'random_strength': 0, 'bagging_temperature': 0.025979255466266955, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:30,886] Trial 395 finished with value: 0.8140245822030209 and parameters: {'iterations': 106, 'depth': 10, 'learning_rate': 0.25957422279623577, 'random_strength': 7, 'bagging_temperature': 0.06849864986417491, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:31,717] Trial 396 finished with value: 0.8321685254027262 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.2321908405898225, 'random_strength': 2, 'bagging_temperature': 0.043053585809324446, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:32,747] Trial 397 finished with value: 0.8415917345645018 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.1890184303028646, 'random_strength': 4, 'bagging_temperature': 0.03651240346452347, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:33,452] Trial 398 finished with value: 0.8183470827148989 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.05265095792150399, 'random_strength': 11, 'bagging_temperature': 0.02195608717894386, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:34,066] Trial 399 finished with value: 0.8459506827044141 and parameters: {'iterations': 122, 'depth': 9, 'learning_rate': 0.21209558201283563, 'random_strength': 1, 'bagging_temperature': 0.030147086472773987, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:34,874] Trial 400 finished with value: 0.8313304629094104 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.28185861990267863, 'random_strength': 5, 'bagging_temperature': 0.07923776562145403, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:35,928] Trial 401 finished with value: 0.84191359062235 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.23297446761359505, 'random_strength': 0, 'bagging_temperature': 0.05232924561493478, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:36,761] Trial 402 finished with value: 0.836512374443409 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.20525285290986395, 'random_strength': 3, 'bagging_temperature': 0.036249309762990664, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:37,729] Trial 403 finished with value: 0.8313304629094104 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.2213584948177154, 'random_strength': 8, 'bagging_temperature': 0.7470842109752908, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:38,794] Trial 404 finished with value: 0.8503124686024315 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.24634621390874709, 'random_strength': 2, 'bagging_temperature': 0.04501440803641807, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:39,447] Trial 405 finished with value: 0.8281925585296372 and parameters: {'iterations': 103, 'depth': 10, 'learning_rate': 0.19679860599818008, 'random_strength': 45, 'bagging_temperature': 1.574954761971272, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:40,341] Trial 406 finished with value: 0.8412404970025789 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.18396978243445727, 'random_strength': 6, 'bagging_temperature': 0.1420397994655227, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:41,205] Trial 407 finished with value: 0.827429728579154 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.26379442428414424, 'random_strength': 4, 'bagging_temperature': 0.09165077934222388, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:41,535] Trial 408 finished with value: 0.833469421937483 and parameters: {'iterations': 109, 'depth': 7, 'learning_rate': 0.21699516016740172, 'random_strength': 0, 'bagging_temperature': 0.0603902257349874, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:42,559] Trial 409 finished with value: 0.8640741317980124 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.239096337434914, 'random_strength': 2, 'bagging_temperature': 0.027830699562813453, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:43,572] Trial 410 finished with value: 0.8151562481961826 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.2475769540573509, 'random_strength': 74, 'bagging_temperature': 0.020830118738935425, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:44,711] Trial 411 finished with value: 0.8503124686024315 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.26548405906807315, 'random_strength': 39, 'bagging_temperature': 0.025729906580542652, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:45,767] Trial 412 finished with value: 0.8187655090640165 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.013949801884985312, 'random_strength': 2, 'bagging_temperature': 0.02937983376180731, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:46,942] Trial 413 finished with value: 0.8546776661719191 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.23841078519969222, 'random_strength': 5, 'bagging_temperature': 0.016577629600851962, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:47,958] Trial 414 finished with value: 0.8328800815150558 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.22948753977193537, 'random_strength': 0, 'bagging_temperature': 0.02245321127527305, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:48,939] Trial 415 finished with value: 0.83723505544913 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.25511756639957267, 'random_strength': 9, 'bagging_temperature': 0.031308154954587254, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:50,185] Trial 416 finished with value: 0.8412404970025789 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.28208545716876127, 'random_strength': 3, 'bagging_temperature': 0.0350193172737381, 'od_type': 'Iter', 'od_wait': 20}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:50,873] Trial 417 finished with value: 0.845595020307664 and parameters: {'iterations': 135, 'depth': 9, 'learning_rate': 0.23042507484417032, 'random_strength': 6, 'bagging_temperature': 0.024563330758345367, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:52,063] Trial 418 finished with value: 0.8368889581576149 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.026116785802217834, 'random_strength': 2, 'bagging_temperature': 0.4082112805753519, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:53,049] Trial 419 finished with value: 0.8415917345645018 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.2121453547174279, 'random_strength': 4, 'bagging_temperature': 0.04150286866786172, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:54,103] Trial 420 finished with value: 0.8281925585296372 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.2439079648453918, 'random_strength': 0, 'bagging_temperature': 0.027727938675099224, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:55,035] Trial 421 finished with value: 0.8135780982868414 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.22301639557155306, 'random_strength': 18, 'bagging_temperature': 0.1008456668243727, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:56,070] Trial 422 finished with value: 0.84191359062235 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.2667865432845625, 'random_strength': 2, 'bagging_temperature': 0.07230589403732357, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:56,995] Trial 423 finished with value: 0.8462775523686227 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.23807996964432385, 'random_strength': 4, 'bagging_temperature': 0.05016514720355997, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:58,157] Trial 424 finished with value: 0.8230965538028735 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.21546482076081303, 'random_strength': 6, 'bagging_temperature': 0.03468564328705605, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:51:59,184] Trial 425 finished with value: 0.8553200492881156 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.20506350064271342, 'random_strength': 0, 'bagging_temperature': 0.12461945781027672, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:00,165] Trial 426 finished with value: 0.8593844402022841 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.22624136599847214, 'random_strength': 2, 'bagging_temperature': 0.04231393037250734, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:01,101] Trial 427 finished with value: 0.8412404970025789 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.22807616341713877, 'random_strength': 2, 'bagging_temperature': 0.04213378620934815, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:02,166] Trial 428 finished with value: 0.8509470997296442 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.2513778153246617, 'random_strength': 0, 'bagging_temperature': 0.03497330158285618, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:03,212] Trial 429 finished with value: 0.8465761215761216 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.19656552871553915, 'random_strength': 2, 'bagging_temperature': 0.027557366134796858, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:03,867] Trial 430 finished with value: 0.8368889581576149 and parameters: {'iterations': 142, 'depth': 9, 'learning_rate': 0.2207089953734037, 'random_strength': 4, 'bagging_temperature': 0.3125809480562506, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:04,852] Trial 431 finished with value: 0.8593844402022841 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.23624274334446402, 'random_strength': 2, 'bagging_temperature': 0.046859515428273636, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:05,878] Trial 432 finished with value: 0.8412404970025789 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.27223921670168794, 'random_strength': 4, 'bagging_temperature': 0.05446380964931088, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:06,727] Trial 433 finished with value: 0.8226718495899223 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.24420223017001005, 'random_strength': 56, 'bagging_temperature': 0.04710848091124278, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:07,811] Trial 434 finished with value: 0.8556010556010556 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.25527045632064305, 'random_strength': 2, 'bagging_temperature': 0.05594152148378419, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:08,818] Trial 435 finished with value: 0.8415917345645018 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.23959780604526867, 'random_strength': 7, 'bagging_temperature': 0.04373226066964228, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:09,901] Trial 436 finished with value: 0.8269994515719551 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.29150108202382913, 'random_strength': 3, 'bagging_temperature': 0.04073990829638127, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:10,906] Trial 437 finished with value: 0.8506436354465302 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.21149222988952646, 'random_strength': 5, 'bagging_temperature': 0.06579459936086636, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:11,961] Trial 438 finished with value: 0.8556010556010556 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.2307815141764611, 'random_strength': 2, 'bagging_temperature': 0.22544106208920073, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:12,971] Trial 439 finished with value: 0.8556010556010556 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.19694995652269348, 'random_strength': 0, 'bagging_temperature': 0.04484081271429687, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:13,793] Trial 440 finished with value: 0.8321685254027262 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.2141801722437029, 'random_strength': 21, 'bagging_temperature': 0.05618208629103625, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:14,818] Trial 441 finished with value: 0.8462775523686227 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.2645428607616036, 'random_strength': 4, 'bagging_temperature': 0.037132984546174475, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:15,871] Trial 442 finished with value: 0.8506436354465302 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.2366870437190667, 'random_strength': 2, 'bagging_temperature': 0.01993818081555783, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:16,143] Trial 443 finished with value: 0.8278272336108157 and parameters: {'iterations': 140, 'depth': 5, 'learning_rate': 0.1870832127111468, 'random_strength': 6, 'bagging_temperature': 0.6186871833111593, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:16,652] Trial 444 finished with value: 0.8144360319184163 and parameters: {'iterations': 159, 'depth': 8, 'learning_rate': 0.22420224765822938, 'random_strength': 1, 'bagging_temperature': 0.03187845162702394, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:17,514] Trial 445 finished with value: 0.83723505544913 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.11822459685211137, 'random_strength': 4, 'bagging_temperature': 0.025772130729056805, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:18,493] Trial 446 finished with value: 0.8325398336824732 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.20621559531547032, 'random_strength': 7, 'bagging_temperature': 0.046331651207638685, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:19,601] Trial 447 finished with value: 0.8556010556010556 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.24656990072281773, 'random_strength': 0, 'bagging_temperature': 0.03931768949848307, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:20,620] Trial 448 finished with value: 0.8321685254027262 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.22404591626394804, 'random_strength': 3, 'bagging_temperature': 0.030821579584921436, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:21,786] Trial 449 finished with value: 0.8509470997296442 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.1754044609718806, 'random_strength': 2, 'bagging_temperature': 1.3667656522589309, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:22,735] Trial 450 finished with value: 0.840859352196084 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.25614989359359003, 'random_strength': 5, 'bagging_temperature': 1.0056417347079354, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:23,705] Trial 451 finished with value: 0.8148130633004671 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.2041706706472413, 'random_strength': 9, 'bagging_temperature': 0.05509134181778931, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:24,889] Trial 452 finished with value: 0.8415917345645018 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.23517099551773996, 'random_strength': 0, 'bagging_temperature': 0.037435021407192605, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:25,857] Trial 453 finished with value: 0.8281925585296372 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.21844743742130038, 'random_strength': 3, 'bagging_temperature': 0.06479690891887174, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:26,887] Trial 454 finished with value: 0.8553200492881156 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.27802697939675924, 'random_strength': 5, 'bagging_temperature': 0.04590596707536456, 'od_type': 'Iter', 'od_wait': 12}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:27,507] Trial 455 finished with value: 0.8415917345645018 and parameters: {'iterations': 131, 'depth': 9, 'learning_rate': 0.19265741832534986, 'random_strength': 2, 'bagging_temperature': 0.023385695788833427, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:28,550] Trial 456 finished with value: 0.8135780982868414 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.2404279560037296, 'random_strength': 7, 'bagging_temperature': 0.0295732299735448, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:29,448] Trial 457 finished with value: 0.8602400900995527 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.21065269927915117, 'random_strength': 0, 'bagging_temperature': 0.049330514773424664, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:30,099] Trial 458 finished with value: 0.8512233217188787 and parameters: {'iterations': 77, 'depth': 10, 'learning_rate': 0.21586128400267776, 'random_strength': 0, 'bagging_temperature': 0.06445725696034924, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:31,015] Trial 459 finished with value: 0.8422065533382046 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.2591900279704393, 'random_strength': 0, 'bagging_temperature': 0.478529765047993, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:31,871] Trial 460 finished with value: 0.8503124686024315 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.23127018295973842, 'random_strength': 2, 'bagging_temperature': 0.08150034538095759, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:32,751] Trial 461 finished with value: 0.8281925585296372 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.2471362101190257, 'random_strength': 4, 'bagging_temperature': 0.052855065791019534, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:33,750] Trial 462 finished with value: 0.84191359062235 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.20890926930914308, 'random_strength': 0, 'bagging_temperature': 0.8301853578270374, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:34,669] Trial 463 finished with value: 0.836512374443409 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.2277234666541783, 'random_strength': 2, 'bagging_temperature': 0.04998424158487918, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:35,584] Trial 464 finished with value: 0.8506436354465302 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.19162590099251026, 'random_strength': 4, 'bagging_temperature': 0.03702702635604569, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:36,430] Trial 465 finished with value: 0.8191500616101444 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.2138637991520526, 'random_strength': 2, 'bagging_temperature': 0.04391723688432843, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:37,355] Trial 466 finished with value: 0.8368889581576149 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.24960498609312856, 'random_strength': 5, 'bagging_temperature': 0.01357720704695765, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:38,214] Trial 467 finished with value: 0.8238465724077614 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.2734265340056341, 'random_strength': 15, 'bagging_temperature': 0.01912696817329596, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:39,070] Trial 468 finished with value: 0.8241730165768567 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.2333281886931293, 'random_strength': 0, 'bagging_temperature': 0.05770852914970005, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:40,047] Trial 469 finished with value: 0.8269994515719551 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.21887427589753394, 'random_strength': 8, 'bagging_temperature': 0.07311679662788138, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:40,612] Trial 470 finished with value: 0.8313304629094104 and parameters: {'iterations': 107, 'depth': 9, 'learning_rate': 0.2034745497034566, 'random_strength': 3, 'bagging_temperature': 0.02888092722487522, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:41,476] Trial 471 finished with value: 0.8556010556010556 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.23805453806396673, 'random_strength': 6, 'bagging_temperature': 0.17115371167557564, 'od_type': 'IncToDec', 'od_wait': 21}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:42,494] Trial 472 finished with value: 0.8503124686024315 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.1798706839404695, 'random_strength': 2, 'bagging_temperature': 1.892731665745094, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:43,425] Trial 473 finished with value: 0.8422065533382046 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.2556210491479315, 'random_strength': 0, 'bagging_temperature': 0.034568306384497406, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:44,360] Trial 474 finished with value: 0.8553200492881156 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.19907239544317681, 'random_strength': 4, 'bagging_temperature': 0.04861799773613465, 'od_type': 'IncToDec', 'od_wait': 22}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:45,225] Trial 475 finished with value: 0.8412404970025789 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.29847061133824077, 'random_strength': 2, 'bagging_temperature': 0.02527670731812796, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:46,276] Trial 476 finished with value: 0.8321685254027262 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.22240370470973458, 'random_strength': 6, 'bagging_temperature': 0.0387470938355035, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:47,245] Trial 477 finished with value: 0.8144360319184163 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.23577862840081235, 'random_strength': 4, 'bagging_temperature': 0.03152480793483565, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:48,019] Trial 478 finished with value: 0.8368889581576149 and parameters: {'iterations': 113, 'depth': 10, 'learning_rate': 0.2133682686167724, 'random_strength': 10, 'bagging_temperature': 0.06382074509108138, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:49,079] Trial 479 finished with value: 0.8459506827044141 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.26949845918657483, 'random_strength': 0, 'bagging_temperature': 0.04341577842321764, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:50,112] Trial 480 finished with value: 0.83723505544913 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.20067229421227809, 'random_strength': 63, 'bagging_temperature': 10.582529035993526, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:50,863] Trial 481 finished with value: 0.8550124072512131 and parameters: {'iterations': 101, 'depth': 10, 'learning_rate': 0.24920927986712807, 'random_strength': 3, 'bagging_temperature': 0.02141915174944024, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:51,869] Trial 482 finished with value: 0.8278272336108157 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.2250259680315723, 'random_strength': 2, 'bagging_temperature': 1.1529376179995323, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:52,464] Trial 483 finished with value: 0.8560848473891952 and parameters: {'iterations': 123, 'depth': 9, 'learning_rate': 0.18829078899187174, 'random_strength': 0, 'bagging_temperature': 0.05591071652667879, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:53,136] Trial 484 finished with value: 0.8556010556010556 and parameters: {'iterations': 120, 'depth': 9, 'learning_rate': 0.17696818469222275, 'random_strength': 0, 'bagging_temperature': 0.08385535128527188, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:53,618] Trial 485 finished with value: 0.8144360319184163 and parameters: {'iterations': 124, 'depth': 8, 'learning_rate': 0.16830124191538431, 'random_strength': 6, 'bagging_temperature': 0.0732760611006497, 'od_type': 'IncToDec', 'od_wait': 21}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:54,263] Trial 486 finished with value: 0.8265357671969952 and parameters: {'iterations': 118, 'depth': 9, 'learning_rate': 0.185936722763378, 'random_strength': 4, 'bagging_temperature': 0.05690541983877812, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:54,904] Trial 487 finished with value: 0.8285262535262534 and parameters: {'iterations': 124, 'depth': 9, 'learning_rate': 0.19295701555197228, 'random_strength': 2, 'bagging_temperature': 0.055022376961732476, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:55,490] Trial 488 finished with value: 0.8325398336824732 and parameters: {'iterations': 112, 'depth': 9, 'learning_rate': 0.2070776667625431, 'random_strength': 8, 'bagging_temperature': 0.06361743827730304, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:55,839] Trial 489 finished with value: 0.8234879328004447 and parameters: {'iterations': 116, 'depth': 7, 'learning_rate': 0.1922924731309834, 'random_strength': 0, 'bagging_temperature': 0.04735736204399029, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:56,283] Trial 490 finished with value: 0.8238465724077614 and parameters: {'iterations': 129, 'depth': 8, 'learning_rate': 0.21343160089283683, 'random_strength': 5, 'bagging_temperature': 0.07386469962762823, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:56,688] Trial 491 finished with value: 0.8130959183590762 and parameters: {'iterations': 108, 'depth': 8, 'learning_rate': 0.22910467416136307, 'random_strength': 2, 'bagging_temperature': 0.10043003633157173, 'od_type': 'IncToDec', 'od_wait': 22}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:57,634] Trial 492 finished with value: 0.8328800815150558 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.2437566933905023, 'random_strength': 4, 'bagging_temperature': 0.05257266074853101, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:58,076] Trial 493 finished with value: 0.8368889581576149 and parameters: {'iterations': 127, 'depth': 8, 'learning_rate': 0.2049084601186555, 'random_strength': 2, 'bagging_temperature': 0.35478423882524884, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:59,000] Trial 494 finished with value: 0.8404477351845774 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.26229464635932825, 'random_strength': 7, 'bagging_temperature': 0.04184081715439523, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:52:59,910] Trial 495 finished with value: 0.8424710748057271 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.22207800442209927, 'random_strength': 0, 'bagging_temperature': 0.06408521029485212, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:00,680] Trial 496 finished with value: 0.8325398336824732 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.18567220824975036, 'random_strength': 4, 'bagging_temperature': 0.04869551874849602, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:01,299] Trial 497 finished with value: 0.8278272336108157 and parameters: {'iterations': 125, 'depth': 9, 'learning_rate': 0.23667731435322253, 'random_strength': 2, 'bagging_temperature': 0.03859334119290182, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:02,221] Trial 498 finished with value: 0.8415917345645018 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.20930597146864752, 'random_strength': 6, 'bagging_temperature': 2.5249036329632366, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:03,086] Trial 499 finished with value: 0.8465761215761216 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.22262714469197706, 'random_strength': 0, 'bagging_temperature': 0.5553001829098483, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:03,948] Trial 500 finished with value: 0.8234879328004447 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.19774404748657692, 'random_strength': 3, 'bagging_temperature': 0.05408237330062399, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:04,898] Trial 501 finished with value: 0.8321685254027262 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.2570183225211349, 'random_strength': 2, 'bagging_temperature': 0.03522724690191582, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:05,854] Trial 502 finished with value: 0.8321685254027262 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.24087305312193, 'random_strength': 12, 'bagging_temperature': 0.261321881089208, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:06,523] Trial 503 finished with value: 0.8506436354465302 and parameters: {'iterations': 105, 'depth': 10, 'learning_rate': 0.21168537555798614, 'random_strength': 80, 'bagging_temperature': 0.08171746463873471, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:07,618] Trial 504 finished with value: 0.8462775523686227 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.16044170115791154, 'random_strength': 4, 'bagging_temperature': 0.04563979474082115, 'od_type': 'IncToDec', 'od_wait': 45}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:08,648] Trial 505 finished with value: 0.8281925585296372 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.2837201826816932, 'random_strength': 0, 'bagging_temperature': 0.03347284507835019, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:09,001] Trial 506 finished with value: 0.8321685254027262 and parameters: {'iterations': 111, 'depth': 7, 'learning_rate': 0.22561499221013842, 'random_strength': 6, 'bagging_temperature': 0.09366746653368395, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:10,081] Trial 507 finished with value: 0.8151562481961826 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.19499205687907034, 'random_strength': 9, 'bagging_temperature': 0.06070193159226977, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:11,005] Trial 508 finished with value: 0.8368889581576149 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.17885959688018963, 'random_strength': 2, 'bagging_temperature': 0.028544566595728058, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:11,861] Trial 509 finished with value: 0.8328800815150558 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.24725405258562, 'random_strength': 4, 'bagging_temperature': 0.015806498039225007, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:12,620] Trial 510 finished with value: 0.8241730165768567 and parameters: {'iterations': 93, 'depth': 10, 'learning_rate': 0.2284174185654242, 'random_strength': 0, 'bagging_temperature': 0.19673044676599147, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:13,604] Trial 511 finished with value: 0.8506436354465302 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.20507967180335088, 'random_strength': 2, 'bagging_temperature': 0.04188458710204592, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:14,768] Trial 512 finished with value: 0.8325398336824732 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.2686469939918997, 'random_strength': 5, 'bagging_temperature': 0.06945510528621471, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:15,789] Trial 513 finished with value: 0.8328800815150558 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.21862482201174366, 'random_strength': 7, 'bagging_temperature': 0.05299364172913677, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:16,548] Trial 514 finished with value: 0.8321685254027262 and parameters: {'iterations': 147, 'depth': 9, 'learning_rate': 0.23648225191190156, 'random_strength': 2, 'bagging_temperature': 0.1150354305214145, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:16,889] Trial 515 finished with value: 0.827429728579154 and parameters: {'iterations': 140, 'depth': 6, 'learning_rate': 0.2528821718473631, 'random_strength': 0, 'bagging_temperature': 0.038314578646073134, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:17,810] Trial 516 finished with value: 0.8328800815150558 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.21236908028916268, 'random_strength': 4, 'bagging_temperature': 0.024897391573969523, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:18,788] Trial 517 finished with value: 0.8415917345645018 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.18849856373013946, 'random_strength': 2, 'bagging_temperature': 0.03222226335547418, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:19,661] Trial 518 finished with value: 0.8593844402022841 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.2342948553853844, 'random_strength': 5, 'bagging_temperature': 1.631596842523483, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:20,620] Trial 519 finished with value: 0.8328800815150558 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.22779391128491047, 'random_strength': 10, 'bagging_temperature': 0.08130590639993625, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:21,641] Trial 520 finished with value: 0.8321685254027262 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.1993987897570137, 'random_strength': 7, 'bagging_temperature': 1.8936984367040892, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:22,350] Trial 521 finished with value: 0.8321685254027262 and parameters: {'iterations': 103, 'depth': 10, 'learning_rate': 0.16824392197871632, 'random_strength': 8, 'bagging_temperature': 1.3670579990956566, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:23,200] Trial 522 finished with value: 0.8465761215761216 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.21612069753992966, 'random_strength': 96, 'bagging_temperature': 1.0058485374194044, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:24,193] Trial 523 finished with value: 0.8462775523686227 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.2485160354928121, 'random_strength': 5, 'bagging_temperature': 2.246204419933988, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:25,365] Trial 524 finished with value: 0.8328800815150558 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.23642027649229047, 'random_strength': 6, 'bagging_temperature': 3.6797865652361925, 'od_type': 'IncToDec', 'od_wait': 21}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:26,206] Trial 525 finished with value: 0.8281925585296372 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.20165026147253648, 'random_strength': 4, 'bagging_temperature': 1.4502061827117367, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:27,031] Trial 526 finished with value: 0.8368889581576149 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.26772188713694134, 'random_strength': 8, 'bagging_temperature': 0.8262424100701894, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:28,114] Trial 527 finished with value: 0.84191359062235 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.21633859287825205, 'random_strength': 4, 'bagging_temperature': 1.2106190814693476, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:29,244] Trial 528 finished with value: 0.8361047435944837 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.22682645434597762, 'random_strength': 6, 'bagging_temperature': 1.7066020840254477, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:30,296] Trial 529 finished with value: 0.8368889581576149 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.1882660696252393, 'random_strength': 3, 'bagging_temperature': 0.6782915151763377, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:31,240] Trial 530 finished with value: 0.8553200492881156 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.2488836134929932, 'random_strength': 2, 'bagging_temperature': 2.3774628542578267, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:32,342] Trial 531 finished with value: 0.8321685254027262 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.2106846992734546, 'random_strength': 5, 'bagging_temperature': 0.4393263521707133, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:32,879] Trial 532 finished with value: 0.8325398336824732 and parameters: {'iterations': 106, 'depth': 9, 'learning_rate': 0.23453637031440175, 'random_strength': 2, 'bagging_temperature': 1.5474975917887663, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:33,665] Trial 533 finished with value: 0.8234879328004447 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.07134216937416217, 'random_strength': 10, 'bagging_temperature': 1.2532052998949277, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:34,514] Trial 534 finished with value: 0.8375511875511874 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.1794855513282718, 'random_strength': 4, 'bagging_temperature': 0.062146469095000025, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:35,611] Trial 535 finished with value: 0.8238465724077614 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.2025442116919627, 'random_strength': 0, 'bagging_temperature': 0.13403609998148716, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:36,025] Trial 536 finished with value: 0.8368889581576149 and parameters: {'iterations': 111, 'depth': 8, 'learning_rate': 0.28255876829907983, 'random_strength': 7, 'bagging_temperature': 5.2452573862872125, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:37,137] Trial 537 finished with value: 0.8459506827044141 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.26005880295379935, 'random_strength': 3, 'bagging_temperature': 0.04576150737188696, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:38,059] Trial 538 finished with value: 0.8331897849575306 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.22548239687324842, 'random_strength': 1, 'bagging_temperature': 1.7146089270552691, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:38,862] Trial 539 finished with value: 0.8361047435944837 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.24009840659746468, 'random_strength': 6, 'bagging_temperature': 0.05126205333139979, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:39,602] Trial 540 finished with value: 0.827429728579154 and parameters: {'iterations': 99, 'depth': 10, 'learning_rate': 0.21682557573277542, 'random_strength': 3, 'bagging_temperature': 0.06910364325124055, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:40,651] Trial 541 finished with value: 0.84191359062235 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.1953641101013647, 'random_strength': 0, 'bagging_temperature': 0.0426638392567976, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:41,336] Trial 542 finished with value: 0.8313304629094104 and parameters: {'iterations': 150, 'depth': 9, 'learning_rate': 0.2497129299128884, 'random_strength': 13, 'bagging_temperature': 0.05349950271827649, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:42,379] Trial 543 finished with value: 0.8459506827044141 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.21176776654868112, 'random_strength': 4, 'bagging_temperature': 0.04274190527501711, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:42,865] Trial 544 finished with value: 0.8465761215761216 and parameters: {'iterations': 50, 'depth': 10, 'learning_rate': 0.23135597473767933, 'random_strength': 2, 'bagging_temperature': 0.09874121200188127, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:43,951] Trial 545 finished with value: 0.8378378378378378 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.2671305973800348, 'random_strength': 5, 'bagging_temperature': 28.082787819243187, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:44,921] Trial 546 finished with value: 0.8646259896259897 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.2066465693020291, 'random_strength': 0, 'bagging_temperature': 0.06085763061857255, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:45,788] Trial 547 finished with value: 0.8140245822030209 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.22379070604565976, 'random_strength': 8, 'bagging_temperature': 0.3041029608822062, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:46,743] Trial 548 finished with value: 0.845595020307664 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.2413687182377639, 'random_strength': 2, 'bagging_temperature': 0.9538762962043387, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:47,700] Trial 549 finished with value: 0.845595020307664 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.20348839573588492, 'random_strength': 4, 'bagging_temperature': 0.08049480967421194, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:48,521] Trial 550 finished with value: 0.8230965538028735 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.21899545168593954, 'random_strength': 33, 'bagging_temperature': 0.01775038513835986, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:49,655] Trial 551 finished with value: 0.8465761215761216 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.23947749857669393, 'random_strength': 1, 'bagging_temperature': 0.03727138339414042, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:50,636] Trial 552 finished with value: 0.8378378378378378 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.25515873230439384, 'random_strength': 85, 'bagging_temperature': 0.06920688336836935, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:51,738] Trial 553 finished with value: 0.8415917345645018 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.20680730626991414, 'random_strength': 6, 'bagging_temperature': 0.02618572561616574, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:52,598] Trial 554 finished with value: 0.8278272336108157 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.22666985610410678, 'random_strength': 3, 'bagging_temperature': 0.048580646720169346, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:53,629] Trial 555 finished with value: 0.8195013195013195 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.2136527973896225, 'random_strength': 27, 'bagging_temperature': 0.035445698093754814, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:54,780] Trial 556 finished with value: 0.84191359062235 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.2814400603566213, 'random_strength': 0, 'bagging_temperature': 0.028585624088260982, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:55,992] Trial 557 finished with value: 0.8553200492881156 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.23576010792424112, 'random_strength': 2, 'bagging_temperature': 0.14768101409728132, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:57,314] Trial 558 finished with value: 0.8462775523686227 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.1950144652297132, 'random_strength': 5, 'bagging_temperature': 0.060310617665611514, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:58,190] Trial 559 finished with value: 0.8331897849575306 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.2568869137886024, 'random_strength': 8, 'bagging_temperature': 0.0884690246180986, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:53:59,265] Trial 560 finished with value: 0.8422065533382046 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.2222350079110287, 'random_strength': 0, 'bagging_temperature': 0.23408564965543485, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:00,004] Trial 561 finished with value: 0.8278272336108157 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.20226398463416537, 'random_strength': 43, 'bagging_temperature': 0.021841735291574977, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:00,317] Trial 562 finished with value: 0.8191500616101444 and parameters: {'iterations': 124, 'depth': 6, 'learning_rate': 0.24167183626880298, 'random_strength': 3, 'bagging_temperature': 0.04179434092572701, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:01,331] Trial 563 finished with value: 0.8368889581576149 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.21651611706121354, 'random_strength': 5, 'bagging_temperature': 0.0333294148912864, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:02,269] Trial 564 finished with value: 0.8234879328004447 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.12681259098646364, 'random_strength': 2, 'bagging_temperature': 0.04839109855375524, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:03,138] Trial 565 finished with value: 0.8462775523686227 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.17544833825014977, 'random_strength': 0, 'bagging_temperature': 0.059444158985408065, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:04,158] Trial 566 finished with value: 0.8234879328004447 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.23533590346456812, 'random_strength': 6, 'bagging_temperature': 2.131644967576359, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:05,162] Trial 567 finished with value: 0.8278272336108157 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.26683407157921113, 'random_strength': 3, 'bagging_temperature': 0.10614205992227739, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:06,026] Trial 568 finished with value: 0.8135780982868414 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.2040438023300977, 'random_strength': 11, 'bagging_temperature': 0.03059798676589757, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:06,311] Trial 569 finished with value: 0.8195013195013195 and parameters: {'iterations': 147, 'depth': 4, 'learning_rate': 0.22829211323718934, 'random_strength': 2, 'bagging_temperature': 0.7305148345420222, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:07,292] Trial 570 finished with value: 0.836512374443409 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.24838055878318538, 'random_strength': 4, 'bagging_temperature': 0.03904419478031891, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:08,043] Trial 571 finished with value: 0.8234879328004447 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.1871717002243101, 'random_strength': 9, 'bagging_temperature': 0.0756001132492369, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:09,138] Trial 572 finished with value: 0.8331897849575306 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.21475710511906954, 'random_strength': 0, 'bagging_temperature': 0.5365197204035428, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:10,236] Trial 573 finished with value: 0.840859352196084 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.22726588616570892, 'random_strength': 6, 'bagging_temperature': 1.218800613244259, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:11,288] Trial 574 finished with value: 0.8556010556010556 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.2559389825300251, 'random_strength': 2, 'bagging_temperature': 0.05252768268816381, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:12,043] Trial 575 finished with value: 0.8550124072512131 and parameters: {'iterations': 104, 'depth': 10, 'learning_rate': 0.2008363423833815, 'random_strength': 5, 'bagging_temperature': 1.683297133759905, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:13,090] Trial 576 finished with value: 0.8459506827044141 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.15030310002875324, 'random_strength': 2, 'bagging_temperature': 0.045001373801302424, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:14,310] Trial 577 finished with value: 0.8328800815150558 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.2167067962555273, 'random_strength': 0, 'bagging_temperature': 0.022721078861194607, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:15,166] Trial 578 finished with value: 0.8281925585296372 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.2420229420331732, 'random_strength': 4, 'bagging_temperature': 0.03650960268126881, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:16,272] Trial 579 finished with value: 0.8415917345645018 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.10802096668078755, 'random_strength': 7, 'bagging_temperature': 0.06845584000789288, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:17,405] Trial 580 finished with value: 0.8553200492881156 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.1943347238655698, 'random_strength': 2, 'bagging_temperature': 0.03012247612629397, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:18,203] Trial 581 finished with value: 0.8368889581576149 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.26639076106172604, 'random_strength': 4, 'bagging_temperature': 0.046637631801332485, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:19,283] Trial 582 finished with value: 0.8415917345645018 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.2876155571462413, 'random_strength': 1, 'bagging_temperature': 0.03835852779507, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:20,486] Trial 583 finished with value: 0.8368889581576149 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.22932631931944306, 'random_strength': 0, 'bagging_temperature': 0.027440787619623614, 'od_type': 'IncToDec', 'od_wait': 13}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:21,382] Trial 584 finished with value: 0.8285262535262534 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.20940429739462368, 'random_strength': 4, 'bagging_temperature': 0.054806541506029746, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:22,329] Trial 585 finished with value: 0.8512233217188787 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.22338335846870738, 'random_strength': 59, 'bagging_temperature': 0.05995010571182654, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:23,203] Trial 586 finished with value: 0.8234879328004447 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.24630618173453156, 'random_strength': 7, 'bagging_temperature': 0.01808418252083362, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:23,842] Trial 587 finished with value: 0.8512233217188787 and parameters: {'iterations': 97, 'depth': 10, 'learning_rate': 0.18281789301788298, 'random_strength': 55, 'bagging_temperature': 0.40236050704954024, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:24,924] Trial 588 finished with value: 0.8465761215761216 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.20689956026053466, 'random_strength': 3, 'bagging_temperature': 0.08794293118510485, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:25,899] Trial 589 finished with value: 0.8499531034991649 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.23179046067989778, 'random_strength': 2, 'bagging_temperature': 0.11746211456015328, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:26,960] Trial 590 finished with value: 0.8368889581576149 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.25489534156791344, 'random_strength': 0, 'bagging_temperature': 0.04128218229150097, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:28,058] Trial 591 finished with value: 0.84191359062235 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.21210896804225196, 'random_strength': 5, 'bagging_temperature': 0.03308844150843779, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:29,158] Trial 592 finished with value: 0.8044843469837604 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.29743787665557475, 'random_strength': 9, 'bagging_temperature': 1.0085231900209832, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:30,098] Trial 593 finished with value: 0.8462775523686227 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.19480549144045003, 'random_strength': 47, 'bagging_temperature': 0.16850245663752692, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:30,915] Trial 594 finished with value: 0.83723505544913 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.24180720756997984, 'random_strength': 3, 'bagging_temperature': 0.02477969530265349, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:31,806] Trial 595 finished with value: 0.8226718495899223 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.22165534652911578, 'random_strength': 6, 'bagging_temperature': 0.04760205272821937, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:32,812] Trial 596 finished with value: 0.8328800815150558 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.27051932846058463, 'random_strength': 2, 'bagging_temperature': 0.06291240542639434, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:33,635] Trial 597 finished with value: 0.8328800815150558 and parameters: {'iterations': 105, 'depth': 10, 'learning_rate': 0.23650315908400388, 'random_strength': 0, 'bagging_temperature': 0.04129698592128501, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:34,570] Trial 598 finished with value: 0.845595020307664 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.203656054011577, 'random_strength': 4, 'bagging_temperature': 44.926968041639284, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:35,708] Trial 599 finished with value: 0.8368889581576149 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.22206344475016732, 'random_strength': 2, 'bagging_temperature': 0.03234130390440221, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:36,688] Trial 600 finished with value: 0.8503124686024315 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.18433849186179033, 'random_strength': 7, 'bagging_temperature': 0.02051685277895437, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:37,821] Trial 601 finished with value: 0.8328800815150558 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.07963272281231802, 'random_strength': 0, 'bagging_temperature': 0.05019433595172412, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:38,976] Trial 602 finished with value: 0.8503124686024315 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.25370816024141063, 'random_strength': 4, 'bagging_temperature': 0.037025940718405724, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:40,350] Trial 603 finished with value: 0.827429728579154 and parameters: {'iterations': 192, 'depth': 10, 'learning_rate': 0.1694894365710935, 'random_strength': 2, 'bagging_temperature': 1.4424598047526562, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:41,175] Trial 604 finished with value: 0.8462775523686227 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.22023270923103574, 'random_strength': 5, 'bagging_temperature': 0.07144661169123148, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:42,292] Trial 605 finished with value: 0.8285262535262534 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.19818987729350496, 'random_strength': 0, 'bagging_temperature': 0.02751687984124293, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:42,807] Trial 606 finished with value: 0.83723505544913 and parameters: {'iterations': 67, 'depth': 10, 'learning_rate': 0.2391107268294679, 'random_strength': 8, 'bagging_temperature': 2.871393134946471, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:43,954] Trial 607 finished with value: 0.8278272336108157 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.21002443859564043, 'random_strength': 3, 'bagging_temperature': 0.08995792163500724, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:44,985] Trial 608 finished with value: 0.8101075646906518 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.2706301670867141, 'random_strength': 6, 'bagging_temperature': 0.012265239247445787, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:45,253] Trial 609 finished with value: 0.8140245822030209 and parameters: {'iterations': 110, 'depth': 5, 'learning_rate': 0.2314060194880017, 'random_strength': 2, 'bagging_temperature': 0.05400541339509392, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:46,235] Trial 610 finished with value: 0.8462775523686227 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.2520760149713969, 'random_strength': 4, 'bagging_temperature': 0.043297795018133474, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:47,066] Trial 611 finished with value: 0.8140245822030209 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.21143159529604583, 'random_strength': 23, 'bagging_temperature': 0.03381503343022118, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:48,058] Trial 612 finished with value: 0.84191359062235 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.18848144416820542, 'random_strength': 0, 'bagging_temperature': 0.06773385127085416, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:48,875] Trial 613 finished with value: 0.827429728579154 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.06566315657016181, 'random_strength': 2, 'bagging_temperature': 0.6317187067901672, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:49,668] Trial 614 finished with value: 0.8553200492881156 and parameters: {'iterations': 101, 'depth': 10, 'learning_rate': 0.22806782264612205, 'random_strength': 6, 'bagging_temperature': 0.8298435387126547, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:50,805] Trial 615 finished with value: 0.8553200492881156 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.19907606010341017, 'random_strength': 4, 'bagging_temperature': 0.024419926913426173, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:51,824] Trial 616 finished with value: 0.8593844402022841 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.24290980861597697, 'random_strength': 2, 'bagging_temperature': 0.3567077332525676, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:52,736] Trial 617 finished with value: 0.8412404970025789 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.21640044054055574, 'random_strength': 11, 'bagging_temperature': 0.1947833131889335, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:53,761] Trial 618 finished with value: 0.8285262535262534 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.2264450783944993, 'random_strength': 0, 'bagging_temperature': 0.03822413957313483, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:54,556] Trial 619 finished with value: 0.83723505544913 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.26379874515994306, 'random_strength': 5, 'bagging_temperature': 0.047436927205918904, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:55,680] Trial 620 finished with value: 0.8368889581576149 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.20778586436044205, 'random_strength': 2, 'bagging_temperature': 0.029633024024079316, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:56,702] Trial 621 finished with value: 0.8325398336824732 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.24074106136286527, 'random_strength': 4, 'bagging_temperature': 0.05705638472256648, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:57,623] Trial 622 finished with value: 0.8187655090640165 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.17425788322237937, 'random_strength': 0, 'bagging_temperature': 0.12818177965185226, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:57,985] Trial 623 finished with value: 0.8187655090640165 and parameters: {'iterations': 115, 'depth': 7, 'learning_rate': 0.19408836006851427, 'random_strength': 8, 'bagging_temperature': 0.0794997735050592, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:54:59,036] Trial 624 finished with value: 0.8640741317980124 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.22106579335531523, 'random_strength': 2, 'bagging_temperature': 0.034111209276380255, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:00,156] Trial 625 finished with value: 0.8321685254027262 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.21228369077950832, 'random_strength': 2, 'bagging_temperature': 0.028887841317884355, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:01,585] Trial 626 finished with value: 0.8195013195013195 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.19791036316534283, 'random_strength': 0, 'bagging_temperature': 0.03523927612659805, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:02,700] Trial 627 finished with value: 0.8637603120361742 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.2239962219755108, 'random_strength': 2, 'bagging_temperature': 0.020492168349493717, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:03,796] Trial 628 finished with value: 0.8506436354465302 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.21745490086532535, 'random_strength': 2, 'bagging_temperature': 0.02599710267985721, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:04,908] Trial 629 finished with value: 0.8328800815150558 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.18165039548116207, 'random_strength': 0, 'bagging_temperature': 0.02362280597733089, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:05,963] Trial 630 finished with value: 0.8375511875511874 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.2036969265095707, 'random_strength': 3, 'bagging_temperature': 0.013933825622938042, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:06,969] Trial 631 finished with value: 0.8462775523686227 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.2159626031022726, 'random_strength': 4, 'bagging_temperature': 0.023881975636598288, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:07,983] Trial 632 finished with value: 0.833469421937483 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.19830392828257892, 'random_strength': 74, 'bagging_temperature': 0.01970592460409361, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:09,059] Trial 633 finished with value: 0.8462775523686227 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.18725747497335413, 'random_strength': 0, 'bagging_temperature': 0.015593082943193724, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:10,182] Trial 634 finished with value: 0.8637603120361742 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.22402160956604808, 'random_strength': 2, 'bagging_temperature': 0.021181372391119984, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:11,154] Trial 635 finished with value: 0.8281925585296372 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.20919695242776926, 'random_strength': 65, 'bagging_temperature': 0.01694025357774111, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:12,261] Trial 636 finished with value: 0.8278272336108157 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.2270725082250918, 'random_strength': 3, 'bagging_temperature': 0.0216023091720469, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:13,300] Trial 637 finished with value: 0.83723505544913 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.25011434873484756, 'random_strength': 6, 'bagging_temperature': 0.019587224864975467, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:14,271] Trial 638 finished with value: 0.8459506827044141 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.2177765877455427, 'random_strength': 41, 'bagging_temperature': 0.015630252846865585, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:15,398] Trial 639 finished with value: 0.8317656008930031 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.1592225543765269, 'random_strength': 1, 'bagging_temperature': 0.011803299045136136, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:16,437] Trial 640 finished with value: 0.8462775523686227 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.19775711756435518, 'random_strength': 4, 'bagging_temperature': 0.017241433069224647, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:17,539] Trial 641 finished with value: 0.8512233217188787 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.22984404596847072, 'random_strength': 0, 'bagging_temperature': 0.02365488766947753, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:18,763] Trial 642 finished with value: 0.8465761215761216 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.18669103596387218, 'random_strength': 2, 'bagging_temperature': 0.025096958840238433, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:20,033] Trial 643 finished with value: 0.8321685254027262 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.25000309241592295, 'random_strength': 6, 'bagging_temperature': 0.018500905171971446, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:21,062] Trial 644 finished with value: 0.8278272336108157 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.20872052750919837, 'random_strength': 4, 'bagging_temperature': 0.01884861627892008, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:21,729] Trial 645 finished with value: 0.8368889581576149 and parameters: {'iterations': 152, 'depth': 9, 'learning_rate': 0.2232789669078679, 'random_strength': 31, 'bagging_temperature': 0.021172237634382675, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:22,789] Trial 646 finished with value: 0.8415917345645018 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.04267970617016479, 'random_strength': 2, 'bagging_temperature': 0.015415201076664416, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:24,053] Trial 647 finished with value: 0.8465761215761216 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.1766034013246807, 'random_strength': 0, 'bagging_temperature': 0.02784193830584026, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:25,042] Trial 648 finished with value: 0.8465761215761216 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.24127613025481184, 'random_strength': 4, 'bagging_temperature': 0.020578876318268564, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:26,099] Trial 649 finished with value: 0.8506436354465302 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.20566526478631933, 'random_strength': 2, 'bagging_temperature': 0.028911132086346648, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:27,133] Trial 650 finished with value: 0.8044843469837604 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.2736283864895587, 'random_strength': 7, 'bagging_temperature': 0.033331520596424656, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:28,297] Trial 651 finished with value: 0.8281925585296372 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.22916197376542363, 'random_strength': 0, 'bagging_temperature': 0.28940930383315405, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:29,287] Trial 652 finished with value: 0.8368889581576149 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.13660742192003522, 'random_strength': 4, 'bagging_temperature': 0.023148306960054963, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:30,373] Trial 653 finished with value: 0.8648648648648649 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.21598117351078988, 'random_strength': 2, 'bagging_temperature': 0.02912505949553427, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:31,439] Trial 654 finished with value: 0.83723505544913 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.2380767809178109, 'random_strength': 0, 'bagging_temperature': 0.030176961713726375, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:32,504] Trial 655 finished with value: 0.8509470997296442 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.2531146212568616, 'random_strength': 2, 'bagging_temperature': 0.02870337223937596, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:33,759] Trial 656 finished with value: 0.8506436354465302 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.2184019620830794, 'random_strength': 2, 'bagging_temperature': 0.02022252596341728, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:34,839] Trial 657 finished with value: 0.8328800815150558 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.22182570976123572, 'random_strength': 0, 'bagging_temperature': 0.01371819367979921, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:35,923] Trial 658 finished with value: 0.8465761215761216 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.2599103934070704, 'random_strength': 2, 'bagging_temperature': 0.03203920495067819, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:36,851] Trial 659 finished with value: 0.8328800815150558 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.23823893557319617, 'random_strength': 36, 'bagging_temperature': 0.024331491849544105, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:37,638] Trial 660 finished with value: 0.8087888675268976 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.029087285705037304, 'random_strength': 5, 'bagging_temperature': 0.026105511440363553, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:38,339] Trial 661 finished with value: 0.8462775523686227 and parameters: {'iterations': 149, 'depth': 9, 'learning_rate': 0.20957902057989325, 'random_strength': 3, 'bagging_temperature': 0.03527472740555693, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:39,360] Trial 662 finished with value: 0.84191359062235 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.28060877754595515, 'random_strength': 0, 'bagging_temperature': 0.03426915429443812, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:40,358] Trial 663 finished with value: 0.8503124686024315 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.19182875872225696, 'random_strength': 2, 'bagging_temperature': 0.01864945852236147, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:41,356] Trial 664 finished with value: 0.8462775523686227 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.2305652430019883, 'random_strength': 5, 'bagging_temperature': 17.285876194134747, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:42,389] Trial 665 finished with value: 0.8356654636603111 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.2536995125905099, 'random_strength': 9, 'bagging_temperature': 0.0255766220931598, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:43,358] Trial 666 finished with value: 0.83723505544913 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.2218116079053054, 'random_strength': 3, 'bagging_temperature': 0.03828638737992541, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:44,385] Trial 667 finished with value: 0.8278272336108157 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.20749655243644688, 'random_strength': 20, 'bagging_temperature': 0.031038242566767307, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:45,496] Trial 668 finished with value: 0.8465761215761216 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.2389470399858332, 'random_strength': 0, 'bagging_temperature': 0.46469417333365515, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:46,487] Trial 669 finished with value: 0.8281925585296372 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.19638417839090355, 'random_strength': 6, 'bagging_temperature': 0.021286775395269596, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:47,615] Trial 670 finished with value: 0.8690141179442328 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.21995261024998883, 'random_strength': 2, 'bagging_temperature': 0.03818509646372318, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 171 with value: 0.8690141179442328.\n","[I 2024-04-02 05:55:48,783] Trial 671 finished with value: 0.8692568584802268 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.2156237931259571, 'random_strength': 2, 'bagging_temperature': 0.04100419966597366, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:55:49,950] Trial 672 finished with value: 0.8281925585296372 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.1837436439008583, 'random_strength': 4, 'bagging_temperature': 0.02827135559601227, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:55:51,200] Trial 673 finished with value: 0.8183470827148989 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.2103583152042896, 'random_strength': 2, 'bagging_temperature': 0.04007773642843162, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:55:52,478] Trial 674 finished with value: 0.8234879328004447 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.19542855650638147, 'random_strength': 0, 'bagging_temperature': 0.016216980126618978, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:55:53,706] Trial 675 finished with value: 0.8140245822030209 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.2122924148072144, 'random_strength': 7, 'bagging_temperature': 0.031926368258618984, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:55:54,900] Trial 676 finished with value: 0.8368889581576149 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.21958641604443976, 'random_strength': 4, 'bagging_temperature': 0.03931202016663265, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:55:56,079] Trial 677 finished with value: 0.8553200492881156 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.1942850577743282, 'random_strength': 2, 'bagging_temperature': 0.028466627851580266, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:55:56,939] Trial 678 finished with value: 0.8331897849575306 and parameters: {'iterations': 169, 'depth': 9, 'learning_rate': 0.17076616585395377, 'random_strength': 0, 'bagging_temperature': 0.02338647083635434, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:55:58,175] Trial 679 finished with value: 0.8230965538028735 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.23774392005099884, 'random_strength': 6, 'bagging_temperature': 0.035070382690453525, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:55:59,291] Trial 680 finished with value: 0.827429728579154 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.047688686052788976, 'random_strength': 3, 'bagging_temperature': 61.599076441286485, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:00,430] Trial 681 finished with value: 0.8325398336824732 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.20415054395094664, 'random_strength': 51, 'bagging_temperature': 0.021867200514524652, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:01,609] Trial 682 finished with value: 0.8278272336108157 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.25971570599957383, 'random_strength': 2, 'bagging_temperature': 0.04067202556474822, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:02,924] Trial 683 finished with value: 0.8375511875511874 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.2250041955464315, 'random_strength': 5, 'bagging_temperature': 0.044407322527465744, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:04,206] Trial 684 finished with value: 0.8412404970025789 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.2430494156290267, 'random_strength': 0, 'bagging_temperature': 0.2323952091250273, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:05,563] Trial 685 finished with value: 0.836512374443409 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.21533546433978268, 'random_strength': 8, 'bagging_temperature': 0.03134661773040147, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:06,762] Trial 686 finished with value: 0.8278272336108157 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.18570469768458023, 'random_strength': 4, 'bagging_temperature': 0.02625790234874101, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:08,157] Trial 687 finished with value: 0.8509470997296442 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.22933867314660572, 'random_strength': 2, 'bagging_temperature': 0.04759552273874933, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:09,336] Trial 688 finished with value: 0.8509470997296442 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.2047358575661484, 'random_strength': 0, 'bagging_temperature': 0.036435238983626, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:10,739] Trial 689 finished with value: 0.840859352196084 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.2490010017313902, 'random_strength': 4, 'bagging_temperature': 0.02847959829490733, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:11,889] Trial 690 finished with value: 0.8368889581576149 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.2771917874891313, 'random_strength': 2, 'bagging_temperature': 0.020012343874988684, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:13,240] Trial 691 finished with value: 0.8368889581576149 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.2196714088744644, 'random_strength': 6, 'bagging_temperature': 0.04075538349627748, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:14,436] Trial 692 finished with value: 0.8412404970025789 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.20011516447869482, 'random_strength': 2, 'bagging_temperature': 0.054377690024536594, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:15,560] Trial 693 finished with value: 0.8226718495899223 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.23243330941621046, 'random_strength': 10, 'bagging_temperature': 0.033938529691737905, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:16,781] Trial 694 finished with value: 0.8321685254027262 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.25410868785192253, 'random_strength': 0, 'bagging_temperature': 0.017760973602532776, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:17,992] Trial 695 finished with value: 0.8415917345645018 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.21688311291096862, 'random_strength': 5, 'bagging_temperature': 0.024935143377324654, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:19,369] Trial 696 finished with value: 0.8415917345645018 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.19217042980170496, 'random_strength': 3, 'bagging_temperature': 0.012958132168117172, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:19,835] Trial 697 finished with value: 0.8087888675268976 and parameters: {'iterations': 149, 'depth': 7, 'learning_rate': 0.023459134510655053, 'random_strength': 7, 'bagging_temperature': 0.04537676403715168, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:21,047] Trial 698 finished with value: 0.8602400900995527 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.23496810839062543, 'random_strength': 0, 'bagging_temperature': 0.032852062189548954, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:21,961] Trial 699 finished with value: 0.8415917345645018 and parameters: {'iterations': 156, 'depth': 9, 'learning_rate': 0.26364841140185485, 'random_strength': 0, 'bagging_temperature': 0.029194909088304962, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:23,064] Trial 700 finished with value: 0.8288288288288288 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.23980960399038903, 'random_strength': 0, 'bagging_temperature': 0.727652429896947, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:24,205] Trial 701 finished with value: 0.8321685254027262 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.2806161557975284, 'random_strength': 2, 'bagging_temperature': 0.5499226251909073, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:25,524] Trial 702 finished with value: 0.8412404970025789 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.2428917139249006, 'random_strength': 0, 'bagging_temperature': 0.021844777564755894, 'od_type': 'IncToDec', 'od_wait': 11}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:26,694] Trial 703 finished with value: 0.8506436354465302 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.29739277337828024, 'random_strength': 4, 'bagging_temperature': 0.03769430112353426, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:27,827] Trial 704 finished with value: 0.8465761215761216 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.2631848614478165, 'random_strength': 2, 'bagging_temperature': 0.04735817714000612, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:28,273] Trial 705 finished with value: 0.8191500616101444 and parameters: {'iterations': 172, 'depth': 6, 'learning_rate': 0.0941595587043755, 'random_strength': 4, 'bagging_temperature': 0.05522154003407461, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:29,586] Trial 706 finished with value: 0.8238465724077614 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.22627633132922806, 'random_strength': 14, 'bagging_temperature': 0.02594293911261213, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:30,895] Trial 707 finished with value: 0.8198198198198198 and parameters: {'iterations': 269, 'depth': 10, 'learning_rate': 0.23110761109675013, 'random_strength': 0, 'bagging_temperature': 0.03200028233463617, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:32,164] Trial 708 finished with value: 0.8404477351845774 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.24471731437003266, 'random_strength': 2, 'bagging_temperature': 0.016325220116105495, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:33,206] Trial 709 finished with value: 0.8191500616101444 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.207715543628722, 'random_strength': 6, 'bagging_temperature': 0.9337950437007694, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:34,328] Trial 710 finished with value: 0.8556010556010556 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.25583890325514536, 'random_strength': 2, 'bagging_temperature': 0.04202201866108459, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:34,633] Trial 711 finished with value: 0.8148130633004671 and parameters: {'iterations': 151, 'depth': 4, 'learning_rate': 0.21847396718244683, 'random_strength': 4, 'bagging_temperature': 0.05956102512946002, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:35,767] Trial 712 finished with value: 0.8241730165768567 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.23338291943860487, 'random_strength': 0, 'bagging_temperature': 0.038424663792777286, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:37,047] Trial 713 finished with value: 0.8462775523686227 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.20589054268951357, 'random_strength': 2, 'bagging_temperature': 0.03246012433223161, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:38,174] Trial 714 finished with value: 0.8285262535262534 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.17831284395005093, 'random_strength': 4, 'bagging_temperature': 0.32603120820598624, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:39,150] Trial 715 finished with value: 0.8281925585296372 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.22548362062262084, 'random_strength': 8, 'bagging_temperature': 0.024573232839279084, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:39,684] Trial 716 finished with value: 0.8234879328004447 and parameters: {'iterations': 140, 'depth': 8, 'learning_rate': 0.2457434144605781, 'random_strength': 83, 'bagging_temperature': 0.04523644569346221, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:40,826] Trial 717 finished with value: 0.8328800815150558 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.21643099007866767, 'random_strength': 0, 'bagging_temperature': 0.02854002827106793, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:41,537] Trial 718 finished with value: 0.8222131906342433 and parameters: {'iterations': 148, 'depth': 9, 'learning_rate': 0.19599198340471363, 'random_strength': 90, 'bagging_temperature': 0.06287982499858495, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:42,757] Trial 719 finished with value: 0.8321685254027262 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.27108066789363927, 'random_strength': 6, 'bagging_temperature': 0.019595710351663034, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:43,758] Trial 720 finished with value: 0.8285262535262534 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.2315341373580972, 'random_strength': 3, 'bagging_temperature': 0.0375400133108347, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:45,120] Trial 721 finished with value: 0.84191359062235 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.20489024054577915, 'random_strength': 2, 'bagging_temperature': 0.05231758969166531, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:46,044] Trial 722 finished with value: 0.8130959183590762 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.012404652570784984, 'random_strength': 5, 'bagging_temperature': 0.4101846570848498, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:47,149] Trial 723 finished with value: 0.84191359062235 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.2470661115834792, 'random_strength': 0, 'bagging_temperature': 0.03483052889208491, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:48,160] Trial 724 finished with value: 0.8506436354465302 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.21147670112264258, 'random_strength': 2, 'bagging_temperature': 0.04951157267489508, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:49,154] Trial 725 finished with value: 0.8422065533382046 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.26111426103195395, 'random_strength': 29, 'bagging_temperature': 0.021552388509601804, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:50,341] Trial 726 finished with value: 0.8317656008930031 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.22960982535706, 'random_strength': 4, 'bagging_temperature': 0.02748679945136627, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:51,504] Trial 727 finished with value: 0.8512233217188787 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.19260097387902206, 'random_strength': 0, 'bagging_temperature': 0.041178084649896, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:52,521] Trial 728 finished with value: 0.8135780982868414 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.22145490204560322, 'random_strength': 9, 'bagging_temperature': 0.03454960102054026, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:53,770] Trial 729 finished with value: 0.8459506827044141 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.2427044965427994, 'random_strength': 2, 'bagging_temperature': 0.07422277349270796, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:54,647] Trial 730 finished with value: 0.8415917345645018 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.1834555556958771, 'random_strength': 6, 'bagging_temperature': 0.016679613936867524, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:55,811] Trial 731 finished with value: 0.827429728579154 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.21202929354491074, 'random_strength': 4, 'bagging_temperature': 0.023780459200839942, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:56,865] Trial 732 finished with value: 0.8550124072512131 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.2351531864810437, 'random_strength': 2, 'bagging_temperature': 0.030690006073755344, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:58,166] Trial 733 finished with value: 0.8325398336824732 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.26228400763805726, 'random_strength': 0, 'bagging_temperature': 0.0568123226446825, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:56:59,227] Trial 734 finished with value: 0.8278272336108157 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.20026173522804017, 'random_strength': 4, 'bagging_temperature': 0.014291245108394395, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:00,070] Trial 735 finished with value: 0.8328800815150558 and parameters: {'iterations': 173, 'depth': 9, 'learning_rate': 0.2191259387843152, 'random_strength': 7, 'bagging_temperature': 0.04346857820968922, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:01,293] Trial 736 finished with value: 0.840859352196084 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.1704596910697266, 'random_strength': 2, 'bagging_temperature': 0.24798538719596433, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:02,355] Trial 737 finished with value: 0.8556010556010556 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.24665488902815125, 'random_strength': 0, 'bagging_temperature': 0.06779279495272755, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:03,589] Trial 738 finished with value: 0.8412404970025789 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.2812273413196938, 'random_strength': 4, 'bagging_temperature': 0.0321407955271773, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:04,776] Trial 739 finished with value: 0.8412404970025789 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.22805087712914773, 'random_strength': 2, 'bagging_temperature': 0.02600966232623231, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:05,737] Trial 740 finished with value: 0.8234879328004447 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.20433909241840384, 'random_strength': 6, 'bagging_temperature': 0.04798823903988608, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:06,875] Trial 741 finished with value: 0.83723505544913 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.21502491441045835, 'random_strength': 3, 'bagging_temperature': 0.03973438114996691, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:07,917] Trial 742 finished with value: 0.8422065533382046 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.2340943990725122, 'random_strength': 0, 'bagging_temperature': 0.010474931708157748, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:09,046] Trial 743 finished with value: 0.8375511875511874 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.1868051856423969, 'random_strength': 5, 'bagging_temperature': 0.6268573025080414, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:09,741] Trial 744 finished with value: 0.827429728579154 and parameters: {'iterations': 84, 'depth': 10, 'learning_rate': 0.08713139473286066, 'random_strength': 2, 'bagging_temperature': 1.0888779318320594, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:10,766] Trial 745 finished with value: 0.8135780982868414 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.01116233342465009, 'random_strength': 4, 'bagging_temperature': 0.021029278814459682, 'od_type': 'Iter', 'od_wait': 15}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:11,912] Trial 746 finished with value: 0.8380954533128446 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.035595063223980504, 'random_strength': 0, 'bagging_temperature': 0.034050235155336665, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:12,991] Trial 747 finished with value: 0.836512374443409 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.24919958424605798, 'random_strength': 11, 'bagging_temperature': 0.05945137153163193, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:13,908] Trial 748 finished with value: 0.8187655090640165 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.1985368452543247, 'random_strength': 8, 'bagging_temperature': 0.050418718653067, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:15,079] Trial 749 finished with value: 0.8503124686024315 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.2207316429976407, 'random_strength': 2, 'bagging_temperature': 0.026884897851956878, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:16,139] Trial 750 finished with value: 0.8459506827044141 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.2607591384594499, 'random_strength': 4, 'bagging_temperature': 0.2023058410316894, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:16,979] Trial 751 finished with value: 0.8509470997296442 and parameters: {'iterations': 116, 'depth': 10, 'learning_rate': 0.23506700372954167, 'random_strength': 6, 'bagging_temperature': 0.16224802168352973, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:18,066] Trial 752 finished with value: 0.8556010556010556 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.20428193636719616, 'random_strength': 2, 'bagging_temperature': 0.039635980013555006, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:19,107] Trial 753 finished with value: 0.8412404970025789 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.2140738207614117, 'random_strength': 0, 'bagging_temperature': 0.03090052803189579, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:20,245] Trial 754 finished with value: 0.8468468468468469 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.22780263447250795, 'random_strength': 70, 'bagging_temperature': 0.04429995779913304, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:21,378] Trial 755 finished with value: 0.8321685254027262 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.24856547784437943, 'random_strength': 3, 'bagging_temperature': 0.023304006434629883, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:22,364] Trial 756 finished with value: 0.8412404970025789 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.21560848956913356, 'random_strength': 25, 'bagging_temperature': 0.06944447619549218, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:23,252] Trial 757 finished with value: 0.8321685254027262 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.19123825225042138, 'random_strength': 5, 'bagging_temperature': 0.018870820263084957, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:24,293] Trial 758 finished with value: 0.8244677690692389 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.2722063228428347, 'random_strength': 94, 'bagging_temperature': 0.03559466473289977, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:24,851] Trial 759 finished with value: 0.8285262535262534 and parameters: {'iterations': 105, 'depth': 9, 'learning_rate': 0.23639323365530537, 'random_strength': 0, 'bagging_temperature': 0.05351672948431527, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:25,794] Trial 760 finished with value: 0.8183470827148989 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.2049778138890105, 'random_strength': 8, 'bagging_temperature': 0.8547528380563556, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:26,953] Trial 761 finished with value: 0.8321685254027262 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.1818515017816527, 'random_strength': 2, 'bagging_temperature': 0.02813027653173182, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:27,820] Trial 762 finished with value: 0.8415917345645018 and parameters: {'iterations': 116, 'depth': 10, 'learning_rate': 0.2524483342669431, 'random_strength': 4, 'bagging_temperature': 0.03794582256982838, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:28,616] Trial 763 finished with value: 0.8278272336108157 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.06070674169813549, 'random_strength': 18, 'bagging_temperature': 0.043342797584448846, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:29,765] Trial 764 finished with value: 0.845595020307664 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.22596652338051793, 'random_strength': 2, 'bagging_temperature': 0.030882536938446673, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:30,978] Trial 765 finished with value: 0.8368889581576149 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.21291202730233663, 'random_strength': 6, 'bagging_temperature': 0.4746422672558941, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:32,061] Trial 766 finished with value: 0.8509470997296442 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.24031192725862224, 'random_strength': 0, 'bagging_temperature': 0.06112622702032701, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:32,919] Trial 767 finished with value: 0.840859352196084 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.1962970713074418, 'random_strength': 3, 'bagging_temperature': 0.02218679124733036, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:34,142] Trial 768 finished with value: 0.8281925585296372 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.22292327587328276, 'random_strength': 1, 'bagging_temperature': 0.3499240691527139, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:35,119] Trial 769 finished with value: 0.836512374443409 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.26154857285306093, 'random_strength': 6, 'bagging_temperature': 0.017359566104400013, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:36,214] Trial 770 finished with value: 0.8415917345645018 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.2367306650901096, 'random_strength': 4, 'bagging_temperature': 0.05060930487656777, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:37,047] Trial 771 finished with value: 0.8375511875511874 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.20696034480712366, 'random_strength': 77, 'bagging_temperature': 0.08685780866474754, 'od_type': 'IncToDec', 'od_wait': 14}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:37,959] Trial 772 finished with value: 0.8422065533382046 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.2221531278807583, 'random_strength': 0, 'bagging_temperature': 0.03618140111239695, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:38,723] Trial 773 finished with value: 0.8230965538028735 and parameters: {'iterations': 156, 'depth': 9, 'learning_rate': 0.16269870964004163, 'random_strength': 2, 'bagging_temperature': 0.02574451721595524, 'od_type': 'IncToDec', 'od_wait': 21}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:39,272] Trial 774 finished with value: 0.8057795541931729 and parameters: {'iterations': 151, 'depth': 8, 'learning_rate': 0.2953202959100639, 'random_strength': 9, 'bagging_temperature': 0.046875015896109824, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:40,582] Trial 775 finished with value: 0.8201060592364939 and parameters: {'iterations': 294, 'depth': 10, 'learning_rate': 0.19057872704644385, 'random_strength': 48, 'bagging_temperature': 0.03154797264868151, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:41,929] Trial 776 finished with value: 0.8452100356170124 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.24870583120434486, 'random_strength': 4, 'bagging_temperature': 0.07541070163231074, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:43,103] Trial 777 finished with value: 0.8378378378378378 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.27424881869670575, 'random_strength': 2, 'bagging_temperature': 1.2174317056653434, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:43,486] Trial 778 finished with value: 0.8001817909863886 and parameters: {'iterations': 131, 'depth': 6, 'learning_rate': 0.03176944237715788, 'random_strength': 7, 'bagging_temperature': 0.0408257594355489, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:44,463] Trial 779 finished with value: 0.8465761215761216 and parameters: {'iterations': 107, 'depth': 10, 'learning_rate': 0.21038914274559417, 'random_strength': 0, 'bagging_temperature': 0.027908671464778614, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:45,511] Trial 780 finished with value: 0.83723505544913 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.2326177461220696, 'random_strength': 4, 'bagging_temperature': 0.10315981323891409, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:46,680] Trial 781 finished with value: 0.8375511875511874 and parameters: {'iterations': 185, 'depth': 10, 'learning_rate': 0.1976842588969785, 'random_strength': 2, 'bagging_temperature': 0.014332058460114028, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:47,808] Trial 782 finished with value: 0.8187655090640165 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.22149870080555348, 'random_strength': 6, 'bagging_temperature': 0.05176784481854471, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:48,753] Trial 783 finished with value: 0.8509470997296442 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.2534658643615584, 'random_strength': 0, 'bagging_temperature': 0.034999273636441355, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:49,889] Trial 784 finished with value: 0.8412404970025789 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.17633481783621277, 'random_strength': 3, 'bagging_temperature': 0.2704801584274193, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:50,237] Trial 785 finished with value: 0.8321685254027262 and parameters: {'iterations': 175, 'depth': 5, 'learning_rate': 0.232312596563134, 'random_strength': 5, 'bagging_temperature': 0.06175566550438287, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:51,362] Trial 786 finished with value: 0.8328800815150558 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.20711284321136866, 'random_strength': 34, 'bagging_temperature': 0.02255735422224264, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:52,214] Trial 787 finished with value: 0.8462775523686227 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.24358617405174754, 'random_strength': 2, 'bagging_temperature': 0.04193019715401173, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:53,384] Trial 788 finished with value: 0.8558558558558559 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.2180721424472561, 'random_strength': 0, 'bagging_temperature': 0.01931720597527718, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:54,628] Trial 789 finished with value: 0.8278272336108157 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.2677040411195779, 'random_strength': 4, 'bagging_temperature': 0.02849714790561424, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:55,621] Trial 790 finished with value: 0.8462775523686227 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.20366904354248228, 'random_strength': 2, 'bagging_temperature': 0.03528260184894628, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:55,990] Trial 791 finished with value: 0.8234879328004447 and parameters: {'iterations': 101, 'depth': 7, 'learning_rate': 0.19165966134731813, 'random_strength': 6, 'bagging_temperature': 0.049947055298365614, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:57,075] Trial 792 finished with value: 0.8509470997296442 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.23076020744754272, 'random_strength': 0, 'bagging_temperature': 0.02426979307191542, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:58,104] Trial 793 finished with value: 0.836512374443409 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.21698691370603843, 'random_strength': 8, 'bagging_temperature': 0.06676762869381911, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:59,095] Trial 794 finished with value: 0.8412404970025789 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.24798852490370354, 'random_strength': 3, 'bagging_temperature': 0.04294420758359619, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:57:59,883] Trial 795 finished with value: 0.8368889581576149 and parameters: {'iterations': 151, 'depth': 9, 'learning_rate': 0.18553923187698995, 'random_strength': 2, 'bagging_temperature': 0.030927850235753562, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:00,840] Trial 796 finished with value: 0.83723505544913 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.22989660897401085, 'random_strength': 5, 'bagging_temperature': 0.05441749250645927, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:01,294] Trial 797 finished with value: 0.8331897849575306 and parameters: {'iterations': 58, 'depth': 10, 'learning_rate': 0.20680993612512075, 'random_strength': 45, 'bagging_temperature': 0.03796037098392965, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:02,230] Trial 798 finished with value: 0.8368889581576149 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.25840282256027614, 'random_strength': 0, 'bagging_temperature': 0.018344245876322062, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:03,441] Trial 799 finished with value: 0.8278272336108157 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.22018072627289234, 'random_strength': 4, 'bagging_temperature': 0.025970079120025354, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:04,720] Trial 800 finished with value: 0.8082763742703633 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.2400010130926778, 'random_strength': 10, 'bagging_temperature': 0.03244839419955478, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:05,760] Trial 801 finished with value: 0.8465761215761216 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.19688797611848122, 'random_strength': 2, 'bagging_temperature': 0.043580440109549756, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:06,338] Trial 802 finished with value: 0.8183470827148989 and parameters: {'iterations': 94, 'depth': 10, 'learning_rate': 0.053705729134125184, 'random_strength': 7, 'bagging_temperature': 0.07709479020980596, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:07,245] Trial 803 finished with value: 0.8317656008930031 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.21518296194427156, 'random_strength': 39, 'bagging_temperature': 0.11831635447828914, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:08,159] Trial 804 finished with value: 0.83723505544913 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.10190153632719208, 'random_strength': 2, 'bagging_temperature': 8.874973161609864, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:08,826] Trial 805 finished with value: 0.8424710748057271 and parameters: {'iterations': 154, 'depth': 9, 'learning_rate': 0.2818042866703941, 'random_strength': 0, 'bagging_temperature': 0.7440953247952029, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:10,090] Trial 806 finished with value: 0.8281925585296372 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.22983046169911092, 'random_strength': 4, 'bagging_temperature': 0.05518731305345784, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:10,948] Trial 807 finished with value: 0.8321685254027262 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.17270012021675007, 'random_strength': 2, 'bagging_temperature': 0.023172348573598837, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:12,143] Trial 808 finished with value: 0.836512374443409 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.24565988950449505, 'random_strength': 5, 'bagging_temperature': 0.584175137298229, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:13,092] Trial 809 finished with value: 0.8144360319184163 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.20541195201570472, 'random_strength': 61, 'bagging_temperature': 0.03886329624610342, 'od_type': 'Iter', 'od_wait': 13}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:14,063] Trial 810 finished with value: 0.8648648648648649 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.260865275433277, 'random_strength': 0, 'bagging_temperature': 0.04732498728681579, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:15,064] Trial 811 finished with value: 0.8281925585296372 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.2711623979760073, 'random_strength': 0, 'bagging_temperature': 0.06802716587711692, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:16,083] Trial 812 finished with value: 0.8556010556010556 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.28203977532036584, 'random_strength': 0, 'bagging_temperature': 0.06273316823457344, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:17,044] Trial 813 finished with value: 0.8238465724077614 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.2673953729531384, 'random_strength': 16, 'bagging_temperature': 0.09192770074439853, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:18,024] Trial 814 finished with value: 0.8503124686024315 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.2583887382232885, 'random_strength': 2, 'bagging_temperature': 0.0495515858417794, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:19,010] Trial 815 finished with value: 0.8321685254027262 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.2596304280468737, 'random_strength': 0, 'bagging_temperature': 0.05502568765869171, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:20,040] Trial 816 finished with value: 0.8325398336824732 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.24787783849520698, 'random_strength': 3, 'bagging_temperature': 0.04729821170462614, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:20,571] Trial 817 finished with value: 0.8375511875511874 and parameters: {'iterations': 133, 'depth': 8, 'learning_rate': 0.27504675983246674, 'random_strength': 0, 'bagging_temperature': 0.13562605515476372, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:21,555] Trial 818 finished with value: 0.8368889581576149 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.294627195005423, 'random_strength': 2, 'bagging_temperature': 0.07920939573480815, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:22,613] Trial 819 finished with value: 0.8459506827044141 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.2410167994288585, 'random_strength': 4, 'bagging_temperature': 0.06475903449670364, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:23,514] Trial 820 finished with value: 0.836512374443409 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.2536350120589746, 'random_strength': 6, 'bagging_temperature': 0.04194278000843102, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:24,601] Trial 821 finished with value: 0.8230965538028735 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.018475211665709923, 'random_strength': 2, 'bagging_temperature': 0.05599707923510482, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:24,954] Trial 822 finished with value: 0.8195013195013195 and parameters: {'iterations': 143, 'depth': 5, 'learning_rate': 0.23155303153855594, 'random_strength': 0, 'bagging_temperature': 0.9870742351488276, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:26,195] Trial 823 finished with value: 0.83723505544913 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.23985083044479819, 'random_strength': 4, 'bagging_temperature': 0.01216693867681901, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:27,266] Trial 824 finished with value: 0.8462775523686227 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.2683581164686369, 'random_strength': 2, 'bagging_temperature': 0.015244886358422116, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:28,327] Trial 825 finished with value: 0.8462775523686227 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.2231050235847744, 'random_strength': 0, 'bagging_temperature': 0.04611496468654789, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:29,236] Trial 826 finished with value: 0.8187655090640165 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.29107337843747055, 'random_strength': 8, 'bagging_temperature': 0.0343970955545933, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:30,430] Trial 827 finished with value: 0.83723505544913 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.2517841426912693, 'random_strength': 4, 'bagging_temperature': 0.3858154613203389, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:31,451] Trial 828 finished with value: 0.84191359062235 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.22886463805591678, 'random_strength': 6, 'bagging_temperature': 0.027968966653100415, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:32,351] Trial 829 finished with value: 0.8553200492881156 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.14561014725286228, 'random_strength': 2, 'bagging_temperature': 0.03903921890126694, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:33,312] Trial 830 finished with value: 0.8465761215761216 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.2994776121764515, 'random_strength': 4, 'bagging_temperature': 0.18646090520060848, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:34,601] Trial 831 finished with value: 0.8380954533128446 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.03970323011057965, 'random_strength': 0, 'bagging_temperature': 0.0211618421069154, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:35,332] Trial 832 finished with value: 0.8226718495899223 and parameters: {'iterations': 143, 'depth': 9, 'learning_rate': 0.21755063411216263, 'random_strength': 2, 'bagging_temperature': 0.031288411954138194, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:36,637] Trial 833 finished with value: 0.8278272336108157 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.24114251847661652, 'random_strength': 5, 'bagging_temperature': 0.05702174694502514, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:37,668] Trial 834 finished with value: 0.8321685254027262 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.20076767878285529, 'random_strength': 2, 'bagging_temperature': 0.29931190466369983, 'od_type': 'IncToDec', 'od_wait': 22}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:38,783] Trial 835 finished with value: 0.8512233217188787 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.22993671088597206, 'random_strength': 0, 'bagging_temperature': 0.047634837489894846, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:39,925] Trial 836 finished with value: 0.8195013195013195 and parameters: {'iterations': 225, 'depth': 10, 'learning_rate': 0.26290298115443095, 'random_strength': 54, 'bagging_temperature': 0.0670572484683846, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:40,850] Trial 837 finished with value: 0.8187655090640165 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.21253167604813367, 'random_strength': 7, 'bagging_temperature': 0.017815898579761895, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:41,888] Trial 838 finished with value: 0.8375511875511874 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.18922825262761134, 'random_strength': 3, 'bagging_temperature': 0.0416147665421345, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:43,203] Trial 839 finished with value: 0.8553200492881156 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.24500255326349538, 'random_strength': 4, 'bagging_temperature': 0.034186232010552015, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:44,368] Trial 840 finished with value: 0.8211912597869924 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.2201030024208931, 'random_strength': 13, 'bagging_temperature': 0.08287980027929413, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:45,709] Trial 841 finished with value: 0.8422065533382046 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.23408900634436633, 'random_strength': 0, 'bagging_temperature': 1.2606149603676813, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:46,792] Trial 842 finished with value: 0.8375511875511874 and parameters: {'iterations': 249, 'depth': 10, 'learning_rate': 0.20239975085780823, 'random_strength': 2, 'bagging_temperature': 0.4764039587077891, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:47,662] Trial 843 finished with value: 0.8230965538028735 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.2626558337379837, 'random_strength': 6, 'bagging_temperature': 0.028975612537777373, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:48,853] Trial 844 finished with value: 0.8234879328004447 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.2163033859797555, 'random_strength': 3, 'bagging_temperature': 0.021281780986371717, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:49,940] Trial 845 finished with value: 0.8556010556010556 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.24650978878438334, 'random_strength': 0, 'bagging_temperature': 0.10171910328078297, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:51,066] Trial 846 finished with value: 0.8044843469837604 and parameters: {'iterations': 210, 'depth': 10, 'learning_rate': 0.1827257975060972, 'random_strength': 8, 'bagging_temperature': 0.05234068295050602, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:51,850] Trial 847 finished with value: 0.8368889581576149 and parameters: {'iterations': 158, 'depth': 9, 'learning_rate': 0.2758118319638848, 'random_strength': 5, 'bagging_temperature': 0.025538697095134247, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:52,796] Trial 848 finished with value: 0.8646259896259897 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.22981415533238087, 'random_strength': 2, 'bagging_temperature': 0.036177745223722295, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:53,682] Trial 849 finished with value: 0.8503124686024315 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.07561704176291377, 'random_strength': 2, 'bagging_temperature': 0.03725926537836411, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:54,729] Trial 850 finished with value: 0.8368889581576149 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.197196746513608, 'random_strength': 10, 'bagging_temperature': 0.04205165510855106, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:55,734] Trial 851 finished with value: 0.8328800815150558 and parameters: {'iterations': 116, 'depth': 10, 'learning_rate': 0.11754505353846226, 'random_strength': 4, 'bagging_temperature': 0.03229202028122013, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:56,889] Trial 852 finished with value: 0.8514727276739713 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.2093275995385728, 'random_strength': 0, 'bagging_temperature': 0.04797265256319926, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:57,972] Trial 853 finished with value: 0.8593844402022841 and parameters: {'iterations': 116, 'depth': 10, 'learning_rate': 0.22560848820957383, 'random_strength': 2, 'bagging_temperature': 0.03580743525545488, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:58,906] Trial 854 finished with value: 0.8412404970025789 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.21149114132106836, 'random_strength': 6, 'bagging_temperature': 0.03076573480630673, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:58:59,855] Trial 855 finished with value: 0.8643625462076083 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.23011531418758746, 'random_strength': 2, 'bagging_temperature': 0.02555479786422081, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:00,389] Trial 856 finished with value: 0.8178941595494262 and parameters: {'iterations': 121, 'depth': 8, 'learning_rate': 0.18741572595508904, 'random_strength': 4, 'bagging_temperature': 0.024226967521120624, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:01,435] Trial 857 finished with value: 0.8230965538028735 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.1983261347938504, 'random_strength': 7, 'bagging_temperature': 0.018397577708062364, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:02,335] Trial 858 finished with value: 0.8593844402022841 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.22555712424133617, 'random_strength': 2, 'bagging_temperature': 0.027181767583966985, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:03,236] Trial 859 finished with value: 0.8368889581576149 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.15676420911629227, 'random_strength': 4, 'bagging_temperature': 0.022786236266124728, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:04,209] Trial 860 finished with value: 0.8550124072512131 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.2084373226116821, 'random_strength': 2, 'bagging_temperature': 0.02771463187533574, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:05,081] Trial 861 finished with value: 0.83723505544913 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.179298527767101, 'random_strength': 5, 'bagging_temperature': 0.016419384253693832, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:06,116] Trial 862 finished with value: 0.8241730165768567 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.22842976976143445, 'random_strength': 0, 'bagging_temperature': 0.020344593306579308, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:07,098] Trial 863 finished with value: 0.827429728579154 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.21669646392959666, 'random_strength': 3, 'bagging_temperature': 0.03493251042132687, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:08,115] Trial 864 finished with value: 0.8331897849575306 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.1991815582918165, 'random_strength': 6, 'bagging_temperature': 0.026434626806361976, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:09,241] Trial 865 finished with value: 0.8234879328004447 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.2327812312683832, 'random_strength': 9, 'bagging_temperature': 0.039351343841364364, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:10,168] Trial 866 finished with value: 0.8462775523686227 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.21229199231134124, 'random_strength': 0, 'bagging_temperature': 0.022238418820411093, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:11,233] Trial 867 finished with value: 0.8593844402022841 and parameters: {'iterations': 116, 'depth': 10, 'learning_rate': 0.24044771332782724, 'random_strength': 2, 'bagging_temperature': 93.79211851649814, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:12,297] Trial 868 finished with value: 0.8183470827148989 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.19569260688313536, 'random_strength': 4, 'bagging_temperature': 0.030938741301953857, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:13,279] Trial 869 finished with value: 0.8412404970025789 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.21966502620351627, 'random_strength': 2, 'bagging_temperature': 0.041326591276991245, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:14,366] Trial 870 finished with value: 0.8462775523686227 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.23612777959367184, 'random_strength': 0, 'bagging_temperature': 0.058305795359108833, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:14,765] Trial 871 finished with value: 0.8092644368506438 and parameters: {'iterations': 125, 'depth': 7, 'learning_rate': 0.20750438508658664, 'random_strength': 6, 'bagging_temperature': 0.04666547784809394, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:15,312] Trial 872 finished with value: 0.8459506827044141 and parameters: {'iterations': 279, 'depth': 6, 'learning_rate': 0.1676982469912411, 'random_strength': 4, 'bagging_temperature': 0.031463853980179236, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:15,994] Trial 873 finished with value: 0.8144360319184163 and parameters: {'iterations': 128, 'depth': 9, 'learning_rate': 0.014450201438010882, 'random_strength': 2, 'bagging_temperature': 0.025072008232747422, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:16,305] Trial 874 finished with value: 0.8238465724077614 and parameters: {'iterations': 134, 'depth': 4, 'learning_rate': 0.18889244734696822, 'random_strength': 12, 'bagging_temperature': 0.037185792996386635, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:17,306] Trial 875 finished with value: 0.8241730165768567 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.25167662713817096, 'random_strength': 8, 'bagging_temperature': 0.014742212887088928, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:18,393] Trial 876 finished with value: 0.8375511875511874 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.2235515533390389, 'random_strength': 0, 'bagging_temperature': 0.02004535037855447, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:19,307] Trial 877 finished with value: 0.8183470827148989 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.23692547204901737, 'random_strength': 4, 'bagging_temperature': 0.04882589625082971, 'od_type': 'IncToDec', 'od_wait': 12}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:20,557] Trial 878 finished with value: 0.8328800815150558 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.20632614721320633, 'random_strength': 2, 'bagging_temperature': 0.028638949918308017, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:21,471] Trial 879 finished with value: 0.8135780982868414 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.21886547783785062, 'random_strength': 6, 'bagging_temperature': 0.03584244199472424, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:22,499] Trial 880 finished with value: 0.8378378378378378 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.25084964909230706, 'random_strength': 0, 'bagging_temperature': 0.06813375599424892, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:23,364] Trial 881 finished with value: 0.8325398336824732 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.22896413588595974, 'random_strength': 3, 'bagging_temperature': 0.04335301865033115, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:24,536] Trial 882 finished with value: 0.8412404970025789 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.1951586279803617, 'random_strength': 5, 'bagging_temperature': 0.024840972750549566, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:25,487] Trial 883 finished with value: 0.827429728579154 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.21209117297317154, 'random_strength': 2, 'bagging_temperature': 0.05792604067105285, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:26,673] Trial 884 finished with value: 0.84191359062235 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.17677895366557686, 'random_strength': 0, 'bagging_temperature': 0.030871026319646992, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:27,616] Trial 885 finished with value: 0.8281925585296372 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.25592724811504375, 'random_strength': 4, 'bagging_temperature': 0.036197140725261055, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:28,414] Trial 886 finished with value: 0.8375511875511874 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.23745771619269862, 'random_strength': 8, 'bagging_temperature': 0.04659186803149014, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:29,604] Trial 887 finished with value: 0.8412404970025789 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.20078985042053574, 'random_strength': 3, 'bagging_temperature': 0.02301488588674001, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:30,824] Trial 888 finished with value: 0.8135780982868414 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.22224880270288486, 'random_strength': 1, 'bagging_temperature': 0.07698683297715364, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:31,526] Trial 889 finished with value: 0.8550124072512131 and parameters: {'iterations': 142, 'depth': 9, 'learning_rate': 0.2394068640474681, 'random_strength': 6, 'bagging_temperature': 0.01696469260869416, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:32,538] Trial 890 finished with value: 0.8468468468468469 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.18792682230559735, 'random_strength': 2, 'bagging_temperature': 0.02851468738477266, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:33,692] Trial 891 finished with value: 0.8514727276739713 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.21874182746665952, 'random_strength': 0, 'bagging_temperature': 0.05899436634014787, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:34,851] Trial 892 finished with value: 0.8462775523686227 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.25911124268061453, 'random_strength': 4, 'bagging_temperature': 0.0409612183503121, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:35,780] Trial 893 finished with value: 0.84191359062235 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.2046530762453472, 'random_strength': 2, 'bagging_temperature': 0.034396059791316734, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:36,886] Trial 894 finished with value: 0.8462775523686227 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.2315262361049215, 'random_strength': 5, 'bagging_temperature': 0.019689572344799084, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:37,987] Trial 895 finished with value: 0.8473064211998946 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.21098472380039177, 'random_strength': 0, 'bagging_temperature': 0.04855420320021795, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:38,848] Trial 896 finished with value: 0.8328800815150558 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.2742944203530118, 'random_strength': 7, 'bagging_temperature': 5.379482765860081, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:39,840] Trial 897 finished with value: 0.8415917345645018 and parameters: {'iterations': 105, 'depth': 10, 'learning_rate': 0.22518143972389731, 'random_strength': 3, 'bagging_temperature': 0.028031731456773828, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:41,013] Trial 898 finished with value: 0.8462775523686227 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.24695727540929133, 'random_strength': 2, 'bagging_temperature': 0.04132632649069899, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:42,064] Trial 899 finished with value: 0.8183470827148989 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.19344900269416265, 'random_strength': 5, 'bagging_temperature': 0.034328152128007404, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:43,121] Trial 900 finished with value: 0.8044843469837604 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.2210340174931107, 'random_strength': 10, 'bagging_temperature': 0.05533362238588472, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:44,076] Trial 901 finished with value: 0.8550124072512131 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.24144212905816592, 'random_strength': 0, 'bagging_temperature': 0.022684011993342593, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:45,123] Trial 902 finished with value: 0.827429728579154 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.20880874001989855, 'random_strength': 3, 'bagging_temperature': 0.0331837365921459, 'od_type': 'IncToDec', 'od_wait': 14}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:46,107] Trial 903 finished with value: 0.8512233217188787 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.25797149335796443, 'random_strength': 2, 'bagging_temperature': 0.04753875792970454, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:47,306] Trial 904 finished with value: 0.827429728579154 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.17818260050432658, 'random_strength': 7, 'bagging_temperature': 13.256628495084094, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:48,268] Trial 905 finished with value: 0.8187655090640165 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.2326454117104468, 'random_strength': 41, 'bagging_temperature': 0.026551321678940254, 'od_type': 'IncToDec', 'od_wait': 16}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:49,332] Trial 906 finished with value: 0.8468468468468469 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.06947689370713021, 'random_strength': 0, 'bagging_temperature': 0.07361278582005937, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:50,295] Trial 907 finished with value: 0.8368889581576149 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.200049745452172, 'random_strength': 4, 'bagging_temperature': 0.04108613603878119, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:51,412] Trial 908 finished with value: 0.8361047435944837 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.2142556783531922, 'random_strength': 2, 'bagging_temperature': 0.061868029580320213, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:52,381] Trial 909 finished with value: 0.845595020307664 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.22912484702663913, 'random_strength': 5, 'bagging_temperature': 0.09313654304555763, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:53,462] Trial 910 finished with value: 0.8285262535262534 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.248957739907199, 'random_strength': 0, 'bagging_temperature': 0.017808416773545888, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:54,348] Trial 911 finished with value: 0.8495650074597443 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.28014223934047083, 'random_strength': 2, 'bagging_temperature': 0.02411964424059898, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:54,950] Trial 912 finished with value: 0.8593844402022841 and parameters: {'iterations': 117, 'depth': 9, 'learning_rate': 0.1903245931090416, 'random_strength': 4, 'bagging_temperature': 0.15033711199104458, 'od_type': 'IncToDec', 'od_wait': 22}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:56,018] Trial 913 finished with value: 0.8151562481961826 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.22014652285354724, 'random_strength': 7, 'bagging_temperature': 0.03003978902574716, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:56,898] Trial 914 finished with value: 0.8368889581576149 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.04503829126021709, 'random_strength': 2, 'bagging_temperature': 0.013792926043237936, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:58,002] Trial 915 finished with value: 0.8415917345645018 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.20445077921246368, 'random_strength': 4, 'bagging_temperature': 0.03789982237669805, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:58,881] Trial 916 finished with value: 0.83723505544913 and parameters: {'iterations': 107, 'depth': 10, 'learning_rate': 0.2379491951036599, 'random_strength': 0, 'bagging_temperature': 0.04929612069373059, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 05:59:59,932] Trial 917 finished with value: 0.8230965538028735 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.26277041896005066, 'random_strength': 6, 'bagging_temperature': 0.03378967717130834, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:00,859] Trial 918 finished with value: 0.8281925585296372 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.22264125416016234, 'random_strength': 2, 'bagging_temperature': 0.020383596906524096, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:01,902] Trial 919 finished with value: 0.8361047435944837 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.2449010003942497, 'random_strength': 9, 'bagging_temperature': 0.061427626692337416, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:02,980] Trial 920 finished with value: 0.8281925585296372 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.20784757728910572, 'random_strength': 0, 'bagging_temperature': 0.04307309009267176, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:04,114] Trial 921 finished with value: 0.8281925585296372 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.18374491559131328, 'random_strength': 4, 'bagging_temperature': 0.027872783380827475, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:05,149] Trial 922 finished with value: 0.8375511875511874 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.22703909392003574, 'random_strength': 2, 'bagging_temperature': 0.05265871694104539, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:06,007] Trial 923 finished with value: 0.8278272336108157 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.21129865791172991, 'random_strength': 5, 'bagging_temperature': 0.11180675745398445, 'od_type': 'IncToDec', 'od_wait': 21}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:06,996] Trial 924 finished with value: 0.8648648648648649 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.19634769795419815, 'random_strength': 0, 'bagging_temperature': 0.0394518479646286, 'od_type': 'Iter', 'od_wait': 20}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:07,978] Trial 925 finished with value: 0.8328800815150558 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.18216165770196469, 'random_strength': 0, 'bagging_temperature': 0.02993337436135396, 'od_type': 'Iter', 'od_wait': 13}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:09,042] Trial 926 finished with value: 0.8154661162009946 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.016233463192937878, 'random_strength': 0, 'bagging_temperature': 0.023947425559052844, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:10,056] Trial 927 finished with value: 0.8465761215761216 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.1581659067426235, 'random_strength': 2, 'bagging_temperature': 0.035540819588294255, 'od_type': 'IncToDec', 'od_wait': 21}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:10,881] Trial 928 finished with value: 0.84191359062235 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.1689268886589826, 'random_strength': 66, 'bagging_temperature': 0.03941908290419338, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:11,827] Trial 929 finished with value: 0.8238465724077614 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.19124981279463674, 'random_strength': 0, 'bagging_temperature': 0.0313093498047303, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:12,729] Trial 930 finished with value: 0.8459506827044141 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.17401854235147482, 'random_strength': 2, 'bagging_temperature': 0.024762472287618777, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:13,406] Trial 931 finished with value: 0.8328800815150558 and parameters: {'iterations': 126, 'depth': 9, 'learning_rate': 0.19603720783046744, 'random_strength': 0, 'bagging_temperature': 0.01946350051963551, 'od_type': 'IncToDec', 'od_wait': 10}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:14,243] Trial 932 finished with value: 0.8230965538028735 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.19719591036291234, 'random_strength': 3, 'bagging_temperature': 0.04128528696924222, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:15,156] Trial 933 finished with value: 0.8230965538028735 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.18230011545357505, 'random_strength': 4, 'bagging_temperature': 0.03330816528739823, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:16,059] Trial 934 finished with value: 0.8328800815150558 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.201837420995799, 'random_strength': 2, 'bagging_temperature': 0.015481119801562217, 'od_type': 'IncToDec', 'od_wait': 21}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:17,042] Trial 935 finished with value: 0.8459506827044141 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.21411595421716167, 'random_strength': 0, 'bagging_temperature': 0.04880588749247521, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:17,991] Trial 936 finished with value: 0.8459506827044141 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.23607526026912445, 'random_strength': 6, 'bagging_temperature': 0.026424380674772076, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:19,045] Trial 937 finished with value: 0.8596955363285586 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.2581998110365131, 'random_strength': 2, 'bagging_temperature': 0.0735706549898071, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:19,973] Trial 938 finished with value: 0.8415917345645018 and parameters: {'iterations': 103, 'depth': 10, 'learning_rate': 0.22287798766144343, 'random_strength': 4, 'bagging_temperature': 0.03720413369441556, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:20,977] Trial 939 finished with value: 0.84191359062235 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.27606814109449174, 'random_strength': 0, 'bagging_temperature': 0.02886806070129458, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:21,461] Trial 940 finished with value: 0.8191500616101444 and parameters: {'iterations': 115, 'depth': 8, 'learning_rate': 0.1919255198466719, 'random_strength': 3, 'bagging_temperature': 0.023003928885839898, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:22,135] Trial 941 finished with value: 0.84191359062235 and parameters: {'iterations': 132, 'depth': 9, 'learning_rate': 0.24338011072376814, 'random_strength': 6, 'bagging_temperature': 0.042444712676243085, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:22,982] Trial 942 finished with value: 0.8191500616101444 and parameters: {'iterations': 109, 'depth': 10, 'learning_rate': 0.2099921463961874, 'random_strength': 2, 'bagging_temperature': 0.03293579306199785, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:23,937] Trial 943 finished with value: 0.8512233217188787 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.22974913217036033, 'random_strength': 0, 'bagging_temperature': 0.05457435939477712, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:24,830] Trial 944 finished with value: 0.8512233217188787 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.16410857430589224, 'random_strength': 8, 'bagging_temperature': 0.0885454022464575, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:25,737] Trial 945 finished with value: 0.845595020307664 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.20320131917200415, 'random_strength': 4, 'bagging_temperature': 0.04570067441842347, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:26,697] Trial 946 finished with value: 0.8108108108108109 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.24882721633480565, 'random_strength': 58, 'bagging_temperature': 0.021653389775532935, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:27,730] Trial 947 finished with value: 0.8553200492881156 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.21651826868950116, 'random_strength': 2, 'bagging_temperature': 0.03752713014198327, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:28,678] Trial 948 finished with value: 0.8368889581576149 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.2650880718453011, 'random_strength': 5, 'bagging_temperature': 0.06226402998102289, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:29,798] Trial 949 finished with value: 0.8328800815150558 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.1820314764003726, 'random_strength': 0, 'bagging_temperature': 0.027518218856395195, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:30,783] Trial 950 finished with value: 0.8599806088369385 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.22884161613772075, 'random_strength': 2, 'bagging_temperature': 0.017289442602859122, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:31,761] Trial 951 finished with value: 0.8321685254027262 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.23233620021771464, 'random_strength': 2, 'bagging_temperature': 0.012762888224710434, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:32,699] Trial 952 finished with value: 0.8556010556010556 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.2512871436825019, 'random_strength': 0, 'bagging_temperature': 0.011021394824463465, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:33,629] Trial 953 finished with value: 0.8690141179442328 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.2238754009494463, 'random_strength': 2, 'bagging_temperature': 0.014943249130397, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:34,564] Trial 954 finished with value: 0.8415917345645018 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.19964253552019143, 'random_strength': 3, 'bagging_temperature': 0.01278805331414523, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:35,477] Trial 955 finished with value: 0.8230965538028735 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.13404688836679607, 'random_strength': 0, 'bagging_temperature': 0.01995381179114752, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:36,382] Trial 956 finished with value: 0.8553200492881156 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.21651982265412473, 'random_strength': 2, 'bagging_temperature': 0.023575483952573927, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:37,185] Trial 957 finished with value: 0.8281925585296372 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.24055575974786075, 'random_strength': 37, 'bagging_temperature': 0.014368544319109063, 'od_type': 'IncToDec', 'od_wait': 12}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:38,249] Trial 958 finished with value: 0.8412404970025789 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.2806164985269633, 'random_strength': 4, 'bagging_temperature': 0.011884579212254635, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:39,119] Trial 959 finished with value: 0.8415917345645018 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.20801735001617075, 'random_strength': 86, 'bagging_temperature': 0.01448126009328078, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:40,214] Trial 960 finished with value: 0.8234879328004447 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.18993545435750125, 'random_strength': 0, 'bagging_temperature': 0.01095947807032654, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:41,172] Trial 961 finished with value: 0.8328800815150558 and parameters: {'iterations': 105, 'depth': 10, 'learning_rate': 0.22664394633805005, 'random_strength': 2, 'bagging_temperature': 0.017272142772176646, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:42,317] Trial 962 finished with value: 0.8368889581576149 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.2585517466468322, 'random_strength': 4, 'bagging_temperature': 0.01918602173666672, 'od_type': 'IncToDec', 'od_wait': 11}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:43,461] Trial 963 finished with value: 0.8553200492881156 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.20558734246496457, 'random_strength': 0, 'bagging_temperature': 0.014530112418466619, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:44,338] Trial 964 finished with value: 0.8368889581576149 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.21887088360934287, 'random_strength': 3, 'bagging_temperature': 0.018121354451635048, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:45,196] Trial 965 finished with value: 0.8317656008930031 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.02794327383441199, 'random_strength': 2, 'bagging_temperature': 0.021381487729721357, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:46,223] Trial 966 finished with value: 0.8317656008930031 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.24015431488916703, 'random_strength': 22, 'bagging_temperature': 0.010241320097237083, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:47,223] Trial 967 finished with value: 0.836512374443409 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.19548535724201938, 'random_strength': 73, 'bagging_temperature': 0.028971793033925084, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:48,158] Trial 968 finished with value: 0.8459506827044141 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.22127179273970723, 'random_strength': 5, 'bagging_temperature': 0.017686586490996813, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:49,063] Trial 969 finished with value: 0.8648648648648649 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.2607224537707486, 'random_strength': 0, 'bagging_temperature': 0.03428870353610667, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:50,018] Trial 970 finished with value: 0.833469421937483 and parameters: {'iterations': 100, 'depth': 10, 'learning_rate': 0.2673455416513932, 'random_strength': 0, 'bagging_temperature': 0.03118476514141792, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:51,158] Trial 971 finished with value: 0.8328800815150558 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.26968247851270843, 'random_strength': 0, 'bagging_temperature': 0.02571085161357524, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:52,043] Trial 972 finished with value: 0.8465761215761216 and parameters: {'iterations': 98, 'depth': 10, 'learning_rate': 0.2721726042592615, 'random_strength': 0, 'bagging_temperature': 0.0228864753527056, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:52,902] Trial 973 finished with value: 0.8412404970025789 and parameters: {'iterations': 105, 'depth': 10, 'learning_rate': 0.29846153027708133, 'random_strength': 2, 'bagging_temperature': 0.013895108696125532, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:53,774] Trial 974 finished with value: 0.8553200492881156 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.24749918813258115, 'random_strength': 2, 'bagging_temperature': 0.0323850932103416, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:54,070] Trial 975 finished with value: 0.8014514514514515 and parameters: {'iterations': 103, 'depth': 4, 'learning_rate': 0.2914241459680231, 'random_strength': 0, 'bagging_temperature': 0.03822588724030191, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:54,978] Trial 976 finished with value: 0.8135780982868414 and parameters: {'iterations': 109, 'depth': 10, 'learning_rate': 0.2848980227554857, 'random_strength': 4, 'bagging_temperature': 0.21925418980404637, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:55,960] Trial 977 finished with value: 0.8325398336824732 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.25358916973626017, 'random_strength': 2, 'bagging_temperature': 0.014980498248123622, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:56,273] Trial 978 finished with value: 0.7877125359785843 and parameters: {'iterations': 107, 'depth': 5, 'learning_rate': 0.2627015312046722, 'random_strength': 0, 'bagging_temperature': 0.016991633790636018, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:57,150] Trial 979 finished with value: 0.8415917345645018 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.17213730998728458, 'random_strength': 4, 'bagging_temperature': 0.025907344353649057, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:57,954] Trial 980 finished with value: 0.8238465724077614 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.29968975105784196, 'random_strength': 29, 'bagging_temperature': 0.03209261352837652, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:00:59,037] Trial 981 finished with value: 0.8452100356170124 and parameters: {'iterations': 300, 'depth': 10, 'learning_rate': 0.24131946542927202, 'random_strength': 2, 'bagging_temperature': 0.02076815915750491, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:00,202] Trial 982 finished with value: 0.8244677690692389 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.021196727083512855, 'random_strength': 0, 'bagging_temperature': 0.039088840338470786, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:01,167] Trial 983 finished with value: 0.8325398336824732 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.2547545798504404, 'random_strength': 6, 'bagging_temperature': 0.027651348184555637, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:02,110] Trial 984 finished with value: 0.8412404970025789 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.2354858543377694, 'random_strength': 3, 'bagging_temperature': 0.03566923677498193, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:02,704] Trial 985 finished with value: 0.8238465724077614 and parameters: {'iterations': 254, 'depth': 6, 'learning_rate': 0.21413314469435013, 'random_strength': 2, 'bagging_temperature': 0.04304647487335587, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:03,781] Trial 986 finished with value: 0.840859352196084 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.2752379514786667, 'random_strength': 4, 'bagging_temperature': 0.022275809449295338, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:04,723] Trial 987 finished with value: 0.8238465724077614 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.2440770004243097, 'random_strength': 98, 'bagging_temperature': 0.027813360073378972, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:05,878] Trial 988 finished with value: 0.8375511875511874 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.183740574903715, 'random_strength': 0, 'bagging_temperature': 0.04518075634863726, 'od_type': 'IncToDec', 'od_wait': 36}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:06,961] Trial 989 finished with value: 0.84191359062235 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.22791187987029377, 'random_strength': 2, 'bagging_temperature': 0.032275638646958704, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:07,775] Trial 990 finished with value: 0.8643625462076083 and parameters: {'iterations': 107, 'depth': 10, 'learning_rate': 0.20030845770821787, 'random_strength': 5, 'bagging_temperature': 0.016981348505227947, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:08,629] Trial 991 finished with value: 0.8368889581576149 and parameters: {'iterations': 101, 'depth': 10, 'learning_rate': 0.16959691166529603, 'random_strength': 7, 'bagging_temperature': 0.01596968948186823, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:09,465] Trial 992 finished with value: 0.827429728579154 and parameters: {'iterations': 104, 'depth': 10, 'learning_rate': 0.1891562512537896, 'random_strength': 6, 'bagging_temperature': 0.015575160627762001, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:10,273] Trial 993 finished with value: 0.8375511875511874 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.20074124229383353, 'random_strength': 63, 'bagging_temperature': 0.017344196886279153, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:11,099] Trial 994 finished with value: 0.827429728579154 and parameters: {'iterations': 109, 'depth': 10, 'learning_rate': 0.18613640775400922, 'random_strength': 5, 'bagging_temperature': 0.013553909319899395, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:11,887] Trial 995 finished with value: 0.8412404970025789 and parameters: {'iterations': 102, 'depth': 10, 'learning_rate': 0.1766841574888622, 'random_strength': 8, 'bagging_temperature': 0.020287444711736102, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:13,189] Trial 996 finished with value: 0.8281925585296372 and parameters: {'iterations': 263, 'depth': 10, 'learning_rate': 0.14974532473432528, 'random_strength': 4, 'bagging_temperature': 37.03593999246622, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:13,941] Trial 997 finished with value: 0.83723505544913 and parameters: {'iterations': 107, 'depth': 10, 'learning_rate': 0.20374461612045322, 'random_strength': 50, 'bagging_temperature': 0.010914906099190333, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:14,805] Trial 998 finished with value: 0.8191500616101444 and parameters: {'iterations': 103, 'depth': 10, 'learning_rate': 0.19556287145478493, 'random_strength': 6, 'bagging_temperature': 0.02095036278095342, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 671 with value: 0.8692568584802268.\n","[I 2024-04-02 06:01:15,766] Trial 999 finished with value: 0.8325398336824732 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.21564478747541624, 'random_strength': 4, 'bagging_temperature': 0.016179742593031336, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 671 with value: 0.8692568584802268.\n"]},{"name":"stdout","output_type":"stream","text":["Model Accuracy: 0.869369\n","Model F1 Score: 0.869257\n","Validation Accuracy: 0.855856\n","Validation F1 Score: 0.855856\n"]}],"source":["import optuna\n","from catboost import CatBoostClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","X_train=X_train.astype('int')\n","X_test=X_test.astype('int')\n","X_val=X_val.astype('int')\n","def objective(trial):\n","    param = {\n","        'iterations' : trial.suggest_int('iterations', 50, 300),\n","        'depth' : trial.suggest_int('depth', 4, 10),\n","        'learning_rate' : trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n","        'random_strength' : trial.suggest_int('random_strength', 0, 100),\n","        'bagging_temperature' : trial.suggest_float('bagging_temperature', 0.01, 100.00, log=True),\n","        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n","        'od_wait' : trial.suggest_int('od_wait', 10, 50)\n","    }\n","    model = CatBoostClassifier(**param)\n","    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n","    preds = model.predict(X_test)\n","    accuracy = f1_score(y_test, preds,average=\"weighted\")\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=1000)\n","\n","# Best hyperparameters\n","best_params = study.best_params\n","\n","# Fit the model with best hyperparameters\n","best_model = CatBoostClassifier(**best_params)\n","best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n","\n","# Make predictions \n","preds = best_model.predict(X_test)\n","\n","# Check the accuracy and F1 score of the model\n","print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n","print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n","\n","# Now let's use the model with the best parameters on the validation set\n","val_preds = best_model.predict(X_val)\n","\n","# Check the accuracy and F1 score of the best model on the validation set\n","print(\"Validation Accuracy: %f\" % accuracy_score(y_val, val_preds))\n","print(\"Validation F1 Score: %f\" % f1_score(y_val, val_preds, average='weighted'))\n"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T06:01:16.903115Z","iopub.status.busy":"2024-04-02T06:01:16.902577Z","iopub.status.idle":"2024-04-02T06:01:16.922229Z","shell.execute_reply":"2024-04-02T06:01:16.921152Z","shell.execute_reply.started":"2024-04-02T06:01:16.903085Z"},"trusted":true},"outputs":[],"source":["best_model.save_model(\"CB\",format=\"cbm\")"]},{"cell_type":"code","execution_count":50,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-02T06:01:16.924437Z","iopub.status.busy":"2024-04-02T06:01:16.923803Z","iopub.status.idle":"2024-04-02T06:04:49.220334Z","shell.execute_reply":"2024-04-02T06:04:49.219138Z","shell.execute_reply.started":"2024-04-02T06:01:16.924376Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-04-02 06:01:16,935] A new study created in memory with name: no-name-9420fc36-0ad4-4fce-8229-0dbeee16b305\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:16,963] Trial 0 finished with value: 0.6111282988119751 and parameters: {'C': 0.0014051314865458657, 'fit_intercept': False, 'solver': 'sag', 'max_iter': 79, 'tol': 0.06285941307876945, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5324541754526508}. Best is trial 0 with value: 0.6111282988119751.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,076] Trial 1 finished with value: 0.7691765275082738 and parameters: {'C': 30.1677613479267, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 184, 'tol': 0.08138407009638748, 'class_weight': None, 'warm_start': False, 'l1_ratio': 0.9144889762029652}. Best is trial 1 with value: 0.7691765275082738.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,176] Trial 2 finished with value: 0.7934145698586808 and parameters: {'C': 22.799457421145306, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 135, 'tol': 0.01436321332419377, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5380925363666086}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,212] Trial 3 finished with value: 0.5715267899478427 and parameters: {'C': 0.00017021568906944802, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 73, 'tol': 0.06394234214125856, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.2162153639175194}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,250] Trial 4 finished with value: 0.6067286798994115 and parameters: {'C': 4.082986895458981e-05, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 93, 'tol': 0.02256324735399416, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8101879888966667}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,292] Trial 5 finished with value: 0.6015576411378512 and parameters: {'C': 7.976008302127804, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 197, 'tol': 0.0657924514176468, 'class_weight': None, 'warm_start': False, 'l1_ratio': 0.8095991913990614}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,355] Trial 6 finished with value: 0.6912358966319292 and parameters: {'C': 0.0010977229761779893, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 82, 'tol': 0.03352778025249231, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.14811624241363408}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,384] Trial 7 finished with value: 0.5434458049768593 and parameters: {'C': 0.00048642768633724127, 'fit_intercept': False, 'solver': 'saga', 'max_iter': 87, 'tol': 0.04931366721243966, 'class_weight': None, 'warm_start': False, 'l1_ratio': 0.6079337005426309}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,410] Trial 8 finished with value: 0.5598018730704815 and parameters: {'C': 0.0004774822257528392, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 194, 'tol': 0.05117701260539242, 'class_weight': None, 'warm_start': False, 'l1_ratio': 0.06377292841252846}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,501] Trial 9 finished with value: 0.6773960865133678 and parameters: {'C': 4.832879343679402, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 96, 'tol': 0.009195009189637319, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.7222619460970857}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,596] Trial 10 finished with value: 0.7563267813267813 and parameters: {'C': 0.1487090292587005, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 147, 'tol': 0.004111143392259549, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.33986979177096055}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,781] Trial 11 finished with value: 0.7691765275082738 and parameters: {'C': 88.58292833675088, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 161, 'tol': 0.0983833316318099, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9960892832425219}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:17,942] Trial 12 finished with value: 0.7534981954904669 and parameters: {'C': 0.23367668540469932, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.09373315404828345, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.964262221501528}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:18,115] Trial 13 finished with value: 0.7934145698586808 and parameters: {'C': 78.12218916361212, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 169, 'tol': 0.08125314784126798, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4012973855214935}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:18,222] Trial 14 finished with value: 0.7468100862542021 and parameters: {'C': 1.0070943754530632, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 118, 'tol': 0.03170253478684212, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.386651171381492}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:18,271] Trial 15 finished with value: 0.6023740711413459 and parameters: {'C': 0.015696670046330394, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 166, 'tol': 0.08396273357556747, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.35851338805177196}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:01:18,388] Trial 16 finished with value: 0.7515784995494071 and parameters: {'C': 5.080271348265836, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 118, 'tol': 0.01777962603067732, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.48077311121612465}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:18,549] Trial 17 finished with value: 0.7934145698586808 and parameters: {'C': 65.91803031515083, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 138, 'tol': 0.04406164613680766, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6146760750823885}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:18,713] Trial 18 finished with value: 0.7720407268897784 and parameters: {'C': 0.011770028884650167, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 56, 'tol': 0.07500974875879277, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.24475591042855227}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:18,850] Trial 19 finished with value: 0.7708024626943547 and parameters: {'C': 0.8653459767996604, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 171, 'tol': 0.03641057419651579, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4710439456210345}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:18,980] Trial 20 finished with value: 0.6335426335426335 and parameters: {'C': 15.38262420870374, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 153, 'tol': 0.02021130968136035, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6606601528012512}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:19,087] Trial 21 finished with value: 0.7934145698586808 and parameters: {'C': 51.96774958242549, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 136, 'tol': 0.04453604648013503, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5804280873065961}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:19,249] Trial 22 finished with value: 0.7934145698586808 and parameters: {'C': 80.9602281372546, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.055705055964808056, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4164050907974572}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:19,404] Trial 23 finished with value: 0.7708024626943547 and parameters: {'C': 2.0382258507127826, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 140, 'tol': 0.041797728283766655, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7049247905495382}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:19,583] Trial 24 finished with value: 0.7890592063171601 and parameters: {'C': 20.83150872538403, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 179, 'tol': 0.07366024666533551, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3019341625118609}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:19,699] Trial 25 finished with value: 0.7563267813267813 and parameters: {'C': 0.17697870676805744, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 156, 'tol': 0.0001800931447552799, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5346357092525318}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:01:19,849] Trial 26 finished with value: 0.7477477477477478 and parameters: {'C': 14.053431173835289, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 122, 'tol': 0.012498195427319128, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.443109269082756}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:19,998] Trial 27 finished with value: 0.7708024626943547 and parameters: {'C': 1.3221162034730498, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 145, 'tol': 0.02823285374296529, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6195885419930741}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:20,167] Trial 28 finished with value: 0.7934145698586808 and parameters: {'C': 94.03009002026657, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.08912435791050374, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7652873684501509}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:20,276] Trial 29 finished with value: 0.5976304645659484 and parameters: {'C': 1.044713433150714e-05, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 175, 'tol': 0.058106528448250774, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.550941665980655}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:20,386] Trial 30 finished with value: 0.7468100862542021 and parameters: {'C': 4.020517818841261, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 133, 'tol': 0.07022037028267727, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.49623828567105105}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:20,489] Trial 31 finished with value: 0.7934145698586808 and parameters: {'C': 36.861655243510896, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 140, 'tol': 0.04257167973134853, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5788338649781333}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:20,649] Trial 32 finished with value: 0.7934145698586808 and parameters: {'C': 44.19347246776928, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.041996824374204864, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6553738737712269}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:20,810] Trial 33 finished with value: 0.7934145698586808 and parameters: {'C': 27.66206928953456, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.050551165343067445, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5470217564349099}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:20,934] Trial 34 finished with value: 0.6514186026381149 and parameters: {'C': 9.779774873284413, 'fit_intercept': False, 'solver': 'sag', 'max_iter': 153, 'tol': 0.025401864377025622, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8627333588168601}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:21,055] Trial 35 finished with value: 0.7934145698586808 and parameters: {'C': 29.144924762894973, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 162, 'tol': 0.058928371425827256, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.28198313679848336}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:21,248] Trial 36 finished with value: 0.7691765275082738 and parameters: {'C': 99.17829275923141, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 190, 'tol': 0.0797161479753523, 'class_weight': None, 'warm_start': False, 'l1_ratio': 0.16768121143154802}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:01:21,458] Trial 37 finished with value: 0.7653517153517153 and parameters: {'C': 2.8638674351792472, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 184, 'tol': 0.04613165920810229, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4181386370246991}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:21,576] Trial 38 finished with value: 0.6335426335426335 and parameters: {'C': 0.5632810643360929, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 125, 'tol': 0.038580157403313046, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6391468221217549}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:21,627] Trial 39 finished with value: 0.5942836311437608 and parameters: {'C': 0.004594465395098067, 'fit_intercept': False, 'solver': 'saga', 'max_iter': 141, 'tol': 0.06390304744195147, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.7070670407836567}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:21,749] Trial 40 finished with value: 0.7934145698586808 and parameters: {'C': 7.090768920402722, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 200, 'tol': 0.014584393647269413, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8001213331238562}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:21,948] Trial 41 finished with value: 0.7934145698586808 and parameters: {'C': 51.36644320502849, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.05629365764497503, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.41508299617743893}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:22,133] Trial 42 finished with value: 0.7934145698586808 and parameters: {'C': 52.37694534952072, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 98, 'tol': 0.0534264000165072, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5019941664220138}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:22,267] Trial 43 finished with value: 0.7890592063171601 and parameters: {'C': 11.82716078003231, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0461658820574498, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.598176377911635}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:22,403] Trial 44 finished with value: 0.7934145698586808 and parameters: {'C': 99.81750398900974, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 149, 'tol': 0.06926771399752348, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.33266853861870005}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:22,671] Trial 45 finished with value: 0.7691765275082738 and parameters: {'C': 21.834131163811662, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 83, 'tol': 0.028250697064558884, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.4347340342704018}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:22,810] Trial 46 finished with value: 0.6335426335426335 and parameters: {'C': 6.811176916960317, 'fit_intercept': False, 'solver': 'sag', 'max_iter': 72, 'tol': 0.033301106454215704, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.37102826412699774}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:22,939] Trial 47 finished with value: 0.7934145698586808 and parameters: {'C': 48.24751222798708, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 134, 'tol': 0.08740253767618497, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5736634954755963}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:23,048] Trial 48 finished with value: 0.5598018730704815 and parameters: {'C': 0.00015655016616135416, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 127, 'tol': 0.06157258102485876, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5028413483201877}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:23,106] Trial 49 finished with value: 0.6068202628858366 and parameters: {'C': 0.4523188515884522, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 113, 'tol': 0.0789346275295872, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.20803768925130667}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:01:23,223] Trial 50 finished with value: 0.7520388695314645 and parameters: {'C': 0.0681741692039623, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 101, 'tol': 0.007224981450669875, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7420589750699491}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:23,387] Trial 51 finished with value: 0.7934145698586808 and parameters: {'C': 60.878881749450954, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.09092433675886569, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.757719650716699}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:23,616] Trial 52 finished with value: 0.7934145698586808 and parameters: {'C': 97.50931372931602, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 90, 'tol': 0.0993025937985838, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8549613658776508}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:23,811] Trial 53 finished with value: 0.7934145698586808 and parameters: {'C': 20.508902643009648, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 70, 'tol': 0.09567467659108861, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3908404994208704}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:24,013] Trial 54 finished with value: 0.7934145698586808 and parameters: {'C': 32.61331416380799, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.08460528417782999, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6849493169909893}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:24,202] Trial 55 finished with value: 0.7934145698586808 and parameters: {'C': 11.159250441667627, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.0904917348205678, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.46691636741910025}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:24,383] Trial 56 finished with value: 0.7934145698586808 and parameters: {'C': 64.16412718940495, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 136, 'tol': 0.03579864794091036, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.04280502841767947}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:24,559] Trial 57 finished with value: 0.7711067983441525 and parameters: {'C': 3.5737497927412867, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 167, 'tol': 0.07607585003532018, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.7628030301257348}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:24,761] Trial 58 finished with value: 0.7934145698586808 and parameters: {'C': 18.83944344506235, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 95, 'tol': 0.046995489709330956, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5198571685544229}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:24,878] Trial 59 finished with value: 0.5436936827079013 and parameters: {'C': 1.776980136997308, 'fit_intercept': False, 'solver': 'saga', 'max_iter': 120, 'tol': 0.07114833285558919, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6270719912683482}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:24,942] Trial 60 finished with value: 0.7515784995494071 and parameters: {'C': 31.45742900434833, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 156, 'tol': 0.05427866606436163, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.45794524584105223}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:25,065] Trial 61 finished with value: 0.7934145698586808 and parameters: {'C': 40.106015082754915, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 140, 'tol': 0.041831956252878714, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5713850191655219}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:25,242] Trial 62 finished with value: 0.7934145698586808 and parameters: {'C': 59.381001394448425, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.06671701405387997, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6762736758548639}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:25,414] Trial 63 finished with value: 0.7890592063171601 and parameters: {'C': 12.41397396743851, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 144, 'tol': 0.03799567725159894, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5919123982644477}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:25,587] Trial 64 finished with value: 0.7800830023306562 and parameters: {'C': 5.776052746775921, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.031187667662290655, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9232427950984733}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:25,760] Trial 65 finished with value: 0.7934145698586808 and parameters: {'C': 31.076489931425133, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 149, 'tol': 0.04848170570763013, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5564219609278105}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:01:25,975] Trial 66 finished with value: 0.7558525831736949 and parameters: {'C': 74.30042990827312, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 161, 'tol': 0.08330406846472556, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.29763556632535415}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:26,099] Trial 67 finished with value: 0.6335426335426335 and parameters: {'C': 18.20265629263563, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 136, 'tol': 0.044220985880124006, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5156316327157009}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:26,222] Trial 68 finished with value: 0.7934145698586808 and parameters: {'C': 37.51512468256738, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.024634764787960298, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4038306300671838}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:26,400] Trial 69 finished with value: 0.784432594635145 and parameters: {'C': 9.144362112536001, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 138, 'tol': 0.019626744661945014, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6000431107378887}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:26,571] Trial 70 finished with value: 0.7227916475797833 and parameters: {'C': 0.003352069413167948, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.094596316944539, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3533801059038745}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:26,749] Trial 71 finished with value: 0.7934145698586808 and parameters: {'C': 97.60819254521704, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.040433396968818015, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6520081903280425}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:26,927] Trial 72 finished with value: 0.7934145698586808 and parameters: {'C': 60.16570374218298, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.05314627157240574, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7935018778864276}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:27,098] Trial 73 finished with value: 0.7934145698586808 and parameters: {'C': 38.95375196213096, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06056198296850797, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.634947815093367}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:27,271] Trial 74 finished with value: 0.7890592063171601 and parameters: {'C': 17.94853417458241, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04404668622496487, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7220150146378219}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:27,488] Trial 75 finished with value: 0.7691765275082738 and parameters: {'C': 26.036536519241523, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 92, 'tol': 0.04984703116028472, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.678062853601743}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:27,658] Trial 76 finished with value: 0.7934145698586808 and parameters: {'C': 48.00680882421054, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 143, 'tol': 0.029460209195229188, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5344858792424624}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:27,781] Trial 77 finished with value: 0.7468100862542021 and parameters: {'C': 13.392299890751222, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 132, 'tol': 0.033732686768754766, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8467486707415675}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:27,851] Trial 78 finished with value: 0.6067286798994115 and parameters: {'C': 70.9646082509279, 'fit_intercept': False, 'solver': 'saga', 'max_iter': 99, 'tol': 0.04308791308237853, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.48404208939746474}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:27,919] Trial 79 finished with value: 0.6335426335426335 and parameters: {'C': 2.774319526062501, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 153, 'tol': 0.03877010493293851, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.565816600747671}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:28,037] Trial 80 finished with value: 0.784432594635145 and parameters: {'C': 8.085324736742699, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 172, 'tol': 0.08757096371250923, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6128795505369219}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:28,215] Trial 81 finished with value: 0.7934145698586808 and parameters: {'C': 25.346559147370478, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.051622473955171624, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4348501557753069}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:28,389] Trial 82 finished with value: 0.7934145698586808 and parameters: {'C': 41.04480798359905, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.0482441765559651, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5523551626342358}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:28,564] Trial 83 finished with value: 0.7934145698586808 and parameters: {'C': 96.06619159792426, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.057410421207880695, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5858521061153052}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:01:28,788] Trial 84 finished with value: 0.7547685616651134 and parameters: {'C': 30.063160504881953, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 184, 'tol': 0.002354580864581436, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6650588622429439}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:28,969] Trial 85 finished with value: 0.7934145698586808 and parameters: {'C': 63.88516378636305, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.015003271711120744, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7004319254994719}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:29,182] Trial 86 finished with value: 0.7691765275082738 and parameters: {'C': 0.07501817704672636, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 148, 'tol': 0.035191311891320534, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.531378595533668}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:29,355] Trial 87 finished with value: 0.7890592063171601 and parameters: {'C': 15.90818079559744, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 135, 'tol': 0.04573782277109202, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.45704169853803495}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:29,528] Trial 88 finished with value: 0.7754506194116096 and parameters: {'C': 4.550376272888676, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 87, 'tol': 0.05465656831992753, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4863254163971386}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:29,791] Trial 89 finished with value: 0.7934145698586808 and parameters: {'C': 22.412817610625623, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.07825736041516737, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3206397320050751}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:29,970] Trial 90 finished with value: 0.7934145698586808 and parameters: {'C': 47.28184090640417, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.039794216740848376, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6345690917027755}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:30,167] Trial 91 finished with value: 0.7934145698586808 and parameters: {'C': 26.933163591316177, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 162, 'tol': 0.05982755781809394, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.23695802023473397}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:30,353] Trial 92 finished with value: 0.7934145698586808 and parameters: {'C': 80.15176173092063, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 178, 'tol': 0.05132307431378072, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.1269205932821391}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:30,553] Trial 93 finished with value: 0.7934145698586808 and parameters: {'C': 10.603507748879343, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 157, 'tol': 0.06741212796894926, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.29901336860982153}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:30,737] Trial 94 finished with value: 0.7934145698586808 and parameters: {'C': 51.500170877170625, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 193, 'tol': 0.05710507545631954, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.2692638054278942}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:30,909] Trial 95 finished with value: 0.632883615560909 and parameters: {'C': 0.00018927803559492916, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 167, 'tol': 0.07296858073199107, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5108956662768518}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:31,036] Trial 96 finished with value: 0.7515784995494071 and parameters: {'C': 35.47915309544305, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 146, 'tol': 0.06479881298802236, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.3787508843913842}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:31,109] Trial 97 finished with value: 0.6067286798994115 and parameters: {'C': 14.96201015723996, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 141, 'tol': 0.04946223078433678, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.537210545581992}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:31,229] Trial 98 finished with value: 0.7934145698586808 and parameters: {'C': 66.20896195401644, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.04519059391600359, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.1863477354407404}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:01:31,436] Trial 99 finished with value: 0.749921839165275 and parameters: {'C': 23.31811551059223, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 138, 'tol': 0.09062860016345908, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.822752299021713}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:31,606] Trial 100 finished with value: 0.784432594635145 and parameters: {'C': 6.9781964301622965, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 151, 'tol': 0.08132795829776655, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5822387899311814}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:31,802] Trial 101 finished with value: 0.7934145698586808 and parameters: {'C': 41.672886005828865, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 199, 'tol': 0.01277893835966111, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8014502012070482}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:31,992] Trial 102 finished with value: 0.7764613692033047 and parameters: {'C': 0.015167288081253363, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 191, 'tol': 0.005578049413848221, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8801280423020067}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:32,198] Trial 103 finished with value: 0.7934145698586808 and parameters: {'C': 69.91408070269996, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 180, 'tol': 0.022125218239002195, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6048186955207652}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:32,367] Trial 104 finished with value: 0.6866397647647647 and parameters: {'C': 17.662749725333185, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 188, 'tol': 0.008761128820749317, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.7310462821468796}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:32,503] Trial 105 finished with value: 0.7934145698586808 and parameters: {'C': 30.929915599770993, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.0426234847980149, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.7813532519182073}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:32,684] Trial 106 finished with value: 0.7934145698586808 and parameters: {'C': 49.91991563747472, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.09776734467387763, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.825810421813398}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:32,862] Trial 107 finished with value: 0.784432594635145 and parameters: {'C': 10.009492286392662, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 138, 'tol': 0.0372194619431365, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9151925213561967}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:33,071] Trial 108 finished with value: 0.7934145698586808 and parameters: {'C': 94.32038193791116, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 143, 'tol': 0.011349540348815055, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7649740040054978}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:33,248] Trial 109 finished with value: 0.7800830023306562 and parameters: {'C': 6.275086582870489, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 97, 'tol': 0.06272830195916837, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.41332480943783145}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:33,437] Trial 110 finished with value: 0.7890592063171601 and parameters: {'C': 22.039767460405074, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.05555101727672569, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6978167434536757}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:33,621] Trial 111 finished with value: 0.7934145698586808 and parameters: {'C': 45.27266708124476, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.04727750911649001, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.35917410553582213}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:33,811] Trial 112 finished with value: 0.7934145698586808 and parameters: {'C': 68.0120388300738, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.05303538148278334, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.44822291671012204}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:33,994] Trial 113 finished with value: 0.7934145698586808 and parameters: {'C': 36.03065216481331, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.0589024137971287, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.42895238605134167}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:34,190] Trial 114 finished with value: 0.7934145698586808 and parameters: {'C': 98.29656965472705, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.017249561353280988, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3951779436139399}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:34,375] Trial 115 finished with value: 0.7890592063171601 and parameters: {'C': 13.09040550683823, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.04095821098363844, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4730825202741259}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:34,590] Trial 116 finished with value: 0.7691765275082738 and parameters: {'C': 27.529197888923505, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 95, 'tol': 0.08671467727434261, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6499158035253454}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:34,717] Trial 117 finished with value: 0.7614561989915297 and parameters: {'C': 73.86450953510781, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 172, 'tol': 0.05602237287316654, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.11190132334188552}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:34,779] Trial 118 finished with value: 0.6112509597075283 and parameters: {'C': 51.44619774340326, 'fit_intercept': False, 'solver': 'saga', 'max_iter': 117, 'tol': 0.051324574516265, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5507968249746724}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:34,898] Trial 119 finished with value: 0.7934145698586808 and parameters: {'C': 33.67136443170229, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 53, 'tol': 0.04933718089647268, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5031735868581424}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:35,024] Trial 120 finished with value: 0.6068202628858366 and parameters: {'C': 17.992245441635728, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 134, 'tol': 0.09285438566844145, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6279576570323404}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:35,154] Trial 121 finished with value: 0.7934145698586808 and parameters: {'C': 54.24749535030272, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.053142988599685546, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5745475654826045}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:35,349] Trial 122 finished with value: 0.7934145698586808 and parameters: {'C': 45.84534383642897, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 99, 'tol': 0.047241061463527266, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4973171868051547}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:35,538] Trial 123 finished with value: 0.7934145698586808 and parameters: {'C': 68.88141631250063, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.0625764047726765, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3284607219697238}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:35,720] Trial 124 finished with value: 0.7934145698586808 and parameters: {'C': 28.8075242714818, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 89, 'tol': 0.05896585734444163, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5252532676663676}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:35,904] Trial 125 finished with value: 0.7934145698586808 and parameters: {'C': 23.96262984622384, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 163, 'tol': 0.044586397166315725, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6107347664922972}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:36,051] Trial 126 finished with value: 0.6021887194743193 and parameters: {'C': 2.986714400087925e-05, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 158, 'tol': 0.05083864907301873, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.2641090766939559}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:36,252] Trial 127 finished with value: 0.7934145698586808 and parameters: {'C': 55.12582963276796, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 79, 'tol': 0.025249757053072888, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5437698148278598}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:36,454] Trial 128 finished with value: 0.7934145698586808 and parameters: {'C': 13.146934561016224, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 139, 'tol': 0.05412719949722342, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5635674853105805}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:36,632] Trial 129 finished with value: 0.7934145698586808 and parameters: {'C': 40.58191413355304, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 145, 'tol': 0.06883161524848941, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.47183253446797596}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:36,846] Trial 130 finished with value: 0.7934145698586808 and parameters: {'C': 99.47097932673567, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.016049641265695837, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5953371793938461}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:37,028] Trial 131 finished with value: 0.7934145698586808 and parameters: {'C': 78.13880326090487, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 149, 'tol': 0.056438170551939074, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.36829633480826557}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:37,213] Trial 132 finished with value: 0.7934145698586808 and parameters: {'C': 56.11999576889019, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 141, 'tol': 0.0728941680520753, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.31609655294360334}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:37,399] Trial 133 finished with value: 0.7934145698586808 and parameters: {'C': 34.35484258410392, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.0767293166326843, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3362585422877248}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:37,564] Trial 134 finished with value: 0.7610556379121386 and parameters: {'C': 0.03517808122994034, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 151, 'tol': 0.06427689441033681, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4027895681105679}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:37,797] Trial 135 finished with value: 0.7691765275082738 and parameters: {'C': 97.91077804615085, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 136, 'tol': 0.08460735043908531, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.3498536320688524}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:37,978] Trial 136 finished with value: 0.7890592063171601 and parameters: {'C': 19.71539403269764, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 93, 'tol': 0.06116680612278018, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.42963567139491077}. Best is trial 2 with value: 0.7934145698586808.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:38,176] Trial 137 finished with value: 0.802641903871957 and parameters: {'C': 0.3851360691856403, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.07044349717006929, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9524614189700604}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:38,365] Trial 138 finished with value: 0.802641903871957 and parameters: {'C': 0.45642969483690726, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.0426920228664376, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9811420275073118}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:38,556] Trial 139 finished with value: 0.802641903871957 and parameters: {'C': 0.23898963321111077, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.04229853660050704, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9862839041720904}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:38,751] Trial 140 finished with value: 0.802641903871957 and parameters: {'C': 0.6413790702096724, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04184741577136419, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9662944389778332}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:38,940] Trial 141 finished with value: 0.802641903871957 and parameters: {'C': 0.3136349483886358, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.042115974429802285, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9986990486807436}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:39,136] Trial 142 finished with value: 0.802641903871957 and parameters: {'C': 0.315535879781626, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.042108667315721264, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9995207826853532}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:39,336] Trial 143 finished with value: 0.802641903871957 and parameters: {'C': 0.39895288967768144, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.042654708912934436, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9744849499927404}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:39,524] Trial 144 finished with value: 0.802641903871957 and parameters: {'C': 0.3169386362453403, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.03905233868374374, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9938662812188215}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:39,857] Trial 145 finished with value: 0.802641903871957 and parameters: {'C': 0.36150435995567237, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.040195982806992665, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9961850437187213}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:40,052] Trial 146 finished with value: 0.802641903871957 and parameters: {'C': 0.42173951608159893, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.03984725794811203, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9977022197802327}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:40,251] Trial 147 finished with value: 0.802641903871957 and parameters: {'C': 0.3465591483369585, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.039585858972510546, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9891535978783591}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:40,442] Trial 148 finished with value: 0.802641903871957 and parameters: {'C': 0.30368237680571436, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.039357375787261936, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9986325911479365}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:40,637] Trial 149 finished with value: 0.802641903871957 and parameters: {'C': 0.3463981906327325, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.0348128385098703, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9975388520382541}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:40,832] Trial 150 finished with value: 0.802641903871957 and parameters: {'C': 0.3074908444966036, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.039289668842503976, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9930832392423335}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:41,031] Trial 151 finished with value: 0.802641903871957 and parameters: {'C': 0.31027645202455917, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.03513166340554435, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.99937281820078}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:41,226] Trial 152 finished with value: 0.802641903871957 and parameters: {'C': 0.33427935925603913, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.03457143746190952, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9983014088725518}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:41,420] Trial 153 finished with value: 0.802641903871957 and parameters: {'C': 0.3284509506931337, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.0350267946411647, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9931475595797995}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:41,610] Trial 154 finished with value: 0.802641903871957 and parameters: {'C': 0.8326782336282562, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.03292243483788374, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9543546874999004}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:41,799] Trial 155 finished with value: 0.802641903871957 and parameters: {'C': 0.18412390597969472, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.038846035400188, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9738288057804038}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:41,994] Trial 156 finished with value: 0.802641903871957 and parameters: {'C': 0.30048815256570216, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.03705703753691214, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9406424381193476}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:42,195] Trial 157 finished with value: 0.802641903871957 and parameters: {'C': 0.5825682177419012, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.03150800594312602, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9990547623315056}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:42,372] Trial 158 finished with value: 0.7982688570923864 and parameters: {'C': 0.13354074035299138, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04044076516768878, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9750532498786296}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:42,564] Trial 159 finished with value: 0.802641903871957 and parameters: {'C': 0.5155276023047937, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.03619138508454939, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9471689959269131}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:42,754] Trial 160 finished with value: 0.7982688570923864 and parameters: {'C': 0.12103785830492586, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.04207429259371966, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8994548565423848}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:42,950] Trial 161 finished with value: 0.802641903871957 and parameters: {'C': 0.33627845407288437, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.03433607059704048, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9829503471128431}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:43,144] Trial 162 finished with value: 0.802641903871957 and parameters: {'C': 0.2560275612031488, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.03909402059152511, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9929164796227654}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:43,336] Trial 163 finished with value: 0.802641903871957 and parameters: {'C': 0.3838810933884572, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.03041421477281532, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9310159636410377}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:43,526] Trial 164 finished with value: 0.802641903871957 and parameters: {'C': 0.7436013351027065, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.035181381400116035, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9642582340264501}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:43,717] Trial 165 finished with value: 0.7934145698586808 and parameters: {'C': 1.2474239308636974, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.03768729798138874, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.996510933225748}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:43,849] Trial 166 finished with value: 0.7700724062928126 and parameters: {'C': 0.21187395495613418, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 127, 'tol': 0.04283878583065727, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9624425233478512}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:43,926] Trial 167 finished with value: 0.6067286798994115 and parameters: {'C': 0.46772851020840883, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 117, 'tol': 0.040294854929015, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9788422100177324}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:44,054] Trial 168 finished with value: 0.7982688570923864 and parameters: {'C': 0.09625235413916627, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.03608062929275167, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.895838503388421}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:44,256] Trial 169 finished with value: 0.802641903871957 and parameters: {'C': 0.2647783426622178, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.032197266387332155, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9460068097172866}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:44,448] Trial 170 finished with value: 0.802641903871957 and parameters: {'C': 0.6646368623479502, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.03813168002724124, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9967943504282792}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:44,639] Trial 171 finished with value: 0.798035410303664 and parameters: {'C': 1.0214320727440205, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.03353514748316465, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9569598733300904}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:44,837] Trial 172 finished with value: 0.802641903871957 and parameters: {'C': 0.3532543425535376, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04091613986019391, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9634498972511741}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:45,031] Trial 173 finished with value: 0.798035410303664 and parameters: {'C': 0.869234152992481, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.026923986022575515, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9376587577351889}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:45,231] Trial 174 finished with value: 0.802641903871957 and parameters: {'C': 0.423268036820494, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.03436740034639847, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9768736950757123}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:45,367] Trial 175 finished with value: 0.6244551002615518 and parameters: {'C': 0.16966453611672683, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 123, 'tol': 0.044128157175339466, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9193119436912887}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:45,508] Trial 176 finished with value: 0.7934145698586808 and parameters: {'C': 1.7129124371361673, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.029014459834841196, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.999631901147473}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:45,695] Trial 177 finished with value: 0.802641903871957 and parameters: {'C': 0.2384005582214441, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.03241910676697277, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9540832641019417}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:01:45,901] Trial 178 finished with value: 0.7757294362181331 and parameters: {'C': 0.5827176400260717, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 115, 'tol': 0.039051394665735366, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9783750207511231}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:46,092] Trial 179 finished with value: 0.802641903871957 and parameters: {'C': 0.3144844893795727, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.042202343273123756, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9573547416336824}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:46,282] Trial 180 finished with value: 0.802641903871957 and parameters: {'C': 0.19061253167725095, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.03604244476701207, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9312392183008569}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:46,471] Trial 181 finished with value: 0.802641903871957 and parameters: {'C': 0.17497345083176902, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.03955437056917121, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9769160155017841}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:46,669] Trial 182 finished with value: 0.802641903871957 and parameters: {'C': 0.4689946273795351, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.03795920436281264, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9689801743966522}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:46,870] Trial 183 finished with value: 0.798035410303664 and parameters: {'C': 0.931350045955561, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.04503531791025483, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9994555436685381}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:47,061] Trial 184 finished with value: 0.802641903871957 and parameters: {'C': 0.23714414660543076, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.04157046761430362, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9810614122163069}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:47,251] Trial 185 finished with value: 0.7982688570923864 and parameters: {'C': 0.10793812147160449, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.036987390700208844, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9472856582256419}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:47,487] Trial 186 finished with value: 0.7691765275082738 and parameters: {'C': 0.6851185445833495, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.03924787934699231, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9033919030745401}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:47,678] Trial 187 finished with value: 0.802641903871957 and parameters: {'C': 0.3720219256808933, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.03351585651693442, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9794197924848506}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:47,882] Trial 188 finished with value: 0.7934145698586808 and parameters: {'C': 1.3816764553592225, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.043507281871437195, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9989246715090301}. Best is trial 137 with value: 0.802641903871957.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:48,066] Trial 189 finished with value: 0.8028531639803915 and parameters: {'C': 0.05955173039979019, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.046271196759698686, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9578533505278128}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:48,258] Trial 190 finished with value: 0.7982688570923864 and parameters: {'C': 0.08392007490107203, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.045650722371381916, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9244080163735431}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:48,448] Trial 191 finished with value: 0.7982688570923864 and parameters: {'C': 0.1473588896995571, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.04136154341531489, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9679492396996987}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:48,643] Trial 192 finished with value: 0.802641903871957 and parameters: {'C': 0.30799690943465574, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.03550769267444251, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9555996287634408}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:48,839] Trial 193 finished with value: 0.802641903871957 and parameters: {'C': 0.4385946868687561, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.039594178107537556, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9800427549160806}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:49,029] Trial 194 finished with value: 0.8028531639803915 and parameters: {'C': 0.061851303247093446, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.043511438499286265, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9497558269477453}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:49,230] Trial 195 finished with value: 0.8028531639803915 and parameters: {'C': 0.04572478916545187, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04740309390946165, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.94040124745508}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:49,434] Trial 196 finished with value: 0.802641903871957 and parameters: {'C': 0.2738051909366031, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.046425328897072404, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9325024872030894}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:49,624] Trial 197 finished with value: 0.8028531639803915 and parameters: {'C': 0.04534579010194394, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.048342448985885814, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9874081621835393}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:49,863] Trial 198 finished with value: 0.7982688570923864 and parameters: {'C': 0.06955662319574153, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04684359832467188, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8738375194474483}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:50,047] Trial 199 finished with value: 0.7936710813206824 and parameters: {'C': 0.03990623080164566, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.04820509071938068, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9996422769006802}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:50,241] Trial 200 finished with value: 0.7895106372229068 and parameters: {'C': 0.020243090828349755, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04304514172076873, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9421625534387968}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:50,427] Trial 201 finished with value: 0.7893030285187149 and parameters: {'C': 0.02263557412636671, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.044233017842970485, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.98246980125271}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:50,623] Trial 202 finished with value: 0.8028531639803915 and parameters: {'C': 0.04781388772238861, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04147040047672491, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.95861330973836}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:50,815] Trial 203 finished with value: 0.8028531639803915 and parameters: {'C': 0.051721823167128395, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04203799106917279, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9580535112921433}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:51,007] Trial 204 finished with value: 0.8028531639803915 and parameters: {'C': 0.050077407942505876, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04130146672615123, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.907413557625075}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:51,149] Trial 205 finished with value: 0.7657657657657657 and parameters: {'C': 0.07519068941549213, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 113, 'tol': 0.04262808107852273, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9233443278150593}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:51,282] Trial 206 finished with value: 0.8028531639803915 and parameters: {'C': 0.04531410175416283, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.045509245719993964, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9603237656196554}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:51,427] Trial 207 finished with value: 0.6067286798994115 and parameters: {'C': 0.04616605505652569, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 109, 'tol': 0.04853967411692822, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9102300775322039}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:51,549] Trial 208 finished with value: 0.7982688570923864 and parameters: {'C': 0.028433587689213783, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.044327508521172156, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9580164032200107}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:51,747] Trial 209 finished with value: 0.8028531639803915 and parameters: {'C': 0.053649268915901854, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04569189650057219, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9448800749071883}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:51,938] Trial 210 finished with value: 0.8028531639803915 and parameters: {'C': 0.05564718448690406, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04608090086644666, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8890775061781566}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:52,137] Trial 211 finished with value: 0.8028531639803915 and parameters: {'C': 0.05517368289238442, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04628154670145862, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9409486979877822}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:52,333] Trial 212 finished with value: 0.8028531639803915 and parameters: {'C': 0.053192235873664645, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04572902918051782, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8814519201601767}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:52,523] Trial 213 finished with value: 0.8028531639803915 and parameters: {'C': 0.05677030036399275, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04655631663937108, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8743211778190138}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:52,710] Trial 214 finished with value: 0.8028531639803915 and parameters: {'C': 0.0554850125729466, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04637871596741572, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8904635511810536}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:52,904] Trial 215 finished with value: 0.8028531639803915 and parameters: {'C': 0.05628323513612067, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04640839292281078, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8870789976484444}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:53,093] Trial 216 finished with value: 0.8028531639803915 and parameters: {'C': 0.05358202407712269, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04698142533824042, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8800161439431262}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:53,231] Trial 217 finished with value: 0.6244551002615518 and parameters: {'C': 0.05347705801010533, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 111, 'tol': 0.047132116462946856, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8530813036225636}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:53,401] Trial 218 finished with value: 0.7643951617832215 and parameters: {'C': 0.045840491849088776, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04601358819621032, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.893447294791575}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:53,588] Trial 219 finished with value: 0.8028531639803915 and parameters: {'C': 0.05611894395265651, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04947382034291205, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8790425376191401}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:01:53,789] Trial 220 finished with value: 0.7515784995494071 and parameters: {'C': 0.05990672502605814, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 105, 'tol': 0.04981529003214191, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8799610843546835}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:53,980] Trial 221 finished with value: 0.7982688570923864 and parameters: {'C': 0.03506121313011149, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04742553568011351, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8315853290075804}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:54,180] Trial 222 finished with value: 0.7936710813206824 and parameters: {'C': 0.02709969371806477, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04896870907216698, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8700053876520112}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:54,384] Trial 223 finished with value: 0.8028531639803915 and parameters: {'C': 0.054802743539277284, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.045535329232840385, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8889454174635671}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:54,630] Trial 224 finished with value: 0.7632115255111387 and parameters: {'C': 0.009787888884522691, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.051180914594305266, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8909745871083846}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:54,885] Trial 225 finished with value: 0.8028531639803915 and parameters: {'C': 0.057756264944423916, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04621821588587979, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9110583739401105}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:55,199] Trial 226 finished with value: 0.8028531639803915 and parameters: {'C': 0.05488732781317893, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04583724335417759, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8506826999714242}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:55,409] Trial 227 finished with value: 0.8028531639803915 and parameters: {'C': 0.054563879958969434, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.046409990620194456, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9048445836350782}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:55,625] Trial 228 finished with value: 0.8028531639803915 and parameters: {'C': 0.0514748226442953, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04572738563151042, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.86081470686236}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:55,869] Trial 229 finished with value: 0.8028531639803915 and parameters: {'C': 0.05518571979305771, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.0458917349646539, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8452232733550529}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:56,072] Trial 230 finished with value: 0.8028531639803915 and parameters: {'C': 0.05509217966654488, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04597426044238992, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8555237651015974}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:56,296] Trial 231 finished with value: 0.8028531639803915 and parameters: {'C': 0.05505706213384157, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.045868531378413374, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8483681795118787}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:56,495] Trial 232 finished with value: 0.8028531639803915 and parameters: {'C': 0.04678049512840824, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.048557999244106954, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8609385157526184}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:56,701] Trial 233 finished with value: 0.7982688570923864 and parameters: {'C': 0.06514706156358249, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.045601030909598536, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8824741458538228}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:56,891] Trial 234 finished with value: 0.7982688570923864 and parameters: {'C': 0.0349131691857892, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.047777137626209935, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9091642531954732}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:57,089] Trial 235 finished with value: 0.7982688570923864 and parameters: {'C': 0.08690706182042279, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04966459093663847, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8382004930932907}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:57,282] Trial 236 finished with value: 0.8028531639803915 and parameters: {'C': 0.057879734619578294, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.045314181792032324, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8664845511259761}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:57,468] Trial 237 finished with value: 0.8028531639803915 and parameters: {'C': 0.04377257820963977, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.051705604088236136, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9058751148427611}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:57,660] Trial 238 finished with value: 0.7982688570923864 and parameters: {'C': 0.028374268823501116, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.0472127063319289, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8196544727795604}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:57,850] Trial 239 finished with value: 0.8028531639803915 and parameters: {'C': 0.0903641209953507, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.044831267787983076, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8671547116645073}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:58,047] Trial 240 finished with value: 0.7982688570923864 and parameters: {'C': 0.06324409112394012, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.049052048535942125, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8846135027170323}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:58,236] Trial 241 finished with value: 0.8028531639803915 and parameters: {'C': 0.051519195788496605, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04582178622588858, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8480305619335926}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:58,428] Trial 242 finished with value: 0.7936710813206824 and parameters: {'C': 0.03783683971529593, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.0466047289838929, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8477067302372532}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:58,627] Trial 243 finished with value: 0.78512441012441 and parameters: {'C': 0.019250053872092526, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.044822040957980584, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8935746130820102}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:58,819] Trial 244 finished with value: 0.8028531639803915 and parameters: {'C': 0.0561076987965776, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.05068163354675261, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8550990124257144}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:59,023] Trial 245 finished with value: 0.7982688570923864 and parameters: {'C': 0.07802455990612567, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04761030328750738, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.914450965778508}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:59,211] Trial 246 finished with value: 0.7982688570923864 and parameters: {'C': 0.032823637861071425, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.045124630867436934, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8763117125437182}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:59,413] Trial 247 finished with value: 0.7982688570923864 and parameters: {'C': 0.11209868970291013, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04642800245776953, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.914503252824578}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:59,601] Trial 248 finished with value: 0.8028531639803915 and parameters: {'C': 0.04928951639364177, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.04990118166631183, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8075304578486737}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:01:59,859] Trial 249 finished with value: 0.7982688570923864 and parameters: {'C': 0.07177990427715324, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.044029198763123445, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.836201104401657}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:00,048] Trial 250 finished with value: 0.7936710813206824 and parameters: {'C': 0.03883246554350753, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04779984123315294, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8914014290634868}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:00,189] Trial 251 finished with value: 0.7704578518597737 and parameters: {'C': 0.09574627965592555, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 110, 'tol': 0.04439550825003875, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.923697460826556}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:00,319] Trial 252 finished with value: 0.7936710813206824 and parameters: {'C': 0.026025071372285005, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.051931010556316264, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8626294012697107}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:00,524] Trial 253 finished with value: 0.8028531639803915 and parameters: {'C': 0.0584014493599646, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04648024302558461, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9030763912840869}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:00,658] Trial 254 finished with value: 0.5365219049694856 and parameters: {'C': 0.04329472395182024, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 116, 'tol': 0.049465399104417475, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9281045097535378}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:00,802] Trial 255 finished with value: 0.7982688570923864 and parameters: {'C': 0.06891787484155681, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.044309584773976014, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8919401673935081}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:00,984] Trial 256 finished with value: 0.7982688570923864 and parameters: {'C': 0.031906034672797894, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04817565869665456, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8713490740411994}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:01,192] Trial 257 finished with value: 0.8028531639803915 and parameters: {'C': 0.05112063940389631, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.045991825569128404, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8401008104698294}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:01,346] Trial 258 finished with value: 0.6290074574872865 and parameters: {'C': 0.014525187603609335, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 113, 'tol': 0.0435442417195659, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9321091202734767}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:01,508] Trial 259 finished with value: 0.7528261852586178 and parameters: {'C': 0.10965594820062718, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 106, 'tol': 0.04791615877232699, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9005294666730073}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:01,725] Trial 260 finished with value: 0.7982688570923864 and parameters: {'C': 0.0804346777712047, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.045863766542138945, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8805361699713464}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:01,924] Trial 261 finished with value: 0.7936710813206824 and parameters: {'C': 0.03758267664337078, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.05063068115150668, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9136493152357009}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:02,143] Trial 262 finished with value: 0.8028531639803915 and parameters: {'C': 0.061612876488635566, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.043983907361305266, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9346900148522418}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:02,326] Trial 263 finished with value: 0.7893030285187149 and parameters: {'C': 0.02322241018375347, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04852236318730721, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8510999358301208}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:02,522] Trial 264 finished with value: 0.8028531639803915 and parameters: {'C': 0.050015102221090305, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04631326833617747, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8169406802202701}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:02,720] Trial 265 finished with value: 0.8028531639803915 and parameters: {'C': 0.0900546214837811, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.04316873671472104, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8772934697041721}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:02,907] Trial 266 finished with value: 0.7936710813206824 and parameters: {'C': 0.039259388665668075, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04946623670498631, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.90742964446911}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:03,106] Trial 267 finished with value: 0.7982688570923864 and parameters: {'C': 0.06523954247491895, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.046481729576668705, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9424144050472184}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:03,303] Trial 268 finished with value: 0.7982688570923864 and parameters: {'C': 0.12407303877499745, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04392194411281625, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8668305665973267}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:03,510] Trial 269 finished with value: 0.7982688570923864 and parameters: {'C': 0.029410674937797206, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04818054244239487, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8924370437047174}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:03,708] Trial 270 finished with value: 0.8028531639803915 and parameters: {'C': 0.046472568325654204, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04547004964819335, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9242114542796128}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:03,922] Trial 271 finished with value: 0.7982688570923864 and parameters: {'C': 0.07759290091859598, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.051801129611286946, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8298057250320683}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:04,164] Trial 272 finished with value: 0.7643951617832215 and parameters: {'C': 0.05218653864588554, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04172178330534412, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8563487769131688}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:04,364] Trial 273 finished with value: 0.7936710813206824 and parameters: {'C': 0.035557816771077694, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04715445916286331, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9469817476851711}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:04,564] Trial 274 finished with value: 0.7893030285187149 and parameters: {'C': 0.022438117233705177, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04353960748301297, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9095351340173646}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:04,759] Trial 275 finished with value: 0.7938919441613183 and parameters: {'C': 0.06764003531027525, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.049842248945716386, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9355486601526171}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:04,956] Trial 276 finished with value: 0.7982688570923864 and parameters: {'C': 0.11519452711885689, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04532043509453139, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.885728792540042}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:05,098] Trial 277 finished with value: 0.7563267813267813 and parameters: {'C': 0.04342427695377075, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 108, 'tol': 0.04741213498374136, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8609220953260017}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:05,242] Trial 278 finished with value: 0.7982688570923864 and parameters: {'C': 0.09459055733108317, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.042014599198375455, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7926503749164551}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:05,442] Trial 279 finished with value: 0.7982688570923864 and parameters: {'C': 0.031217399550527197, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.053366738188514666, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9163576927424318}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:05,591] Trial 280 finished with value: 0.6067286798994115 and parameters: {'C': 0.05846753450442197, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 112, 'tol': 0.04480522753154145, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8876610253999013}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:05,730] Trial 281 finished with value: 0.7982688570923864 and parameters: {'C': 0.06869623918491238, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04986862797316479, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8338497035597562}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:05,931] Trial 282 finished with value: 0.8028531639803915 and parameters: {'C': 0.04395369634563418, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.0467816942197588, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9430223855423874}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:06,133] Trial 283 finished with value: 0.7982688570923864 and parameters: {'C': 0.08787544170794599, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.04394999636483215, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9023452295948131}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:06,279] Trial 284 finished with value: 0.6244551002615518 and parameters: {'C': 0.02760642030644546, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 114, 'tol': 0.04830545588757217, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.87397751538241}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:06,419] Trial 285 finished with value: 0.7807327381878917 and parameters: {'C': 0.018670659999747385, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.041390134500215066, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9233585048439937}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:06,632] Trial 286 finished with value: 0.8028531639803915 and parameters: {'C': 0.055127707193816045, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.05219803553001239, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8480807660556885}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:06,822] Trial 287 finished with value: 0.7558525831736949 and parameters: {'C': 0.0388004879847557, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 68, 'tol': 0.04562778297579989, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9479574307348851}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:07,034] Trial 288 finished with value: 0.7982688570923864 and parameters: {'C': 0.12842228133118633, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04331110033034146, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8962444490745392}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:07,246] Trial 289 finished with value: 0.7982688570923864 and parameters: {'C': 0.0737154787405129, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04883898312291688, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8693193438139507}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:07,446] Trial 290 finished with value: 0.8028531639803915 and parameters: {'C': 0.05225742859301164, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.045890024530159224, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.909773161474362}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:07,639] Trial 291 finished with value: 0.7936710813206824 and parameters: {'C': 0.03810160227337015, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.041487129532013334, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9290110651961243}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:07,882] Trial 292 finished with value: 0.7729338533936235 and parameters: {'C': 0.027067356398786855, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.05077737810217934, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9571420463081133}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:08,088] Trial 293 finished with value: 0.7982688570923864 and parameters: {'C': 0.0857073703803943, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04776735448569515, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.812219824503462}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:08,288] Trial 294 finished with value: 0.8028531639803915 and parameters: {'C': 0.05754525161579179, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04386602774417507, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8817239975496853}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:08,485] Trial 295 finished with value: 0.8028531639803915 and parameters: {'C': 0.045704159870377466, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.046560001117504815, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8441157552858298}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:08,696] Trial 296 finished with value: 0.7808748507543689 and parameters: {'C': 0.014093337776758665, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04486946837580646, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9180937501233867}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:08,885] Trial 297 finished with value: 0.7982688570923864 and parameters: {'C': 0.032002061468057674, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04998405252016475, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8640553340871188}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:09,094] Trial 298 finished with value: 0.7982688570923864 and parameters: {'C': 0.10003874275397624, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04297977809896195, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8959952032905065}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:09,292] Trial 299 finished with value: 0.7982688570923864 and parameters: {'C': 0.07099773878149994, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04719075746774661, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9419284919127039}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:09,502] Trial 300 finished with value: 0.8028531639803915 and parameters: {'C': 0.04913316418180981, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04154211973265313, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.962125117995737}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:09,760] Trial 301 finished with value: 0.7938919441613183 and parameters: {'C': 0.06671520189498265, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04525131586991567, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8813281735548942}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:09,949] Trial 302 finished with value: 0.7936710813206824 and parameters: {'C': 0.036577522466148114, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.0496715941959378, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9261367335133459}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:10,097] Trial 303 finished with value: 0.7657657657657657 and parameters: {'C': 0.13705326677192614, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 117, 'tol': 0.04779225075432513, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.830403700751124}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:10,241] Trial 304 finished with value: 0.7849307243422452 and parameters: {'C': 0.021277219270317806, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.04312254663004642, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9057271905452926}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:10,383] Trial 305 finished with value: 0.6111282988119751 and parameters: {'C': 0.09344675759552584, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 110, 'tol': 0.05370634788666891, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8617126154677702}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:10,528] Trial 306 finished with value: 0.8028531639803915 and parameters: {'C': 0.056624628496963064, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04590397546662721, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9556552617327261}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:10,724] Trial 307 finished with value: 0.7982688570923864 and parameters: {'C': 0.03011879204727318, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 100, 'tol': 0.04820407687680215, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8914683174870336}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:10,920] Trial 308 finished with value: 0.8028531639803915 and parameters: {'C': 0.042563736459055354, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04467407058467943, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8467040082073246}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:11,130] Trial 309 finished with value: 0.7632115255111387 and parameters: {'C': 0.01025167175081059, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04072013738098412, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9379898764855432}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:11,277] Trial 310 finished with value: 0.6244551002615518 and parameters: {'C': 0.07283958891389228, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 111, 'tol': 0.05121374949627858, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9171952300560999}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:11,458] Trial 311 finished with value: 0.7643951617832215 and parameters: {'C': 0.05349668011483815, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04659215543168349, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.004657761899579893}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:11,673] Trial 312 finished with value: 0.7606120086567014 and parameters: {'C': 0.09276749827945469, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 113, 'tol': 0.043114872941751, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8770288398029441}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:11,879] Trial 313 finished with value: 0.7936710813206824 and parameters: {'C': 0.036136493763049955, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.044986405804586634, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.957534626898314}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:12,074] Trial 314 finished with value: 0.7936710813206824 and parameters: {'C': 0.026500618886837968, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04891975558119753, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8984526600058593}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:12,275] Trial 315 finished with value: 0.8028531639803915 and parameters: {'C': 0.056979194127408185, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04708742727593609, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8584277975593892}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:12,471] Trial 316 finished with value: 0.7982688570923864 and parameters: {'C': 0.1287403043952866, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.041018330423208745, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7832184068234078}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:12,662] Trial 317 finished with value: 0.8028531639803915 and parameters: {'C': 0.04456463541434226, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.04382209009887815, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9394124680019921}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:12,862] Trial 318 finished with value: 0.7982688570923864 and parameters: {'C': 0.07411624606950151, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.050532325684681946, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9180615851472665}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:13,058] Trial 319 finished with value: 0.7936710813206824 and parameters: {'C': 0.03650724860434673, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04593631857251229, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8173219159870234}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:13,268] Trial 320 finished with value: 0.8028531639803915 and parameters: {'C': 0.061745345116072686, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.047888603606234634, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8805160000800238}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:13,463] Trial 321 finished with value: 0.7895106372229068 and parameters: {'C': 0.020826505339272557, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.0526237079651216, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9603309835989999}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:13,677] Trial 322 finished with value: 0.7982688570923864 and parameters: {'C': 0.10594600775029592, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.041610615166475386, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9086249532313443}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:13,876] Trial 323 finished with value: 0.8028531639803915 and parameters: {'C': 0.04632819184826415, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.043337172384713914, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8391359962161208}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:14,083] Trial 324 finished with value: 0.7982688570923864 and parameters: {'C': 0.07566739674070336, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.045523282616489205, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8627479071982552}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:14,277] Trial 325 finished with value: 0.7936710813206824 and parameters: {'C': 0.03745657402294035, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04927516067651904, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9357402756873864}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:14,475] Trial 326 finished with value: 0.7936710813206824 and parameters: {'C': 0.026815522943888864, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.046972036394340375, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8921691118141145}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:14,680] Trial 327 finished with value: 0.8028531639803915 and parameters: {'C': 0.061561947837466706, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.044405064115263265, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9681163596443705}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:14,878] Trial 328 finished with value: 0.8028531639803915 and parameters: {'C': 0.04820573225648911, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04867770232217512, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9282170440414783}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:15,026] Trial 329 finished with value: 0.7610556379121386 and parameters: {'C': 0.10273379248265471, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 107, 'tol': 0.04264303412959371, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8775728921838852}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:15,206] Trial 330 finished with value: 0.7691765275082738 and parameters: {'C': 0.07812785700852887, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.046097908100823023, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9053220343193457}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:15,399] Trial 331 finished with value: 0.7982688570923864 and parameters: {'C': 0.03204267748911075, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.050546440712044796, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8581735925046472}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:15,601] Trial 332 finished with value: 0.8028531639803915 and parameters: {'C': 0.05300771311585626, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04035383109680259, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9531871082882808}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:15,752] Trial 333 finished with value: 0.6067286798994115 and parameters: {'C': 0.125246175869009, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 113, 'tol': 0.04453511956685469, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9178975015989927}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:15,896] Trial 334 finished with value: 0.7936710813206824 and parameters: {'C': 0.04089345855844779, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.048582828791506556, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8360862766401312}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:16,101] Trial 335 finished with value: 0.7982688570923864 and parameters: {'C': 0.06904225291747013, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04665905671082889, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8880529769028211}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:16,252] Trial 336 finished with value: 0.6335426335426335 and parameters: {'C': 0.016854076885904033, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 115, 'tol': 0.04330855730765172, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9426829809007546}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:16,391] Trial 337 finished with value: 0.7936710813206824 and parameters: {'C': 0.02643717851775754, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.052335780918799604, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9703112299935954}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:16,599] Trial 338 finished with value: 0.7982688570923864 and parameters: {'C': 0.1594953769071147, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04217755749634682, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9023617777177344}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:16,806] Trial 339 finished with value: 0.7704578518597737 and parameters: {'C': 0.05399804968011046, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 102, 'tol': 0.04523953881574384, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8719439516500131}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:17,014] Trial 340 finished with value: 0.7982688570923864 and parameters: {'C': 0.08371589302877869, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.047976773985106365, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8493797066886543}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:17,223] Trial 341 finished with value: 0.7936710813206824 and parameters: {'C': 0.03938673139070166, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05000242875046676, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9274782301205071}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:17,431] Trial 342 finished with value: 0.8028531639803915 and parameters: {'C': 0.059439852737946185, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.046421718620259324, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8025238591353718}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:17,657] Trial 343 finished with value: 0.7982688570923864 and parameters: {'C': 0.09949469618548773, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04043597531890497, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8833786658493908}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:17,882] Trial 344 finished with value: 0.6640778330919175 and parameters: {'C': 0.0007084479488466931, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04472249759991595, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9688345929816569}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:18,105] Trial 345 finished with value: 0.7982688570923864 and parameters: {'C': 0.028605884503763074, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04278680039253688, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8226441193753438}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:18,317] Trial 346 finished with value: 0.8028531639803915 and parameters: {'C': 0.0435926311289593, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04793423719051909, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.93350126629938}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:18,547] Trial 347 finished with value: 0.7982688570923864 and parameters: {'C': 0.07044075460629119, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04493099898540306, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9040525183712333}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:18,755] Trial 348 finished with value: 0.8028531639803915 and parameters: {'C': 0.0550704473087832, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.05086629399995783, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8653606365466427}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:18,989] Trial 349 finished with value: 0.7638512075293685 and parameters: {'C': 0.03241773747825377, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04728001837072995, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9406497841788297}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:19,194] Trial 350 finished with value: 0.7982688570923864 and parameters: {'C': 0.08592342213188171, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.05488448790004346, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9158050327428624}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:19,390] Trial 351 finished with value: 0.7849307243422452 and parameters: {'C': 0.02134286340747035, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04199762568082804, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8894528399987165}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:19,595] Trial 352 finished with value: 0.8028531639803915 and parameters: {'C': 0.043716110226675826, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.0492499986796201, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9575410210397575}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:19,851] Trial 353 finished with value: 0.7982688570923864 and parameters: {'C': 0.06393689976946051, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.04410094577046197, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8541059704798339}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:20,053] Trial 354 finished with value: 0.7982688570923864 and parameters: {'C': 0.1447457798868708, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.046238173826397895, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9711029376059803}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:20,260] Trial 355 finished with value: 0.7982688570923864 and parameters: {'C': 0.03474327588809827, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04708662148546957, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.902331831046765}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:20,463] Trial 356 finished with value: 0.8028531639803915 and parameters: {'C': 0.0919182282682607, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.044148015248993755, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8771802612869207}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:20,615] Trial 357 finished with value: 0.7610556379121386 and parameters: {'C': 0.05008969080277501, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 116, 'tol': 0.04081959279567462, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9474619995210143}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:20,764] Trial 358 finished with value: 0.7982688570923864 and parameters: {'C': 0.06966080229931416, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.03781812116568343, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9242457476023285}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:20,916] Trial 359 finished with value: 0.6067286798994115 and parameters: {'C': 0.045048930731066084, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 97, 'tol': 0.05151833886016114, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8377082468194073}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:21,069] Trial 360 finished with value: 0.7893030285187149 and parameters: {'C': 0.025132301603986645, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04897372036700757, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.870398045947732}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:21,254] Trial 361 finished with value: 0.623929557403858 and parameters: {'C': 1.196405525147861e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04611068983638775, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9019007324485249}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:21,410] Trial 362 finished with value: 0.6335426335426335 and parameters: {'C': 0.10863377395716345, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 111, 'tol': 0.04231905666075429, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9189537315510367}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:21,560] Trial 363 finished with value: 0.8028531639803915 and parameters: {'C': 0.05860868009175401, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04511537949091464, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9477189191423111}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:21,765] Trial 364 finished with value: 0.7982688570923864 and parameters: {'C': 0.034369168587831844, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.048333981860028345, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8495600093111771}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:21,976] Trial 365 finished with value: 0.7618143239764861 and parameters: {'C': 0.07689728038187742, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 113, 'tol': 0.04306896401302122, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8885105423321806}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:22,175] Trial 366 finished with value: 0.8028531639803915 and parameters: {'C': 0.04600863043980426, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.04996628151404985, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8213455142333507}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:22,377] Trial 367 finished with value: 0.7982688570923864 and parameters: {'C': 0.032714749041418856, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04052359756741614, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9646215242713405}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:22,587] Trial 368 finished with value: 0.7982688570923864 and parameters: {'C': 0.10983326945783355, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04661542215325174, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9275970892958776}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:22,830] Trial 369 finished with value: 0.7820164992578785 and parameters: {'C': 0.01551566394028312, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.05333196535996866, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8753060820242826}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:23,021] Trial 370 finished with value: 0.632883615560909 and parameters: {'C': 0.00023627262281959857, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04433495078368844, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9769932748499583}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:23,233] Trial 371 finished with value: 0.8028531639803915 and parameters: {'C': 0.05646510045351014, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.047769103617887824, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9044727598359511}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:23,438] Trial 372 finished with value: 0.7982688570923864 and parameters: {'C': 0.07833876797072241, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 100, 'tol': 0.04533525381721687, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8562500489478215}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:23,643] Trial 373 finished with value: 0.7936710813206824 and parameters: {'C': 0.04006601682891402, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.0430973137233641, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9412182561656719}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:23,852] Trial 374 finished with value: 0.7893030285187149 and parameters: {'C': 0.02202097109088709, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.05068595377063097, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8902980160686654}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:24,068] Trial 375 finished with value: 0.7982688570923864 and parameters: {'C': 0.06378366819648636, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.03929478163222345, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7425600759887897}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:24,274] Trial 376 finished with value: 0.8028531639803915 and parameters: {'C': 0.04746956767862562, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.04697509335298824, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9182340533954724}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:24,492] Trial 377 finished with value: 0.7982688570923864 and parameters: {'C': 0.15541310704189862, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04948674875989323, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9531046854142775}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:24,691] Trial 378 finished with value: 0.7982688570923864 and parameters: {'C': 0.029029016127242242, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04553709050069625, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8417903444740107}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:24,899] Trial 379 finished with value: 0.7982688570923864 and parameters: {'C': 0.09700521795923388, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04194315891697677, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8688828833218105}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:25,108] Trial 380 finished with value: 0.8028531639803915 and parameters: {'C': 0.061149269444040186, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.048510016073052525, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9746314927395257}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:25,325] Trial 381 finished with value: 0.6957880957880956 and parameters: {'C': 0.0017531331580212057, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04380910896974487, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.931521635167911}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:25,476] Trial 382 finished with value: 0.7606120086567014 and parameters: {'C': 0.03832032815962042, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 114, 'tol': 0.04700179903531717, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.892199951079}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:25,622] Trial 383 finished with value: 0.7982688570923864 and parameters: {'C': 0.08409755424996704, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.051702818692850025, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9084560609825512}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:25,829] Trial 384 finished with value: 0.8028531639803915 and parameters: {'C': 0.04677270059566063, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.040932946907620664, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8232140449058946}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:25,987] Trial 385 finished with value: 0.6067286798994115 and parameters: {'C': 0.02410331099315985, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 104, 'tol': 0.045069483121715784, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7989441371768097}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:26,152] Trial 386 finished with value: 0.7982688570923864 and parameters: {'C': 0.06254565533566384, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04317569220343949, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8600094231864894}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:26,357] Trial 387 finished with value: 0.7982688570923864 and parameters: {'C': 0.12513263099458513, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 66, 'tol': 0.047883163046389565, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9480516417744604}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:26,735] Trial 388 finished with value: 0.7643951617832215 and parameters: {'C': 0.034453792853643715, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.03840214419939611, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8800424492909208}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:26,907] Trial 389 finished with value: 0.6244551002615518 and parameters: {'C': 0.08373856821620664, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 109, 'tol': 0.04586959911285096, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9158171499268162}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:27,114] Trial 390 finished with value: 0.8028531639803915 and parameters: {'C': 0.049877582820963766, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04406503715245085, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9717688458872494}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:27,452] Trial 391 finished with value: 0.7618143239764861 and parameters: {'C': 0.0703217493748967, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 112, 'tol': 0.048803949651665866, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9370640995327416}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:27,665] Trial 392 finished with value: 0.7982688570923864 and parameters: {'C': 0.03482080290521756, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.04650718148238288, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8989429378871008}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:27,886] Trial 393 finished with value: 0.8028531639803915 and parameters: {'C': 0.050991649458341254, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.05056578344176733, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8669572375473357}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:28,173] Trial 394 finished with value: 0.7807327381878917 and parameters: {'C': 0.018520470828296148, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04220016698552867, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8392925888788489}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:28,401] Trial 395 finished with value: 0.7982688570923864 and parameters: {'C': 0.10912460409603893, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04491911791959556, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9615204949927348}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:28,633] Trial 396 finished with value: 0.7936710813206824 and parameters: {'C': 0.025913764026428573, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04820717146883967, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.92353492012496}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:28,847] Trial 397 finished with value: 0.8028531639803915 and parameters: {'C': 0.06172745691969019, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.053127289413952665, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8846494208968525}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:29,050] Trial 398 finished with value: 0.8028531639803915 and parameters: {'C': 0.0447720102122724, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.0403490462989946, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9081922594081592}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:29,260] Trial 399 finished with value: 0.7982688570923864 and parameters: {'C': 0.08710973899854192, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.0465978932672728, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9443816569769513}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:29,492] Trial 400 finished with value: 0.7982688570923864 and parameters: {'C': 0.03509381708250024, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.043035078844824756, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8523910934868327}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:29,729] Trial 401 finished with value: 0.7938919441613183 and parameters: {'C': 0.06774237734064442, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04990744940526415, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8816596964551162}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:29,949] Trial 402 finished with value: 0.7982688570923864 and parameters: {'C': 0.14697478715171142, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.045137208680974074, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9805857530970598}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:30,158] Trial 403 finished with value: 0.8028531639803915 and parameters: {'C': 0.045718737739342805, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04105414515395665, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9336964816054693}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:30,361] Trial 404 finished with value: 0.7936710813206824 and parameters: {'C': 0.027230704305669654, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04797971350149217, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8944042347545893}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:30,572] Trial 405 finished with value: 0.8028531639803915 and parameters: {'C': 0.05751135557976308, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0429840812259827, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9607034841304553}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:30,790] Trial 406 finished with value: 0.7982688570923864 and parameters: {'C': 0.08765696412641891, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04572810488177883, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7770337788239835}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:30,999] Trial 407 finished with value: 0.7936710813206824 and parameters: {'C': 0.0379827803834279, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.049445566851343443, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8282936390355536}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:31,249] Trial 408 finished with value: 0.7691765275082738 and parameters: {'C': 0.06846293189261149, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.05154404392337149, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.866729029652629}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:31,403] Trial 409 finished with value: 0.7661378770074423 and parameters: {'C': 0.11926420149817685, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 125, 'tol': 0.04667179001378907, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9166423373644215}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:31,502] Trial 410 finished with value: 0.6067286798994115 and parameters: {'C': 0.04811956120933412, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 111, 'tol': 0.045040343714258774, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8491476237513322}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:31,660] Trial 411 finished with value: 0.7809803062274343 and parameters: {'C': 0.012356505186917294, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04353696661447504, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8952262809545746}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:31,864] Trial 412 finished with value: 0.7982688570923864 and parameters: {'C': 0.031825061828253884, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.038549846679342754, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9536806956812949}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:32,075] Trial 413 finished with value: 0.7982688570923864 and parameters: {'C': 0.07594894934686448, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04771635605775425, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.809862312465609}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:32,280] Trial 414 finished with value: 0.7807327381878917 and parameters: {'C': 0.01874815733877525, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04180502564661541, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9279468491766585}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:32,497] Trial 415 finished with value: 0.8028531639803915 and parameters: {'C': 0.05198569814760587, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.044259056240400295, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8666706385137704}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:32,653] Trial 416 finished with value: 0.6244551002615518 and parameters: {'C': 0.038113735137486324, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 123, 'tol': 0.04924091715930508, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.21428093303622398}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:32,804] Trial 417 finished with value: 0.7982688570923864 and parameters: {'C': 0.09894065618210553, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04674805480663411, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9737920492218007}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:33,016] Trial 418 finished with value: 0.7571431799692669 and parameters: {'C': 0.06047316919497748, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 101, 'tol': 0.04099053735519569, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9075923106316898}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:33,220] Trial 419 finished with value: 0.7936710813206824 and parameters: {'C': 0.02683395625086508, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.0544490382148822, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.0723737219426468}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:33,428] Trial 420 finished with value: 0.8028531639803915 and parameters: {'C': 0.043642741627311674, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 61, 'tol': 0.04458857276642479, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8798222563337944}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:33,637] Trial 421 finished with value: 0.7982688570923864 and parameters: {'C': 0.07714892645875406, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.051756060671273786, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.935371522686372}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:33,841] Trial 422 finished with value: 0.8028531639803915 and parameters: {'C': 0.05326701044786655, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04752195709578412, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8411515103782414}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:34,048] Trial 423 finished with value: 0.7982688570923864 and parameters: {'C': 0.03474858932632478, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.049485189596620044, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9520120913267718}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:34,260] Trial 424 finished with value: 0.7982688570923864 and parameters: {'C': 0.11990535388444422, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04350989262356552, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9158494227705384}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:34,474] Trial 425 finished with value: 0.7982688570923864 and parameters: {'C': 0.0788451032804609, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04527385123810634, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8927647359236534}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:34,682] Trial 426 finished with value: 0.8028531639803915 and parameters: {'C': 0.05717250525830505, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.047166468678213024, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9765877691965241}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:34,919] Trial 427 finished with value: 0.7681093417714366 and parameters: {'C': 0.021553345290610704, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04183446151974291, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.863281279577202}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:35,133] Trial 428 finished with value: 0.7982688570923864 and parameters: {'C': 0.16737959069558137, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.03928098766604371, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9352346454325312}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:35,344] Trial 429 finished with value: 0.8028531639803915 and parameters: {'C': 0.04425423480234974, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.046173389582282606, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9070651833209101}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:35,549] Trial 430 finished with value: 0.7982688570923864 and parameters: {'C': 0.03385607610933304, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04883694470150758, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8806579250859479}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:35,762] Trial 431 finished with value: 0.7982688570923864 and parameters: {'C': 0.09962303837632877, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.043377306760913524, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8380984921113239}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:35,976] Trial 432 finished with value: 0.7982688570923864 and parameters: {'C': 0.06375314795679607, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05130549356952386, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9533064987352011}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:36,185] Trial 433 finished with value: 0.8028531639803915 and parameters: {'C': 0.04271848122541815, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04501045327106522, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8994252911797344}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:36,394] Trial 434 finished with value: 0.7893030285187149 and parameters: {'C': 0.024141247128384585, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04835388959102467, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9211365067483299}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:36,550] Trial 435 finished with value: 0.7614561989915297 and parameters: {'C': 0.08056558534082045, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 125, 'tol': 0.046355608826808094, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9819956899255298}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:36,652] Trial 436 finished with value: 0.6067286798994115 and parameters: {'C': 0.05520328009086281, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 113, 'tol': 0.03699613151912606, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8606489990304882}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:36,806] Trial 437 finished with value: 0.7982688570923864 and parameters: {'C': 0.030187219650966986, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04268078377888718, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8798298340759273}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:37,028] Trial 438 finished with value: 0.7938919441613183 and parameters: {'C': 0.06534594876239518, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04044856570557155, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9600839483913727}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:37,250] Trial 439 finished with value: 0.7982688570923864 and parameters: {'C': 0.10617153019269444, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04956005845937242, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9355785863845965}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:37,461] Trial 440 finished with value: 0.8028531639803915 and parameters: {'C': 0.044747714171135884, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.0448335660535049, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8155955959053787}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:37,626] Trial 441 finished with value: 0.6335426335426335 and parameters: {'C': 0.08105554842615302, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 117, 'tol': 0.047020307342713105, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9141808666986605}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:37,771] Trial 442 finished with value: 0.7982688570923864 and parameters: {'C': 0.031383484811285, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.05225185009861835, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8504999922175718}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:38,003] Trial 443 finished with value: 0.7528261852586178 and parameters: {'C': 0.1776739594233211, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 128, 'tol': 0.04298801266698906, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8907192715752417}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:38,197] Trial 444 finished with value: 0.633156233156233 and parameters: {'C': 6.982467758170788e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.04768435158012513, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9451665200230526}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:38,433] Trial 445 finished with value: 0.7643951617832215 and parameters: {'C': 0.05323617198162786, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.050418160070737586, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8768447350928977}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:38,640] Trial 446 finished with value: 0.7982688570923864 and parameters: {'C': 0.04141451022506177, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.045492902312313566, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9812592671204123}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:38,864] Trial 447 finished with value: 0.7808748507543689 and parameters: {'C': 0.01772337101292645, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.041581510075060446, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.916021317042311}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:39,089] Trial 448 finished with value: 0.7938919441613183 and parameters: {'C': 0.06661610807765347, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04392549044799972, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9626068026205101}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:39,308] Trial 449 finished with value: 0.7982688570923864 and parameters: {'C': 0.11379785171725526, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04630620747268235, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8267388869665}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:39,525] Trial 450 finished with value: 0.7936710813206824 and parameters: {'C': 0.04084051130522327, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.048357560692477715, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8606948716622598}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:39,849] Trial 451 finished with value: 0.7982688570923864 and parameters: {'C': 0.08175063402860562, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 80, 'tol': 0.044323180723144256, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.1708134312030395}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:40,056] Trial 452 finished with value: 0.7982688570923864 and parameters: {'C': 0.028744181896652312, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04086648438837716, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8964578662529586}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:40,266] Trial 453 finished with value: 0.8028531639803915 and parameters: {'C': 0.05611284442198725, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.050219036529883285, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.926804983287709}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:40,475] Trial 454 finished with value: 0.7936710813206824 and parameters: {'C': 0.03865158134312263, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.046507103582950154, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9408398975375006}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:40,692] Trial 455 finished with value: 0.7982688570923864 and parameters: {'C': 0.0635371732173423, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.038961510876121, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8805929393122944}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:40,912] Trial 456 finished with value: 0.7893030285187149 and parameters: {'C': 0.024697380795034283, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.043160812275619576, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9052527651891914}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:41,131] Trial 457 finished with value: 0.7982688570923864 and parameters: {'C': 0.08500774140563516, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04838502993800416, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8451823801521163}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:41,354] Trial 458 finished with value: 0.8028531639803915 and parameters: {'C': 0.047741234893785615, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 99, 'tol': 0.05346212698499579, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9803074342991372}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:41,584] Trial 459 finished with value: 0.7982688570923864 and parameters: {'C': 0.11096053065818205, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.0006885649437826172, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9589824168233604}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:41,743] Trial 460 finished with value: 0.7657657657657657 and parameters: {'C': 0.1414241318731385, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 110, 'tol': 0.045572169408258326, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.926652215877197}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:41,892] Trial 461 finished with value: 0.7982688570923864 and parameters: {'C': 0.033130022443896866, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04176966500315088, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8639088149778185}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:42,107] Trial 462 finished with value: 0.8028531639803915 and parameters: {'C': 0.055852186719762664, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.04779070797846934, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8997866036651779}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:42,318] Trial 463 finished with value: 0.7982688570923864 and parameters: {'C': 0.07353681490323982, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04435268665570971, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8781358745720086}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:42,559] Trial 464 finished with value: 0.7643951617832215 and parameters: {'C': 0.04372022631122787, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.05025501838244118, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.944339382925424}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:42,720] Trial 465 finished with value: 0.6067286798994115 and parameters: {'C': 0.023179734973239326, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 112, 'tol': 0.04565049168237811, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.839175352126901}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:42,875] Trial 466 finished with value: 0.8028531639803915 and parameters: {'C': 0.057465114678395185, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04270971449911067, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9112960644229555}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:43,038] Trial 467 finished with value: 0.6244551002615518 and parameters: {'C': 0.08655244308179687, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 110, 'tol': 0.04730275377163276, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7965248275074028}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:43,205] Trial 468 finished with value: 0.7587471277840314 and parameters: {'C': 0.005771341961092765, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04954589806060739, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.967264563089962}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:43,427] Trial 469 finished with value: 0.7982688570923864 and parameters: {'C': 0.03449430869487134, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.039321319517278894, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8891289223575033}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:43,655] Trial 470 finished with value: 0.7618143239764861 and parameters: {'C': 0.0497250699037521, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 117, 'tol': 0.0440859713277453, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9250977311912748}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:43,871] Trial 471 finished with value: 0.7982688570923864 and parameters: {'C': 0.07424038237842215, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04698263445815532, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8646135252173252}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:44,086] Trial 472 finished with value: 0.7982688570923864 and parameters: {'C': 0.031872110732437696, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05206563341699119, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8213404294446938}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:44,308] Trial 473 finished with value: 0.7982688570923864 and parameters: {'C': 0.10649130555490705, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.045112681369249834, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9426502189462871}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:44,521] Trial 474 finished with value: 0.8028531639803915 and parameters: {'C': 0.045568046829735705, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.04224354044307293, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9837913061717596}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:44,738] Trial 475 finished with value: 0.7764613692033047 and parameters: {'C': 0.016019810250857632, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04868582893187688, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8929522266977693}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:44,952] Trial 476 finished with value: 0.7938919441613183 and parameters: {'C': 0.06567360981623378, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.04607144158735248, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8526231231190697}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:45,163] Trial 477 finished with value: 0.7982688570923864 and parameters: {'C': 0.13654084371616465, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.040139189679774395, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9164846109857774}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:45,379] Trial 478 finished with value: 0.7936710813206824 and parameters: {'C': 0.037804667832988456, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.055390722172864906, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9564985362190856}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:45,592] Trial 479 finished with value: 0.7893030285187149 and parameters: {'C': 0.024598805437591586, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04371364258139099, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8790161319890105}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:45,805] Trial 480 finished with value: 0.8028531639803915 and parameters: {'C': 0.059627067260244464, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 51, 'tol': 0.03695724346059376, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9343263239795944}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:46,024] Trial 481 finished with value: 0.7982688570923864 and parameters: {'C': 0.08737808534322061, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.0509855825640325, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9042196526271828}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:46,245] Trial 482 finished with value: 0.8028531639803915 and parameters: {'C': 0.0462349958458182, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.048225032214024445, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8686080436477841}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:46,497] Trial 483 finished with value: 0.7595927526039051 and parameters: {'C': 0.061988395681795996, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 75, 'tol': 0.046484079375372675, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.954984616725058}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:46,721] Trial 484 finished with value: 0.8028531639803915 and parameters: {'C': 0.09167295463490563, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04456806533050069, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9828995079889828}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:46,931] Trial 485 finished with value: 0.7936710813206824 and parameters: {'C': 0.03587266762047098, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04942269200874037, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8461511769458967}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:47,151] Trial 486 finished with value: 0.8028531639803915 and parameters: {'C': 0.053258749939747003, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04180023646942877, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9192728122140658}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:47,317] Trial 487 finished with value: 0.7653517153517153 and parameters: {'C': 0.1890625767759344, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 107, 'tol': 0.04654799831405521, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8864029092864195}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:47,473] Trial 488 finished with value: 0.7982688570923864 and parameters: {'C': 0.028313853115985253, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.043158130306153245, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8305788349006699}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:47,642] Trial 489 finished with value: 0.6067286798994115 and parameters: {'C': 0.0685122517659614, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 124, 'tol': 0.047993557867930935, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9018763894643067}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:47,805] Trial 490 finished with value: 0.8028531639803915 and parameters: {'C': 0.04191851291136679, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04461051810503797, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9369867867222236}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:48,018] Trial 491 finished with value: 0.78512441012441 and parameters: {'C': 0.019245981352828675, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04091460881333151, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9679673278763568}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:48,241] Trial 492 finished with value: 0.7982688570923864 and parameters: {'C': 0.11914449665114969, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.0525923858360937, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9190365976958146}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:48,407] Trial 493 finished with value: 0.6290074574872865 and parameters: {'C': 0.08322573347781044, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 109, 'tol': 0.04579139715266971, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8701603795277459}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:48,559] Trial 494 finished with value: 0.8028531639803915 and parameters: {'C': 0.04649834268762503, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05077589290458739, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8600682145731596}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:48,776] Trial 495 finished with value: 0.7757294362181331 and parameters: {'C': 0.029847380000553658, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 105, 'tol': 0.04802131106320199, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9999388538785267}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:48,992] Trial 496 finished with value: 0.7938919441613183 and parameters: {'C': 0.0666609687535008, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.042564192860000606, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9438192476150747}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:49,200] Trial 497 finished with value: 0.7936710813206824 and parameters: {'C': 0.03910528091610275, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.037860038281450015, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8845126492019184}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:49,414] Trial 498 finished with value: 0.8028531639803915 and parameters: {'C': 0.054856289124940484, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.045376777799670275, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9013925299664671}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:49,643] Trial 499 finished with value: 0.7982688570923864 and parameters: {'C': 0.1024191247979037, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.046955901527506796, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9573774521928479}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:49,866] Trial 500 finished with value: 0.7982688570923864 and parameters: {'C': 0.028407730669360084, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04908967621200321, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9235825400661541}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:50,083] Trial 501 finished with value: 0.7982688570923864 and parameters: {'C': 0.07411370356363481, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04004790692969208, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8479659610670567}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:50,301] Trial 502 finished with value: 0.8028531639803915 and parameters: {'C': 0.05085914726730584, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04366915956708634, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9734827543014738}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:50,548] Trial 503 finished with value: 0.7643951617832215 and parameters: {'C': 0.03732459744772711, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04489741556247383, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9005457765003856}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:50,767] Trial 504 finished with value: 0.7982688570923864 and parameters: {'C': 0.09560403329974744, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.050076513146531956, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8023477336379256}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:50,983] Trial 505 finished with value: 0.7982688570923864 and parameters: {'C': 0.14410924741739764, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04721085590526312, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8756642401292596}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:51,212] Trial 506 finished with value: 0.8028531639803915 and parameters: {'C': 0.06162468111247669, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04326582043537048, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9348998531315494}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:51,429] Trial 507 finished with value: 0.7893030285187149 and parameters: {'C': 0.022255809984406124, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 100, 'tol': 0.041347797445137294, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8324319768209238}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:51,650] Trial 508 finished with value: 0.8028531639803915 and parameters: {'C': 0.044509430001560754, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04585796979863793, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8552785296951314}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:51,865] Trial 509 finished with value: 0.7982688570923864 and parameters: {'C': 0.07391266411753374, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.04860677588219764, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7677132939372441}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:52,078] Trial 510 finished with value: 0.7982688570923864 and parameters: {'C': 0.03284495886892221, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05166958398351165, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9637633972568496}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:52,305] Trial 511 finished with value: 0.7854029144351726 and parameters: {'C': 0.012668180910251967, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.0446835267265968, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9091172818544561}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:52,530] Trial 512 finished with value: 0.8028531639803915 and parameters: {'C': 0.05126135465056538, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.047043760930221626, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8881224662883684}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:52,698] Trial 513 finished with value: 0.7653517153517153 and parameters: {'C': 0.0938813561898156, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 116, 'tol': 0.04199318473029701, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9429939725898904}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:52,862] Trial 514 finished with value: 0.8028531639803915 and parameters: {'C': 0.06005572425821601, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04968920097284034, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9271630190227265}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:53,081] Trial 515 finished with value: 0.7936710813206824 and parameters: {'C': 0.03880097565543059, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.039635381519685264, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7219338181008375}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:53,252] Trial 516 finished with value: 0.6067286798994115 and parameters: {'C': 0.02868204122610814, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 119, 'tol': 0.04447985112929414, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.872712013530354}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:53,414] Trial 517 finished with value: 0.7982688570923864 and parameters: {'C': 0.0685795002724541, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04681447091514529, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8177685311966858}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:53,636] Trial 518 finished with value: 0.7982688570923864 and parameters: {'C': 0.12904044891335983, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.05407614191106047, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9682029069680242}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:53,806] Trial 519 finished with value: 0.6335426335426335 and parameters: {'C': 0.048803912996897854, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 111, 'tol': 0.04298973118311291, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8973304805744826}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:53,963] Trial 520 finished with value: 0.7807327381878917 and parameters: {'C': 0.01893606433437003, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0482439745755352, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9856656425365912}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:54,185] Trial 521 finished with value: 0.7982688570923864 and parameters: {'C': 0.08420263719358372, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04595867603646347, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9137016344657685}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:02:54,409] Trial 522 finished with value: 0.7612179224383437 and parameters: {'C': 0.03879953247268677, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 102, 'tol': 0.04431644491985148, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8576207403242895}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:54,630] Trial 523 finished with value: 0.8028531639803915 and parameters: {'C': 0.0548811324961406, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05063242934602069, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9488282426035514}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:54,854] Trial 524 finished with value: 0.7893030285187149 and parameters: {'C': 0.024663966881940697, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04180955174127522, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8832973023831552}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:55,081] Trial 525 finished with value: 0.7982688570923864 and parameters: {'C': 0.07170720995270499, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 187, 'tol': 0.04827357926615317, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9284302475162723}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:55,304] Trial 526 finished with value: 0.7982688570923864 and parameters: {'C': 0.10494056384131281, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04599863577543415, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8361710120136241}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:55,526] Trial 527 finished with value: 0.7936710813206824 and parameters: {'C': 0.03684956711886552, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.03915551968774606, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8721308534768007}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:55,755] Trial 528 finished with value: 0.8028531639803915 and parameters: {'C': 0.05296749801231685, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04361658240304781, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9036586861599082}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:55,990] Trial 529 finished with value: 0.7982688570923864 and parameters: {'C': 0.07437213306241347, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04724628151406863, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9524046578462816}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:56,226] Trial 530 finished with value: 0.802641903871957 and parameters: {'C': 0.19471240431888173, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.049540632202105285, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9191365754838403}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:56,464] Trial 531 finished with value: 0.7982688570923864 and parameters: {'C': 0.03055912818441829, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.05213938781518935, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8504773280611609}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:56,689] Trial 532 finished with value: 0.8028531639803915 and parameters: {'C': 0.05169243835317992, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.045352194701247225, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9992282953884633}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:56,908] Trial 533 finished with value: 0.7936710813206824 and parameters: {'C': 0.04007796008021026, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04101715501941908, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9770538589469137}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:57,138] Trial 534 finished with value: 0.7982688570923864 and parameters: {'C': 0.10707692726218744, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04298592817448867, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8895605177317129}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:57,343] Trial 535 finished with value: 0.7563267813267813 and parameters: {'C': 0.0676319543688014, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04763206242502289, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9396767830850173}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:57,563] Trial 536 finished with value: 0.7893030285187149 and parameters: {'C': 0.024961032658433965, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.0451613699945646, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.866199127381957}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:57,784] Trial 537 finished with value: 0.7936710813206824 and parameters: {'C': 0.04040710154591036, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.049167348328403235, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9075596042147818}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:57,953] Trial 538 finished with value: 0.7610556379121386 and parameters: {'C': 0.05578054441864076, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 110, 'tol': 0.03796003957492471, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9525147859669363}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:58,118] Trial 539 finished with value: 0.7982688570923864 and parameters: {'C': 0.0834036486108181, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04644645159703673, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8905072064305155}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:58,334] Trial 540 finished with value: 0.7982688570923864 and parameters: {'C': 0.12676892719549523, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 97, 'tol': 0.0433504695446847, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.13016124131199525}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:58,494] Trial 541 finished with value: 0.5468723080840191 and parameters: {'C': 0.030571136550290534, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 124, 'tol': 0.0572381319973402, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9240429874443826}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:58,663] Trial 542 finished with value: 0.8028531639803915 and parameters: {'C': 0.047305609497170185, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04503035398673674, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6696585686865293}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:58,972] Trial 543 finished with value: 0.7938919441613183 and parameters: {'C': 0.06792992803948535, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.050806066580060365, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.814118757254845}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:59,249] Trial 544 finished with value: 0.7807327381878917 and parameters: {'C': 0.018530041284781733, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.040232786982053625, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9714254203889254}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:59,452] Trial 545 finished with value: 0.6244551002615518 and parameters: {'C': 0.0925710581170823, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 104, 'tol': 0.047416559791261206, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8458655472377459}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:59,664] Trial 546 finished with value: 0.7936710813206824 and parameters: {'C': 0.04091273883906692, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04243785904399231, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8752994640668312}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:02:59,922] Trial 547 finished with value: 0.7587471277840314 and parameters: {'C': 0.00861967126437889, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04939044393513609, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9341906342798941}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:00,169] Trial 548 finished with value: 0.7528261852586178 and parameters: {'C': 0.05644448073520753, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 128, 'tol': 0.044603035344367895, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.907822469838559}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:00,474] Trial 549 finished with value: 0.7982688570923864 and parameters: {'C': 0.03299081184542058, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04681498203821308, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8613798189877806}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:00,731] Trial 550 finished with value: 0.7982688570923864 and parameters: {'C': 0.16423366443687737, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04121717429724353, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8300443198243023}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:00,962] Trial 551 finished with value: 0.7982688570923864 and parameters: {'C': 0.07939129443098751, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05272232491503259, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9623070071711354}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:01,192] Trial 552 finished with value: 0.8028531639803915 and parameters: {'C': 0.049355715284986335, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04849373632112309, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8928832899125483}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:01,389] Trial 553 finished with value: 0.7743766493766494 and parameters: {'C': 0.02644082454859937, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.02180480332979244, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9833695057566849}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:01,623] Trial 554 finished with value: 0.7982688570923864 and parameters: {'C': 0.0633289700384265, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04404928936526295, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7896705472610149}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:01,882] Trial 555 finished with value: 0.7982688570923864 and parameters: {'C': 0.10453712418679595, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.045844607331293016, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9331241018431811}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:02,142] Trial 556 finished with value: 0.8028531639803915 and parameters: {'C': 0.05948154043275268, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.04235491243378203, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8746199829619847}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:02,394] Trial 557 finished with value: 0.7936710813206824 and parameters: {'C': 0.03915207091777598, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.05056287501120779, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9172396970041758}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:02,643] Trial 558 finished with value: 0.7893030285187149 and parameters: {'C': 0.0228064890048586, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04738639292396649, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9468584012451149}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:02,916] Trial 559 finished with value: 0.7691765275082738 and parameters: {'C': 0.08047685721764977, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.045217594614922835, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.894361224814497}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:03,154] Trial 560 finished with value: 0.8028531639803915 and parameters: {'C': 0.04434065424345822, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.04897457812860582, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8489531301032148}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:03,394] Trial 561 finished with value: 0.7982688570923864 and parameters: {'C': 0.03121918867167644, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04334484946409689, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9610652178382623}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:03,639] Trial 562 finished with value: 0.7982688570923864 and parameters: {'C': 0.13812241254078933, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.046344740482016665, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9202737875334674}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:03,864] Trial 563 finished with value: 0.8028531639803915 and parameters: {'C': 0.04820679297523503, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.03855935734235136, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8650561174577649}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:04,036] Trial 564 finished with value: 0.7657657657657657 and parameters: {'C': 0.0718952833826237, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 117, 'tol': 0.04020347780318048, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8939460325955862}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:04,196] Trial 565 finished with value: 0.7936710813206824 and parameters: {'C': 0.03670740041203901, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.047901339569986635, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9876711481696521}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:04,420] Trial 566 finished with value: 0.7982688570923864 and parameters: {'C': 0.08810034892251782, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04389771753731495, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9465009425153077}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:04,590] Trial 567 finished with value: 0.6067286798994115 and parameters: {'C': 0.0620880915663099, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 111, 'tol': 0.0512070081076146, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8266313782179976}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:04,766] Trial 568 finished with value: 0.7982688570923864 and parameters: {'C': 0.11089273649584193, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04629882658368011, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8794477014927209}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:05,002] Trial 569 finished with value: 0.8028531639803915 and parameters: {'C': 0.04857168379910483, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04291638551486669, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9107841041457228}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:05,239] Trial 570 finished with value: 0.7764613692033047 and parameters: {'C': 0.015513234810056396, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04934687202132582, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9271976724462203}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:05,481] Trial 571 finished with value: 0.7982688570923864 and parameters: {'C': 0.030925175335991595, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.05365438239379705, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.23742583227430913}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:05,666] Trial 572 finished with value: 0.6335426335426335 and parameters: {'C': 0.06113644120387776, 'fit_intercept': False, 'solver': 'sag', 'max_iter': 108, 'tol': 0.04524181354958159, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.850307586657424}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:05,845] Trial 573 finished with value: 0.7893030285187149 and parameters: {'C': 0.022428638863449753, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04169993875762839, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.969043331235804}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:06,110] Trial 574 finished with value: 0.7664686441880739 and parameters: {'C': 0.039109832049725415, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 124, 'tol': 0.04762902291740455, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9014457818945085}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:06,359] Trial 575 finished with value: 0.8028531639803915 and parameters: {'C': 0.09092932382966461, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04471278089630311, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8828485073955765}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:06,606] Trial 576 finished with value: 0.8028531639803915 and parameters: {'C': 0.053850977508627856, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.05078675607654467, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9411550555787177}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:06,847] Trial 577 finished with value: 0.7982688570923864 and parameters: {'C': 0.07096767149908018, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.03634732762084521, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8576520426334368}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:07,126] Trial 578 finished with value: 0.7643951617832215 and parameters: {'C': 0.04140525191394513, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04621612917652716, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9561393205937871}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:07,351] Trial 579 finished with value: 0.7982688570923864 and parameters: {'C': 0.13773896809702374, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.041446288657933546, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8079165759750485}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:07,568] Trial 580 finished with value: 0.7982688570923864 and parameters: {'C': 0.029206695695937455, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04923265917848759, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9207242625506075}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:07,793] Trial 581 finished with value: 0.8028531639803915 and parameters: {'C': 0.05092580747313733, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.04404663160401894, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9999454037481553}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:08,022] Trial 582 finished with value: 0.7982688570923864 and parameters: {'C': 0.09642650324723569, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.047043273610372735, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8371435642286227}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:08,245] Trial 583 finished with value: 0.7982688570923864 and parameters: {'C': 0.07003210287682397, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.09677204360110067, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8715072628036267}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:08,466] Trial 584 finished with value: 0.7936710813206824 and parameters: {'C': 0.03775893931681283, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04286442784261391, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9039669267767759}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:08,686] Trial 585 finished with value: 0.7893030285187149 and parameters: {'C': 0.022258817110880687, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.0398614455525583, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9782098965854561}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:08,913] Trial 586 finished with value: 0.8028531639803915 and parameters: {'C': 0.0524065088118471, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.045746845310659874, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9363492193848136}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:09,142] Trial 587 finished with value: 0.7982688570923864 and parameters: {'C': 0.08332918160233783, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04811505613422398, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.2678316939686237}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:09,365] Trial 588 finished with value: 0.7982688570923864 and parameters: {'C': 0.029980162882191762, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.044034193516712214, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8759290093296672}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:09,593] Trial 589 finished with value: 0.8028531639803915 and parameters: {'C': 0.0617505848970359, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.04908631493856522, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8937371672440618}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:09,778] Trial 590 finished with value: 0.7563267813267813 and parameters: {'C': 0.04292185892280664, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 117, 'tol': 0.05526113627715498, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9569951181769552}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:09,947] Trial 591 finished with value: 0.7563267813267813 and parameters: {'C': 0.11034812013112319, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.046094845338151995, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9272416633171279}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:10,191] Trial 592 finished with value: 0.7982688570923864 and parameters: {'C': 0.0704411518369332, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.05107067258111924, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8576778025818838}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:10,422] Trial 593 finished with value: 0.7936710813206824 and parameters: {'C': 0.03640389036314597, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.04246324121993347, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9073734049412268}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:10,662] Trial 594 finished with value: 0.8028531639803915 and parameters: {'C': 0.049405383628226225, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 196, 'tol': 0.04780479813297612, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8352709213772633}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:10,901] Trial 595 finished with value: 0.802641903871957 and parameters: {'C': 0.18398955293994385, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04446062372966435, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9784652647297887}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:11,081] Trial 596 finished with value: 0.6335426335426335 and parameters: {'C': 2.8318829751442536, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 115, 'tol': 0.04082748173176269, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.942851900498012}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:11,193] Trial 597 finished with value: 0.5436936827079013 and parameters: {'C': 0.08958415398978499, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 110, 'tol': 0.052634392580027715, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8853142580324664}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:11,371] Trial 598 finished with value: 0.718244275019191 and parameters: {'C': 0.0025907745501106746, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.03795865812528309, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.918472416525348}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:11,589] Trial 599 finished with value: 0.8028531639803915 and parameters: {'C': 0.05988888613763706, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.046038671519998055, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8658035454335343}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:11,869] Trial 600 finished with value: 0.7797906014122231 and parameters: {'C': 0.029368680900945993, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 177, 'tol': 0.049706752430987454, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9546103652678988}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:12,094] Trial 601 finished with value: 0.7982688570923864 and parameters: {'C': 0.12899174678267777, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04390417661092236, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8940519553437584}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:12,325] Trial 602 finished with value: 0.7895106372229068 and parameters: {'C': 0.020968781606807332, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04765448636203201, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7539520379282986}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:12,550] Trial 603 finished with value: 0.8028531639803915 and parameters: {'C': 0.044771700794624975, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.045792810342549714, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9311509023773374}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:12,781] Trial 604 finished with value: 0.7982688570923864 and parameters: {'C': 0.07320680358682574, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04275453055604361, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8447087136887512}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:13,013] Trial 605 finished with value: 0.7936710813206824 and parameters: {'C': 0.03650472797501381, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.01158197109972714, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9718197504968799}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:13,243] Trial 606 finished with value: 0.8028531639803915 and parameters: {'C': 0.05507830172055714, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.048347936380479684, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9094377726005792}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:13,474] Trial 607 finished with value: 0.7982688570923864 and parameters: {'C': 0.09686675319814014, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04143956429012847, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8794050367185936}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:13,701] Trial 608 finished with value: 0.7982688570923864 and parameters: {'C': 0.028796048765410646, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04495014812443808, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9449593763020988}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:13,924] Trial 609 finished with value: 0.8028531639803915 and parameters: {'C': 0.049432079471532345, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.05077117484927511, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8092612876349083}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:14,106] Trial 610 finished with value: 0.6554371600095441 and parameters: {'C': 0.00036848060017236506, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.046925269605827824, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8599223112618869}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:14,343] Trial 611 finished with value: 0.7982688570923864 and parameters: {'C': 0.07199486391515635, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.039232164216189164, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9117722062137101}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:14,570] Trial 612 finished with value: 0.633156233156233 and parameters: {'C': 8.567489131099656e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.005551795771202732, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9862189301715196}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:14,795] Trial 613 finished with value: 0.7936710813206824 and parameters: {'C': 0.03910988445959379, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04410611812728325, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8894640628961964}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:15,034] Trial 614 finished with value: 0.7764613692033047 and parameters: {'C': 0.0151464487012841, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0476535343776725, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8252396911685278}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:15,264] Trial 615 finished with value: 0.8028531639803915 and parameters: {'C': 0.06100262488677356, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04172270819412277, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9638702239635953}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:15,521] Trial 616 finished with value: 0.7691765275082738 and parameters: {'C': 0.1013016857088221, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04954417841520261, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9274993447694446}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:15,754] Trial 617 finished with value: 0.7893030285187149 and parameters: {'C': 0.024653611579112576, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.045999589679573995, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.901591841235099}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:15,930] Trial 618 finished with value: 0.7563267813267813 and parameters: {'C': 0.042533731037400706, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 109, 'tol': 0.052037138696635274, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8707816913524277}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:16,067] Trial 619 finished with value: 0.6067286798994115 and parameters: {'C': 0.07063486359895593, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 118, 'tol': 0.04305007806447471, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9362265166771352}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:16,252] Trial 620 finished with value: 0.7982688570923864 and parameters: {'C': 0.1385312200346723, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04492723979655041, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9611221974374048}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:16,503] Trial 621 finished with value: 0.7982688570923864 and parameters: {'C': 0.032260871696120054, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 99, 'tol': 0.04715235079731978, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8506468633411439}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:16,764] Trial 622 finished with value: 0.8028531639803915 and parameters: {'C': 0.05690053166410116, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.04910731604619193, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8857370891897232}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:16,959] Trial 623 finished with value: 0.6335426335426335 and parameters: {'C': 0.08902675662993173, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 125, 'tol': 0.039968909023362274, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9171902089868895}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:17,160] Trial 624 finished with value: 0.8028531639803915 and parameters: {'C': 0.04674059107975733, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04524497012314793, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9471269439000843}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:17,415] Trial 625 finished with value: 0.7982688570923864 and parameters: {'C': 0.03442069833055701, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.0426776782153737, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8669677603514375}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:17,684] Trial 626 finished with value: 0.7982688570923864 and parameters: {'C': 0.06916068096089094, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.047093520866908885, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9062270214381141}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:17,944] Trial 627 finished with value: 0.8028531639803915 and parameters: {'C': 0.04891878642793389, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04439334813905817, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9842003492838666}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:18,191] Trial 628 finished with value: 0.7387387387387387 and parameters: {'C': 0.102516184708502, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 112, 'tol': 0.09292818613624695, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8381597254597594}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:18,398] Trial 629 finished with value: 0.7606120086567014 and parameters: {'C': 0.019703272208099372, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.050294971441216266, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8842960173793823}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:18,634] Trial 630 finished with value: 0.7982688570923864 and parameters: {'C': 0.07370636281116524, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.053709592378764756, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.08048731894252947}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:18,863] Trial 631 finished with value: 0.8028531639803915 and parameters: {'C': 0.04170350103224696, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.04798011037456968, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9240783262448989}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:19,092] Trial 632 finished with value: 0.7982688570923864 and parameters: {'C': 0.03125042002459628, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04612391659646567, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9645039379137352}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:19,323] Trial 633 finished with value: 0.8028531639803915 and parameters: {'C': 0.05523856153061058, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04131744099166242, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9381058794662707}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:19,559] Trial 634 finished with value: 0.7982688570923864 and parameters: {'C': 0.12737877667973876, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 170, 'tol': 0.03688455285355906, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9980154375297793}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:19,828] Trial 635 finished with value: 0.7982688570923864 and parameters: {'C': 0.08260096750670946, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.0435272755446523, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7011096755598641}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:20,105] Trial 636 finished with value: 0.7729338533936235 and parameters: {'C': 0.026383989593297175, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04815369932856524, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8523291628004472}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:20,343] Trial 637 finished with value: 0.8028531639803915 and parameters: {'C': 0.056672337793683046, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.051676973661374206, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8961264040472372}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:20,578] Trial 638 finished with value: 0.7936710813206824 and parameters: {'C': 0.04037297186859402, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04530159269343253, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8728266063102043}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:20,816] Trial 639 finished with value: 0.802641903871957 and parameters: {'C': 0.18053014812374, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04916921164259068, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7910342374578136}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:21,055] Trial 640 finished with value: 0.7982688570923864 and parameters: {'C': 0.06447705487898905, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.041868140113905314, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9113838505247606}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:21,295] Trial 641 finished with value: 0.8028531639803915 and parameters: {'C': 0.04517597629868243, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.0460574194498272, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.945848183111768}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:21,545] Trial 642 finished with value: 0.7982688570923864 and parameters: {'C': 0.08722915453309614, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.03990825112558504, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8312810496947187}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:21,787] Trial 643 finished with value: 0.7936710813206824 and parameters: {'C': 0.025701473350345443, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04417720318020159, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.971517796516978}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:21,965] Trial 644 finished with value: 0.7606120086567014 and parameters: {'C': 0.03524811926147227, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 103, 'tol': 0.05008632932421961, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.88907244049264}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:22,148] Trial 645 finished with value: 0.8028531639803915 and parameters: {'C': 0.05731658016928375, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.046949024982705485, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9297390315290159}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:22,391] Trial 646 finished with value: 0.7982688570923864 and parameters: {'C': 0.12371194960971124, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.043688917263574496, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8677536119651288}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:22,586] Trial 647 finished with value: 0.6067286798994115 and parameters: {'C': 0.08056973202355584, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 107, 'tol': 0.04827879238184086, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9016148736160681}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:22,797] Trial 648 finished with value: 0.7808748507543689 and parameters: {'C': 0.017727188796949872, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 87, 'tol': 0.0461823678697951, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9533813069746568}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:23,028] Trial 649 finished with value: 0.7515784995494071 and parameters: {'C': 0.046563407347176206, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04231813079809403, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8506571350950355}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:23,215] Trial 650 finished with value: 0.6335426335426335 and parameters: {'C': 0.03520446982357562, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 115, 'tol': 0.044687215433434464, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9268759153172279}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:23,376] Trial 651 finished with value: 0.6285520514310458 and parameters: {'C': 1.7537894288958928e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.052303326917479166, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8809547217827027}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:23,612] Trial 652 finished with value: 0.7982688570923864 and parameters: {'C': 0.06473486648613624, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.03887842461054132, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8164914910511147}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:23,851] Trial 653 finished with value: 0.7571431799692669 and parameters: {'C': 0.0491126980787613, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 109, 'tol': 0.049249319913448476, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9072155044016409}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:24,095] Trial 654 finished with value: 0.7982688570923864 and parameters: {'C': 0.1119106155114725, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.0469532369086976, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9540255629903812}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:24,370] Trial 655 finished with value: 0.7729338533936235 and parameters: {'C': 0.02381293156771432, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04319683639996844, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8626261319865965}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:24,615] Trial 656 finished with value: 0.7982688570923864 and parameters: {'C': 0.08121738305653574, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.040836143195185894, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9165222944408664}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:24,847] Trial 657 finished with value: 0.7982688570923864 and parameters: {'C': 0.03520310160754335, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.045592061769071594, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9788101425256827}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:25,079] Trial 658 finished with value: 0.8028531639803915 and parameters: {'C': 0.05900955230711893, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04825502302942834, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8875014643324096}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:25,315] Trial 659 finished with value: 0.8028531639803915 and parameters: {'C': 0.046808666756842254, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.05100616917823199, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.003902675310247683}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:25,551] Trial 660 finished with value: 0.7982688570923864 and parameters: {'C': 0.0936611790142638, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.04416526291534076, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8400549721976035}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:25,785] Trial 661 finished with value: 0.7982688570923864 and parameters: {'C': 0.02965688393543547, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04680128105324308, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9423125657753263}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:26,021] Trial 662 finished with value: 0.7938919441613183 and parameters: {'C': 0.06581346806513846, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04312798789150722, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6358241093648949}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:26,250] Trial 663 finished with value: 0.8028531639803915 and parameters: {'C': 0.0443020076762893, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04938362915855496, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9729840656626981}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:26,481] Trial 664 finished with value: 0.7982688570923864 and parameters: {'C': 0.16538104580561078, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04521952908878497, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8705406252822913}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:26,717] Trial 665 finished with value: 0.7938919441613183 and parameters: {'C': 0.06699304044259298, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04075687675778893, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9015133851003692}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:26,961] Trial 666 finished with value: 0.7765503863064839 and parameters: {'C': 0.012277978874783635, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.047582016929585955, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.926038394281748}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:27,168] Trial 667 finished with value: 0.7653517153517153 and parameters: {'C': 0.03319122427715148, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 95, 'tol': 0.04190491449535176, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.957764972471774}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:27,347] Trial 668 finished with value: 0.7610556379121386 and parameters: {'C': 0.10050120448996415, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 121, 'tol': 0.04577296640267857, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8522360537078882}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:27,518] Trial 669 finished with value: 0.8028531639803915 and parameters: {'C': 0.05197020889321675, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05028900303157045, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.2960843439132713}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:27,747] Trial 670 finished with value: 0.7982688570923864 and parameters: {'C': 0.07470718946130987, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.08265720139081251, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9879062144967028}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:27,931] Trial 671 finished with value: 0.6067286798994115 and parameters: {'C': 0.023436071025291997, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 105, 'tol': 0.03734256884885246, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8885825130893367}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:28,111] Trial 672 finished with value: 0.7936710813206824 and parameters: {'C': 0.04134420224887151, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.05403879812449742, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9160132043824709}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:28,368] Trial 673 finished with value: 0.7595927526039051 and parameters: {'C': 0.0571715715784541, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04333664808321604, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8222164379670241}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:28,608] Trial 674 finished with value: 0.7982688570923864 and parameters: {'C': 0.12893467130449998, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.048005100864397396, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9345377381895921}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:28,829] Trial 675 finished with value: 0.7982688570923864 and parameters: {'C': 0.03266963973372134, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04516742416290137, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8715084430868673}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:29,062] Trial 676 finished with value: 0.7982688570923864 and parameters: {'C': 0.07766909620340517, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.046719265911946944, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9977569432926984}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:29,248] Trial 677 finished with value: 0.6335426335426335 and parameters: {'C': 0.04302240947270256, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 108, 'tol': 0.039441287074721915, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8998249684421253}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:29,482] Trial 678 finished with value: 0.6822553692964368 and parameters: {'C': 0.0009733620566050719, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 124, 'tol': 0.04914457686852855, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9647910959139924}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:29,879] Trial 679 finished with value: 0.7808748507543689 and parameters: {'C': 0.017780538166639142, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.044048074600948894, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9435297301077552}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:30,129] Trial 680 finished with value: 0.7982688570923864 and parameters: {'C': 0.0964677839288014, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 58, 'tol': 0.05188735423760529, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9180487152997531}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:30,378] Trial 681 finished with value: 0.8028531639803915 and parameters: {'C': 0.05891674787764114, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.042327001410110816, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.844916266137562}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:30,619] Trial 682 finished with value: 0.7936710813206824 and parameters: {'C': 0.037479209647327365, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.04657600284906053, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8759564145552046}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:30,852] Trial 683 finished with value: 0.8028531639803915 and parameters: {'C': 0.05352534558151754, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.044695629987412694, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.894298236672523}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:31,153] Trial 684 finished with value: 0.7893030285187149 and parameters: {'C': 0.02522442515881212, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.07868287240183225, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9325612236531745}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:31,504] Trial 685 finished with value: 0.7982688570923864 and parameters: {'C': 0.07707184124303576, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04790406967778187, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8562200604696711}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:31,782] Trial 686 finished with value: 0.7515784995494071 and parameters: {'C': 0.0443979323313724, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.050589664726238354, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9647258782112806}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:32,016] Trial 687 finished with value: 0.7982688570923864 and parameters: {'C': 0.10979257037334725, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.041096347866749414, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9090614409427573}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:32,219] Trial 688 finished with value: 0.7982688570923864 and parameters: {'C': 0.06299773030804383, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.045926858314870096, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8310124829206913}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:32,422] Trial 689 finished with value: 0.802641903871957 and parameters: {'C': 0.21770528109009557, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.0431531227387855, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8843708403679892}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:32,631] Trial 690 finished with value: 0.7982688570923864 and parameters: {'C': 0.028723247170006294, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.048741402454081456, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.948362586196762}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:32,828] Trial 691 finished with value: 0.7936710813206824 and parameters: {'C': 0.038050081025589814, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.045754497575365954, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8028708903457364}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:33,063] Trial 692 finished with value: 0.7982688570923864 and parameters: {'C': 0.081751065806593, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.04441387083239503, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8669079456113336}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:33,318] Trial 693 finished with value: 0.7643951617832215 and parameters: {'C': 0.05386497533626677, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04762519642991254, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9800035875895443}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:33,505] Trial 694 finished with value: 0.7657657657657657 and parameters: {'C': 0.13893020971182365, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 116, 'tol': 0.0384897390206234, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.914347934571222}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:33,677] Trial 695 finished with value: 0.7895106372229068 and parameters: {'C': 0.020945703994108382, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04129504671003123, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7789204285685891}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:33,904] Trial 696 finished with value: 0.7982688570923864 and parameters: {'C': 0.03291467787179598, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 136, 'tol': 0.05032813552465675, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9382931092923603}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:34,089] Trial 697 finished with value: 0.6067286798994115 and parameters: {'C': 0.0747467197295545, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 108, 'tol': 0.04311620938526705, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8924012092146155}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:34,258] Trial 698 finished with value: 0.8028531639803915 and parameters: {'C': 0.047952269435251625, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04706546704008754, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8518351223746542}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:34,490] Trial 699 finished with value: 0.7982688570923864 and parameters: {'C': 0.10116169900938599, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.07570330414465531, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9654836166704569}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:34,720] Trial 700 finished with value: 0.8028531639803915 and parameters: {'C': 0.06078718068180131, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04475285199433392, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9990205769975956}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:34,952] Trial 701 finished with value: 0.8028531639803915 and parameters: {'C': 0.041917401459088156, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.049266467419429756, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9251580292632684}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:35,138] Trial 702 finished with value: 0.6244551002615518 and parameters: {'C': 0.029826081313755352, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 106, 'tol': 0.052655378575535164, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.375506887062918}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:35,317] Trial 703 finished with value: 0.7982688570923864 and parameters: {'C': 0.07537741386856922, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04630525891305626, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8725357586336262}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:35,568] Trial 704 finished with value: 0.7614561989915297 and parameters: {'C': 0.0501593841622478, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 122, 'tol': 0.008727410200439024, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9043661702412821}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:35,804] Trial 705 finished with value: 0.7982688570923864 and parameters: {'C': 0.11192035390585085, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.05574624081909426, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9506275460924044}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:36,018] Trial 706 finished with value: 0.7563267813267813 and parameters: {'C': 0.061679697097276776, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.042658575749572124, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8850763515569732}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:36,246] Trial 707 finished with value: 0.7936710813206824 and parameters: {'C': 0.03917086663099335, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04062593572426619, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8241554356706444}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:36,488] Trial 708 finished with value: 0.7587471277840314 and parameters: {'C': 0.00818221485206667, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.04807287955824355, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9354111673925806}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:36,762] Trial 709 finished with value: 0.7893030285187149 and parameters: {'C': 0.024029774749298148, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04507582816899358, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8448632299591686}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:37,023] Trial 710 finished with value: 0.8028531639803915 and parameters: {'C': 0.0907052856305084, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.050149497947519765, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9115298971416512}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:37,299] Trial 711 finished with value: 0.7643951617832215 and parameters: {'C': 0.05206507721913108, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.043781202715190065, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8640175571696718}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:37,555] Trial 712 finished with value: 0.7982688570923864 and parameters: {'C': 0.150097810992534, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.046890696711635295, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9773346070111043}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:37,788] Trial 713 finished with value: 0.7982688570923864 and parameters: {'C': 0.0333149120314692, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.042544280158885575, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.951640120880926}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:38,026] Trial 714 finished with value: 0.7982688570923864 and parameters: {'C': 0.07010756577762406, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04867169799457416, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8901693989802749}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:38,264] Trial 715 finished with value: 0.8028531639803915 and parameters: {'C': 0.046469113170367136, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04508108865473622, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.917467774093641}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:38,498] Trial 716 finished with value: 0.7938919441613183 and parameters: {'C': 0.06691951948679555, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.05133567609320994, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8736500658098477}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:38,742] Trial 717 finished with value: 0.78512441012441 and parameters: {'C': 0.01931784950690195, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.017949828795162798, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9313573696862233}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:38,982] Trial 718 finished with value: 0.7936710813206824 and parameters: {'C': 0.03614576168541526, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.036128952100423405, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8436927116048323}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:39,223] Trial 719 finished with value: 0.7982688570923864 and parameters: {'C': 0.09402115181944143, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 99, 'tol': 0.039522235044347424, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8986372527824078}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:39,486] Trial 720 finished with value: 0.7982688570923864 and parameters: {'C': 0.028652379046002048, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04677155236656515, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9578726927254659}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:39,824] Trial 721 finished with value: 0.8028531639803915 and parameters: {'C': 0.05433399108325253, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04177275282533079, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9761943960677714}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:40,008] Trial 722 finished with value: 0.7563267813267813 and parameters: {'C': 0.04380558151914117, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 181, 'tol': 0.04508010572635147, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8092156477494482}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:40,138] Trial 723 finished with value: 0.6067286798994115 and parameters: {'C': 0.07771402647327504, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 109, 'tol': 0.04854708633882683, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8611951972582871}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:40,296] Trial 724 finished with value: 0.7563267813267813 and parameters: {'C': 0.11659407648232291, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04396402637820736, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9002011756869096}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:40,531] Trial 725 finished with value: 0.8028531639803915 and parameters: {'C': 0.05406766006980029, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.046841652085562596, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9256306574759238}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:40,769] Trial 726 finished with value: 0.7936710813206824 and parameters: {'C': 0.03747786906937465, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.05256983217106273, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8859321807626415}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:40,957] Trial 727 finished with value: 0.6244551002615518 and parameters: {'C': 0.014808837775609708, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 114, 'tol': 0.05017633943264355, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9386070437658529}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:41,142] Trial 728 finished with value: 0.7938919441613183 and parameters: {'C': 0.06749962959033708, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 166, 'tol': 0.04211434095418315, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8291873550854459}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:41,383] Trial 729 finished with value: 0.7893030285187149 and parameters: {'C': 0.023865089837862834, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.045819270576384824, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9611125449159802}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:41,644] Trial 730 finished with value: 0.7401577401577403 and parameters: {'C': 0.0879528793710577, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 123, 'tol': 0.04811071609355229, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.4426807581505505}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:41,897] Trial 731 finished with value: 0.8028531639803915 and parameters: {'C': 0.04364834384525926, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.03961439101049674, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5132844723317063}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:42,150] Trial 732 finished with value: 0.7982688570923864 and parameters: {'C': 0.02936769041272654, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04355493267031108, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.906350591656657}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:42,400] Trial 733 finished with value: 0.7982688570923864 and parameters: {'C': 0.1533892638916773, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.046170119122130045, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.872658875155461}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:42,657] Trial 734 finished with value: 0.8028531639803915 and parameters: {'C': 0.05733743511721914, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.04932286244265908, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9847728791796656}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:42,919] Trial 735 finished with value: 0.7982688570923864 and parameters: {'C': 0.07315838652383361, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04407363310948248, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.923778223577872}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:43,183] Trial 736 finished with value: 0.7936710813206824 and parameters: {'C': 0.03873720925483728, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04110670616931412, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.949888752437002}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:43,444] Trial 737 finished with value: 0.7982688570923864 and parameters: {'C': 0.09886828926907604, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.047728274197523, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8626127776365445}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:43,705] Trial 738 finished with value: 0.8028531639803915 and parameters: {'C': 0.05438206919685393, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.08955074887084445, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.885753536178743}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:43,957] Trial 739 finished with value: 0.7982688570923864 and parameters: {'C': 0.030981665754181393, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04528654713576711, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8405034339081944}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:44,209] Trial 740 finished with value: 0.8028531639803915 and parameters: {'C': 0.0442391022602412, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.05126521872841124, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9147564635727324}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:44,477] Trial 741 finished with value: 0.7982688570923864 and parameters: {'C': 0.07601945034036228, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.03741409584182751, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9993325580795472}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:44,733] Trial 742 finished with value: 0.802641903871957 and parameters: {'C': 0.2056857449667475, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.0475054593737513, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9439683278674003}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:44,977] Trial 743 finished with value: 0.7982688570923864 and parameters: {'C': 0.12212286712481488, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04278864853098027, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9695226039461379}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:45,208] Trial 744 finished with value: 0.7563267813267813 and parameters: {'C': 0.06152725035386192, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04494573852529208, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9014844422053193}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:45,448] Trial 745 finished with value: 0.7849307243422452 and parameters: {'C': 0.021414458242901613, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05429529774503151, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8608403130149118}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:45,693] Trial 746 finished with value: 0.7936710813206824 and parameters: {'C': 0.038343240866412096, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04959880474470902, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8812123025664991}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:45,882] Trial 747 finished with value: 0.7515784995494071 and parameters: {'C': 0.04986232370095177, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 110, 'tol': 0.06629312024498503, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.926077271285972}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:46,102] Trial 748 finished with value: 0.7691765275082738 and parameters: {'C': 0.09398025243946784, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.047092306855615156, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9020360851053751}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:46,353] Trial 749 finished with value: 0.7982688570923864 and parameters: {'C': 0.02899104738882354, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04085869839061884, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8501150435593646}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:46,605] Trial 750 finished with value: 0.7938919441613183 and parameters: {'C': 0.06663998007239291, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.043558574472184405, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6062586706548126}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:46,795] Trial 751 finished with value: 0.6067286798994115 and parameters: {'C': 0.04543410479497398, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 101, 'tol': 0.04635273845164155, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9482315140005362}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:46,987] Trial 752 finished with value: 0.7982688570923864 and parameters: {'C': 0.08311744190162097, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04920056641043493, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8241783866498643}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:47,179] Trial 753 finished with value: 0.6244551002615518 and parameters: {'C': 0.05756333607729002, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 110, 'tol': 0.04500554089939234, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9691907856907939}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:47,357] Trial 754 finished with value: 0.7982688570923864 and parameters: {'C': 0.03435561695887421, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04260211175003136, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8809346251090007}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:47,602] Trial 755 finished with value: 0.7982688570923864 and parameters: {'C': 0.1062267116899019, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05145659378254739, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9276106416710465}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:47,843] Trial 756 finished with value: 0.7893030285187149 and parameters: {'C': 0.025299138803587928, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.038592058768901996, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9078134892909342}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:48,087] Trial 757 finished with value: 0.8028531639803915 and parameters: {'C': 0.06057297086771649, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04818321759780779, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4688785348278629}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:48,323] Trial 758 finished with value: 0.7982688570923864 and parameters: {'C': 0.04151612093824511, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.046429181675891405, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8693474857599601}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:48,575] Trial 759 finished with value: 0.7571431799692669 and parameters: {'C': 0.07577884622986786, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 109, 'tol': 0.044313647581580795, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.047124474452887255}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:48,817] Trial 760 finished with value: 0.7982688570923864 and parameters: {'C': 0.14355409746970757, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.041782002716294765, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9424693586853833}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:49,062] Trial 761 finished with value: 0.8028531639803915 and parameters: {'C': 0.04973956567986638, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.049603262518322866, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8965201192829326}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:49,271] Trial 762 finished with value: 0.7473018473018472 and parameters: {'C': 0.014248413053477304, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.04595620490807122, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7971978622103262}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:49,514] Trial 763 finished with value: 0.7936710813206824 and parameters: {'C': 0.03840074270696601, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04371530393079226, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9780363560472448}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:49,842] Trial 764 finished with value: 0.7982688570923864 and parameters: {'C': 0.027538510377205096, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04751698370554737, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8509809947276454}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:50,088] Trial 765 finished with value: 0.7982688570923864 and parameters: {'C': 0.08694695920604395, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.04047260863294681, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9156036730399387}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:50,330] Trial 766 finished with value: 0.8028531639803915 and parameters: {'C': 0.060945824203365535, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.05185409950361416, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9563894546602405}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:50,569] Trial 767 finished with value: 0.7807327381878917 and parameters: {'C': 0.01859664738395089, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 155, 'tol': 0.04565332151469612, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8810306386654962}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:50,837] Trial 768 finished with value: 0.7643951617832215 and parameters: {'C': 0.0512409010154746, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.0996831039337468, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9293867238649032}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:51,097] Trial 769 finished with value: 0.7982688570923864 and parameters: {'C': 0.0337150759589844, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.048340095352078664, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8415549562284345}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:51,369] Trial 770 finished with value: 0.7938919441613183 and parameters: {'C': 0.06775211637060012, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04266925735817219, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9838357323264721}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:51,648] Trial 771 finished with value: 0.7982688570923864 and parameters: {'C': 0.11860632028876512, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.04456357569334564, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8913298126469369}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:51,849] Trial 772 finished with value: 0.7563267813267813 and parameters: {'C': 0.04387187315907033, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 116, 'tol': 0.04677481025404216, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8675338683916726}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:52,032] Trial 773 finished with value: 0.7982688570923864 and parameters: {'C': 0.08477797626185575, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.05022292311860844, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9610457217784475}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:52,271] Trial 774 finished with value: 0.7982688570923864 and parameters: {'C': 0.03254830350007894, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04052923995767985, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9181854831425924}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:52,462] Trial 775 finished with value: 0.6067286798994115 and parameters: {'C': 0.05664598902100733, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 104, 'tol': 0.048470411757097, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8156533682461654}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:52,643] Trial 776 finished with value: 0.7982688570923864 and parameters: {'C': 0.10445241597539782, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.05316785833298527, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9395138709692933}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:52,893] Trial 777 finished with value: 0.7936710813206824 and parameters: {'C': 0.025788028703173437, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.044407216471950645, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9042569000937284}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:53,150] Trial 778 finished with value: 0.8028531639803915 and parameters: {'C': 0.044504707297504956, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.03516821605401725, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.19048216693635645}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:53,409] Trial 779 finished with value: 0.7938919441613183 and parameters: {'C': 0.0667299231427547, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.042695537239432514, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8596954428701457}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:53,615] Trial 780 finished with value: 0.6244551002615518 and parameters: {'C': 0.036748456544990385, 'fit_intercept': False, 'solver': 'sag', 'max_iter': 110, 'tol': 0.04622478518500818, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8842556495598797}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:53,836] Trial 781 finished with value: 0.7982688570923864 and parameters: {'C': 0.08088861383588675, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.03871047662148309, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9993772595967162}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:54,088] Trial 782 finished with value: 0.7982688570923864 and parameters: {'C': 0.16515197086070063, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 91, 'tol': 0.050343768809013485, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9459581724269394}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:03:54,355] Trial 783 finished with value: 0.7751325740456175 and parameters: {'C': 0.05006454690951196, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 119, 'tol': 0.04763355576371547, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.831872413969784}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:54,595] Trial 784 finished with value: 0.7893030285187149 and parameters: {'C': 0.023438169229786372, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04445104603900205, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9234211559280582}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:54,842] Trial 785 finished with value: 0.7982688570923864 and parameters: {'C': 0.0647126408188093, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.041821291660017086, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9727879674485039}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:55,119] Trial 786 finished with value: 0.7643951617832215 and parameters: {'C': 0.03914188460755485, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05886894967819381, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5757928728687419}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:55,368] Trial 787 finished with value: 0.7982688570923864 and parameters: {'C': 0.09681014223425091, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04616115059517678, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.902199538445671}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:55,612] Trial 788 finished with value: 0.8028531639803915 and parameters: {'C': 0.04904415287336942, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04806373525984767, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8741572659954204}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:55,857] Trial 789 finished with value: 0.7982688570923864 and parameters: {'C': 0.030759708112117475, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.04363913597263643, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9545072967145153}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:56,108] Trial 790 finished with value: 0.7982688570923864 and parameters: {'C': 0.07250898686952054, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04996656080186728, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3417012859170607}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:56,358] Trial 791 finished with value: 0.7852816940651992 and parameters: {'C': 0.01830328473921788, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.04556859414746731, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8470201554148251}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:56,602] Trial 792 finished with value: 0.8028531639803915 and parameters: {'C': 0.05416327047363113, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04068570985870258, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9331028990061546}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:56,847] Trial 793 finished with value: 0.7982688570923864 and parameters: {'C': 0.1246254752532221, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04740330618186252, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8938297755977488}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:57,104] Trial 794 finished with value: 0.7936710813206824 and parameters: {'C': 0.03733734369317787, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04272309191877534, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.911314018110147}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:57,351] Trial 795 finished with value: 0.7982688570923864 and parameters: {'C': 0.07766567308930712, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04510986445231368, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8600625331529358}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:57,610] Trial 796 finished with value: 0.7934145698586808 and parameters: {'C': 4.936468617007003, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.052093741447087914, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8811089395938116}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:57,862] Trial 797 finished with value: 0.8028531639803915 and parameters: {'C': 0.05707672784131936, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.049161481532471504, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.968406950371086}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:58,052] Trial 798 finished with value: 0.7696455177639956 and parameters: {'C': 0.028072641266326026, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 107, 'tol': 0.04657555118749336, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7166774434440646}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:58,216] Trial 799 finished with value: 0.7515784995494071 and parameters: {'C': 0.042895637638490115, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04208710536111834, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6774876026041211}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:58,463] Trial 800 finished with value: 0.7982688570923864 and parameters: {'C': 0.09663725552391036, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04424898333960848, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9328591263359658}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:58,656] Trial 801 finished with value: 0.6067286798994115 and parameters: {'C': 0.06489714601460347, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 105, 'tol': 0.048684982117576575, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7431191864483819}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:58,844] Trial 802 finished with value: 0.8028531639803915 and parameters: {'C': 0.04764346812594934, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.038085863770474536, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9170829970279344}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:59,089] Trial 803 finished with value: 0.7982688570923864 and parameters: {'C': 0.03152367644077598, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 73, 'tol': 0.04693914542438918, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9818460406004939}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:59,335] Trial 804 finished with value: 0.7982688570923864 and parameters: {'C': 0.12552198793676142, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.039899503503474265, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9465956045237348}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:59,615] Trial 805 finished with value: 0.7691765275082738 and parameters: {'C': 0.07542836035626897, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04448059266410107, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8435849332314816}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:03:59,823] Trial 806 finished with value: 0.6244551002615518 and parameters: {'C': 0.22501309067677364, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 110, 'tol': 0.049945087390755746, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8931366665681214}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:00,003] Trial 807 finished with value: 0.8028531639803915 and parameters: {'C': 0.05407124359611704, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.045602343996237596, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6514344351576511}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:04:00,253] Trial 808 finished with value: 0.7667586136668584 and parameters: {'C': 0.02070527445149754, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 98, 'tol': 0.04255358291236473, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8618576474278254}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:00,503] Trial 809 finished with value: 0.8028531639803915 and parameters: {'C': 0.09088154590404345, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.051152239075940145, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8793138187922339}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:00,748] Trial 810 finished with value: 0.7936710813206824 and parameters: {'C': 0.03882101655602054, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.047851247013511705, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8137694357690747}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:01,004] Trial 811 finished with value: 0.8028531639803915 and parameters: {'C': 0.06219195827179876, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.05345907090909746, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.961377268740674}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:01,254] Trial 812 finished with value: 0.8028531639803915 and parameters: {'C': 0.04286426093268727, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.045515248444180284, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9132655037037855}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:01,495] Trial 813 finished with value: 0.7982688570923864 and parameters: {'C': 0.030356289249070228, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04353565295727446, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8338533011640002}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:01,746] Trial 814 finished with value: 0.7982688570923864 and parameters: {'C': 0.07918409518697629, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.05613227760134901, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9343212453124536}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:01,988] Trial 815 finished with value: 0.7982688570923864 and parameters: {'C': 0.15544238350903725, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04864216653750877, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8919745907686278}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:02,258] Trial 816 finished with value: 0.8028531639803915 and parameters: {'C': 0.05289052154739148, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04038278964403651, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8664290389701306}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:02,530] Trial 817 finished with value: 0.7982688570923864 and parameters: {'C': 0.09283538256173396, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.045939786862968436, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9831585285810756}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:02,775] Trial 818 finished with value: 0.7610556379121386 and parameters: {'C': 0.03663933970300559, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.02650809648668282, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9569759445763427}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:03,034] Trial 819 finished with value: 0.7893030285187149 and parameters: {'C': 0.02328237081367596, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04707143193879978, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7820193182790096}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:03,351] Trial 820 finished with value: 0.7982688570923864 and parameters: {'C': 0.06317511414329598, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04362523239401385, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9146500280801266}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:03,801] Trial 821 finished with value: 0.7982688570923864 and parameters: {'C': 0.11184388736807564, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.051067189319767115, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8990916876047713}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:04,109] Trial 822 finished with value: 0.8028531639803915 and parameters: {'C': 0.04548302833932287, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04195584523194911, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9369961479313564}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:04,365] Trial 823 finished with value: 0.7982688570923864 and parameters: {'C': 0.06355046074631539, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04913706532016895, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8541146887387598}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:04,555] Trial 824 finished with value: 0.5724680195067033 and parameters: {'C': 0.032127937801003356, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 125, 'tol': 0.044295566401308446, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8838793190740345}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:04,753] Trial 825 finished with value: 0.8028531639803915 and parameters: {'C': 0.047633087676225545, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.046470385597267266, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9209766203275008}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:05,010] Trial 826 finished with value: 0.7982688570923864 and parameters: {'C': 0.07892619898880254, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06854950568908433, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.96306967829782}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:05,206] Trial 827 finished with value: 0.6067286798994115 and parameters: {'C': 0.027101325785733345, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 114, 'tol': 0.04794115077031899, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8328879335408862}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:05,396] Trial 828 finished with value: 0.8028531639803915 and parameters: {'C': 0.05548750434175933, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.041534709563878267, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4210312455890366}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:05,641] Trial 829 finished with value: 0.6287980131205215 and parameters: {'C': 4.2306973474746876e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.045158609010071175, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.875192503591894}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:05,903] Trial 830 finished with value: 0.7720407268897784 and parameters: {'C': 0.011803801988995, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.0384952499994853, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9439909092954377}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:06,100] Trial 831 finished with value: 0.6244551002615518 and parameters: {'C': 0.04147902944262113, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 112, 'tol': 0.05034585808304841, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9052999246949053}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:06,299] Trial 832 finished with value: 0.7982688570923864 and parameters: {'C': 0.11420363020235377, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.04373836630896879, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9891696446868781}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:06,560] Trial 833 finished with value: 0.7982688570923864 and parameters: {'C': 0.07022181303041278, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04701566697798398, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8573392375351556}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:06,817] Trial 834 finished with value: 0.7764613692033047 and parameters: {'C': 0.01647170007594609, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04868275560468344, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9316954913045896}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:04:07,078] Trial 835 finished with value: 0.7520388695314645 and parameters: {'C': 0.03685242546895429, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 100, 'tol': 0.045372449734029756, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8984884969385685}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:07,337] Trial 836 finished with value: 0.7982688570923864 and parameters: {'C': 0.08869807383692738, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04232961709102653, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.963000080919808}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:07,572] Trial 837 finished with value: 0.7515784995494071 and parameters: {'C': 0.053876540766873246, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.039651675735104974, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8788361128057824}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:07,825] Trial 838 finished with value: 0.7893030285187149 and parameters: {'C': 0.024436640871760763, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05213990389334883, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8042747750638721}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:08,089] Trial 839 finished with value: 0.7938919441613183 and parameters: {'C': 0.0667832007822847, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.0471283608589405, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9160588613686542}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:08,348] Trial 840 finished with value: 0.7982688570923864 and parameters: {'C': 0.14791379636181454, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04486175118909308, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9433674366973253}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:08,598] Trial 841 finished with value: 0.7936710813206824 and parameters: {'C': 0.03736868671446267, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.04318650922246463, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8430282568857493}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:08,855] Trial 842 finished with value: 0.8028531639803915 and parameters: {'C': 0.04973983314580133, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.049510389691922944, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8728962651604563}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:09,140] Trial 843 finished with value: 0.7691765275082738 and parameters: {'C': 0.09859454165310406, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.045965117194925235, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9797783241323235}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:09,392] Trial 844 finished with value: 0.7982688570923864 and parameters: {'C': 0.02998969364476757, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.04128748025658396, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9041877924698344}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:09,663] Trial 845 finished with value: 0.7938919441613183 and parameters: {'C': 0.06722198197743391, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.047888471416226513, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9290386820563481}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:09,932] Trial 846 finished with value: 0.8028531639803915 and parameters: {'C': 0.04300120212703689, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04393209655551002, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8260079828784634}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:10,187] Trial 847 finished with value: 0.7982688570923864 and parameters: {'C': 0.078247202221578, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.037021809530430674, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.09396799500716224}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:10,440] Trial 848 finished with value: 0.7893030285187149 and parameters: {'C': 0.021779548640774873, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.05365072015380392, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9530383966139133}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:10,698] Trial 849 finished with value: 0.8028531639803915 and parameters: {'C': 0.05449851839760115, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.0504696822950417, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8587391310477716}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:10,958] Trial 850 finished with value: 0.7982688570923864 and parameters: {'C': 0.11331773502382632, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04650401390453781, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8948058926665301}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:11,207] Trial 851 finished with value: 0.7982688570923864 and parameters: {'C': 0.03446209213664809, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.04304693304343803, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5436726704851137}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:11,408] Trial 852 finished with value: 0.7610556379121386 and parameters: {'C': 0.048842726799700725, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 114, 'tol': 0.04863440002880593, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.886338760368057}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:11,611] Trial 853 finished with value: 0.7982688570923864 and parameters: {'C': 0.0697022678657686, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.045719087910984266, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9184836412868644}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:11,821] Trial 854 finished with value: 0.6067286798994115 and parameters: {'C': 0.08975087287807768, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 107, 'tol': 0.04058565611470319, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9997597165344946}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:12,015] Trial 855 finished with value: 0.7936710813206824 and parameters: {'C': 0.03901275480022281, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04430561318174335, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9654253584821001}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:12,251] Trial 856 finished with value: 0.7563267813267813 and parameters: {'C': 0.05691105104662674, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.047306180972718256, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8682618704923131}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:12,450] Trial 857 finished with value: 0.6244551002615518 and parameters: {'C': 0.029042011121811602, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 120, 'tol': 0.05077162674780157, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9402575563258975}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:12,651] Trial 858 finished with value: 0.802641903871957 and parameters: {'C': 0.18755562221807018, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.041929910575386885, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9140954761359459}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:12,908] Trial 859 finished with value: 0.8028531639803915 and parameters: {'C': 0.045885991838980573, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04493190894389049, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8454777409024322}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:13,170] Trial 860 finished with value: 0.7982688570923864 and parameters: {'C': 0.11907485197579375, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04839358220264561, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8870568552174501}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:04:13,431] Trial 861 finished with value: 0.7528261852586178 and parameters: {'C': 0.07678094898229955, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 101, 'tol': 0.04640076566095266, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9696653561647885}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:13,735] Trial 862 finished with value: 0.7681093417714366 and parameters: {'C': 0.022488637679169157, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04342609599928625, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9286317737953066}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:13,995] Trial 863 finished with value: 0.8028531639803915 and parameters: {'C': 0.05928321377591771, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.03960268560499573, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9516884907052588}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:14,247] Trial 864 finished with value: 0.7936710813206824 and parameters: {'C': 0.037151716970707134, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04904232176283042, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8620951162259487}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:14,502] Trial 865 finished with value: 0.7982688570923864 and parameters: {'C': 0.08742065138846011, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.045466460245508766, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8989874879118721}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:14,753] Trial 866 finished with value: 0.8028531639803915 and parameters: {'C': 0.04909741597324165, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.051368097482185585, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9812760953900417}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:15,007] Trial 867 finished with value: 0.7982688570923864 and parameters: {'C': 0.03164363284306913, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04755084620629714, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4923364431850581}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:15,269] Trial 868 finished with value: 0.8028531639803915 and parameters: {'C': 0.058577215354022626, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.042837404337823806, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8187651759926952}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:15,531] Trial 869 finished with value: 0.7982688570923864 and parameters: {'C': 0.07622729965568723, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 160, 'tol': 0.04495220913103674, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8780904118494365}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:15,790] Trial 870 finished with value: 0.7982688570923864 and parameters: {'C': 0.13612633756643933, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04668336494877829, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9254251329335502}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:16,048] Trial 871 finished with value: 0.7764613692033047 and parameters: {'C': 0.01653159708234532, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04153160528906387, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9994359028746428}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:16,308] Trial 872 finished with value: 0.8028531639803915 and parameters: {'C': 0.0416077267344793, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04935299668521518, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9077023791077286}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:16,562] Trial 873 finished with value: 0.7936710813206824 and parameters: {'C': 0.026962410899348133, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.05252109325949418, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.842123711665445}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:16,818] Trial 874 finished with value: 0.7938919441613183 and parameters: {'C': 0.06662759684046672, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.044207353115106394, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9461767487072856}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:17,055] Trial 875 finished with value: 0.7515784995494071 and parameters: {'C': 0.04709040603349961, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04737705733674032, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8713064700160112}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:17,252] Trial 876 finished with value: 0.7606120086567014 and parameters: {'C': 0.09801344186502993, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 103, 'tol': 0.07186051980535847, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.901566800956782}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:17,457] Trial 877 finished with value: 0.7982688570923864 and parameters: {'C': 0.033371572318692144, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.01381015609586951, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9617945934253467}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:17,747] Trial 878 finished with value: 0.7982688570923864 and parameters: {'C': 0.06458129650247128, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.03966119374032299, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.926719564299886}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:17,961] Trial 879 finished with value: 0.6067286798994115 and parameters: {'C': 0.0450956009430676, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 107, 'tol': 0.049708969309476644, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8508004122388809}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:18,192] Trial 880 finished with value: 0.7982688570923864 and parameters: {'C': 0.09250948239501298, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.0429913345165204, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8904122486740828}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:18,509] Trial 881 finished with value: 0.7681093417714366 and parameters: {'C': 0.021594232466384884, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.045855436410459895, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9460970200310876}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:18,770] Trial 882 finished with value: 0.8028531639803915 and parameters: {'C': 0.055751124005092516, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.05483056742839003, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9790623519716624}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:18,970] Trial 883 finished with value: 0.6244551002615518 and parameters: {'C': 0.03477002757914546, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 119, 'tol': 0.047885275093894675, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8647324284313247}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:19,161] Trial 884 finished with value: 0.7982688570923864 and parameters: {'C': 0.12726604093985316, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04129819717828717, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8323002918036531}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:19,419] Trial 885 finished with value: 0.7982688570923864 and parameters: {'C': 0.075821778394878, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.03594626434677023, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9123918864266398}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:04:19,717] Trial 886 finished with value: 0.7621305943576487 and parameters: {'C': 0.042938144723061546, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 125, 'tol': 0.044542893441162315, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8852164792774602}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:19,982] Trial 887 finished with value: 0.7982688570923864 and parameters: {'C': 0.029622108580513177, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04603119817458409, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9345132706673245}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:20,243] Trial 888 finished with value: 0.8028531639803915 and parameters: {'C': 0.06185712826586862, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0508210229248193, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.968546598849586}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:20,521] Trial 889 finished with value: 0.7934145698586808 and parameters: {'C': 2.036538683708051, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04293552160395296, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8974860718627307}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:20,803] Trial 890 finished with value: 0.8028531639803915 and parameters: {'C': 0.0903534231729925, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.048430635563828005, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8569728950290887}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:21,082] Trial 891 finished with value: 0.8028531639803915 and parameters: {'C': 0.04983670022865961, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04468733459530634, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9218046465608092}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:21,365] Trial 892 finished with value: 0.7936710813206824 and parameters: {'C': 0.03779805823840059, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04719099204434272, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7974824026639078}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:21,628] Trial 893 finished with value: 0.802641903871957 and parameters: {'C': 0.1681646473402631, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04111757386527917, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9520905608100148}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:21,865] Trial 894 finished with value: 0.7563267813267813 and parameters: {'C': 0.06743063921302252, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.0376656673697761, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8840115361580326}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:22,123] Trial 895 finished with value: 0.7893030285187149 and parameters: {'C': 0.02505047477013571, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.046148987827564956, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9113659502609843}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:22,372] Trial 896 finished with value: 0.8028531639803915 and parameters: {'C': 0.05090380726679832, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04945143732374889, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.38996405996793515}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:22,624] Trial 897 finished with value: 0.7982688570923864 and parameters: {'C': 0.10194791451640933, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04346667589944692, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8702598247178084}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:22,879] Trial 898 finished with value: 0.7982688570923864 and parameters: {'C': 0.07098229307954536, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.04516987456710097, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7685036732950444}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:23,131] Trial 899 finished with value: 0.7936710813206824 and parameters: {'C': 0.03676842168577492, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.05278395083892745, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8219191340184268}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:23,407] Trial 900 finished with value: 0.7777366958036103 and parameters: {'C': 0.018498193752264816, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 82, 'tol': 0.04839494641252762, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9394210535458714}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:23,660] Trial 901 finished with value: 0.8028531639803915 and parameters: {'C': 0.05299904099379427, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04229441578063014, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9790042872484221}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:23,864] Trial 902 finished with value: 0.7704578518597737 and parameters: {'C': 0.11357289879600548, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 115, 'tol': 0.04677602576660511, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8475738579050582}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:24,055] Trial 903 finished with value: 0.7982688570923864 and parameters: {'C': 0.027624060680405717, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.03916559052770886, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9034075648688905}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:24,319] Trial 904 finished with value: 0.7982688570923864 and parameters: {'C': 0.07853909621461283, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.0500259835478738, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9585841122586171}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:24,566] Trial 905 finished with value: 0.632883615560909 and parameters: {'C': 0.0001646075388573671, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.044333020089676926, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8785020405274003}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:24,775] Trial 906 finished with value: 0.6067286798994115 and parameters: {'C': 0.040368306378637496, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 192, 'tol': 0.04717781019377932, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9301714998725802}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:24,987] Trial 907 finished with value: 0.8028531639803915 and parameters: {'C': 0.05808856836255777, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.04163765037919328, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8945546593870187}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:25,242] Trial 908 finished with value: 0.7318465565181727 and parameters: {'C': 0.004407218480356024, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.050975107984609316, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9194149140984336}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:25,502] Trial 909 finished with value: 0.8028531639803915 and parameters: {'C': 0.04492774795623308, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.04543944854188248, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9999630589169012}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:25,707] Trial 910 finished with value: 0.6335426335426335 and parameters: {'C': 0.08734278458447936, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 118, 'tol': 0.04343089640036202, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8603705959840249}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:25,915] Trial 911 finished with value: 0.7982688570923864 and parameters: {'C': 0.029225667816639368, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04791470673066492, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9489014761450764}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:04:26,194] Trial 912 finished with value: 0.7520388695314645 and parameters: {'C': 0.058403977999369285, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 122, 'tol': 0.044840418698713594, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8332675292199341}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:26,453] Trial 913 finished with value: 0.7982688570923864 and parameters: {'C': 0.13442095265301096, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04017150101639208, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9704515370981804}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:26,712] Trial 914 finished with value: 0.7936710813206824 and parameters: {'C': 0.037482872802485294, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04890752234731531, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8863604973699947}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:26,963] Trial 915 finished with value: 0.7982688570923864 and parameters: {'C': 0.08367456881727124, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.04577869522830667, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9317311346970453}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:27,216] Trial 916 finished with value: 0.6461619841901532 and parameters: {'C': 0.0005116392517293962, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.042906146906656034, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9047817023070901}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:27,472] Trial 917 finished with value: 0.8028531639803915 and parameters: {'C': 0.05641744514610837, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.051906332946185, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8703836359117453}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:27,765] Trial 918 finished with value: 0.7729338533936235 and parameters: {'C': 0.02315279069457079, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 174, 'tol': 0.04662751160534367, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9508967448981488}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:28,028] Trial 919 finished with value: 0.802641903871957 and parameters: {'C': 0.22308530472620153, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.0865846279050495, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8451588369185833}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:28,282] Trial 920 finished with value: 0.8028531639803915 and parameters: {'C': 0.043089394153536936, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04942636808286034, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9154155964565539}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:28,547] Trial 921 finished with value: 0.7982688570923864 and parameters: {'C': 0.07342758724436664, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04376808709826884, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8146655067626556}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:28,799] Trial 922 finished with value: 0.7982688570923864 and parameters: {'C': 0.03359789204469752, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.03434558323222325, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9753211754546751}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:29,065] Trial 923 finished with value: 0.7982688570923864 and parameters: {'C': 0.10392643539850735, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04699127223287257, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.882254659240016}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:29,341] Trial 924 finished with value: 0.8028531639803915 and parameters: {'C': 0.06189077970639081, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04119182260558048, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9329632449472243}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:29,611] Trial 925 finished with value: 0.8028531639803915 and parameters: {'C': 0.04611566140136036, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04488335097007649, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8569263040478823}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:29,906] Trial 926 finished with value: 0.7854029144351726 and parameters: {'C': 0.01256666838949038, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04870272218590456, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9019296653636251}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:30,171] Trial 927 finished with value: 0.7982688570923864 and parameters: {'C': 0.030297342482726756, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.042571892934193285, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.15363543350439035}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:30,426] Trial 928 finished with value: 0.7982688570923864 and parameters: {'C': 0.07106495099007472, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.03839376437204618, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9600343463595818}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:30,691] Trial 929 finished with value: 0.7764613692033047 and parameters: {'C': 0.017596615173306986, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.047081593833374846, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3131069265437842}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:30,898] Trial 930 finished with value: 0.7661378770074423 and parameters: {'C': 0.11927665722655928, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 99, 'tol': 0.05075544834408951, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8726823268899588}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:31,048] Trial 931 finished with value: 0.6067286798994115 and parameters: {'C': 0.04801758432647772, 'fit_intercept': False, 'solver': 'saga', 'max_iter': 107, 'tol': 0.04536495955995587, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8960590570198983}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:31,262] Trial 932 finished with value: 0.7982688570923864 and parameters: {'C': 0.0814504010901987, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04368969209097891, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9869274590844751}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:31,525] Trial 933 finished with value: 0.7936710813206824 and parameters: {'C': 0.040631740229030926, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.048387498331448, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9204108416671182}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:31,806] Trial 934 finished with value: 0.8028531639803915 and parameters: {'C': 0.05901219493680969, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.054368540069027596, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9410782730498415}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:32,031] Trial 935 finished with value: 0.6335426335426335 and parameters: {'C': 0.024283262648275843, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 125, 'tol': 0.041610666341757176, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8491469192423151}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:32,266] Trial 936 finished with value: 0.7982688570923864 and parameters: {'C': 0.03426335187864176, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.024095208822189445, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9158742426011922}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:32,575] Trial 937 finished with value: 0.7691765275082738 and parameters: {'C': 0.10385317736460987, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.046230728257138094, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8794248848606313}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:04:32,857] Trial 938 finished with value: 0.7477477477477478 and parameters: {'C': 0.16866982070999811, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 113, 'tol': 0.039768270786850864, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9604515693043839}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:33,118] Trial 939 finished with value: 0.8028531639803915 and parameters: {'C': 0.057630893444357435, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 95, 'tol': 0.050050814939058094, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.83440748693176}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:33,378] Trial 940 finished with value: 0.7982688570923864 and parameters: {'C': 0.07674209611255862, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04442089569486414, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9415211350524566}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:33,633] Trial 941 finished with value: 0.8028531639803915 and parameters: {'C': 0.047135225565001375, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04707221132317641, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8945299131040281}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:33,894] Trial 942 finished with value: 0.7936710813206824 and parameters: {'C': 0.03624231769096231, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.05188718808115978, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8595430782020437}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:34,156] Trial 943 finished with value: 0.7982688570923864 and parameters: {'C': 0.0647422053498529, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04271004430341356, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9769220878034407}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:34,412] Trial 944 finished with value: 0.7936710813206824 and parameters: {'C': 0.026726459903155395, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 146, 'tol': 0.048375904139859885, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.9221017150265837}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:34,673] Trial 945 finished with value: 0.7982688570923864 and parameters: {'C': 0.09742831534663661, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.04575809069586967, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8744112348729378}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:34,934] Trial 946 finished with value: 0.7982688570923864 and parameters: {'C': 0.041637642478382655, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.043706830413028405, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8106258902300517}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:35,196] Trial 947 finished with value: 0.8028531639803915 and parameters: {'C': 0.05643084825067862, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04753432361409731, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9547627489090444}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:35,594] Trial 948 finished with value: 0.7982688570923864 and parameters: {'C': 0.14120310519769455, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.0410509648269792, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8996916730234114}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:35,925] Trial 949 finished with value: 0.7982688570923864 and parameters: {'C': 0.08117884785721777, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.049708552962871376, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9335594047980947}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:36,266] Trial 950 finished with value: 0.7515784995494071 and parameters: {'C': 0.04819908009063763, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.045222063852746526, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9860693301796716}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:36,561] Trial 951 finished with value: 0.7936710813206824 and parameters: {'C': 0.03673300103570502, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.031425832096200694, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.832748974548231}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:36,812] Trial 952 finished with value: 0.7895106372229068 and parameters: {'C': 0.021056688081228594, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.03753383784521963, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9063514309522208}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:37,063] Trial 953 finished with value: 0.7938919441613183 and parameters: {'C': 0.06789227157844491, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04592042259621019, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8656326910116917}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:37,257] Trial 954 finished with value: 0.7610556379121386 and parameters: {'C': 0.05088207343986277, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 115, 'tol': 0.043613132521630536, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8853215890872472}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:37,458] Trial 955 finished with value: 0.7982688570923864 and parameters: {'C': 0.03234872182784728, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.04787030413153946, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9457466752658089}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:37,754] Trial 956 finished with value: 0.7691765275082738 and parameters: {'C': 0.10445814380069098, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.052728363009638984, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.7890957791427748}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:37,969] Trial 957 finished with value: 0.6067286798994115 and parameters: {'C': 0.0710401466994231, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 112, 'tol': 0.041773785348534945, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9133976276352485}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:38,184] Trial 958 finished with value: 0.7936710813206824 and parameters: {'C': 0.02583101114435692, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.05042276100974523, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8559221767993572}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:38,446] Trial 959 finished with value: 0.8028531639803915 and parameters: {'C': 0.04796030814133882, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.04657093768731272, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9660305466077407}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:38,732] Trial 960 finished with value: 0.7982688570923864 and parameters: {'C': 0.09069055377545095, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04428563092832198, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.931877351278873}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:38,955] Trial 961 finished with value: 0.6335426335426335 and parameters: {'C': 0.06317935500672904, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 110, 'tol': 0.040230792748222305, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9999029232353965}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:39,176] Trial 962 finished with value: 0.7982688570923864 and parameters: {'C': 0.03429358511353392, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.048513057380799904, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8846169644657359}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:39,493] Trial 963 finished with value: 0.7764613692033047 and parameters: {'C': 0.015241448988469354, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.045369514034674, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9108423911698029}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:04:39,873] Trial 964 finished with value: 0.7618143239764861 and parameters: {'C': 0.04906375463193806, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 116, 'tol': 0.042577327358041456, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8468712047683938}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:40,142] Trial 965 finished with value: 0.7982688570923864 and parameters: {'C': 0.0785507708427485, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.049277181990625994, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9592303016985613}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:40,398] Trial 966 finished with value: 0.7936710813206824 and parameters: {'C': 0.037869964955834626, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.04681704479731234, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8716285699370956}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:40,659] Trial 967 finished with value: 0.7982688570923864 and parameters: {'C': 0.10838267051538386, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04456867357162187, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8979838394499731}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:40,925] Trial 968 finished with value: 0.8028531639803915 and parameters: {'C': 0.060506821869221954, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.05101216017202516, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9329050931785191}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:41,166] Trial 969 finished with value: 0.7743766493766494 and parameters: {'C': 0.030585001321176083, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04746815630640981, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8296730221649508}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:41,427] Trial 970 finished with value: 0.7982688570923864 and parameters: {'C': 0.14886365782356661, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.03930703036094462, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9766043182365549}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:41,682] Trial 971 finished with value: 0.8028531639803915 and parameters: {'C': 0.0439614029275984, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.04408404020750502, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8868554683727806}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:41,946] Trial 972 finished with value: 0.7893030285187149 and parameters: {'C': 0.022775273549358797, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04226691412870592, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9180834183098907}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:42,225] Trial 973 finished with value: 0.8028531639803915 and parameters: {'C': 0.06102649130382609, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.045941839085789, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9562515833805421}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:42,517] Trial 974 finished with value: 0.7982688570923864 and parameters: {'C': 0.08623978005414318, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.049382122563528225, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8619759197826287}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:42,805] Trial 975 finished with value: 0.8028531639803915 and parameters: {'C': 0.044218442331008204, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04743072787381145, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9445799287805509}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:43,145] Trial 976 finished with value: 0.7686647242037578 and parameters: {'C': 0.030138134324041055, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.042944802761092214, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.9029901116646496}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:43,441] Trial 977 finished with value: 0.7982688570923864 and parameters: {'C': 0.06314055362567594, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.05338164596193502, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9253498416149541}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:43,734] Trial 978 finished with value: 0.7982688570923864 and parameters: {'C': 0.11838664224792156, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04541045884387729, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8769480788142174}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:44,022] Trial 979 finished with value: 0.8028531639803915 and parameters: {'C': 0.04859470493804613, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0619327251595385, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8412832786938}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:44,236] Trial 980 finished with value: 0.7657657657657657 and parameters: {'C': 0.07347255289373418, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 112, 'tol': 0.04863557084826865, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8090422185535011}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:44,448] Trial 981 finished with value: 0.7936710813206824 and parameters: {'C': 0.036968809022193856, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04038059220452411, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9800881993546711}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:44,713] Trial 982 finished with value: 0.78512441012441 and parameters: {'C': 0.0194339903885557, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.05128120426786115, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8839135367908209}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:44,929] Trial 983 finished with value: 0.6067286798994115 and parameters: {'C': 0.08855577827733416, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 111, 'tol': 0.04408621166039516, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9474897291564934}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:45,142] Trial 984 finished with value: 0.8028531639803915 and parameters: {'C': 0.05245749756841219, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.0023160943370061082, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.916654133424794}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:45,411] Trial 985 finished with value: 0.7936710813206824 and parameters: {'C': 0.025782602894500063, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.04660571931430108, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8973857176516727}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:45,685] Trial 986 finished with value: 0.7938919441613183 and parameters: {'C': 0.0664739166142834, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.041907688431232964, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9646507199430971}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:45,901] Trial 987 finished with value: 0.6335426335426335 and parameters: {'C': 0.039232841522047084, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 115, 'tol': 0.03697152897173695, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8510109430977064}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:46,122] Trial 988 finished with value: 0.7982688570923864 and parameters: {'C': 0.1238156646858587, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.045358955079151, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9318307161115371}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:46,391] Trial 989 finished with value: 0.7515784995494071 and parameters: {'C': 0.05242509520814309, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.048552086385383435, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8620648801212974}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-04-02 06:04:46,691] Trial 990 finished with value: 0.7893030285187149 and parameters: {'C': 0.03024897025907826, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 118, 'tol': 0.04352445126671637, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8954094400236072}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:46,986] Trial 991 finished with value: 0.7982688570923864 and parameters: {'C': 0.08501224386983205, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04679641902706019, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9837678087909414}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:47,252] Trial 992 finished with value: 0.7936710813206824 and parameters: {'C': 0.04133066474720495, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.050343488379422666, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8244519101835049}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:47,520] Trial 993 finished with value: 0.8028531639803915 and parameters: {'C': 0.06120492247361028, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04504328760372334, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9136489220695188}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:47,808] Trial 994 finished with value: 0.7691765275082738 and parameters: {'C': 0.10309621977713021, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.04091976090002725, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8765345091405737}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:48,073] Trial 995 finished with value: 0.8028531639803915 and parameters: {'C': 0.04899123109150763, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.0484264557354552, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9434934542440169}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:48,336] Trial 996 finished with value: 0.802641903871957 and parameters: {'C': 0.23401349888733158, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04251486157354735, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8669534948187977}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:48,602] Trial 997 finished with value: 0.7982688570923864 and parameters: {'C': 0.07766160735246251, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.056202971548300056, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9611650918731944}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:48,864] Trial 998 finished with value: 0.7632115255111387 and parameters: {'C': 0.009721480160633341, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04688159713312586, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9332483076509271}. Best is trial 189 with value: 0.8028531639803915.\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-04-02 06:04:49,125] Trial 999 finished with value: 0.7982688570923864 and parameters: {'C': 0.029568564433943987, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.03925777595093351, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9018934520776063}. Best is trial 189 with value: 0.8028531639803915.\n"]},{"name":"stdout","output_type":"stream","text":["Model Accuracy: 0.801802\n","Model F1 Score: 0.802853\n","Validation Accuracy: 0.765766\n","Validation F1 Score: 0.766848\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n"]}],"source":["import optuna\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def objective(trial):\n","    param = {\n","        'C': trial.suggest_float('C', 1e-5, 100,log=True),\n","        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n","        # 'penalty': trial.suggest_categorical('penalty', ['l2','none']),\n","        'solver': trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n","        'max_iter': trial.suggest_int('max_iter', 50, 200),\n","        'tol': trial.suggest_float('tol', 1e-5, 1e-1),\n","        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n","        'warm_start': trial.suggest_categorical('warm_start', [True, False]),\n","        'l1_ratio': trial.suggest_float('l1_ratio', 0, 1)\n","    }\n","    model = LogisticRegression(**param)\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_test)\n","    accuracy = f1_score(y_test, preds, average='weighted')\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=1000)\n","\n","# Best hyperparameters\n","best_params = study.best_params\n","\n","# Fit the model with best hyperparameters\n","best_model = LogisticRegression(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","# Make predictions \n","preds = best_model.predict(X_test)\n","\n","# Check the accuracy and F1 score of the model\n","print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n","print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n","\n","# Now let's use the model with the best parameters on the validation set\n","val_preds = best_model.predict(X_val)\n","\n","# Check the accuracy and F1 score of the best model on the validation set\n","print(\"Validation Accuracy: %f\" % accuracy_score(y_val, val_preds))\n","print(\"Validation F1 Score: %f\" % f1_score(y_val, val_preds, average='weighted'))\n"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T06:04:49.223133Z","iopub.status.busy":"2024-04-02T06:04:49.222321Z","iopub.status.idle":"2024-04-02T06:04:49.228933Z","shell.execute_reply":"2024-04-02T06:04:49.227665Z","shell.execute_reply.started":"2024-04-02T06:04:49.223091Z"},"trusted":true},"outputs":[],"source":["import pickle\n","\n","pickle.dump(best_model, open(\"LR\", 'wb'))"]},{"cell_type":"code","execution_count":52,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-02T06:04:49.231862Z","iopub.status.busy":"2024-04-02T06:04:49.231039Z","iopub.status.idle":"2024-04-02T06:23:40.676938Z","shell.execute_reply":"2024-04-02T06:23:40.674560Z","shell.execute_reply.started":"2024-04-02T06:04:49.231820Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-04-02 06:04:49,247] A new study created in memory with name: no-name-d9395e85-4693-4abe-914f-e1b9b0b7c40e\n","[I 2024-04-02 06:04:49,833] Trial 0 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 132, 'max_depth': 4, 'learning_rate': 0.021956433986196188, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8148130633004671.\n","[I 2024-04-02 06:04:50,583] Trial 1 finished with value: 0.7958806390033156 and parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.05005908388181817, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8148130633004671.\n","[I 2024-04-02 06:04:51,737] Trial 2 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 163, 'max_depth': 6, 'learning_rate': 0.018516460319209636, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:04:51,907] Trial 3 finished with value: 0.767182448060619 and parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.010492143853464211, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:04:53,692] Trial 4 finished with value: 0.8034347634347635 and parameters: {'n_estimators': 141, 'max_depth': 9, 'learning_rate': 0.05204333614802928, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:04:54,594] Trial 5 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 126, 'max_depth': 6, 'learning_rate': 0.01001178141899658, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:04:55,470] Trial 6 finished with value: 0.7845125438458628 and parameters: {'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.018434045085206623, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:04:56,297] Trial 7 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 153, 'max_depth': 5, 'learning_rate': 0.030824032858099905, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:04:56,874] Trial 8 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 133, 'max_depth': 4, 'learning_rate': 0.015249639082993748, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:04:57,867] Trial 9 finished with value: 0.8082763742703633 and parameters: {'n_estimators': 79, 'max_depth': 9, 'learning_rate': 0.09522383091884674, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:04:59,762] Trial 10 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 198, 'max_depth': 7, 'learning_rate': 0.027790409899382817, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:01,061] Trial 11 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 172, 'max_depth': 6, 'learning_rate': 0.036229941511352476, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:02,161] Trial 12 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 168, 'max_depth': 5, 'learning_rate': 0.033829763111842916, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:03,269] Trial 13 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.04415941078285799, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:05,230] Trial 14 finished with value: 0.7862968443775985 and parameters: {'n_estimators': 196, 'max_depth': 7, 'learning_rate': 0.062343075016503074, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:05,912] Trial 15 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.014375256422324399, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:06,339] Trial 16 finished with value: 0.7838319257674097 and parameters: {'n_estimators': 103, 'max_depth': 3, 'learning_rate': 0.013787599927163892, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:07,202] Trial 17 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 105, 'max_depth': 6, 'learning_rate': 0.020928599184691414, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:07,782] Trial 18 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 108, 'max_depth': 4, 'learning_rate': 0.013957843904706042, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:08,834] Trial 19 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 86, 'max_depth': 8, 'learning_rate': 0.024794956749183365, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:10,403] Trial 20 finished with value: 0.8230965538028735 and parameters: {'n_estimators': 155, 'max_depth': 7, 'learning_rate': 0.017450495937371965, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:11,553] Trial 21 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.03872499381851249, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:12,609] Trial 22 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.07407365732341976, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:13,867] Trial 23 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 159, 'max_depth': 6, 'learning_rate': 0.01289357401761915, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:14,605] Trial 24 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 144, 'max_depth': 4, 'learning_rate': 0.037281759587771, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:15,761] Trial 25 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.024789439271518453, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:16,683] Trial 26 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 121, 'max_depth': 6, 'learning_rate': 0.018640362777267435, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:17,181] Trial 27 finished with value: 0.8039786460839093 and parameters: {'n_estimators': 95, 'max_depth': 4, 'learning_rate': 0.012127440764147002, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:17,933] Trial 28 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.041704547914718164, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:18,637] Trial 29 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 188, 'max_depth': 3, 'learning_rate': 0.0232382365846996, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:19,983] Trial 30 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 140, 'max_depth': 7, 'learning_rate': 0.02071582702845045, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:21,069] Trial 31 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 171, 'max_depth': 5, 'learning_rate': 0.04420776052200576, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:22,110] Trial 32 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.05861326615279022, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:23,459] Trial 33 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 179, 'max_depth': 6, 'learning_rate': 0.029671845305622634, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:24,145] Trial 34 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 148, 'max_depth': 4, 'learning_rate': 0.04413166773472445, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:26,268] Trial 35 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 165, 'max_depth': 8, 'learning_rate': 0.016291105176044998, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:27,730] Trial 36 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 191, 'max_depth': 6, 'learning_rate': 0.051821352580072456, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:28,549] Trial 37 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.03946750410987847, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:28,831] Trial 38 finished with value: 0.7772934906737723 and parameters: {'n_estimators': 65, 'max_depth': 3, 'learning_rate': 0.011482455269012894, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:29,687] Trial 39 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 136, 'max_depth': 5, 'learning_rate': 0.026922442365522475, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:30,308] Trial 40 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 120, 'max_depth': 4, 'learning_rate': 0.047307250274785696, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:31,373] Trial 41 finished with value: 0.83723505544913 and parameters: {'n_estimators': 173, 'max_depth': 5, 'learning_rate': 0.05900051451666935, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:32,758] Trial 42 finished with value: 0.799683575504369 and parameters: {'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.06348930752610059, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:33,784] Trial 43 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 169, 'max_depth': 5, 'learning_rate': 0.07234787871256702, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:34,979] Trial 44 finished with value: 0.772367699436783 and parameters: {'n_estimators': 153, 'max_depth': 6, 'learning_rate': 0.0988262994766194, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:36,184] Trial 45 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.03510847706459968, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:37,155] Trial 46 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.0534559845407355, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:40,353] Trial 47 finished with value: 0.799683575504369 and parameters: {'n_estimators': 160, 'max_depth': 10, 'learning_rate': 0.015169356409711326, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:41,989] Trial 48 finished with value: 0.7991466778070471 and parameters: {'n_estimators': 171, 'max_depth': 7, 'learning_rate': 0.03274156270973966, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:42,772] Trial 49 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 91, 'max_depth': 6, 'learning_rate': 0.04774275514245095, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:43,925] Trial 50 finished with value: 0.833469421937483 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.010046177805280714, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:45,030] Trial 51 finished with value: 0.833469421937483 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.010412314693663863, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:46,216] Trial 52 finished with value: 0.833469421937483 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.011047795922413166, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:47,146] Trial 53 finished with value: 0.8006420599704182 and parameters: {'n_estimators': 175, 'max_depth': 4, 'learning_rate': 0.010151208864662519, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:48,259] Trial 54 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.012778582630509124, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:49,673] Trial 55 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.012604603986024525, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:50,960] Trial 56 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.08232739145323806, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:52,302] Trial 57 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 173, 'max_depth': 6, 'learning_rate': 0.05506006295786051, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:53,134] Trial 58 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 166, 'max_depth': 4, 'learning_rate': 0.011250817660968748, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:54,273] Trial 59 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.03998661905231916, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:55,010] Trial 60 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 157, 'max_depth': 4, 'learning_rate': 0.03739325802156089, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:56,155] Trial 61 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.041320752914840185, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:57,343] Trial 62 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04169658490184628, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:05:58,611] Trial 63 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03027215677573435, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:00,025] Trial 64 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 177, 'max_depth': 6, 'learning_rate': 0.04711615449280157, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:01,118] Trial 65 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.039576489390429515, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:03,107] Trial 66 finished with value: 0.8001817909863886 and parameters: {'n_estimators': 196, 'max_depth': 7, 'learning_rate': 0.033438874989351684, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:04,194] Trial 67 finished with value: 0.8317656008930031 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.06702930773962419, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:05,504] Trial 68 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 164, 'max_depth': 6, 'learning_rate': 0.05716943596227812, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:06,419] Trial 69 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 181, 'max_depth': 4, 'learning_rate': 0.045134507931904946, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:07,021] Trial 70 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.0436492591515811, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:07,993] Trial 71 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.04996300887224096, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:08,870] Trial 72 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 178, 'max_depth': 4, 'learning_rate': 0.04015314865419405, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:10,045] Trial 73 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.03656201472719913, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:11,241] Trial 74 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 173, 'max_depth': 5, 'learning_rate': 0.019063143624243592, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:12,002] Trial 75 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 162, 'max_depth': 4, 'learning_rate': 0.04378591019050648, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:12,759] Trial 76 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 187, 'max_depth': 3, 'learning_rate': 0.027097836344003045, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:13,728] Trial 77 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 193, 'max_depth': 4, 'learning_rate': 0.0495554116483107, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:14,850] Trial 78 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.029020722685134483, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:16,316] Trial 79 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 181, 'max_depth': 6, 'learning_rate': 0.031710850737600986, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:17,406] Trial 80 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 169, 'max_depth': 5, 'learning_rate': 0.03478642171546837, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:18,556] Trial 81 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.03621447835052265, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:19,599] Trial 82 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.03763378862145159, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:21,951] Trial 83 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 188, 'max_depth': 8, 'learning_rate': 0.04065093313499143, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:23,065] Trial 84 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.04569567621940513, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:24,384] Trial 85 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 166, 'max_depth': 6, 'learning_rate': 0.046308587809314405, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:25,190] Trial 86 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 175, 'max_depth': 4, 'learning_rate': 0.06231861969279027, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:26,325] Trial 87 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.05256469068691705, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:28,867] Trial 88 finished with value: 0.7910991451221336 and parameters: {'n_estimators': 159, 'max_depth': 9, 'learning_rate': 0.016796451578884816, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:30,064] Trial 89 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04426526011968853, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:31,416] Trial 90 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 172, 'max_depth': 6, 'learning_rate': 0.05520763438394607, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:32,534] Trial 91 finished with value: 0.83723505544913 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.03754002781135674, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:33,653] Trial 92 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.03811787728574143, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:34,523] Trial 93 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 177, 'max_depth': 4, 'learning_rate': 0.045412724369768225, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:35,570] Trial 94 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 168, 'max_depth': 5, 'learning_rate': 0.050672066782351796, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:36,552] Trial 95 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.042308341152852875, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:37,550] Trial 96 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 167, 'max_depth': 5, 'learning_rate': 0.050832119161009444, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:39,117] Trial 97 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 195, 'max_depth': 6, 'learning_rate': 0.04910909590380057, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:40,999] Trial 98 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 187, 'max_depth': 7, 'learning_rate': 0.032172082874649496, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:41,958] Trial 99 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.042182307083854655, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:43,357] Trial 100 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.03496503999870005, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:44,456] Trial 101 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.05979413154501504, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:45,500] Trial 102 finished with value: 0.833469421937483 and parameters: {'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.03875100332847576, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:46,626] Trial 103 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.046137713160132945, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:47,751] Trial 104 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.0458883841124578, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:48,917] Trial 105 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.013736900264535298, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:50,149] Trial 106 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.014547120222989094, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:51,152] Trial 107 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 191, 'max_depth': 4, 'learning_rate': 0.013257365489759882, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8509470997296442.\n","[I 2024-04-02 06:06:52,367] Trial 108 finished with value: 0.8514727276739713 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.014111608206072528, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:06:53,542] Trial 109 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.014377710869785667, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:06:54,799] Trial 110 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.015527821213697236, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:06:55,878] Trial 111 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.0142117972863533, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:06:57,066] Trial 112 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.011945986567853084, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:06:58,222] Trial 113 finished with value: 0.84709015035102 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.013377828009618141, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:06:59,410] Trial 114 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.013663144545818063, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:01,012] Trial 115 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 192, 'max_depth': 6, 'learning_rate': 0.012682920880622645, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:02,276] Trial 116 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.012019445067653232, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:03,466] Trial 117 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.013309780469394275, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:03,847] Trial 118 finished with value: 0.7930305672241157 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.015007955984498127, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:05,360] Trial 119 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.013362991345204078, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:06,615] Trial 120 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.010864472578135786, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:07,819] Trial 121 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.016114829801724795, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:09,077] Trial 122 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.01777798148157456, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:10,345] Trial 123 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.01282390535250341, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:11,611] Trial 124 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.01247028505616304, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:12,859] Trial 125 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.01145500125981078, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:14,093] Trial 126 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.011565650540541319, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:15,617] Trial 127 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 197, 'max_depth': 6, 'learning_rate': 0.011914454396717414, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:16,864] Trial 128 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.011463923547440942, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:18,042] Trial 129 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.011454944895201838, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:19,293] Trial 130 finished with value: 0.833469421937483 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.010638010738550807, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:20,582] Trial 131 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.01361210598447428, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:21,889] Trial 132 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.013825144401212955, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:23,161] Trial 133 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.013259233703950095, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:24,406] Trial 134 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.01445384613903903, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:25,574] Trial 135 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.011361309930298122, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:26,775] Trial 136 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.019754619862032783, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:28,009] Trial 137 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.01578640122107057, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:29,508] Trial 138 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 195, 'max_depth': 6, 'learning_rate': 0.012311864423103239, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:30,655] Trial 139 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.013085537688439777, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:31,656] Trial 140 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 198, 'max_depth': 4, 'learning_rate': 0.011588173984376502, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:32,834] Trial 141 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.012940805575814607, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:33,979] Trial 142 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.014682471805103462, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:35,199] Trial 143 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.02300509919864725, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:35,723] Trial 144 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.013780585610031657, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:37,014] Trial 145 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.017119057919727683, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:38,235] Trial 146 finished with value: 0.833469421937483 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.010958556850949323, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:39,475] Trial 147 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.01293932608529624, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:40,724] Trial 148 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.012175419236058374, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:41,937] Trial 149 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.01506225480736154, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:43,363] Trial 150 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.013537069890175736, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:44,569] Trial 151 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.014610262696582567, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:45,927] Trial 152 finished with value: 0.833469421937483 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.01042825850163651, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:47,389] Trial 153 finished with value: 0.84709015035102 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.014008146194018786, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:48,618] Trial 154 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.011710478059375539, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:49,875] Trial 155 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.012470013062858014, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:51,135] Trial 156 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.011524923213344697, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:52,358] Trial 157 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.011681538251430345, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:53,315] Trial 158 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 194, 'max_depth': 4, 'learning_rate': 0.01138028366884974, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:54,506] Trial 159 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.011098360890079333, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:55,305] Trial 160 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 129, 'max_depth': 5, 'learning_rate': 0.01175295622563962, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:56,440] Trial 161 finished with value: 0.833469421937483 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.010316455913707097, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:57,151] Trial 162 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.011886495825652906, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:58,238] Trial 163 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.010751638450612389, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:07:59,312] Trial 164 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.012507369875841036, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:00,568] Trial 165 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.013861091182310926, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:01,726] Trial 166 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.012234123851860151, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:02,689] Trial 167 finished with value: 0.833469421937483 and parameters: {'n_estimators': 144, 'max_depth': 5, 'learning_rate': 0.014052274104236082, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:03,720] Trial 168 finished with value: 0.833469421937483 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.010012765079808951, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:05,113] Trial 169 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 189, 'max_depth': 6, 'learning_rate': 0.011548945075293766, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:06,184] Trial 170 finished with value: 0.84709015035102 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.012705698965921478, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:07,283] Trial 171 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.012898450353221996, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:08,395] Trial 172 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.015516043528876682, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:09,562] Trial 173 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.011004010179725522, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:13,633] Trial 174 finished with value: 0.7782284283903023 and parameters: {'n_estimators': 192, 'max_depth': 10, 'learning_rate': 0.01260949751177569, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:14,758] Trial 175 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.016446376010233483, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:15,994] Trial 176 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.011870000229953897, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:17,162] Trial 177 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.011929991039596794, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:18,395] Trial 178 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.011222740431604192, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:21,474] Trial 179 finished with value: 0.7963322301543593 and parameters: {'n_estimators': 183, 'max_depth': 9, 'learning_rate': 0.01052297863371495, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:22,015] Trial 180 finished with value: 0.799683575504369 and parameters: {'n_estimators': 97, 'max_depth': 4, 'learning_rate': 0.012398026281027588, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:23,273] Trial 181 finished with value: 0.8291007562746693 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.011280661549417075, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:24,492] Trial 182 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.010952993542153611, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:25,690] Trial 183 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.011697052602069513, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:26,883] Trial 184 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.01285624936044172, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:28,091] Trial 185 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.01185315297365356, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:29,337] Trial 186 finished with value: 0.84709015035102 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.013377808434018184, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:30,480] Trial 187 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.014426905457827495, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:31,643] Trial 188 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.013295963397590859, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:32,794] Trial 189 finished with value: 0.833469421937483 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.014074907787807813, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:33,980] Trial 190 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.013261984202416723, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:35,209] Trial 191 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.012282832554982404, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:36,415] Trial 192 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.011254833349244778, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:37,686] Trial 193 finished with value: 0.833469421937483 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.010781150805790144, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:38,866] Trial 194 finished with value: 0.833469421937483 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.01155939190478486, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:40,155] Trial 195 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.012784131579085875, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:41,382] Trial 196 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.025024245798120084, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:42,554] Trial 197 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.012070397569438326, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:43,714] Trial 198 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.015134891453983914, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:44,935] Trial 199 finished with value: 0.8514727276739713 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.0138272228580854, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:46,084] Trial 200 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.013771921262326275, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:47,326] Trial 201 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.012978166784069127, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:48,565] Trial 202 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.01235115331652588, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:49,925] Trial 203 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.014604261774959233, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:50,347] Trial 204 finished with value: 0.7930305672241157 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.013835490587203125, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:51,529] Trial 205 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.01144764816796157, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:52,759] Trial 206 finished with value: 0.833469421937483 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.010455267583216715, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:53,966] Trial 207 finished with value: 0.84709015035102 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.013368749681573582, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:54,839] Trial 208 finished with value: 0.833469421937483 and parameters: {'n_estimators': 136, 'max_depth': 5, 'learning_rate': 0.013363631184728112, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:56,266] Trial 209 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 188, 'max_depth': 6, 'learning_rate': 0.014299556816801338, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:57,415] Trial 210 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.015891337290272225, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:58,655] Trial 211 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.01262986074610351, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:08:59,925] Trial 212 finished with value: 0.83723505544913 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.011957502575384357, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:01,154] Trial 213 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.013607747009675644, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:02,341] Trial 214 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.012649136522496806, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:03,560] Trial 215 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.040527461735205834, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:04,724] Trial 216 finished with value: 0.833469421937483 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.010987070716872513, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:05,500] Trial 217 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.011631004913686007, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:06,731] Trial 218 finished with value: 0.84709015035102 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.013154777137543552, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:07,886] Trial 219 finished with value: 0.833469421937483 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.015052343468758262, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:09,021] Trial 220 finished with value: 0.833469421937483 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.013228242217933051, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:11,110] Trial 221 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 198, 'max_depth': 7, 'learning_rate': 0.01219419524553136, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:12,380] Trial 222 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.014356741958911973, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:13,627] Trial 223 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.013108376056499687, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:14,849] Trial 224 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.021439261474076148, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:16,118] Trial 225 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.013634595398353606, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:17,305] Trial 226 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.011250027200693376, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:18,500] Trial 227 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.042976181431288105, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:19,705] Trial 228 finished with value: 0.84709015035102 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.01285872699104246, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:21,077] Trial 229 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.012776309588900497, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:22,440] Trial 230 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.012158882316941656, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:23,543] Trial 231 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.01399503259312586, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:24,749] Trial 232 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.01394746783626536, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:25,922] Trial 233 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.08753152274804564, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:27,117] Trial 234 finished with value: 0.833469421937483 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.01499921724058088, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:28,229] Trial 235 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.013318642762713497, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:29,374] Trial 236 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.013976129820682097, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:30,555] Trial 237 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.012875313506664949, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:31,806] Trial 238 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.014427424493069958, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:33,016] Trial 239 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.012393466259882713, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:34,157] Trial 240 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.011764074440057204, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:35,276] Trial 241 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.013379852093864462, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:36,447] Trial 242 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.011401209716778852, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:37,697] Trial 243 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.01195245647100585, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:38,881] Trial 244 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.012705606014709917, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:40,119] Trial 245 finished with value: 0.833469421937483 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.010707951464050673, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:41,361] Trial 246 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.018056959093174042, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:42,572] Trial 247 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.014026792513986492, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:43,805] Trial 248 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.012330118884457527, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:44,971] Trial 249 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.013078488691249559, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:46,126] Trial 250 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.013475204290416182, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:47,295] Trial 251 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.01292262382094853, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:48,469] Trial 252 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.014961764269126245, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:49,644] Trial 253 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04739906737011426, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:50,838] Trial 254 finished with value: 0.84709015035102 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.014250443105856853, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:51,988] Trial 255 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.014381025352664285, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:53,078] Trial 256 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.0155308125700379, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:54,122] Trial 257 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.0137589083078374, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:55,281] Trial 258 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.013434232459247663, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:56,483] Trial 259 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.014572244840609852, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:57,564] Trial 260 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.013197924715610406, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:58,658] Trial 261 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.012651492461514145, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:09:59,785] Trial 262 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.014066599336863961, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:00,888] Trial 263 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.019753749958212885, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:01,996] Trial 264 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.016471286856995834, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:02,881] Trial 265 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 184, 'max_depth': 4, 'learning_rate': 0.015588391318232739, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:04,026] Trial 266 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.012900319185538493, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:06,383] Trial 267 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 187, 'max_depth': 8, 'learning_rate': 0.013749666860707976, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:07,477] Trial 268 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.014730598043544485, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:08,953] Trial 269 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 193, 'max_depth': 6, 'learning_rate': 0.012344746970619772, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:10,023] Trial 270 finished with value: 0.84709015035102 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.013133862116730595, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:11,073] Trial 271 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.013312266137621265, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:12,095] Trial 272 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.014604966516263094, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:13,097] Trial 273 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.014056298583785942, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:14,126] Trial 274 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.013355400555750975, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:15,178] Trial 275 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.04147801319546324, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:16,210] Trial 276 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.012560663215561482, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:17,621] Trial 277 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 188, 'max_depth': 6, 'learning_rate': 0.013959647106415509, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:18,789] Trial 278 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.03923983675371171, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:19,680] Trial 279 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.03954852091734761, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:20,823] Trial 280 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.03839128143593781, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:21,953] Trial 281 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.037337569842437586, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:23,337] Trial 282 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 151, 'max_depth': 7, 'learning_rate': 0.03617409576880242, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:24,610] Trial 283 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.03936825296391934, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:25,768] Trial 284 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.04354225761239715, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:26,908] Trial 285 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.03394906766479444, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:28,054] Trial 286 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.040954767297442074, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:29,098] Trial 287 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.03799785218169466, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:30,102] Trial 288 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.044073250917651706, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:31,207] Trial 289 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04061059642824825, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:32,313] Trial 290 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04185224673811906, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:33,226] Trial 291 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 157, 'max_depth': 5, 'learning_rate': 0.03971552807937292, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:34,344] Trial 292 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04524266460905489, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:35,417] Trial 293 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.04912565401169545, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:36,499] Trial 294 finished with value: 0.83723505544913 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04568519353623626, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:37,504] Trial 295 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.042810986533808576, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:40,123] Trial 296 finished with value: 0.7910991451221336 and parameters: {'n_estimators': 190, 'max_depth': 9, 'learning_rate': 0.03628930964570417, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:41,466] Trial 297 finished with value: 0.8057795541931729 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.045611056371464294, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:42,187] Trial 298 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.02848568710558536, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:43,303] Trial 299 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.03885104795546564, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:44,119] Trial 300 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 181, 'max_depth': 4, 'learning_rate': 0.04744121990344231, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:44,789] Trial 301 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 193, 'max_depth': 3, 'learning_rate': 0.04077785668741753, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:45,925] Trial 302 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.042643578344834863, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:47,014] Trial 303 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.04456664052200383, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:47,568] Trial 304 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 86, 'max_depth': 5, 'learning_rate': 0.015240828353590516, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:48,719] Trial 305 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.052699516813839734, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:49,858] Trial 306 finished with value: 0.83723505544913 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04016692728625356, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:50,953] Trial 307 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.03549700245719146, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:52,012] Trial 308 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.014289484472499354, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:53,082] Trial 309 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.02610144072945138, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:54,180] Trial 310 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.013070038210139396, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:55,305] Trial 311 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.038565686020243406, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:56,818] Trial 312 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 195, 'max_depth': 6, 'learning_rate': 0.03049225087963791, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:57,954] Trial 313 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.03775589012102685, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:10:59,042] Trial 314 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.041574012072677316, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:11:00,109] Trial 315 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.043117295712737695, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:11:01,237] Trial 316 finished with value: 0.84191359062235 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03717544634788248, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:11:02,200] Trial 317 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 164, 'max_depth': 5, 'learning_rate': 0.034438892607285776, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:11:03,236] Trial 318 finished with value: 0.84191359062235 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.03819039335095509, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 108 with value: 0.8514727276739713.\n","[I 2024-04-02 06:11:04,307] Trial 319 finished with value: 0.8553200492881156 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.03954960858556617, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 319 with value: 0.8553200492881156.\n","[I 2024-04-02 06:11:05,603] Trial 320 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 184, 'max_depth': 6, 'learning_rate': 0.041824707097992124, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 319 with value: 0.8553200492881156.\n","[I 2024-04-02 06:11:06,680] Trial 321 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.038946651388806916, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 319 with value: 0.8553200492881156.\n","[I 2024-04-02 06:11:07,782] Trial 322 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.03207039866354452, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 319 with value: 0.8553200492881156.\n","[I 2024-04-02 06:11:08,592] Trial 323 finished with value: 0.8061394798155086 and parameters: {'n_estimators': 173, 'max_depth': 4, 'learning_rate': 0.02273043338101769, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 319 with value: 0.8553200492881156.\n","[I 2024-04-02 06:11:09,559] Trial 324 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 167, 'max_depth': 5, 'learning_rate': 0.040333477607091446, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 319 with value: 0.8553200492881156.\n","[I 2024-04-02 06:11:10,634] Trial 325 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.0443020670629537, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 319 with value: 0.8553200492881156.\n","[I 2024-04-02 06:11:11,636] Trial 326 finished with value: 0.836512374443409 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.047931344651275784, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 319 with value: 0.8553200492881156.\n","[I 2024-04-02 06:11:12,658] Trial 327 finished with value: 0.8599806088369385 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.043690787193571605, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:13,681] Trial 328 finished with value: 0.83723505544913 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.04472753195047899, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:14,787] Trial 329 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.046558334058562634, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:15,836] Trial 330 finished with value: 0.84191359062235 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04368097758830116, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:16,690] Trial 331 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 195, 'max_depth': 4, 'learning_rate': 0.05002083323175681, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:17,769] Trial 332 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.045307630247418684, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:18,805] Trial 333 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.04075972601495513, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:19,856] Trial 334 finished with value: 0.83723505544913 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.04244426402099027, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:21,136] Trial 335 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.040833422094259254, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:22,167] Trial 336 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04225312231967079, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:23,216] Trial 337 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04416576147452289, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:25,243] Trial 338 finished with value: 0.8034347634347635 and parameters: {'n_estimators': 183, 'max_depth': 8, 'learning_rate': 0.047034447233265476, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:26,234] Trial 339 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.04395637884029404, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:27,378] Trial 340 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04529004277559339, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:28,355] Trial 341 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.048903949391032216, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:29,356] Trial 342 finished with value: 0.83723505544913 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.04233349628219293, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:30,408] Trial 343 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.044486015442318505, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:31,416] Trial 344 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.0429678646459397, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:32,442] Trial 345 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.04577380787773176, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:33,467] Trial 346 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.04128514817626022, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:34,490] Trial 347 finished with value: 0.83723505544913 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04417189211674766, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:35,526] Trial 348 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.041376502413251526, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:36,532] Trial 349 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.04718534307680701, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:38,180] Trial 350 finished with value: 0.8082763742703633 and parameters: {'n_estimators': 185, 'max_depth': 7, 'learning_rate': 0.043394862949404485, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:39,509] Trial 351 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 188, 'max_depth': 6, 'learning_rate': 0.013657385755028497, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:40,365] Trial 352 finished with value: 0.8006420599704182 and parameters: {'n_estimators': 189, 'max_depth': 4, 'learning_rate': 0.015012210356241716, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:41,385] Trial 353 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.01705129092809873, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:42,435] Trial 354 finished with value: 0.84191359062235 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.040774029581626424, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:43,437] Trial 355 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.04413475050512683, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:44,486] Trial 356 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.013406758474261022, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:45,507] Trial 357 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.01605691821746447, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:46,330] Trial 358 finished with value: 0.833469421937483 and parameters: {'n_estimators': 142, 'max_depth': 5, 'learning_rate': 0.013999911131908791, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:46,812] Trial 359 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 101, 'max_depth': 4, 'learning_rate': 0.051185870557088474, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:47,812] Trial 360 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.04608207407239657, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:48,650] Trial 361 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 147, 'max_depth': 5, 'learning_rate': 0.04025865437094963, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:49,719] Trial 362 finished with value: 0.8550124072512131 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04251581851097582, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:50,789] Trial 363 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.041959380862954, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:51,863] Trial 364 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.0129312228752098, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:52,923] Trial 365 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.014281359183364532, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:54,239] Trial 366 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 188, 'max_depth': 6, 'learning_rate': 0.014761689269344114, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:55,293] Trial 367 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.07127154753658303, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:56,341] Trial 368 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.03964890153468916, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:57,397] Trial 369 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.013469737638472618, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:58,435] Trial 370 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.012914194012781013, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:11:59,506] Trial 371 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.04228883198223179, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:00,590] Trial 372 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.013703812310446551, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:01,671] Trial 373 finished with value: 0.83723505544913 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.04747318118506095, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:02,732] Trial 374 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.03681013938543329, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:03,803] Trial 375 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.015278576391961545, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:04,866] Trial 376 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.013041809530758829, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:05,959] Trial 377 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.014317933409421515, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:07,016] Trial 378 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04205128150165061, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:08,386] Trial 379 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 195, 'max_depth': 6, 'learning_rate': 0.012557342769034505, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:09,218] Trial 380 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.039345714126764186, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:10,318] Trial 381 finished with value: 0.836512374443409 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.044260208262124616, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:14,051] Trial 382 finished with value: 0.77867902687129 and parameters: {'n_estimators': 191, 'max_depth': 10, 'learning_rate': 0.013392960517502387, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:15,138] Trial 383 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.01397477071078644, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:16,241] Trial 384 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.012438688106815528, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:17,292] Trial 385 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04273068192325417, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:18,191] Trial 386 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 161, 'max_depth': 5, 'learning_rate': 0.040042840793214504, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:19,204] Trial 387 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.04899015138113358, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:20,224] Trial 388 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.045790635025405646, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:21,263] Trial 389 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.014736212631940106, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:22,388] Trial 390 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.0542916335782822, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:23,479] Trial 391 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.013639332576090329, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:24,495] Trial 392 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.013041463073057558, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:25,584] Trial 393 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.0407376382816277, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:26,321] Trial 394 finished with value: 0.833469421937483 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.015515201961546224, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:27,372] Trial 395 finished with value: 0.827429728579154 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.0430812851448951, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:28,471] Trial 396 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.03580855097800467, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:29,535] Trial 397 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.01398601104589144, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:31,305] Trial 398 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 183, 'max_depth': 6, 'learning_rate': 0.019801843880532993, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:32,367] Trial 399 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.03823978627643118, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:33,368] Trial 400 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.012470669624560587, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:34,435] Trial 401 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04496735675173318, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:35,476] Trial 402 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.014567690616990878, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:36,568] Trial 403 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.013236180653781598, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:37,416] Trial 404 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 193, 'max_depth': 4, 'learning_rate': 0.04163968810193709, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:38,483] Trial 405 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.012190163121445375, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:39,468] Trial 406 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.016150442449440496, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:39,939] Trial 407 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.04828972756808316, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:40,967] Trial 408 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.013755568056307038, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:42,041] Trial 409 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.012879404073776479, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:42,834] Trial 410 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 137, 'max_depth': 5, 'learning_rate': 0.0437652477272931, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:44,587] Trial 411 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 190, 'max_depth': 7, 'learning_rate': 0.03973134431501997, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:45,702] Trial 412 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.01419438894993215, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:46,978] Trial 413 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 185, 'max_depth': 6, 'learning_rate': 0.03719828707686706, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:48,328] Trial 414 finished with value: 0.8230965538028735 and parameters: {'n_estimators': 188, 'max_depth': 6, 'learning_rate': 0.03755452889878055, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:49,675] Trial 415 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 192, 'max_depth': 6, 'learning_rate': 0.015122506913701863, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:51,112] Trial 416 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 196, 'max_depth': 6, 'learning_rate': 0.013031583485447513, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:52,449] Trial 417 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.038150244826844724, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:53,737] Trial 418 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.03272594973906415, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:54,804] Trial 419 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.03648263759674622, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:56,199] Trial 420 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 194, 'max_depth': 6, 'learning_rate': 0.018934790380178906, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:57,461] Trial 421 finished with value: 0.8130959183590762 and parameters: {'n_estimators': 132, 'max_depth': 7, 'learning_rate': 0.013576836997125762, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:58,509] Trial 422 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.012340021695948632, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:12:59,941] Trial 423 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 198, 'max_depth': 6, 'learning_rate': 0.03503230021234415, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:00,987] Trial 424 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.01746519803514306, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:02,295] Trial 425 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.014491652561311952, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:03,174] Trial 426 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.042872867337506816, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:04,176] Trial 427 finished with value: 0.83723505544913 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.04533947989035795, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:05,248] Trial 428 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.013472440825519025, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:06,300] Trial 429 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.012786548044200556, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:07,157] Trial 430 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 195, 'max_depth': 4, 'learning_rate': 0.040391955304053144, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:08,195] Trial 431 finished with value: 0.84191359062235 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.039059028213345004, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:09,162] Trial 432 finished with value: 0.83723505544913 and parameters: {'n_estimators': 171, 'max_depth': 5, 'learning_rate': 0.046187487001657535, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:10,231] Trial 433 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.013903252673544277, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:12,022] Trial 434 finished with value: 0.7910991451221336 and parameters: {'n_estimators': 198, 'max_depth': 7, 'learning_rate': 0.042367218482479645, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:13,091] Trial 435 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.0208672593426112, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:14,397] Trial 436 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 181, 'max_depth': 6, 'learning_rate': 0.01496602539688092, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:15,484] Trial 437 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.012060048198244551, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:16,534] Trial 438 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.023815860694227593, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:17,610] Trial 439 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.01443450896996139, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:18,677] Trial 440 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.013180645774911912, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:19,690] Trial 441 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.04143692657399343, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:20,827] Trial 442 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.015796979671700833, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:21,500] Trial 443 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 194, 'max_depth': 3, 'learning_rate': 0.04414358049345404, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:22,560] Trial 444 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.012775151551344602, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:23,554] Trial 445 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.047712923864236215, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:24,435] Trial 446 finished with value: 0.833469421937483 and parameters: {'n_estimators': 156, 'max_depth': 5, 'learning_rate': 0.01348126995495817, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:25,802] Trial 447 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 189, 'max_depth': 6, 'learning_rate': 0.013964226703681623, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:26,644] Trial 448 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 192, 'max_depth': 4, 'learning_rate': 0.03917016463921774, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:27,741] Trial 449 finished with value: 0.8183470827148989 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.050277244860817784, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:28,790] Trial 450 finished with value: 0.8514727276739713 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.012279869167279349, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:29,831] Trial 451 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.012233345467631617, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:30,819] Trial 452 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.012653638563981813, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:31,824] Trial 453 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.012296276673346068, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:32,860] Trial 454 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.02724389386342268, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:34,042] Trial 455 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.01305043302912615, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:35,345] Trial 456 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.012032528712886854, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:36,378] Trial 457 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.014032315285082024, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:37,439] Trial 458 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.01316132228493141, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:40,063] Trial 459 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 188, 'max_depth': 9, 'learning_rate': 0.014861373880488997, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:41,068] Trial 460 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.012585240896527634, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:42,098] Trial 461 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.013510459010749131, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:42,939] Trial 462 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 189, 'max_depth': 4, 'learning_rate': 0.01415383001406395, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:44,213] Trial 463 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 177, 'max_depth': 6, 'learning_rate': 0.01207259032842434, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:45,283] Trial 464 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.013134131337560872, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:46,297] Trial 465 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.04565977973657819, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:47,336] Trial 466 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.01172571075893359, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:48,631] Trial 467 finished with value: 0.7851496251496252 and parameters: {'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.09239488268370905, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:49,740] Trial 468 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.013636892190797488, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:50,856] Trial 469 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.01266733447477582, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:52,529] Trial 470 finished with value: 0.8001817909863886 and parameters: {'n_estimators': 188, 'max_depth': 7, 'learning_rate': 0.07856425491284187, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:53,627] Trial 471 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.014484488798671513, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:54,635] Trial 472 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.04362129982606553, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:55,626] Trial 473 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.04372047449468274, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:56,592] Trial 474 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 173, 'max_depth': 5, 'learning_rate': 0.048104943010759946, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:57,598] Trial 475 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.04635393011148799, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:58,057] Trial 476 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 92, 'max_depth': 4, 'learning_rate': 0.029387396475515214, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:13:59,041] Trial 477 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.04298065416706239, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:00,166] Trial 478 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04167281733042393, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:01,361] Trial 479 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 169, 'max_depth': 6, 'learning_rate': 0.04563185073654966, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:01,752] Trial 480 finished with value: 0.84709015035102 and parameters: {'n_estimators': 56, 'max_depth': 5, 'learning_rate': 0.044477869814956224, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:02,274] Trial 481 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 83, 'max_depth': 5, 'learning_rate': 0.044183062980858216, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:03,107] Trial 482 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 147, 'max_depth': 5, 'learning_rate': 0.050635184711977324, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:04,128] Trial 483 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.04657814692711323, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:05,116] Trial 484 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.043866277103323276, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:05,902] Trial 485 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 127, 'max_depth': 5, 'learning_rate': 0.04224605877676066, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:06,353] Trial 486 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.0485635175572953, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:07,054] Trial 487 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.03992494430894976, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:07,408] Trial 488 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.04474395808506656, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:07,910] Trial 489 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 80, 'max_depth': 5, 'learning_rate': 0.041148398282832455, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:08,322] Trial 490 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.034133085316526, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:09,053] Trial 491 finished with value: 0.84191359062235 and parameters: {'n_estimators': 98, 'max_depth': 6, 'learning_rate': 0.037774894831697006, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:10,084] Trial 492 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.04690018360100309, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:10,918] Trial 493 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.04282584456675629, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:11,298] Trial 494 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 54, 'max_depth': 5, 'learning_rate': 0.04098057319144356, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:12,318] Trial 495 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.044474712946480616, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:14,435] Trial 496 finished with value: 0.8087888675268976 and parameters: {'n_estimators': 190, 'max_depth': 8, 'learning_rate': 0.03883515032545942, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:15,362] Trial 497 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 164, 'max_depth': 5, 'learning_rate': 0.04217551311878397, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:15,833] Trial 498 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.03688048637508821, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:16,947] Trial 499 finished with value: 0.8178941595494262 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.04871062450372954, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:17,990] Trial 500 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.052894500995240235, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:18,909] Trial 501 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 160, 'max_depth': 5, 'learning_rate': 0.044564022756966186, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:19,984] Trial 502 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.046400902226799254, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:21,061] Trial 503 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04361795977804839, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:21,743] Trial 504 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.030933351398402354, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:22,312] Trial 505 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 89, 'max_depth': 5, 'learning_rate': 0.018237805347525983, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:23,580] Trial 506 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 181, 'max_depth': 6, 'learning_rate': 0.04031774742319124, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:24,578] Trial 507 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.016592693641599217, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:25,619] Trial 508 finished with value: 0.83723505544913 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04277371769087869, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:26,726] Trial 509 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.015348388922493822, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:27,794] Trial 510 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.035597200663239764, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:30,998] Trial 511 finished with value: 0.7958806390033156 and parameters: {'n_estimators': 151, 'max_depth': 10, 'learning_rate': 0.038381729095176544, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:32,060] Trial 512 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.011762690135467716, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:33,326] Trial 513 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 183, 'max_depth': 6, 'learning_rate': 0.04089097423714175, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:33,967] Trial 514 finished with value: 0.8201060592364939 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.01254927025568302, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:35,503] Trial 515 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.04586806667622447, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:35,924] Trial 516 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.0499660087078296, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:37,113] Trial 517 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.04198238970341231, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:38,252] Trial 518 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.013073456747068586, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:39,347] Trial 519 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.039606572746864376, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:40,479] Trial 520 finished with value: 0.84709015035102 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.013815337325265102, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:41,329] Trial 521 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 189, 'max_depth': 4, 'learning_rate': 0.04718610982162699, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:42,361] Trial 522 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.043994784651935896, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:44,177] Trial 523 finished with value: 0.8039786460839093 and parameters: {'n_estimators': 192, 'max_depth': 7, 'learning_rate': 0.012083678445054983, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:45,236] Trial 524 finished with value: 0.84709015035102 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.013390495434914471, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:46,571] Trial 525 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 181, 'max_depth': 6, 'learning_rate': 0.014816933188665395, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:47,552] Trial 526 finished with value: 0.8291007562746693 and parameters: {'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.012698191840375754, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:48,691] Trial 527 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.04484563478433182, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:49,786] Trial 528 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04220448604025233, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:50,865] Trial 529 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.03750136223983309, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:51,918] Trial 530 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.04028821088038614, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:53,005] Trial 531 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.025112412289450946, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:54,065] Trial 532 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.03334102910882746, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:54,928] Trial 533 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 193, 'max_depth': 4, 'learning_rate': 0.041273575687933904, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:55,960] Trial 534 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.036480519621167086, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:57,329] Trial 535 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 188, 'max_depth': 6, 'learning_rate': 0.014234936927275916, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:58,452] Trial 536 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.011188572584308946, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:14:59,509] Trial 537 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.03931457369893424, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:00,623] Trial 538 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.042560099548482146, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:01,701] Trial 539 finished with value: 0.8154661162009946 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.02166821567751081, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:02,849] Trial 540 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.013488664667049642, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:03,957] Trial 541 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.015732223332466513, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:04,998] Trial 542 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.012493799028772103, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:06,101] Trial 543 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04217580714915315, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:07,447] Trial 544 finished with value: 0.8039786460839093 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.05634373387957729, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:08,487] Trial 545 finished with value: 0.8291007562746693 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.012006426691872065, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:09,645] Trial 546 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.03835735127987982, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:10,768] Trial 547 finished with value: 0.84709015035102 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.01304100567041027, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:11,831] Trial 548 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.013815125812244405, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:12,899] Trial 549 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.014476648410686554, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:13,900] Trial 550 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.04053752000403643, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:14,980] Trial 551 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.043102232758413656, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:16,790] Trial 552 finished with value: 0.8034347634347635 and parameters: {'n_estimators': 192, 'max_depth': 7, 'learning_rate': 0.04238965418304932, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:17,901] Trial 553 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.04689335310608679, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:19,302] Trial 554 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 191, 'max_depth': 6, 'learning_rate': 0.043809279936501216, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:20,408] Trial 555 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04017848241011632, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:21,526] Trial 556 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04547836912240444, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:22,592] Trial 557 finished with value: 0.836512374443409 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.043058693502416534, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:23,726] Trial 558 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.03847223438484234, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:24,823] Trial 559 finished with value: 0.83723505544913 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.048433226513709716, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:25,933] Trial 560 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.04113097762871982, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:26,778] Trial 561 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.04554383398155676, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:27,852] Trial 562 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04254880250955963, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:28,958] Trial 563 finished with value: 0.83723505544913 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.03945251578317223, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:30,040] Trial 564 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.03748931023198172, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:31,181] Trial 565 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.0354046236132387, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:31,990] Trial 566 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 139, 'max_depth': 5, 'learning_rate': 0.04367058078764528, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:33,069] Trial 567 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.05158499696378001, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:33,731] Trial 568 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 183, 'max_depth': 3, 'learning_rate': 0.04151030044651546, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:34,830] Trial 569 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04624511264094022, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:36,195] Trial 570 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 185, 'max_depth': 6, 'learning_rate': 0.04434167868020356, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:37,278] Trial 571 finished with value: 0.84191359062235 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04759829276964133, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:38,381] Trial 572 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.040293504841088214, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:39,455] Trial 573 finished with value: 0.83723505544913 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04376830797841979, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:40,410] Trial 574 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 197, 'max_depth': 4, 'learning_rate': 0.015285179273907741, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:41,522] Trial 575 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.042044201481284196, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:42,844] Trial 576 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 184, 'max_depth': 6, 'learning_rate': 0.039026464911019604, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:43,948] Trial 577 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.011571330633035434, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:45,033] Trial 578 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04929680276070959, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:46,131] Trial 579 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.014136653253333282, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:47,274] Trial 580 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.036807659440424516, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:48,318] Trial 581 finished with value: 0.84709015035102 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.013489645607202543, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:49,404] Trial 582 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.012480646448873258, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:50,489] Trial 583 finished with value: 0.84191359062235 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.04497677574310609, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:51,374] Trial 584 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 196, 'max_depth': 4, 'learning_rate': 0.04155334548869137, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:52,484] Trial 585 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.012938649875325637, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:53,532] Trial 586 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.014611894322857403, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:54,844] Trial 587 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 185, 'max_depth': 6, 'learning_rate': 0.04301746803366567, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:55,926] Trial 588 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.019779450333156947, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:57,047] Trial 589 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.016526340209190655, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:58,148] Trial 590 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04706949718925773, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:15:59,226] Trial 591 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04042857268161407, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:00,319] Trial 592 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.013428949475369614, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:01,446] Trial 593 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.01203190256905736, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:02,557] Trial 594 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.04556077693446255, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:03,615] Trial 595 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.038552167917910066, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:04,707] Trial 596 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.013994657936961443, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:06,153] Trial 597 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 198, 'max_depth': 6, 'learning_rate': 0.042557645045047374, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:07,188] Trial 598 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.012731245481916688, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:08,301] Trial 599 finished with value: 0.833469421937483 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.015000897433920204, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:09,338] Trial 600 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.034168047729037726, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:10,463] Trial 601 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.063695173481205, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:11,332] Trial 602 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.028124414403382703, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:12,463] Trial 603 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.0401701727668877, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:14,883] Trial 604 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 197, 'max_depth': 8, 'learning_rate': 0.01738922176057559, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:15,936] Trial 605 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04497246674037885, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:17,270] Trial 606 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 182, 'max_depth': 6, 'learning_rate': 0.013647825480886581, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:18,417] Trial 607 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.04303704527470646, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:20,175] Trial 608 finished with value: 0.8130959183590762 and parameters: {'n_estimators': 191, 'max_depth': 7, 'learning_rate': 0.010912816788257429, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:21,252] Trial 609 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.012459651811908898, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:22,352] Trial 610 finished with value: 0.84191359062235 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.03670648399626782, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:23,452] Trial 611 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.04725873567076019, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:24,497] Trial 612 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.0417675352908603, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:25,609] Trial 613 finished with value: 0.84709015035102 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.013117179039700364, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:26,648] Trial 614 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.03891958597840748, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:27,727] Trial 615 finished with value: 0.833469421937483 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.01553804558394576, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:28,694] Trial 616 finished with value: 0.833469421937483 and parameters: {'n_estimators': 167, 'max_depth': 5, 'learning_rate': 0.010123131858559592, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:29,832] Trial 617 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.011693375016573053, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:30,934] Trial 618 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.02368859372063622, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:31,770] Trial 619 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 182, 'max_depth': 4, 'learning_rate': 0.04935323460482685, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:32,843] Trial 620 finished with value: 0.8512233217188787 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.014159979075732061, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:33,923] Trial 621 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04430072218571495, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:34,994] Trial 622 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.04451337069425612, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:36,319] Trial 623 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 187, 'max_depth': 6, 'learning_rate': 0.045282213644168595, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:37,401] Trial 624 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.047653415503709336, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:38,473] Trial 625 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.05109190428250662, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:39,539] Trial 626 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.05338766605686623, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:40,626] Trial 627 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.048573807285721596, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:41,720] Trial 628 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04685504791995959, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:42,876] Trial 629 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.0480970969416909, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:43,989] Trial 630 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.05246410633906601, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:45,038] Trial 631 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.05058176813890967, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:46,100] Trial 632 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04813744179143801, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:47,432] Trial 633 finished with value: 0.7963322301543593 and parameters: {'n_estimators': 188, 'max_depth': 6, 'learning_rate': 0.04854683371354784, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:48,486] Trial 634 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.04915317267291137, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:49,559] Trial 635 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.046452654784648106, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:50,667] Trial 636 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.05926901958997332, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:51,748] Trial 637 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04624227126896215, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:52,794] Trial 638 finished with value: 0.836512374443409 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.05076744311381212, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:53,874] Trial 639 finished with value: 0.84191359062235 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04471939913047025, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:54,926] Trial 640 finished with value: 0.83723505544913 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04301054407541096, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:55,775] Trial 641 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.046446617417317364, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:56,862] Trial 642 finished with value: 0.836512374443409 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04391795836962302, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:57,845] Trial 643 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.04125682562907541, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:58,861] Trial 644 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.04820383168079464, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:16:59,942] Trial 645 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04365668713912074, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:00,985] Trial 646 finished with value: 0.83723505544913 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.05144133266122483, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:02,086] Trial 647 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.045548231461690306, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:02,989] Trial 648 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 155, 'max_depth': 5, 'learning_rate': 0.041654634588538283, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:04,062] Trial 649 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04339463472025602, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:05,406] Trial 650 finished with value: 0.7905782834818402 and parameters: {'n_estimators': 187, 'max_depth': 6, 'learning_rate': 0.054982879141637075, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:06,453] Trial 651 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.04090195034953723, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:07,540] Trial 652 finished with value: 0.83723505544913 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.046931530344186616, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:08,614] Trial 653 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.03922500881460012, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:09,631] Trial 654 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.048693531693632795, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:10,723] Trial 655 finished with value: 0.84191359062235 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.044403282932456684, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:11,831] Trial 656 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04244359028694623, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:13,445] Trial 657 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.045588643179661555, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:14,311] Trial 658 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.04029493623783159, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:15,413] Trial 659 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.037655122334597974, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:16,452] Trial 660 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.04972409268017418, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:17,543] Trial 661 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.0433422493854009, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:18,588] Trial 662 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.04709608159875634, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:19,935] Trial 663 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 189, 'max_depth': 6, 'learning_rate': 0.041412328891590994, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:20,788] Trial 664 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 145, 'max_depth': 5, 'learning_rate': 0.038708007493363145, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:21,879] Trial 665 finished with value: 0.84191359062235 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04444191222413795, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:22,926] Trial 666 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.04219112073798705, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:24,035] Trial 667 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04004006644173482, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:26,115] Trial 668 finished with value: 0.7814729914593116 and parameters: {'n_estimators': 187, 'max_depth': 8, 'learning_rate': 0.045953155252196703, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:27,192] Trial 669 finished with value: 0.84191359062235 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.03561207115143231, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:28,254] Trial 670 finished with value: 0.84191359062235 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04403494862760883, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:29,330] Trial 671 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04161224458697968, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:30,387] Trial 672 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.04834774326952249, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:31,513] Trial 673 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.052272969355763164, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:32,868] Trial 674 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 193, 'max_depth': 6, 'learning_rate': 0.045153117524364975, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:33,715] Trial 675 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 183, 'max_depth': 4, 'learning_rate': 0.03934092134618586, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:34,715] Trial 676 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.042941569463861066, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:35,798] Trial 677 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04715896727013739, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:36,858] Trial 678 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.031686176408157275, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:37,934] Trial 679 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.0500366058667998, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:38,987] Trial 680 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.053980603963442314, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:40,080] Trial 681 finished with value: 0.84191359062235 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04739070829492691, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:41,118] Trial 682 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.050462070724288266, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:42,210] Trial 683 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.022570139439208173, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:44,731] Trial 684 finished with value: 0.8140245822030209 and parameters: {'n_estimators': 184, 'max_depth': 9, 'learning_rate': 0.04784587448457582, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:45,890] Trial 685 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04609719256833439, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:47,307] Trial 686 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.045619700156235524, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:48,913] Trial 687 finished with value: 0.8178941595494262 and parameters: {'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.04411166099502323, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:50,247] Trial 688 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 185, 'max_depth': 6, 'learning_rate': 0.03744958134027124, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:50,933] Trial 689 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 189, 'max_depth': 3, 'learning_rate': 0.049013013973082165, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:52,024] Trial 690 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.04220214718778762, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:53,065] Trial 691 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.04648586179042037, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:54,140] Trial 692 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.026576832697939163, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:55,153] Trial 693 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.04036772267764964, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:56,236] Trial 694 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04342696162981515, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:57,291] Trial 695 finished with value: 0.8599806088369385 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.044883180767894236, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:58,391] Trial 696 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.05159208155784087, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:17:59,246] Trial 697 finished with value: 0.83723505544913 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.04574438541289766, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:00,355] Trial 698 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04764859342223662, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:01,463] Trial 699 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04899970555966869, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:02,562] Trial 700 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.05398966384112527, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:03,949] Trial 701 finished with value: 0.786808667403463 and parameters: {'n_estimators': 195, 'max_depth': 6, 'learning_rate': 0.048191148116876956, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:05,032] Trial 702 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.05094042874498272, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:06,124] Trial 703 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04664643270252952, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:07,194] Trial 704 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.04428987870749883, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:08,285] Trial 705 finished with value: 0.827429728579154 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.0559768592140673, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:09,355] Trial 706 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.047551382645581584, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:10,772] Trial 707 finished with value: 0.7857441015335751 and parameters: {'n_estimators': 196, 'max_depth': 6, 'learning_rate': 0.05002004369152256, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:11,845] Trial 708 finished with value: 0.84191359062235 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.04510175061986188, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:12,927] Trial 709 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.041966410108604926, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:14,039] Trial 710 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04454633464107356, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:14,780] Trial 711 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.04744544357703557, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:15,914] Trial 712 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04287919338095462, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:16,787] Trial 713 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.040712801072447284, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:17,949] Trial 714 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04597170929832345, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:19,033] Trial 715 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.05249886835937913, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:21,650] Trial 716 finished with value: 0.8034347634347635 and parameters: {'n_estimators': 185, 'max_depth': 10, 'learning_rate': 0.04329503718415296, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:22,756] Trial 717 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.0496585544552493, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:23,840] Trial 718 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.046923650131858397, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:24,892] Trial 719 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.04126600393445836, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:25,839] Trial 720 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 162, 'max_depth': 5, 'learning_rate': 0.044397495381441186, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:26,903] Trial 721 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.03759056301815173, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:28,013] Trial 722 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04342376558972723, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:29,140] Trial 723 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04277755890960092, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:30,577] Trial 724 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 195, 'max_depth': 6, 'learning_rate': 0.039623426384831996, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:31,512] Trial 725 finished with value: 0.83723505544913 and parameters: {'n_estimators': 159, 'max_depth': 5, 'learning_rate': 0.04531129198119705, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:32,643] Trial 726 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.04152668995655517, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:33,787] Trial 727 finished with value: 0.8596955363285586 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.039491980958491775, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:34,700] Trial 728 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 199, 'max_depth': 4, 'learning_rate': 0.03580744232157975, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:35,848] Trial 729 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03870715651637795, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:36,994] Trial 730 finished with value: 0.8553200492881156 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03816265830637385, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:38,127] Trial 731 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.037522658858676616, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:39,267] Trial 732 finished with value: 0.83723505544913 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03723841551898395, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:40,432] Trial 733 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.035524032593078625, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:41,567] Trial 734 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.03856025663842696, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:43,020] Trial 735 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.035438518483682936, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:44,177] Trial 736 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03954938357852923, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:45,324] Trial 737 finished with value: 0.83723505544913 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03711656025589753, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:46,458] Trial 738 finished with value: 0.83723505544913 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.03449730172294146, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:47,581] Trial 739 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04034256842392025, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:49,000] Trial 740 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 197, 'max_depth': 6, 'learning_rate': 0.03838631229346023, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:50,204] Trial 741 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.033969387635899004, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:51,325] Trial 742 finished with value: 0.84191359062235 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04085179643424248, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:52,471] Trial 743 finished with value: 0.83723505544913 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.039117648599397196, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:54,274] Trial 744 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 197, 'max_depth': 7, 'learning_rate': 0.0411915104923209, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:55,180] Trial 745 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 196, 'max_depth': 4, 'learning_rate': 0.03226968463061184, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:56,309] Trial 746 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.03660033019504076, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:57,454] Trial 747 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.04027557332077768, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:58,562] Trial 748 finished with value: 0.84191359062235 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.03883973716020186, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:18:59,467] Trial 749 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 151, 'max_depth': 5, 'learning_rate': 0.04161083690726581, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:00,278] Trial 750 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 129, 'max_depth': 5, 'learning_rate': 0.029695069681732376, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:01,666] Trial 751 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 196, 'max_depth': 6, 'learning_rate': 0.04172837343416592, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:02,799] Trial 752 finished with value: 0.8599806088369385 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.039419797062395276, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:03,946] Trial 753 finished with value: 0.84191359062235 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03641493947309636, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:05,071] Trial 754 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.03835609604474741, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:06,194] Trial 755 finished with value: 0.84191359062235 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.03687412757185161, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:07,337] Trial 756 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03923929886152812, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:08,443] Trial 757 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.040119360711124895, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:09,564] Trial 758 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.033499065567440006, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:10,697] Trial 759 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.03756995041083981, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:11,835] Trial 760 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04019429644984131, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:12,940] Trial 761 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.04209298498740773, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:14,059] Trial 762 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.036371826158535514, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:15,480] Trial 763 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 197, 'max_depth': 6, 'learning_rate': 0.03468430015872716, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:16,593] Trial 764 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.03862662867104382, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:17,733] Trial 765 finished with value: 0.83723505544913 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.04180549990109425, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:18,843] Trial 766 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.04141065429714644, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:19,998] Trial 767 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03982204521104111, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:21,217] Trial 768 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04283060508902895, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:22,368] Trial 769 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.03839714839330152, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:23,510] Trial 770 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.043907157725566075, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:24,614] Trial 771 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04023261956641521, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:25,719] Trial 772 finished with value: 0.83723505544913 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04035279094316924, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:26,841] Trial 773 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.044735810393623024, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:27,940] Trial 774 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.042501049121136295, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:28,833] Trial 775 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 195, 'max_depth': 4, 'learning_rate': 0.041195023097995345, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:29,987] Trial 776 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.045334127046556656, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:31,090] Trial 777 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.01703878505356963, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:31,939] Trial 778 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 142, 'max_depth': 5, 'learning_rate': 0.04275718133852438, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:33,064] Trial 779 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.03950903625065851, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:34,170] Trial 780 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.046378059838341514, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:35,281] Trial 781 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.041565109822295755, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:36,389] Trial 782 finished with value: 0.84191359062235 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04485391725911406, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:37,513] Trial 783 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.043399032646471374, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:38,669] Trial 784 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.04012999543111836, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:39,824] Trial 785 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.018228986626516827, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:40,953] Trial 786 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04323509598758483, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:42,069] Trial 787 finished with value: 0.8512233217188787 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.03807492921754686, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:43,215] Trial 788 finished with value: 0.84191359062235 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03795703894047214, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:44,350] Trial 789 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.03556257199866358, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:45,472] Trial 790 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.03859003320969448, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:46,618] Trial 791 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.018931538890632916, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:47,737] Trial 792 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04253076189430257, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:48,625] Trial 793 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 191, 'max_depth': 4, 'learning_rate': 0.040903223114076424, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:49,776] Trial 794 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.036107076034072746, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:50,915] Trial 795 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.03964022668102625, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:52,110] Trial 796 finished with value: 0.84191359062235 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.03788259834808752, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:53,602] Trial 797 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.041473237777749195, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:54,697] Trial 798 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04402061892870584, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:55,847] Trial 799 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.025241027410394887, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:56,945] Trial 800 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.04605844773539843, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:58,084] Trial 801 finished with value: 0.833469421937483 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.010618146022032251, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:19:59,185] Trial 802 finished with value: 0.84191359062235 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.0479323711356751, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:00,319] Trial 803 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.043484869232539025, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:01,474] Trial 804 finished with value: 0.84191359062235 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.039910646231431784, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:02,578] Trial 805 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.0370405132506175, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:03,492] Trial 806 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.041747702869320585, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:04,618] Trial 807 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.016206893908000064, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:05,720] Trial 808 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.020906845871241305, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:06,837] Trial 809 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.03287893476699202, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:07,930] Trial 810 finished with value: 0.83723505544913 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.04468182750644302, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:08,905] Trial 811 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 165, 'max_depth': 5, 'learning_rate': 0.03915020385130624, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:11,719] Trial 812 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 193, 'max_depth': 9, 'learning_rate': 0.04994378489239594, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:12,848] Trial 813 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.09706451739112583, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:13,955] Trial 814 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.047248679619451533, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:15,096] Trial 815 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.04261679672891045, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:16,186] Trial 816 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.0406113093334283, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:17,313] Trial 817 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.03493835206080806, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:18,422] Trial 818 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04478812945704702, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:19,557] Trial 819 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04185666917271389, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:20,683] Trial 820 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.038180379100125054, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:21,556] Trial 821 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 189, 'max_depth': 4, 'learning_rate': 0.04347912291789955, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:22,688] Trial 822 finished with value: 0.83723505544913 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04665866754387599, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:23,862] Trial 823 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.040216352631556256, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:25,097] Trial 824 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.03702449224560251, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:26,192] Trial 825 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.048790388773173786, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:27,325] Trial 826 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04488710718402546, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:28,441] Trial 827 finished with value: 0.83723505544913 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.042389306561740336, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:29,536] Trial 828 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.03942448727323502, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:30,683] Trial 829 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.046915108952315626, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:31,795] Trial 830 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04088296721757056, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:32,874] Trial 831 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.051974792686652546, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:33,791] Trial 832 finished with value: 0.84191359062235 and parameters: {'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.044429119860256674, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:34,937] Trial 833 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04271069099834074, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:36,049] Trial 834 finished with value: 0.83723505544913 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.038542432713277106, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:37,137] Trial 835 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04617930375285708, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:38,257] Trial 836 finished with value: 0.84191359062235 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04115143812075661, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:39,419] Trial 837 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03638214584230164, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:40,539] Trial 838 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.048789388384522736, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:41,662] Trial 839 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04380568469658214, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:42,753] Trial 840 finished with value: 0.8291007562746693 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.03951033100146304, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:43,485] Trial 841 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.042006888602895566, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:44,622] Trial 842 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.07946535229332594, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:45,500] Trial 843 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.045715294511519, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:46,606] Trial 844 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.043260619669583805, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:48,755] Trial 845 finished with value: 0.8034347634347635 and parameters: {'n_estimators': 186, 'max_depth': 8, 'learning_rate': 0.010020859181959363, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:49,929] Trial 846 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05770335686888024, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:51,031] Trial 847 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.03759286388914352, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:52,167] Trial 848 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.05052925375579094, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:53,181] Trial 849 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.031004106421895477, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:54,293] Trial 850 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04128457279722032, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:55,054] Trial 851 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.04719735961609373, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:56,249] Trial 852 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.039336174652934604, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:57,318] Trial 853 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.043653652910452576, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:57,969] Trial 854 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.04481789759812462, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:58,961] Trial 855 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 169, 'max_depth': 5, 'learning_rate': 0.035082149735901264, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:20:59,884] Trial 856 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 195, 'max_depth': 4, 'learning_rate': 0.04050000554271287, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:00,975] Trial 857 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.03822615034163706, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:02,103] Trial 858 finished with value: 0.845595020307664 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.048237278570502536, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:03,209] Trial 859 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.042191821415132995, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:03,917] Trial 860 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.04472135047344762, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:04,613] Trial 861 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 187, 'max_depth': 3, 'learning_rate': 0.05272669157664058, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:05,674] Trial 862 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.04062127860945149, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:06,800] Trial 863 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.04648997581041097, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:07,911] Trial 864 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.017541155385405727, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:09,011] Trial 865 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04291069782957578, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:10,161] Trial 866 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.03602901907430983, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:11,245] Trial 867 finished with value: 0.8183470827148989 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.05042975627321542, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:12,344] Trial 868 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.03352006251654914, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:13,272] Trial 869 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.03816829984628784, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:14,378] Trial 870 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.04004094104468236, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:15,507] Trial 871 finished with value: 0.8001817909863886 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.06742058403367178, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:16,590] Trial 872 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.045546148461420806, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:17,747] Trial 873 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.04324041138333602, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:18,850] Trial 874 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.041290647993967096, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:19,940] Trial 875 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.0480237326655172, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:21,034] Trial 876 finished with value: 0.84191359062235 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.039401960559553924, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:22,145] Trial 877 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04509586118469192, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:23,298] Trial 878 finished with value: 0.83723505544913 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.037461005725046084, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:24,407] Trial 879 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.042698097314746906, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:25,294] Trial 880 finished with value: 0.833469421937483 and parameters: {'n_estimators': 149, 'max_depth': 5, 'learning_rate': 0.04166818970220229, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:26,402] Trial 881 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.01986643256604859, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:27,584] Trial 882 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.048739097623522895, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:28,678] Trial 883 finished with value: 0.8553200492881156 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04427227747533797, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:29,748] Trial 884 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.04702570679218922, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:30,828] Trial 885 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.015964503054424862, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:31,871] Trial 886 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.045500710578952025, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:32,891] Trial 887 finished with value: 0.84191359062235 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.054032838239049676, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:33,961] Trial 888 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.050101722447004, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:34,803] Trial 889 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 139, 'max_depth': 5, 'learning_rate': 0.03641463269368071, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:35,871] Trial 890 finished with value: 0.8512233217188787 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.039551344921613475, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:36,908] Trial 891 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.03472066259119551, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:37,959] Trial 892 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.03843017545497987, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:39,011] Trial 893 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.04465878468587731, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:39,884] Trial 894 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 183, 'max_depth': 4, 'learning_rate': 0.04716671473554885, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:40,922] Trial 895 finished with value: 0.84191359062235 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.0419014675859969, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:42,021] Trial 896 finished with value: 0.84191359062235 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.0391019367649973, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:43,146] Trial 897 finished with value: 0.83723505544913 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.04444653267544714, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:44,219] Trial 898 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.03695995311852284, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:45,257] Trial 899 finished with value: 0.833469421937483 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.010891450844088496, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:45,933] Trial 900 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.04108084716156505, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:47,011] Trial 901 finished with value: 0.833469421937483 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.042920077738002674, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:48,091] Trial 902 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04741380800290092, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:48,942] Trial 903 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 183, 'max_depth': 4, 'learning_rate': 0.03926857002764533, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:50,014] Trial 904 finished with value: 0.8503124686024315 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.0499831146091948, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:51,097] Trial 905 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.04571062046536201, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:52,197] Trial 906 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04117432915945406, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:53,259] Trial 907 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.04366017923899812, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:54,343] Trial 908 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.036969445873109866, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:55,639] Trial 909 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.03993849292738232, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:56,713] Trial 910 finished with value: 0.827429728579154 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.04650030732345281, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:21:58,927] Trial 911 finished with value: 0.7905782834818402 and parameters: {'n_estimators': 188, 'max_depth': 8, 'learning_rate': 0.04282322982306806, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:00,028] Trial 912 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.048698127187433285, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:01,141] Trial 913 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.04436843386451035, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:01,685] Trial 914 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.03801594649442978, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:02,741] Trial 915 finished with value: 0.833469421937483 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.03523261126725305, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:03,765] Trial 916 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 173, 'max_depth': 5, 'learning_rate': 0.051032236687544634, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:04,870] Trial 917 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.024143545885928253, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:06,260] Trial 918 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.04092141535855492, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:07,381] Trial 919 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.02824318029558269, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:08,457] Trial 920 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.042241581641100624, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:09,541] Trial 921 finished with value: 0.84191359062235 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.04581011168529514, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:10,685] Trial 922 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.015663368527965738, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:12,329] Trial 923 finished with value: 0.827429728579154 and parameters: {'n_estimators': 178, 'max_depth': 7, 'learning_rate': 0.01668248339920473, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:13,210] Trial 924 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.03928529193909108, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:14,310] Trial 925 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04381698339539474, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:15,386] Trial 926 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.04131366391902582, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:16,478] Trial 927 finished with value: 0.84191359062235 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04822066712153109, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:17,599] Trial 928 finished with value: 0.84191359062235 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.03848043617708346, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:18,662] Trial 929 finished with value: 0.8140245822030209 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.0897697286136844, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:19,762] Trial 930 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 145, 'max_depth': 6, 'learning_rate': 0.0453604915948795, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:20,864] Trial 931 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.03287369801966899, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:21,983] Trial 932 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.042149344140836924, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:23,076] Trial 933 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.036661909631498804, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:24,153] Trial 934 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.021783686316084964, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:25,054] Trial 935 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 192, 'max_depth': 4, 'learning_rate': 0.05295879829707524, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:26,157] Trial 936 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.043988213235971955, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:29,110] Trial 937 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 176, 'max_depth': 10, 'learning_rate': 0.039982960805721834, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:29,791] Trial 938 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 95, 'max_depth': 5, 'learning_rate': 0.04783643796157397, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:30,983] Trial 939 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04363307902512935, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:32,064] Trial 940 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.04060718573916205, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:32,883] Trial 941 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 132, 'max_depth': 5, 'learning_rate': 0.03826163621418427, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:33,830] Trial 942 finished with value: 0.84191359062235 and parameters: {'n_estimators': 157, 'max_depth': 5, 'learning_rate': 0.04501652401142145, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:34,894] Trial 943 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.04645695079645708, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:35,995] Trial 944 finished with value: 0.83723505544913 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.04185698941108473, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:37,150] Trial 945 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.03537876257563876, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:38,235] Trial 946 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.05064368465730129, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:39,360] Trial 947 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.01117514162490178, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:40,472] Trial 948 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.03976685774548691, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:41,518] Trial 949 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.04258060370488393, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:42,638] Trial 950 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04873682616365648, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:44,032] Trial 951 finished with value: 0.8087888675268976 and parameters: {'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.045434557192460465, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:45,187] Trial 952 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03752717095208782, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:46,253] Trial 953 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.015270141042353342, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:47,345] Trial 954 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.04318250754282737, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:48,477] Trial 955 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.0406247283645242, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:49,602] Trial 956 finished with value: 0.83723505544913 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.05565789157517896, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:50,785] Trial 957 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.046201898170483105, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:51,868] Trial 958 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.03422666522941174, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:52,923] Trial 959 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.038585295736234405, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:54,008] Trial 960 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.04217367041859291, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:54,928] Trial 961 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 197, 'max_depth': 4, 'learning_rate': 0.04741736124511124, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:56,326] Trial 962 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 192, 'max_depth': 6, 'learning_rate': 0.01851877738711717, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:57,293] Trial 963 finished with value: 0.84191359062235 and parameters: {'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.044280657672036136, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:58,399] Trial 964 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.040223842489003736, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:22:59,389] Trial 965 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 167, 'max_depth': 5, 'learning_rate': 0.04184815020696532, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:00,534] Trial 966 finished with value: 0.83723505544913 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04450156553506242, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:01,652] Trial 967 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.03710605409444627, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:02,867] Trial 968 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03954300174823083, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:03,941] Trial 969 finished with value: 0.840859352196084 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.0506890702003603, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:05,057] Trial 970 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.029561930536676866, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:06,187] Trial 971 finished with value: 0.83723505544913 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.04298264388419546, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:07,229] Trial 972 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.047398925660189925, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:08,143] Trial 973 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 197, 'max_depth': 4, 'learning_rate': 0.03604726664014711, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:09,249] Trial 974 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.040929073294220304, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:10,628] Trial 975 finished with value: 0.8006420599704182 and parameters: {'n_estimators': 187, 'max_depth': 6, 'learning_rate': 0.04514829529804295, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:11,680] Trial 976 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.03892158287524347, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:12,785] Trial 977 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.060952744415238624, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:14,525] Trial 978 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 184, 'max_depth': 7, 'learning_rate': 0.04344608733411463, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:15,643] Trial 979 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.049215029334516595, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:16,736] Trial 980 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.04642881299490069, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:17,891] Trial 981 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.014952293705488347, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:19,002] Trial 982 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.04102751536023939, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:20,116] Trial 983 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.03798785521843397, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:21,235] Trial 984 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.04272442628171825, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:22,340] Trial 985 finished with value: 0.83723505544913 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.04446805973846995, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:23,412] Trial 986 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.019935294020451508, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:24,569] Trial 987 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03959785608875092, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:25,417] Trial 988 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 178, 'max_depth': 4, 'learning_rate': 0.046226692545119324, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:26,559] Trial 989 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.05220875342966108, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:27,943] Trial 990 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 193, 'max_depth': 6, 'learning_rate': 0.04912484315179802, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:29,022] Trial 991 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.042595482657254186, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:30,146] Trial 992 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.025814029010609852, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:32,981] Trial 993 finished with value: 0.8140245822030209 and parameters: {'n_estimators': 191, 'max_depth': 9, 'learning_rate': 0.04097685375922646, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:34,175] Trial 994 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.0226722888152744, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:35,264] Trial 995 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.03819733615998667, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:36,326] Trial 996 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.044269631363226904, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:37,466] Trial 997 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.03158984465062331, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:38,481] Trial 998 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 171, 'max_depth': 5, 'learning_rate': 0.035791253069143734, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n","[I 2024-04-02 06:23:39,603] Trial 999 finished with value: 0.833469421937483 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.010417245112380125, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 327 with value: 0.8599806088369385.\n"]},{"name":"stdout","output_type":"stream","text":["Model Accuracy: 0.860360\n","Model F1 Score: 0.859981\n","Validation Accuracy: 0.801802\n","Validation F1 Score: 0.802082\n"]}],"source":["import optuna\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def objective(trial):\n","    param = {\n","        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1,log=True),\n","        'min_samples_split': trial.suggest_int('min_samples_split', 2, 5),\n","        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n","    }\n","    model = GradientBoostingClassifier(**param)\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_test)\n","    accuracy = f1_score(y_test, preds,average=\"weighted\")\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=1000)\n","\n","# Best hyperparameters\n","best_params = study.best_params\n","\n","# Fit the model with best hyperparameters\n","best_model = GradientBoostingClassifier(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","# Make predictions \n","preds = best_model.predict(X_test)\n","\n","# Check the accuracy and F1 score of the model\n","print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n","print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n","\n","# Now let's use the model with the best parameters on the validation set\n","val_preds = best_model.predict(X_val)\n","\n","# Check the accuracy and F1 score of the best model on the validation set\n","print(\"Validation Accuracy: %f\" % accuracy_score(y_val, val_preds))\n","print(\"Validation F1 Score: %f\" % f1_score(y_val, val_preds, average='weighted'))\n"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T06:23:40.681380Z","iopub.status.busy":"2024-04-02T06:23:40.680581Z","iopub.status.idle":"2024-04-02T06:23:40.709848Z","shell.execute_reply":"2024-04-02T06:23:40.707379Z","shell.execute_reply.started":"2024-04-02T06:23:40.681311Z"},"trusted":true},"outputs":[],"source":["pickle.dump(best_model, open(\"GB\", 'wb'))"]},{"cell_type":"code","execution_count":54,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-02T06:23:40.713813Z","iopub.status.busy":"2024-04-02T06:23:40.713034Z","iopub.status.idle":"2024-04-02T06:32:12.082126Z","shell.execute_reply":"2024-04-02T06:32:12.080501Z","shell.execute_reply.started":"2024-04-02T06:23:40.713751Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-04-02 06:23:40,726] A new study created in memory with name: no-name-3d9f0f9d-9ce7-45a5-b993-222fff9d2e00\n","[I 2024-04-02 06:23:47,743] Trial 0 finished with value: 0.7524326798760307 and parameters: {'n_estimators': 707, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1034, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 0 with value: 0.7524326798760307.\n","[I 2024-04-02 06:23:57,578] Trial 1 finished with value: 0.7747747747747747 and parameters: {'n_estimators': 1398, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 464, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 1 with value: 0.7747747747747747.\n","[I 2024-04-02 06:24:05,431] Trial 2 finished with value: 0.6684496379196839 and parameters: {'n_estimators': 828, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1209, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.7747747747747747.\n","[I 2024-04-02 06:24:15,998] Trial 3 finished with value: 0.7171264760611449 and parameters: {'n_estimators': 1202, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 1112, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.7747747747747747.\n","[I 2024-04-02 06:24:17,180] Trial 4 finished with value: 0.7576616795366797 and parameters: {'n_estimators': 111, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 257, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.7747747747747747.\n","[I 2024-04-02 06:24:25,259] Trial 5 finished with value: 0.7489127890777376 and parameters: {'n_estimators': 856, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 698, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.7747747747747747.\n","[I 2024-04-02 06:24:31,605] Trial 6 finished with value: 0.7971407701137431 and parameters: {'n_estimators': 863, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 158, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 6 with value: 0.7971407701137431.\n","[I 2024-04-02 06:24:44,983] Trial 7 finished with value: 0.7576616795366797 and parameters: {'n_estimators': 1247, 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 130, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 6 with value: 0.7971407701137431.\n","[I 2024-04-02 06:24:52,693] Trial 8 finished with value: 0.7889673710297429 and parameters: {'n_estimators': 1413, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1044, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 6 with value: 0.7971407701137431.\n","[I 2024-04-02 06:24:54,032] Trial 9 finished with value: 0.7576616795366797 and parameters: {'n_estimators': 153, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 373, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 6 with value: 0.7971407701137431.\n","[I 2024-04-02 06:24:55,979] Trial 10 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 534, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 2, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:24:57,705] Trial 11 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 510, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:00,945] Trial 12 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 451, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 12, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:04,598] Trial 13 finished with value: 0.788723176958471 and parameters: {'n_estimators': 476, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 574, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:08,648] Trial 14 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 543, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1483, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:10,966] Trial 15 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 286, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 33, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:16,151] Trial 16 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 682, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 337, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:22,463] Trial 17 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 1019, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 865, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:24,757] Trial 18 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 338, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 504, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:29,688] Trial 19 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 630, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 189, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:30,825] Trial 20 finished with value: 0.7231703403151786 and parameters: {'n_estimators': 306, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 682, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:37,238] Trial 21 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 1044, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 875, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:45,007] Trial 22 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 1032, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 910, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:52,398] Trial 23 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 997, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 810, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:25:56,393] Trial 24 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 577, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1364, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:00,623] Trial 25 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 565, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 1461, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:02,118] Trial 26 finished with value: 0.6811865358120865 and parameters: {'n_estimators': 424, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1239, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:07,834] Trial 27 finished with value: 0.7666371728871729 and parameters: {'n_estimators': 721, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 1334, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:11,900] Trial 28 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 575, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 297, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:17,727] Trial 29 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 766, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 590, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:19,206] Trial 30 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 194, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 76, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:24,714] Trial 31 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 954, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1044, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:27,584] Trial 32 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 383, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 931, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:32,872] Trial 33 finished with value: 0.7894847929579429 and parameters: {'n_estimators': 1113, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 451, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:37,056] Trial 34 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 667, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1321, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:42,903] Trial 35 finished with value: 0.7171264760611449 and parameters: {'n_estimators': 654, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1194, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:46,182] Trial 36 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 508, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 1361, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:53,376] Trial 37 finished with value: 0.7171264760611449 and parameters: {'n_estimators': 813, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 1356, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:26:57,631] Trial 38 finished with value: 0.7704375758850468 and parameters: {'n_estimators': 602, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 219, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:27:03,251] Trial 39 finished with value: 0.7527611645258704 and parameters: {'n_estimators': 735, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 1147, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:27:09,475] Trial 40 finished with value: 0.7884424718940626 and parameters: {'n_estimators': 903, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 109, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:27:17,105] Trial 41 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 1149, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1282, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:27:23,211] Trial 42 finished with value: 0.7894847929579429 and parameters: {'n_estimators': 1153, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1310, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:27:31,782] Trial 43 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 1260, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1414, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:27:41,008] Trial 44 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 1350, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1233, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:27:49,055] Trial 45 finished with value: 0.7756126662376662 and parameters: {'n_estimators': 1493, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 1101, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:27:58,284] Trial 46 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 1333, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 1244, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:28:08,798] Trial 47 finished with value: 0.7884424718940626 and parameters: {'n_estimators': 1348, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 993, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:28:17,327] Trial 48 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 1498, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 6, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:28:26,891] Trial 49 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 1212, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 1475, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:28:31,964] Trial 50 finished with value: 0.7490970232905718 and parameters: {'n_estimators': 499, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 1168, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:28:40,579] Trial 51 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 1313, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 1229, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:28:49,615] Trial 52 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 1291, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 1267, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:28:56,760] Trial 53 finished with value: 0.7894847929579429 and parameters: {'n_estimators': 1402, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1412, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:06,448] Trial 54 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 1277, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 1274, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:15,133] Trial 55 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 1159, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1093, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:26,769] Trial 56 finished with value: 0.7884424718940626 and parameters: {'n_estimators': 1435, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1396, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:28,257] Trial 57 finished with value: 0.7979474829008179 and parameters: {'n_estimators': 236, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 736, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:31,311] Trial 58 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 420, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 985, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:34,461] Trial 59 finished with value: 0.7843572540630146 and parameters: {'n_estimators': 386, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 58, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:38,630] Trial 60 finished with value: 0.7794400238895547 and parameters: {'n_estimators': 527, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 1004, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:41,801] Trial 61 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 434, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1143, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:44,545] Trial 62 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 380, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 1284, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:47,442] Trial 63 finished with value: 0.788723176958471 and parameters: {'n_estimators': 346, 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 1284, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:50,110] Trial 64 finished with value: 0.798311750118979 and parameters: {'n_estimators': 454, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 166, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:53,342] Trial 65 finished with value: 0.7977136800666212 and parameters: {'n_estimators': 396, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 1498, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:54,860] Trial 66 finished with value: 0.7559405727344658 and parameters: {'n_estimators': 318, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 1432, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:29:57,265] Trial 67 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 284, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 112, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:00,612] Trial 68 finished with value: 0.7979474829008179 and parameters: {'n_estimators': 495, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 629, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:09,495] Trial 69 finished with value: 0.7884424718940626 and parameters: {'n_estimators': 1088, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 815, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:15,184] Trial 70 finished with value: 0.744066811674369 and parameters: {'n_estimators': 574, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 261, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:15,994] Trial 71 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 103, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1211, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:17,066] Trial 72 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 134, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1206, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:17,757] Trial 73 finished with value: 0.8028619468711635 and parameters: {'n_estimators': 103, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1059, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:19,279] Trial 74 finished with value: 0.7979474829008179 and parameters: {'n_estimators': 231, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1355, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:23,348] Trial 75 finished with value: 0.7977136800666212 and parameters: {'n_estimators': 599, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1278, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:28,265] Trial 76 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 696, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 412, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:32,793] Trial 77 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 640, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 408, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:38,201] Trial 78 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 700, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1172, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:44,066] Trial 79 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 760, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 355, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:50,337] Trial 80 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 855, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 551, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:54,311] Trial 81 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 542, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 646, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:30:59,045] Trial 82 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 620, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 386, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:03,402] Trial 83 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 642, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1384, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:07,501] Trial 84 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 669, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 446, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:13,164] Trial 85 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 762, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 495, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:22,209] Trial 86 finished with value: 0.7707421707421708 and parameters: {'n_estimators': 911, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1308, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:25,617] Trial 87 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 473, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 929, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:30,614] Trial 88 finished with value: 0.7891754645052336 and parameters: {'n_estimators': 794, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 1440, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:33,658] Trial 89 finished with value: 0.744066811674369 and parameters: {'n_estimators': 698, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 1252, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:36,839] Trial 90 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 416, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 214, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:40,846] Trial 91 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 555, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 704, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:43,937] Trial 92 finished with value: 0.8025391462891464 and parameters: {'n_estimators': 534, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 645, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:47,930] Trial 93 finished with value: 0.7979474829008179 and parameters: {'n_estimators': 594, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 530, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:50,551] Trial 94 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 348, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 399, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:55,011] Trial 95 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 622, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 295, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:31:59,471] Trial 96 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 529, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 816, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:32:00,853] Trial 97 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 165, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 866, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:32:04,464] Trial 98 finished with value: 0.7750929952558943 and parameters: {'n_estimators': 472, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 1122, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 10 with value: 0.8285569013829883.\n","[I 2024-04-02 06:32:10,045] Trial 99 finished with value: 0.7895866536211117 and parameters: {'n_estimators': 728, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1349, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 10 with value: 0.8285569013829883.\n"]},{"name":"stdout","output_type":"stream","text":["Model Accuracy: 0.833333\n","Model F1 Score: 0.832169\n"]}],"source":["import optuna\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def objective(trial):\n","    param = {\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n","        'max_depth': trial.suggest_int('max_depth', 2, 32),\n","        'min_samples_split': trial.suggest_int('min_samples_split', 2, 5),\n","        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n","        'max_features': trial.suggest_int('max_features', 1,1500),\n","        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n","        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy'])\n","    }\n","    model = RandomForestClassifier(**param)\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_val)\n","    accuracy = f1_score(y_val, preds,average=\"weighted\")\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=100)\n","\n","# Best hyperparameters\n","best_params = study.best_params\n","\n","# Fit the model with best hyperparameters\n","best_model = RandomForestClassifier(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","# Make predictions \n","preds = best_model.predict(X_test)\n","\n","# Check the accuracy and F1 score of the model\n","print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n","print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T06:32:12.084386Z","iopub.status.busy":"2024-04-02T06:32:12.083975Z","iopub.status.idle":"2024-04-02T06:32:12.142928Z","shell.execute_reply":"2024-04-02T06:32:12.141622Z","shell.execute_reply.started":"2024-04-02T06:32:12.084351Z"},"trusted":true},"outputs":[],"source":["pickle.dump(best_model, open(\"RF\", 'wb'))"]},{"cell_type":"code","execution_count":56,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-02T06:32:12.144797Z","iopub.status.busy":"2024-04-02T06:32:12.144357Z","iopub.status.idle":"2024-04-02T06:40:33.654124Z","shell.execute_reply":"2024-04-02T06:40:33.653107Z","shell.execute_reply.started":"2024-04-02T06:32:12.144754Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-04-02 06:32:12,158] A new study created in memory with name: no-name-97e5947b-0f21-4c88-a50a-82e8fbff323f\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:12,326] Trial 0 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 118, 'max_depth': 79, 'learning_rate': 1.5695164628158915e-06, 'n_estimators': 264, 'min_child_samples': 78, 'min_child_weight': 0.03495579765689083, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.10622335247519998, 'reg_lambda': 0.013561713380720021}. Best is trial 0 with value: 0.42711942711942713.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:12,949] Trial 1 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 487, 'max_depth': 8, 'learning_rate': 1.0008324999085661e-06, 'n_estimators': 964, 'min_child_samples': 72, 'min_child_weight': 0.00040260111885731753, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 0.0001307539422107591, 'reg_lambda': 0.00010071563707176668}. Best is trial 0 with value: 0.42711942711942713.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:13,389] Trial 2 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 177, 'max_depth': 51, 'learning_rate': 5.574499295428427e-07, 'n_estimators': 627, 'min_child_samples': 65, 'min_child_weight': 0.029679132764628153, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.023828507763690387, 'reg_lambda': 0.0007140107624680601}. Best is trial 0 with value: 0.42711942711942713.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:13,472] Trial 3 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 232, 'max_depth': 11, 'learning_rate': 0.0004407100070481899, 'n_estimators': 59, 'min_child_samples': 23, 'min_child_weight': 0.0299343180442034, 'subsample': 0.6, 'colsample_bytree': 0.7, 'reg_alpha': 6.338023734751029e-05, 'reg_lambda': 9.889057395085682e-05}. Best is trial 0 with value: 0.42711942711942713.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:13,534] Trial 4 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 421, 'max_depth': 97, 'learning_rate': 3.093814091879437e-08, 'n_estimators': 68, 'min_child_samples': 35, 'min_child_weight': 0.005399289613178823, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.268103446866172e-05, 'reg_lambda': 4.404376294150687}. Best is trial 0 with value: 0.42711942711942713.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:13,933] Trial 5 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 141, 'max_depth': 52, 'learning_rate': 0.005101361487092899, 'n_estimators': 695, 'min_child_samples': 86, 'min_child_weight': 0.004941225578571915, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 2.645102882722736, 'reg_lambda': 5.22201388511344e-05}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:14,665] Trial 6 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 368, 'max_depth': 84, 'learning_rate': 1.7702529447421652e-07, 'n_estimators': 696, 'min_child_samples': 27, 'min_child_weight': 0.00021055305472718637, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.02366379167155913, 'reg_lambda': 0.058262656841397156}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:14,953] Trial 7 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 254, 'max_depth': 79, 'learning_rate': 5.492543873109962e-06, 'n_estimators': 548, 'min_child_samples': 54, 'min_child_weight': 0.0021197317087000432, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.00037559889372050645, 'reg_lambda': 9.71964785217189}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:15,213] Trial 8 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 188, 'max_depth': 29, 'learning_rate': 0.027357154930286474, 'n_estimators': 407, 'min_child_samples': 79, 'min_child_weight': 0.20015778897063105, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.002744322250313138, 'reg_lambda': 0.000386470239134236}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:15,373] Trial 9 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 341, 'max_depth': 110, 'learning_rate': 0.09639869870830885, 'n_estimators': 746, 'min_child_samples': 26, 'min_child_weight': 3.888107892780332e-05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 9.718512180502145, 'reg_lambda': 7.993502387120615e-05}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:15,896] Trial 10 finished with value: 0.7927182029735046 and parameters: {'num_leaves': 13, 'max_depth': 48, 'learning_rate': 0.0009978146910886163, 'n_estimators': 959, 'min_child_samples': 100, 'min_child_weight': 0.7347845203464021, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 4.993104493049485, 'reg_lambda': 0.2996796595927196}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:16,210] Trial 11 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 336, 'max_depth': 128, 'learning_rate': 0.032778729004677015, 'n_estimators': 784, 'min_child_samples': 11, 'min_child_weight': 1.8794081968618216e-05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 9.282397356622873, 'reg_lambda': 1.0001481246353548e-05}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:16,472] Trial 12 finished with value: 0.7516453706391525 and parameters: {'num_leaves': 65, 'max_depth': 125, 'learning_rate': 0.5349165159840363, 'n_estimators': 834, 'min_child_samples': 5, 'min_child_weight': 7.33402298828697e-05, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.6466407866038397, 'reg_lambda': 1.17514687141044e-05}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:16,804] Trial 13 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 302, 'max_depth': 57, 'learning_rate': 0.006326893509969213, 'n_estimators': 442, 'min_child_samples': 100, 'min_child_weight': 1.3021051078426148e-05, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.8193949338904192, 'reg_lambda': 1.3525674647382305e-05}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:17,109] Trial 14 finished with value: 0.804646390820453 and parameters: {'num_leaves': 299, 'max_depth': 54, 'learning_rate': 0.002268017182504798, 'n_estimators': 404, 'min_child_samples': 100, 'min_child_weight': 0.003354812353508065, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_alpha': 0.4484257166956645, 'reg_lambda': 0.0018888900727731521}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:17,357] Trial 15 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 127, 'max_depth': 37, 'learning_rate': 7.015471551196972e-05, 'n_estimators': 267, 'min_child_samples': 89, 'min_child_weight': 0.0005231123344055826, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.8085658533657452, 'reg_lambda': 0.005254860348317723}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:17,732] Trial 16 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 259, 'max_depth': 64, 'learning_rate': 3.0241179911354268e-05, 'n_estimators': 488, 'min_child_samples': 87, 'min_child_weight': 1.1456753383434822e-05, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.13916668596832657, 'reg_lambda': 4.0439902389214646e-05}. Best is trial 5 with value: 0.8200743962047155.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:17,989] Trial 17 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 164, 'max_depth': 24, 'learning_rate': 0.010355581076956442, 'n_estimators': 260, 'min_child_samples': 58, 'min_child_weight': 0.0011629219524938996, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 1.613856076428579, 'reg_lambda': 0.0003891061933497826}. Best is trial 17 with value: 0.8238939900895808.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:18,258] Trial 18 finished with value: 0.7117117117117117 and parameters: {'num_leaves': 102, 'max_depth': 24, 'learning_rate': 0.6903591624433664, 'n_estimators': 239, 'min_child_samples': 51, 'min_child_weight': 0.0013602201980194503, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.0029473145587151878, 'reg_lambda': 0.00035214638412085016}. Best is trial 17 with value: 0.8238939900895808.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:18,467] Trial 19 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 171, 'max_depth': 33, 'learning_rate': 0.00017156313893482825, 'n_estimators': 159, 'min_child_samples': 55, 'min_child_weight': 0.010553521223278406, 'subsample': 1.0, 'colsample_bytree': 0.6, 'reg_alpha': 1.0559211351583135e-05, 'reg_lambda': 0.004080862204995615}. Best is trial 17 with value: 0.8238939900895808.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:18,912] Trial 20 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 65, 'max_depth': 18, 'learning_rate': 0.005988953220842548, 'n_estimators': 595, 'min_child_samples': 64, 'min_child_weight': 0.0008427296424562672, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 2.511973969914995, 'reg_lambda': 0.047760059150784566}. Best is trial 20 with value: 0.8241886674319105.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:19,270] Trial 21 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 10, 'max_depth': 18, 'learning_rate': 0.013086538038249418, 'n_estimators': 564, 'min_child_samples': 45, 'min_child_weight': 0.0008855326220728502, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 2.447567922425244, 'reg_lambda': 0.04199146798729767}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:19,570] Trial 22 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 56, 'max_depth': 19, 'learning_rate': 0.08029541816888866, 'n_estimators': 579, 'min_child_samples': 43, 'min_child_weight': 0.0008561463195987716, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 2.096255817477791, 'reg_lambda': 0.09747330086306083}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:19,921] Trial 23 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 7, 'max_depth': 5, 'learning_rate': 0.011598291205677848, 'n_estimators': 624, 'min_child_samples': 63, 'min_child_weight': 0.00021831364138250807, 'subsample': 1.0, 'colsample_bytree': 0.7, 'reg_alpha': 0.13161557024511472, 'reg_lambda': 0.7701746015256303}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:20,141] Trial 24 finished with value: 0.7837837837837838 and parameters: {'num_leaves': 64, 'max_depth': 18, 'learning_rate': 0.1591801206462325, 'n_estimators': 342, 'min_child_samples': 44, 'min_child_weight': 0.00010234159489695706, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1.678284277273526, 'reg_lambda': 0.01512083848856751}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:20,586] Trial 25 finished with value: 0.8252406132840915 and parameters: {'num_leaves': 40, 'max_depth': 39, 'learning_rate': 0.001104147396521503, 'n_estimators': 516, 'min_child_samples': 65, 'min_child_weight': 0.0010202553250904444, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.2295119798682137, 'reg_lambda': 0.12925789886429423}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:21,019] Trial 26 finished with value: 0.748003003003003 and parameters: {'num_leaves': 35, 'max_depth': 39, 'learning_rate': 0.0005646870565999835, 'n_estimators': 532, 'min_child_samples': 67, 'min_child_weight': 0.012438936894094857, 'subsample': 1.0, 'colsample_bytree': 0.6, 'reg_alpha': 0.34256904782153896, 'reg_lambda': 0.04843629115645728}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:21,751] Trial 27 finished with value: 0.828254477109439 and parameters: {'num_leaves': 91, 'max_depth': 42, 'learning_rate': 0.0018407675268264157, 'n_estimators': 853, 'min_child_samples': 45, 'min_child_weight': 0.0002582519781146834, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.04566659308810037, 'reg_lambda': 0.7003859743130558}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:22,493] Trial 28 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 98, 'max_depth': 41, 'learning_rate': 2.1514877781708245e-05, 'n_estimators': 871, 'min_child_samples': 41, 'min_child_weight': 0.00018634050503630906, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.0381952987598368, 'reg_lambda': 0.9214053720203106}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:23,333] Trial 29 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 94, 'max_depth': 73, 'learning_rate': 0.00013876344616806544, 'n_estimators': 896, 'min_child_samples': 34, 'min_child_weight': 4.6777832658475416e-05, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.00538140455216588, 'reg_lambda': 0.25479629598141085}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:23,575] Trial 30 finished with value: 0.8098436842623904 and parameters: {'num_leaves': 7, 'max_depth': 67, 'learning_rate': 0.0015358441950736855, 'n_estimators': 341, 'min_child_samples': 50, 'min_child_weight': 0.000378270072297158, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.20602686647128216, 'reg_lambda': 0.01820853933523936}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:24,087] Trial 31 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 44, 'max_depth': 12, 'learning_rate': 0.003644542531632472, 'n_estimators': 639, 'min_child_samples': 73, 'min_child_weight': 0.0007277014662210268, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.037872597853901346, 'reg_lambda': 0.24049813897901687}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:24,334] Trial 32 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 71, 'max_depth': 2, 'learning_rate': 0.000322139839382497, 'n_estimators': 483, 'min_child_samples': 62, 'min_child_weight': 0.001773089122824281, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.059422036161487, 'reg_lambda': 1.1813549319156849}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:24,895] Trial 33 finished with value: 0.7971407701137431 and parameters: {'num_leaves': 29, 'max_depth': 29, 'learning_rate': 0.024421346639479348, 'n_estimators': 727, 'min_child_samples': 73, 'min_child_weight': 0.0003378470189983415, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.012538617768651705, 'reg_lambda': 0.02928764006910737}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:25,359] Trial 34 finished with value: 0.8074315620902139 and parameters: {'num_leaves': 131, 'max_depth': 44, 'learning_rate': 0.0013895517043788228, 'n_estimators': 605, 'min_child_samples': 45, 'min_child_weight': 9.656712323463015e-05, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 4.059187564926405, 'reg_lambda': 0.11139206547657662}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:25,999] Trial 35 finished with value: 0.7397106928356928 and parameters: {'num_leaves': 212, 'max_depth': 18, 'learning_rate': 0.16876030678775586, 'n_estimators': 788, 'min_child_samples': 59, 'min_child_weight': 0.008626643021129012, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.08536604667198762, 'reg_lambda': 2.1538296986360037}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:26,657] Trial 36 finished with value: 0.8075892088630943 and parameters: {'num_leaves': 90, 'max_depth': 13, 'learning_rate': 0.0006019982090382512, 'n_estimators': 663, 'min_child_samples': 35, 'min_child_weight': 0.0025592476261313652, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.39391588124078697, 'reg_lambda': 0.4606657190085634}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:27,046] Trial 37 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 34, 'max_depth': 30, 'learning_rate': 0.003828397323248128, 'n_estimators': 497, 'min_child_samples': 79, 'min_child_weight': 0.0860445214390039, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.23656948472235984, 'reg_lambda': 0.12123946417393945}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:27,765] Trial 38 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 150, 'max_depth': 22, 'learning_rate': 0.017431247164926236, 'n_estimators': 985, 'min_child_samples': 68, 'min_child_weight': 0.0007111971099804429, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 1.1424366098656527, 'reg_lambda': 0.006923816733211848}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:28,329] Trial 39 finished with value: 0.7663870252349325 and parameters: {'num_leaves': 469, 'max_depth': 60, 'learning_rate': 0.058467619135292345, 'n_estimators': 566, 'min_child_samples': 48, 'min_child_weight': 0.005083181533692737, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.0007274291851806946, 'reg_lambda': 0.043464262304138544}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:28,818] Trial 40 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 114, 'max_depth': 46, 'learning_rate': 1.7018019702869575e-06, 'n_estimators': 684, 'min_child_samples': 39, 'min_child_weight': 0.018401291332695083, 'subsample': 1.0, 'colsample_bytree': 0.7, 'reg_alpha': 3.960343887343807, 'reg_lambda': 3.979157018422533}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:29,423] Trial 41 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 47, 'max_depth': 11, 'learning_rate': 0.0027420165334388308, 'n_estimators': 647, 'min_child_samples': 73, 'min_child_weight': 0.0005984363731827709, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.030944169221303136, 'reg_lambda': 0.18713581937563242}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:29,946] Trial 42 finished with value: 0.828254477109439 and parameters: {'num_leaves': 74, 'max_depth': 10, 'learning_rate': 0.004977912693684162, 'n_estimators': 432, 'min_child_samples': 70, 'min_child_weight': 0.00018668689982626543, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.011564910629066042, 'reg_lambda': 0.14051849187021875}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:30,410] Trial 43 finished with value: 0.626716765637427 and parameters: {'num_leaves': 83, 'max_depth': 9, 'learning_rate': 0.0003780804641273786, 'n_estimators': 413, 'min_child_samples': 82, 'min_child_weight': 0.000145881714993023, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.012515758644364498, 'reg_lambda': 0.15908531683836644}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:30,721] Trial 44 finished with value: 0.8262677006692055 and parameters: {'num_leaves': 29, 'max_depth': 7, 'learning_rate': 0.002236469768801961, 'n_estimators': 332, 'min_child_samples': 70, 'min_child_weight': 0.0003185589532102082, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.02173893654710843, 'reg_lambda': 0.3510940365303852}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:30,910] Trial 45 finished with value: 0.6756903842618128 and parameters: {'num_leaves': 2, 'max_depth': 8, 'learning_rate': 0.00233128425996367, 'n_estimators': 331, 'min_child_samples': 73, 'min_child_weight': 0.00032051632783439843, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0011144752746048328, 'reg_lambda': 1.916554136032426}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:31,259] Trial 46 finished with value: 0.8250604918234916 and parameters: {'num_leaves': 28, 'max_depth': 2, 'learning_rate': 0.008493651085498896, 'n_estimators': 923, 'min_child_samples': 91, 'min_child_weight': 4.022673518828196e-05, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.024866273650738444, 'reg_lambda': 0.36424174015537447}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:31,544] Trial 47 finished with value: 0.8014869384434602 and parameters: {'num_leaves': 112, 'max_depth': 12, 'learning_rate': 0.038280951031117956, 'n_estimators': 179, 'min_child_samples': 18, 'min_child_weight': 2.407226834969101e-05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.005446068720026953, 'reg_lambda': 5.55749899755429}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:31,973] Trial 48 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 51, 'max_depth': 92, 'learning_rate': 2.046241628968069e-08, 'n_estimators': 451, 'min_child_samples': 57, 'min_child_weight': 7.022077986185623e-05, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 0.007189810982352746, 'reg_lambda': 0.026692002548681013}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:32,279] Trial 49 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 147, 'max_depth': 14, 'learning_rate': 5.166090972941207e-05, 'n_estimators': 376, 'min_child_samples': 94, 'min_child_weight': 0.00014119391617524105, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.018377650823034317, 'reg_lambda': 0.5412356268550088}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:32,819] Trial 50 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 188, 'max_depth': 25, 'learning_rate': 7.33033442314703e-08, 'n_estimators': 808, 'min_child_samples': 83, 'min_child_weight': 0.0005380404825246979, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.002377518455688189, 'reg_lambda': 1.811813262314281}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:33,204] Trial 51 finished with value: 0.7990355797704357 and parameters: {'num_leaves': 23, 'max_depth': 34, 'learning_rate': 0.0010587899643801407, 'n_estimators': 451, 'min_child_samples': 70, 'min_child_weight': 0.0002462258914350766, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.04247407791157304, 'reg_lambda': 0.19991112909537703}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:33,705] Trial 52 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 78, 'max_depth': 27, 'learning_rate': 0.0025352210040715016, 'n_estimators': 520, 'min_child_samples': 60, 'min_child_weight': 0.0031529753683262715, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.07850270570635001, 'reg_lambda': 0.1101943745302473}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:34,259] Trial 53 finished with value: 0.8074315620902139 and parameters: {'num_leaves': 46, 'max_depth': 6, 'learning_rate': 0.0009239526976200714, 'n_estimators': 744, 'min_child_samples': 76, 'min_child_weight': 0.0014047351996993545, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.018988130706789428, 'reg_lambda': 0.5723864581637859}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:34,566] Trial 54 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 21, 'max_depth': 50, 'learning_rate': 0.00024103304948464854, 'n_estimators': 304, 'min_child_samples': 53, 'min_child_weight': 0.000474074646839376, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.13079990239619563, 'reg_lambda': 0.07314862447049106}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:35,239] Trial 55 finished with value: 0.788723176958471 and parameters: {'num_leaves': 52, 'max_depth': 34, 'learning_rate': 0.010513551678598273, 'n_estimators': 551, 'min_child_samples': 30, 'min_child_weight': 0.0011626810787679267, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.05389302659698641, 'reg_lambda': 0.01060468274621771}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:35,576] Trial 56 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 71, 'max_depth': 16, 'learning_rate': 0.004730584773023785, 'n_estimators': 378, 'min_child_samples': 77, 'min_child_weight': 0.0018350038611083667, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.007759787424921136, 'reg_lambda': 0.2995696447984261}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:35,917] Trial 57 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 122, 'max_depth': 15, 'learning_rate': 0.018446540529680238, 'n_estimators': 382, 'min_child_samples': 77, 'min_child_weight': 0.0036820753473127037, 'subsample': 1.0, 'colsample_bytree': 0.7, 'reg_alpha': 0.002072701601893134, 'reg_lambda': 0.3468526926478793}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:36,158] Trial 58 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 74, 'max_depth': 22, 'learning_rate': 0.21886038727357188, 'n_estimators': 210, 'min_child_samples': 82, 'min_child_weight': 0.002141599577716375, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.008291825246736223, 'reg_lambda': 1.2020949609602565}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:36,475] Trial 59 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 275, 'max_depth': 7, 'learning_rate': 0.005776578624815253, 'n_estimators': 281, 'min_child_samples': 47, 'min_child_weight': 0.0002647538945582484, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.00033408225744244006, 'reg_lambda': 0.07341131005428858}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:36,866] Trial 60 finished with value: 0.7750929952558943 and parameters: {'num_leaves': 368, 'max_depth': 18, 'learning_rate': 0.056293756992656124, 'n_estimators': 423, 'min_child_samples': 69, 'min_child_weight': 0.00060035538134182, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031684010128266867, 'reg_lambda': 0.0019444802827201214}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:37,125] Trial 61 finished with value: 0.7769684578195216 and parameters: {'num_leaves': 55, 'max_depth': 2, 'learning_rate': 0.0022444351184317877, 'n_estimators': 460, 'min_child_samples': 65, 'min_child_weight': 0.0009872055806477837, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.025148286488672355, 'reg_lambda': 0.19990258201510017}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:37,268] Trial 62 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 21, 'max_depth': 10, 'learning_rate': 0.004503667272977588, 'n_estimators': 12, 'min_child_samples': 76, 'min_child_weight': 0.00016270717356298492, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.01132110345714254, 'reg_lambda': 0.027970179776850634}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:37,811] Trial 63 finished with value: 0.82204077140786 and parameters: {'num_leaves': 101, 'max_depth': 22, 'learning_rate': 0.0007291557741258981, 'n_estimators': 507, 'min_child_samples': 39, 'min_child_weight': 0.0004944986021049857, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.004277960727015514, 'reg_lambda': 0.1715699487491178}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:38,159] Trial 64 finished with value: 0.8014869384434602 and parameters: {'num_leaves': 40, 'max_depth': 54, 'learning_rate': 0.013878454711817291, 'n_estimators': 369, 'min_child_samples': 66, 'min_child_weight': 0.0018362621664242912, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 0.18300570160454277, 'reg_lambda': 0.6622610682537062}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:38,495] Trial 65 finished with value: 0.8154468935434523 and parameters: {'num_leaves': 82, 'max_depth': 41, 'learning_rate': 0.0016138673324304694, 'n_estimators': 321, 'min_child_samples': 55, 'min_child_weight': 0.007034558843571503, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.027184204478356035, 'reg_lambda': 0.3995944812463634}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:38,798] Trial 66 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 2, 'max_depth': 15, 'learning_rate': 0.00789130809511498, 'n_estimators': 842, 'min_child_samples': 71, 'min_child_weight': 8.945403946188557e-05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 6.9341910477959425, 'reg_lambda': 0.06994634147373766}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:39,299] Trial 67 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 222, 'max_depth': 120, 'learning_rate': 9.72368211946665e-05, 'n_estimators': 644, 'min_child_samples': 86, 'min_child_weight': 0.0003239479146434008, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.015393014664419854, 'reg_lambda': 0.8763094802992288}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:39,512] Trial 68 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 66, 'max_depth': 29, 'learning_rate': 0.0004445199713446769, 'n_estimators': 123, 'min_child_samples': 63, 'min_child_weight': 0.0014399453855034657, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.5917985862738868, 'reg_lambda': 0.2747700858855561}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:39,976] Trial 69 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 18, 'max_depth': 35, 'learning_rate': 0.030846324213491528, 'n_estimators': 482, 'min_child_samples': 51, 'min_child_weight': 6.204792414863945e-05, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.07588705287145148, 'reg_lambda': 0.044076549928669884}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:40,394] Trial 70 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 37, 'max_depth': 5, 'learning_rate': 0.00019053369059502848, 'n_estimators': 580, 'min_child_samples': 79, 'min_child_weight': 0.5730261463294302, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.008396161778814606, 'reg_lambda': 0.15867803766987384}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:40,697] Trial 71 finished with value: 0.820490132990133 and parameters: {'num_leaves': 31, 'max_depth': 2, 'learning_rate': 0.007275250429305667, 'n_estimators': 707, 'min_child_samples': 97, 'min_child_weight': 3.4456966350336736e-05, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.03349731663005863, 'reg_lambda': 0.29395299327104496}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:41,321] Trial 72 finished with value: 0.8202977117191788 and parameters: {'num_leaves': 61, 'max_depth': 11, 'learning_rate': 0.003166938767048961, 'n_estimators': 911, 'min_child_samples': 90, 'min_child_weight': 0.0008127050833050688, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.05274848922733603, 'reg_lambda': 1.2086765116596414}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:41,944] Trial 73 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 18, 'max_depth': 16, 'learning_rate': 0.00478503545113368, 'n_estimators': 902, 'min_child_samples': 91, 'min_child_weight': 0.00011030288339799454, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.02415126856026, 'reg_lambda': 0.3734887427274615}. Best is trial 21 with value: 0.8329250675208845.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:42,532] Trial 74 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 105, 'max_depth': 5, 'learning_rate': 0.010876354710305465, 'n_estimators': 981, 'min_child_samples': 74, 'min_child_weight': 1.5385065627941032e-05, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0017109002486713843, 'reg_lambda': 0.10368538846121614}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:43,228] Trial 75 finished with value: 0.814519979719652 and parameters: {'num_leaves': 102, 'max_depth': 21, 'learning_rate': 0.0012843384899709099, 'n_estimators': 944, 'min_child_samples': 75, 'min_child_weight': 1.741372882001118e-05, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0011986802129327957, 'reg_lambda': 0.020259239607806928}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:43,966] Trial 76 finished with value: 0.828254477109439 and parameters: {'num_leaves': 87, 'max_depth': 8, 'learning_rate': 0.001890241628429333, 'n_estimators': 999, 'min_child_samples': 71, 'min_child_weight': 0.00021392768828515808, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0014819858638123904, 'reg_lambda': 0.09786082892522342}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:44,586] Trial 77 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 136, 'max_depth': 6, 'learning_rate': 0.021087453288867228, 'n_estimators': 996, 'min_child_samples': 80, 'min_child_weight': 0.00038665829772732897, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0014074732168555765, 'reg_lambda': 0.07594616372170795}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:45,312] Trial 78 finished with value: 0.7304465675787681 and parameters: {'num_leaves': 155, 'max_depth': 12, 'learning_rate': 0.10306791623156267, 'n_estimators': 965, 'min_child_samples': 73, 'min_child_weight': 0.00021343804657897485, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0003695931177432074, 'reg_lambda': 0.04373739745061988}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:45,986] Trial 79 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 113, 'max_depth': 9, 'learning_rate': 0.013216773370565316, 'n_estimators': 877, 'min_child_samples': 84, 'min_child_weight': 2.705086460822768e-05, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 0.00023333556949349315, 'reg_lambda': 0.09406398673176442}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:46,748] Trial 80 finished with value: 0.7254253358625067 and parameters: {'num_leaves': 87, 'max_depth': 25, 'learning_rate': 0.3288617228241501, 'n_estimators': 944, 'min_child_samples': 61, 'min_child_weight': 5.769973846822932e-05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 4.327555981037621e-05, 'reg_lambda': 2.9570854371532778}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:47,487] Trial 81 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 68, 'max_depth': 17, 'learning_rate': 0.0018839704005999876, 'n_estimators': 849, 'min_child_samples': 68, 'min_child_weight': 0.0006672406782763922, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0038446063623678597, 'reg_lambda': 0.1329151100924953}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:47,819] Trial 82 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 47, 'max_depth': 5, 'learning_rate': 0.0037607191137351047, 'n_estimators': 396, 'min_child_samples': 71, 'min_child_weight': 0.0002675619252629964, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0006225083498750496, 'reg_lambda': 0.2199116728336082}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:48,168] Trial 83 finished with value: 0.8188643188643188 and parameters: {'num_leaves': 92, 'max_depth': 7, 'learning_rate': 0.003064255149164486, 'n_estimators': 356, 'min_child_samples': 70, 'min_child_weight': 0.00012373720299813524, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0005868469708663387, 'reg_lambda': 0.22503010608377794}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:48,534] Trial 84 finished with value: 0.7119190428013957 and parameters: {'num_leaves': 58, 'max_depth': 5, 'learning_rate': 0.0006738049473610198, 'n_estimators': 433, 'min_child_samples': 72, 'min_child_weight': 0.00019131335222194733, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.001733744509311967, 'reg_lambda': 0.5089954620591444}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:48,846] Trial 85 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 127, 'max_depth': 20, 'learning_rate': 0.047021900656938634, 'n_estimators': 291, 'min_child_samples': 75, 'min_child_weight': 0.0002745547603015884, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0001315111387493344, 'reg_lambda': 0.0346430370496173}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:49,217] Trial 86 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 74, 'max_depth': 10, 'learning_rate': 0.009861307552384487, 'n_estimators': 395, 'min_child_samples': 67, 'min_child_weight': 0.0003950998098043873, 'subsample': 0.6, 'colsample_bytree': 1.0, 'reg_alpha': 0.0007728325679642712, 'reg_lambda': 0.056937413094512605}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:49,543] Trial 87 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 42, 'max_depth': 14, 'learning_rate': 0.006497215916357316, 'n_estimators': 245, 'min_child_samples': 41, 'min_child_weight': 8.363522061005481e-05, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.005282431592477183, 'reg_lambda': 0.7368033561539078}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:50,403] Trial 88 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 110, 'max_depth': 9, 'learning_rate': 0.003505096368445454, 'n_estimators': 979, 'min_child_samples': 48, 'min_child_weight': 1.0223579351580899e-05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009257443155747507, 'reg_lambda': 0.09635710116446643}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:50,845] Trial 89 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 13, 'max_depth': 4, 'learning_rate': 0.023921852476261374, 'n_estimators': 798, 'min_child_samples': 57, 'min_child_weight': 0.0004755431405118521, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.00019224845375358265, 'reg_lambda': 0.1613948905279438}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:51,396] Trial 90 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 49, 'max_depth': 77, 'learning_rate': 0.0017559143588112532, 'n_estimators': 766, 'min_child_samples': 80, 'min_child_weight': 0.0001640933479820589, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.0005867871204084824, 'reg_lambda': 0.26202238001139905}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:51,946] Trial 91 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 45, 'max_depth': 79, 'learning_rate': 0.001883701291014479, 'n_estimators': 757, 'min_child_samples': 79, 'min_child_weight': 0.00018134434455267524, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.0005985983093060458, 'reg_lambda': 0.2963396525756545}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:52,545] Trial 92 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 84, 'max_depth': 63, 'learning_rate': 0.004996532236318575, 'n_estimators': 819, 'min_child_samples': 81, 'min_child_weight': 0.00026694717252449053, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0.0005486843523792777, 'reg_lambda': 0.4902988442876534}. Best is trial 74 with value: 0.8332046332046333.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:53,098] Trial 93 finished with value: 0.8339022041891073 and parameters: {'num_leaves': 53, 'max_depth': 94, 'learning_rate': 0.0008876058967754117, 'n_estimators': 769, 'min_child_samples': 85, 'min_child_weight': 0.0009077756892139396, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.01658548074686549, 'reg_lambda': 0.21934351330122082}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:53,670] Trial 94 finished with value: 0.8209185409185409 and parameters: {'num_leaves': 59, 'max_depth': 101, 'learning_rate': 0.0010471380182137215, 'n_estimators': 776, 'min_child_samples': 78, 'min_child_weight': 0.0009820267523243744, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.0026516258998339716, 'reg_lambda': 0.09789429968202645}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:54,167] Trial 95 finished with value: 0.4944594594594594 and parameters: {'num_leaves': 73, 'max_depth': 90, 'learning_rate': 0.00025307084745083606, 'n_estimators': 686, 'min_child_samples': 87, 'min_child_weight': 0.0026716717192984568, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.001668572606030951, 'reg_lambda': 0.20153615261883848}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:54,640] Trial 96 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 99, 'max_depth': 70, 'learning_rate': 1.542493248453845e-05, 'n_estimators': 613, 'min_child_samples': 85, 'min_child_weight': 0.001571532290571091, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.013307685479517306, 'reg_lambda': 0.14253482529769967}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:55,164] Trial 97 finished with value: 0.8015928153859189 and parameters: {'num_leaves': 52, 'max_depth': 83, 'learning_rate': 0.0005450334243762302, 'n_estimators': 712, 'min_child_samples': 74, 'min_child_weight': 0.0006305179262736009, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.00044423585130435575, 'reg_lambda': 1.0132873503286048}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:55,595] Trial 98 finished with value: 0.8234333624404547 and parameters: {'num_leaves': 10, 'max_depth': 100, 'learning_rate': 0.0007878874283246231, 'n_estimators': 659, 'min_child_samples': 77, 'min_child_weight': 0.0011367162091519161, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0.007380161803909218, 'reg_lambda': 0.06269304657227105}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:56,185] Trial 99 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 78, 'max_depth': 114, 'learning_rate': 0.01702244199292118, 'n_estimators': 872, 'min_child_samples': 93, 'min_child_weight': 0.00014225403984111185, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.003592734092322049, 'reg_lambda': 0.21451306612481022}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:56,869] Trial 100 finished with value: 0.8141433939473363 and parameters: {'num_leaves': 429, 'max_depth': 93, 'learning_rate': 0.0013753812511177502, 'n_estimators': 938, 'min_child_samples': 87, 'min_child_weight': 5.0247520095017965e-05, 'subsample': 1.0, 'colsample_bytree': 0.6, 'reg_alpha': 0.005633988580589715, 'reg_lambda': 0.019821626244685593}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:57,267] Trial 101 finished with value: 0.8180626352268143 and parameters: {'num_leaves': 33, 'max_depth': 13, 'learning_rate': 0.0023709585361384104, 'n_estimators': 401, 'min_child_samples': 70, 'min_child_weight': 0.0002980712632967154, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.02003246700799084, 'reg_lambda': 0.33576628270511805}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:58,017] Trial 102 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 27, 'max_depth': 73, 'learning_rate': 0.004048810399512412, 'n_estimators': 739, 'min_child_samples': 36, 'min_child_weight': 0.0004590370424672385, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.01090284631837347, 'reg_lambda': 0.643293476849902}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:58,425] Trial 103 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 48, 'max_depth': 85, 'learning_rate': 0.008638169384812157, 'n_estimators': 345, 'min_child_samples': 45, 'min_child_weight': 0.004217648173443128, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 7.769775612417385e-05, 'reg_lambda': 0.4418073713856924}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:59,009] Trial 104 finished with value: 0.6877638127638127 and parameters: {'num_leaves': 62, 'max_depth': 109, 'learning_rate': 0.0003250567957246457, 'n_estimators': 775, 'min_child_samples': 72, 'min_child_weight': 0.00022208533283809212, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0.016082686778385966, 'reg_lambda': 1.5870725883863102}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:59,377] Trial 105 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 89, 'max_depth': 4, 'learning_rate': 0.0032049856562737992, 'n_estimators': 543, 'min_child_samples': 83, 'min_child_weight': 0.000817507655066953, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.032649101795420986, 'reg_lambda': 0.115713035362431}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:32:59,741] Trial 106 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 41, 'max_depth': 11, 'learning_rate': 0.005484277275889559, 'n_estimators': 313, 'min_child_samples': 65, 'min_child_weight': 0.00036581190418279603, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009254350762278285, 'reg_lambda': 0.28095028741942607}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:00,075] Trial 107 finished with value: 0.6836194302410519 and parameters: {'num_leaves': 2, 'max_depth': 15, 'learning_rate': 0.0020276331336012547, 'n_estimators': 828, 'min_child_samples': 77, 'min_child_weight': 1.5084231254044376e-05, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.00023752324703265964, 'reg_lambda': 0.0818760135938054}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:00,444] Trial 108 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 107, 'max_depth': 8, 'learning_rate': 0.014414294156262738, 'n_estimators': 366, 'min_child_samples': 81, 'min_child_weight': 0.00012043802457355288, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020973065948596105, 'reg_lambda': 0.23542871067525228}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:00,878] Trial 109 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 124, 'max_depth': 20, 'learning_rate': 0.010935892098902803, 'n_estimators': 458, 'min_child_samples': 81, 'min_child_weight': 0.00011362051265520343, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019379707654115107, 'reg_lambda': 0.1736759587799509}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:01,580] Trial 110 finished with value: 0.7660967150661299 and parameters: {'num_leaves': 118, 'max_depth': 23, 'learning_rate': 0.03103253052958244, 'n_estimators': 473, 'min_child_samples': 42, 'min_child_weight': 0.00011033199982240534, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023509430069707286, 'reg_lambda': 0.17198683010717927}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:01,988] Trial 111 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 136, 'max_depth': 19, 'learning_rate': 0.01903667666263047, 'n_estimators': 422, 'min_child_samples': 81, 'min_child_weight': 7.977781783667598e-05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012706812707795688, 'reg_lambda': 0.11796972885634005}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:02,360] Trial 112 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 105, 'max_depth': 8, 'learning_rate': 0.011572829867657761, 'n_estimators': 365, 'min_child_samples': 75, 'min_child_weight': 0.0001499503639276578, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018444334413638592, 'reg_lambda': 0.23618153257107904}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:02,734] Trial 113 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 106, 'max_depth': 8, 'learning_rate': 0.011349896410649325, 'n_estimators': 389, 'min_child_samples': 76, 'min_child_weight': 0.0005558533579621023, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018088945253530578, 'reg_lambda': 0.05496652687808033}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:03,105] Trial 114 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 107, 'max_depth': 13, 'learning_rate': 0.010305557488697199, 'n_estimators': 362, 'min_child_samples': 74, 'min_child_weight': 0.0005857925322370855, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018096809263235907, 'reg_lambda': 0.03445045519584223}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:03,476] Trial 115 finished with value: 0.788723176958471 and parameters: {'num_leaves': 175, 'max_depth': 26, 'learning_rate': 0.08238304874018494, 'n_estimators': 390, 'min_child_samples': 84, 'min_child_weight': 0.00012789166899660303, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0026358724529692073, 'reg_lambda': 0.05952888788338083}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:03,870] Trial 116 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 122, 'max_depth': 31, 'learning_rate': 0.013657107383754813, 'n_estimators': 412, 'min_child_samples': 76, 'min_child_weight': 0.002288741146523886, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.009252423684598414, 'reg_lambda': 0.012072293112301756}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:04,148] Trial 117 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 142, 'max_depth': 2, 'learning_rate': 0.03795944413044871, 'n_estimators': 442, 'min_child_samples': 78, 'min_child_weight': 0.001782324520440149, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00457982937602558, 'reg_lambda': 0.21718971138838367}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:04,515] Trial 118 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 159, 'max_depth': 16, 'learning_rate': 0.007529540880821134, 'n_estimators': 377, 'min_child_samples': 88, 'min_child_weight': 0.0009389024959235155, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.006301478387739966, 'reg_lambda': 0.14361070696019312}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:04,940] Trial 119 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 197, 'max_depth': 9, 'learning_rate': 0.011960567028937226, 'n_estimators': 469, 'min_child_samples': 82, 'min_child_weight': 0.0012896108256571885, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0032869296322527155, 'reg_lambda': 0.00015225350266782987}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:05,421] Trial 120 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 100, 'max_depth': 18, 'learning_rate': 0.006249573636564608, 'n_estimators': 529, 'min_child_samples': 75, 'min_child_weight': 0.0007547056427920039, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009521333564584881, 'reg_lambda': 0.3850466055076184}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:05,824] Trial 121 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 90, 'max_depth': 7, 'learning_rate': 0.024388215273377548, 'n_estimators': 503, 'min_child_samples': 72, 'min_child_weight': 0.00019330158843074177, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014755665247931985, 'reg_lambda': 0.04985329788977236}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:06,200] Trial 122 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 79, 'max_depth': 5, 'learning_rate': 0.004265413604769862, 'n_estimators': 443, 'min_child_samples': 69, 'min_child_weight': 0.00024308008715000567, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021558885055399666, 'reg_lambda': 0.08515259884848882}. Best is trial 93 with value: 0.8339022041891073.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:06,556] Trial 123 finished with value: 0.8422205989773557 and parameters: {'num_leaves': 71, 'max_depth': 5, 'learning_rate': 0.016029826212628447, 'n_estimators': 443, 'min_child_samples': 68, 'min_child_weight': 0.0004008362225913478, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020797557378745483, 'reg_lambda': 0.157972656991286}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:06,918] Trial 124 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 109, 'max_depth': 5, 'learning_rate': 0.014515279277317938, 'n_estimators': 453, 'min_child_samples': 69, 'min_child_weight': 0.00042402923905115667, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021265984537328546, 'reg_lambda': 0.18124351396824062}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:07,291] Trial 125 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 128, 'max_depth': 5, 'learning_rate': 0.015650097188395076, 'n_estimators': 455, 'min_child_samples': 67, 'min_child_weight': 0.0004546887675892379, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.002010977198633828, 'reg_lambda': 0.1884266655103098}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:07,612] Trial 126 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 110, 'max_depth': 4, 'learning_rate': 0.054341465415828315, 'n_estimators': 409, 'min_child_samples': 63, 'min_child_weight': 0.0005504891474299751, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0029109579806261736, 'reg_lambda': 0.07834192584962964}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:08,028] Trial 127 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 80, 'max_depth': 11, 'learning_rate': 0.029793314471404007, 'n_estimators': 442, 'min_child_samples': 74, 'min_child_weight': 0.00035635547508163504, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010937915395712343, 'reg_lambda': 0.12286008813671517}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:08,373] Trial 128 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 70, 'max_depth': 3, 'learning_rate': 0.11206721764426471, 'n_estimators': 573, 'min_child_samples': 68, 'min_child_weight': 0.0007019740260996909, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0040578348248760075, 'reg_lambda': 0.2521182711798563}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:08,786] Trial 129 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 101, 'max_depth': 7, 'learning_rate': 0.008918909126697419, 'n_estimators': 491, 'min_child_samples': 79, 'min_child_weight': 0.00024643268633659676, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007441158297945847, 'reg_lambda': 0.02424166994823193}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:09,138] Trial 130 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 148, 'max_depth': 13, 'learning_rate': 6.295103590344593e-07, 'n_estimators': 353, 'min_child_samples': 85, 'min_child_weight': 2.9793450655152543e-05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.002003795426028023, 'reg_lambda': 0.008432435460396999}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:09,540] Trial 131 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 100, 'max_depth': 7, 'learning_rate': 0.010130747708105485, 'n_estimators': 473, 'min_child_samples': 78, 'min_child_weight': 0.0002812891614658262, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012449619364272595, 'reg_lambda': 0.03590408333800364}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:09,980] Trial 132 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 120, 'max_depth': 8, 'learning_rate': 0.015463001403720915, 'n_estimators': 488, 'min_child_samples': 81, 'min_child_weight': 0.0004202430752111649, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0006617902353399154, 'reg_lambda': 0.019580018343800173}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:10,244] Trial 133 finished with value: 0.8094043185704923 and parameters: {'num_leaves': 108, 'max_depth': 2, 'learning_rate': 0.007450893083750678, 'n_estimators': 390, 'min_child_samples': 69, 'min_child_weight': 0.0002455180948711648, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0022871087422690474, 'reg_lambda': 0.024121715194659256}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:10,625] Trial 134 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 95, 'max_depth': 6, 'learning_rate': 0.00401429790597684, 'n_estimators': 427, 'min_child_samples': 76, 'min_child_weight': 0.00015351283815682852, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.00040946583754559665, 'reg_lambda': 0.05871754705782404}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:11,117] Trial 135 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 134, 'max_depth': 11, 'learning_rate': 0.03726118773300336, 'n_estimators': 513, 'min_child_samples': 72, 'min_child_weight': 0.00010429228027424974, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007659854876846317, 'reg_lambda': 0.015024143040021835}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:11,533] Trial 136 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 75, 'max_depth': 9, 'learning_rate': 0.005256475618984959, 'n_estimators': 453, 'min_child_samples': 79, 'min_child_weight': 0.0005467780236236347, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008770300241218779, 'reg_lambda': 0.09355952578275636}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:11,899] Trial 137 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 64, 'max_depth': 15, 'learning_rate': 0.018732926000952433, 'n_estimators': 374, 'min_child_samples': 83, 'min_child_weight': 0.00034306033099345504, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015907070384508521, 'reg_lambda': 0.0387341334655894}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:12,303] Trial 138 finished with value: 0.8422205989773557 and parameters: {'num_leaves': 117, 'max_depth': 5, 'learning_rate': 0.011596671170253156, 'n_estimators': 555, 'min_child_samples': 74, 'min_child_weight': 0.0010913043023280972, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003131638080222269, 'reg_lambda': 0.17266911457974762}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:12,721] Trial 139 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 306, 'max_depth': 5, 'learning_rate': 0.011927208304928391, 'n_estimators': 561, 'min_child_samples': 65, 'min_child_weight': 0.0009946869781601655, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031900903796464827, 'reg_lambda': 1.853339898325754e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:13,286] Trial 140 finished with value: 0.7799872591586683 and parameters: {'num_leaves': 391, 'max_depth': 12, 'learning_rate': 0.023175181923064225, 'n_estimators': 595, 'min_child_samples': 66, 'min_child_weight': 0.0011638829675674571, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0041778813092877435, 'reg_lambda': 0.15995923263510495}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:13,666] Trial 141 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 325, 'max_depth': 4, 'learning_rate': 0.011796903115843721, 'n_estimators': 553, 'min_child_samples': 71, 'min_child_weight': 0.0009475586004227696, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002809600115401214, 'reg_lambda': 0.22598637450895745}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:14,009] Trial 142 finished with value: 0.818480303400469 and parameters: {'num_leaves': 303, 'max_depth': 6, 'learning_rate': 0.003135390162698655, 'n_estimators': 326, 'min_child_samples': 74, 'min_child_weight': 0.0015277738489632758, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006661816042481491, 'reg_lambda': 0.004116373581509406}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:14,314] Trial 143 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 328, 'max_depth': 2, 'learning_rate': 0.006095225357501493, 'n_estimators': 530, 'min_child_samples': 69, 'min_child_weight': 0.0028395632301714494, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0033259591318831167, 'reg_lambda': 0.0011012305066673911}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:14,615] Trial 144 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 348, 'max_depth': 2, 'learning_rate': 0.006949770994558299, 'n_estimators': 536, 'min_child_samples': 64, 'min_child_weight': 0.0025385583849969586, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004633826999496278, 'reg_lambda': 0.0008909444053079807}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:14,939] Trial 145 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 341, 'max_depth': 2, 'learning_rate': 0.007081212532681727, 'n_estimators': 588, 'min_child_samples': 64, 'min_child_weight': 0.003940920426600085, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005296806793594903, 'reg_lambda': 1.584532639479189e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:15,273] Trial 146 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 353, 'max_depth': 2, 'learning_rate': 0.006418951879346518, 'n_estimators': 631, 'min_child_samples': 61, 'min_child_weight': 0.0027721330028607034, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004717506914383706, 'reg_lambda': 1.6270427881989136e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:15,601] Trial 147 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 352, 'max_depth': 2, 'learning_rate': 0.006232913769244478, 'n_estimators': 622, 'min_child_samples': 61, 'min_child_weight': 0.005982601179374924, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004881264662473564, 'reg_lambda': 1.4436108230019841e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:15,970] Trial 148 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 349, 'max_depth': 3, 'learning_rate': 0.006398033674080055, 'n_estimators': 627, 'min_child_samples': 60, 'min_child_weight': 0.007149585129518125, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00929054559153702, 'reg_lambda': 1.936233527579904e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:16,292] Trial 149 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 353, 'max_depth': 2, 'learning_rate': 0.007211632821335577, 'n_estimators': 594, 'min_child_samples': 62, 'min_child_weight': 0.002859844520613535, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.005001994127667889, 'reg_lambda': 1.7989051409973463e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:16,665] Trial 150 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 351, 'max_depth': 3, 'learning_rate': 0.007148386987136939, 'n_estimators': 588, 'min_child_samples': 58, 'min_child_weight': 0.0029669298527007417, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005542961496096721, 'reg_lambda': 1.7350952500382592e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:17,011] Trial 151 finished with value: 0.7998688987494958 and parameters: {'num_leaves': 327, 'max_depth': 2, 'learning_rate': 0.0030922569033147874, 'n_estimators': 657, 'min_child_samples': 62, 'min_child_weight': 0.005408143056218637, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.003736466576977614, 'reg_lambda': 3.078485060496394e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:17,447] Trial 152 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 360, 'max_depth': 5, 'learning_rate': 0.005529082816949319, 'n_estimators': 558, 'min_child_samples': 55, 'min_child_weight': 0.004235564516130087, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004959969785394788, 'reg_lambda': 3.0030551795876544e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:17,786] Trial 153 finished with value: 0.8050772180423282 and parameters: {'num_leaves': 387, 'max_depth': 2, 'learning_rate': 0.004121071888877201, 'n_estimators': 615, 'min_child_samples': 64, 'min_child_weight': 0.01225906181945282, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007354426553794086, 'reg_lambda': 1.122381372669864e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:18,128] Trial 154 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 314, 'max_depth': 2, 'learning_rate': 0.007542353653186975, 'n_estimators': 634, 'min_child_samples': 61, 'min_child_weight': 0.002281758201687982, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00332748341237252, 'reg_lambda': 0.0007034060893865179}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:18,469] Trial 155 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 333, 'max_depth': 2, 'learning_rate': 0.021645748581790938, 'n_estimators': 634, 'min_child_samples': 61, 'min_child_weight': 0.0022076721031983187, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0033200645425220726, 'reg_lambda': 0.0012203424929044943}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:18,806] Trial 156 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 313, 'max_depth': 2, 'learning_rate': 0.022020746472926286, 'n_estimators': 634, 'min_child_samples': 61, 'min_child_weight': 0.00367039336289324, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003170773975308521, 'reg_lambda': 0.0005750161669341264}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:19,145] Trial 157 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 307, 'max_depth': 2, 'learning_rate': 0.04230815159507537, 'n_estimators': 607, 'min_child_samples': 61, 'min_child_weight': 0.0035225081333101374, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0032742719529983274, 'reg_lambda': 0.0009934559351553662}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:19,608] Trial 158 finished with value: 0.7847823906380608 and parameters: {'num_leaves': 319, 'max_depth': 5, 'learning_rate': 0.06378296410901162, 'n_estimators': 671, 'min_child_samples': 59, 'min_child_weight': 0.0024632998183862762, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004412149725061432, 'reg_lambda': 0.0006983967659797038}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:19,967] Trial 159 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 278, 'max_depth': 2, 'learning_rate': 0.015471963784887457, 'n_estimators': 635, 'min_child_samples': 63, 'min_child_weight': 0.005324402969035767, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0034356338353383085, 'reg_lambda': 0.001235697195330635}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:20,304] Trial 160 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 291, 'max_depth': 2, 'learning_rate': 0.02233284254382912, 'n_estimators': 592, 'min_child_samples': 64, 'min_child_weight': 0.005782768717201294, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031377034276374033, 'reg_lambda': 0.0019658525745550274}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:20,646] Trial 161 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 278, 'max_depth': 2, 'learning_rate': 0.02416156973829692, 'n_estimators': 632, 'min_child_samples': 65, 'min_child_weight': 0.005784048127885447, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005576479676579179, 'reg_lambda': 0.001769963184533955}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:21,076] Trial 162 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 275, 'max_depth': 5, 'learning_rate': 0.019431749278849747, 'n_estimators': 581, 'min_child_samples': 63, 'min_child_weight': 0.008861311047266835, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0034093570657717847, 'reg_lambda': 0.0007673088507434397}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:21,499] Trial 163 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 289, 'max_depth': 5, 'learning_rate': 0.016130719629576178, 'n_estimators': 581, 'min_child_samples': 63, 'min_child_weight': 0.019104229037212823, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028223014592762092, 'reg_lambda': 0.0013175151614656271}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:21,950] Trial 164 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 340, 'max_depth': 6, 'learning_rate': 0.008255565162362803, 'n_estimators': 528, 'min_child_samples': 56, 'min_child_weight': 0.010160474045079488, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004854758809796099, 'reg_lambda': 0.0027297978777070203}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:22,494] Trial 165 finished with value: 0.7799872591586683 and parameters: {'num_leaves': 239, 'max_depth': 10, 'learning_rate': 0.03777787655240687, 'n_estimators': 567, 'min_child_samples': 65, 'min_child_weight': 0.002968539503108351, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003887498475477401, 'reg_lambda': 0.0003124059670084787}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:22,898] Trial 166 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 262, 'max_depth': 4, 'learning_rate': 0.016868452510646184, 'n_estimators': 601, 'min_child_samples': 58, 'min_child_weight': 0.006959866008265146, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006870738495715073, 'reg_lambda': 6.079083557694632e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:23,345] Trial 167 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 292, 'max_depth': 7, 'learning_rate': 0.025833110742959006, 'n_estimators': 542, 'min_child_samples': 63, 'min_child_weight': 0.004729168558647574, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.009246417345692183, 'reg_lambda': 1.5320063366661767e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:23,687] Trial 168 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 335, 'max_depth': 2, 'learning_rate': 0.00864726992690961, 'n_estimators': 684, 'min_child_samples': 53, 'min_child_weight': 0.00199329214278441, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002785183119547939, 'reg_lambda': 2.192649161767761e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:24,287] Trial 169 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 372, 'max_depth': 9, 'learning_rate': 0.008478487337528163, 'n_estimators': 675, 'min_child_samples': 67, 'min_child_weight': 0.017884810345814232, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024821529398663137, 'reg_lambda': 2.5630686240753062e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:24,741] Trial 170 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 349, 'max_depth': 5, 'learning_rate': 0.013280026085700839, 'n_estimators': 596, 'min_child_samples': 52, 'min_child_weight': 0.0020179751765198807, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0049293290681287774, 'reg_lambda': 2.2962643957673425e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:25,090] Trial 171 finished with value: 0.8202977117191788 and parameters: {'num_leaves': 337, 'max_depth': 2, 'learning_rate': 0.01890973211253812, 'n_estimators': 649, 'min_child_samples': 60, 'min_child_weight': 0.0023928802665290853, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0029223199932537085, 'reg_lambda': 0.0009833606110805802}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:25,440] Trial 172 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 326, 'max_depth': 2, 'learning_rate': 0.00694943950145494, 'n_estimators': 702, 'min_child_samples': 64, 'min_child_weight': 0.008378788672623531, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003370434575172348, 'reg_lambda': 4.316926280073337e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:25,875] Trial 173 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 266, 'max_depth': 5, 'learning_rate': 0.0314574504334678, 'n_estimators': 613, 'min_child_samples': 62, 'min_child_weight': 0.003953925298004171, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003966219149462094, 'reg_lambda': 0.0004670562030457432}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:26,394] Trial 174 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 360, 'max_depth': 7, 'learning_rate': 0.010696054880555191, 'n_estimators': 572, 'min_child_samples': 66, 'min_child_weight': 0.006075366123293417, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006131929913799684, 'reg_lambda': 1.0470867511565236e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:26,805] Trial 175 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 284, 'max_depth': 4, 'learning_rate': 0.06099165342702457, 'n_estimators': 625, 'min_child_samples': 54, 'min_child_weight': 0.001926010409603324, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.012409556362296872, 'reg_lambda': 0.00027114114592361084}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:27,361] Trial 176 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 332, 'max_depth': 10, 'learning_rate': 0.0062837031949104635, 'n_estimators': 544, 'min_child_samples': 59, 'min_child_weight': 0.003110633443211641, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0037326387560967056, 'reg_lambda': 0.0010397147832852277}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:27,910] Trial 177 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 318, 'max_depth': 7, 'learning_rate': 0.014254893579688285, 'n_estimators': 648, 'min_child_samples': 57, 'min_child_weight': 0.0015426755873750885, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024263143005495897, 'reg_lambda': 0.0026947831495798915}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:28,239] Trial 178 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 298, 'max_depth': 2, 'learning_rate': 0.009033084029543675, 'n_estimators': 586, 'min_child_samples': 68, 'min_child_weight': 0.004672492759222139, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0075875596879237195, 'reg_lambda': 0.0014456953208629123}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:28,633] Trial 179 finished with value: 0.8246851893910718 and parameters: {'num_leaves': 375, 'max_depth': 5, 'learning_rate': 0.02852984467044827, 'n_estimators': 524, 'min_child_samples': 64, 'min_child_weight': 0.002463628308859302, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0027426733189089463, 'reg_lambda': 0.0007140759865397064}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:29,282] Trial 180 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 345, 'max_depth': 9, 'learning_rate': 0.020420720877158596, 'n_estimators': 721, 'min_child_samples': 61, 'min_child_weight': 0.007733815477457952, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013920228862956167, 'reg_lambda': 1.325282805697342e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:29,625] Trial 181 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 319, 'max_depth': 2, 'learning_rate': 0.02019089013506206, 'n_estimators': 635, 'min_child_samples': 61, 'min_child_weight': 0.0035974048083081203, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003517193303377315, 'reg_lambda': 0.0006659442764655644}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:30,029] Trial 182 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 307, 'max_depth': 4, 'learning_rate': 0.013395294913813204, 'n_estimators': 564, 'min_child_samples': 62, 'min_child_weight': 0.0031283480142884255, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004748755134680868, 'reg_lambda': 0.0007854584770641101}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:30,355] Trial 183 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 249, 'max_depth': 2, 'learning_rate': 0.009381846913749074, 'n_estimators': 618, 'min_child_samples': 66, 'min_child_weight': 0.005150102907984591, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0030892115995867354, 'reg_lambda': 0.00023174255283858077}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:30,949] Trial 184 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 336, 'max_depth': 7, 'learning_rate': 0.00534925181064963, 'n_estimators': 680, 'min_child_samples': 59, 'min_child_weight': 0.01043248940264622, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0056249468159500285, 'reg_lambda': 0.0004598482534401441}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:31,386] Trial 185 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 355, 'max_depth': 5, 'learning_rate': 0.04872521506622819, 'n_estimators': 642, 'min_child_samples': 64, 'min_child_weight': 0.0021252262466002238, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.0023211441353229926, 'reg_lambda': 2.2129844199183124e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:31,697] Trial 186 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 312, 'max_depth': 2, 'learning_rate': 0.01741167217547018, 'n_estimators': 594, 'min_child_samples': 68, 'min_child_weight': 0.0037555341244738813, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003796931705960784, 'reg_lambda': 0.001487288847733309}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:32,223] Trial 187 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 299, 'max_depth': 8, 'learning_rate': 0.026203758657860936, 'n_estimators': 550, 'min_child_samples': 60, 'min_child_weight': 0.0013107492557687952, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017126577701006293, 'reg_lambda': 1.686048719006683e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:32,912] Trial 188 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 380, 'max_depth': 11, 'learning_rate': 0.008996828242829286, 'n_estimators': 664, 'min_child_samples': 66, 'min_child_weight': 0.0025705189161464607, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006385421714818217, 'reg_lambda': 3.598309469756501e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:33,529] Trial 189 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 362, 'max_depth': 128, 'learning_rate': 0.004635705783886157, 'n_estimators': 609, 'min_child_samples': 62, 'min_child_weight': 0.00635657071022614, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.009282576124463343, 'reg_lambda': 0.0009195541105260807}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:33,970] Trial 190 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 342, 'max_depth': 5, 'learning_rate': 0.014561498763273286, 'n_estimators': 633, 'min_child_samples': 56, 'min_child_weight': 0.0017316650562942226, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00436491415121755, 'reg_lambda': 0.00010576515676274732}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:34,434] Trial 191 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 342, 'max_depth': 5, 'learning_rate': 0.013640745704795877, 'n_estimators': 634, 'min_child_samples': 53, 'min_child_weight': 0.0015911057904793584, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004128370100733639, 'reg_lambda': 7.859934266872624e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:34,877] Trial 192 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 341, 'max_depth': 5, 'learning_rate': 0.011575212883074037, 'n_estimators': 589, 'min_child_samples': 49, 'min_child_weight': 0.0018293434205617755, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004658166415045577, 'reg_lambda': 0.00014471514358023932}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:35,411] Trial 193 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 320, 'max_depth': 7, 'learning_rate': 0.006369724246652132, 'n_estimators': 574, 'min_child_samples': 58, 'min_child_weight': 0.001604768448983082, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023568550715882433, 'reg_lambda': 9.927049015637522e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:35,836] Trial 194 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 345, 'max_depth': 4, 'learning_rate': 0.014747474704776496, 'n_estimators': 631, 'min_child_samples': 52, 'min_child_weight': 0.0012076434249013509, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004233475338381233, 'reg_lambda': 4.875101877010455e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:36,516] Trial 195 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 268, 'max_depth': 9, 'learning_rate': 0.007880940229930812, 'n_estimators': 695, 'min_child_samples': 54, 'min_child_weight': 0.0029815671109643532, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031799246322596706, 'reg_lambda': 1.4135494797398416e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:37,052] Trial 196 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 325, 'max_depth': 6, 'learning_rate': 0.012055358965325771, 'n_estimators': 662, 'min_child_samples': 55, 'min_child_weight': 0.004671070378659333, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006386078518358029, 'reg_lambda': 5.74423002952752e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:37,358] Trial 197 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 281, 'max_depth': 2, 'learning_rate': 0.03454424239025595, 'n_estimators': 511, 'min_child_samples': 57, 'min_child_weight': 0.003797506549367455, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016303677084710199, 'reg_lambda': 0.0005010559683117357}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:37,796] Trial 198 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 364, 'max_depth': 5, 'learning_rate': 0.020237715975066146, 'n_estimators': 606, 'min_child_samples': 64, 'min_child_weight': 0.0014990866902037951, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002426743820435647, 'reg_lambda': 2.767416171253258e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:38,333] Trial 199 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 294, 'max_depth': 11, 'learning_rate': 0.0029160938839113333, 'n_estimators': 563, 'min_child_samples': 69, 'min_child_weight': 0.0028394282376582787, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.004657843453974627, 'reg_lambda': 1.9717678197645274e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:38,723] Trial 200 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 353, 'max_depth': 4, 'learning_rate': 0.00493960647154627, 'n_estimators': 537, 'min_child_samples': 51, 'min_child_weight': 0.009005336675491318, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.010554836921128071, 'reg_lambda': 0.0024715441062624927}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:39,062] Trial 201 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 331, 'max_depth': 2, 'learning_rate': 1.0460196056970649e-08, 'n_estimators': 635, 'min_child_samples': 61, 'min_child_weight': 0.0020227128072368896, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0033559065515830827, 'reg_lambda': 0.0011036629840528041}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:39,394] Trial 202 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 332, 'max_depth': 2, 'learning_rate': 0.021072478172274332, 'n_estimators': 620, 'min_child_samples': 63, 'min_child_weight': 0.0022945744875572105, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0034077612742122233, 'reg_lambda': 0.0006533927934360057}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:39,936] Trial 203 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 314, 'max_depth': 7, 'learning_rate': 0.01445859147770194, 'n_estimators': 584, 'min_child_samples': 56, 'min_child_weight': 0.005497535707992033, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0022041523879291662, 'reg_lambda': 0.0019910285918784093}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:40,567] Trial 204 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 342, 'max_depth': 57, 'learning_rate': 0.008804439690773318, 'n_estimators': 645, 'min_child_samples': 60, 'min_child_weight': 0.0693279327523133, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005475940180899474, 'reg_lambda': 1.219799428395296e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:41,037] Trial 205 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 337, 'max_depth': 5, 'learning_rate': 0.02948862129720894, 'n_estimators': 684, 'min_child_samples': 66, 'min_child_weight': 0.0020099550091034458, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0040385509720610585, 'reg_lambda': 0.0014185547920138178}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:41,380] Trial 206 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 353, 'max_depth': 2, 'learning_rate': 0.01827147699157613, 'n_estimators': 624, 'min_child_samples': 62, 'min_child_weight': 0.0011023058945164033, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0029396765623685393, 'reg_lambda': 0.00040321558946991234}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:41,939] Trial 207 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 358, 'max_depth': 8, 'learning_rate': 0.00711084970084184, 'n_estimators': 604, 'min_child_samples': 65, 'min_child_weight': 0.0012441744195251046, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008116890368446261, 'reg_lambda': 7.463733638595992e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:42,364] Trial 208 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 396, 'max_depth': 4, 'learning_rate': 0.014927285465127917, 'n_estimators': 658, 'min_child_samples': 63, 'min_child_weight': 0.014748103549258703, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002601969022075912, 'reg_lambda': 0.0003691884123766163}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:43,044] Trial 209 finished with value: 0.8292828261332198 and parameters: {'num_leaves': 369, 'max_depth': 7, 'learning_rate': 0.01032268387423243, 'n_estimators': 562, 'min_child_samples': 13, 'min_child_weight': 0.00099430528034054, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014761613269922715, 'reg_lambda': 0.000149493148421833}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:43,393] Trial 210 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 306, 'max_depth': 2, 'learning_rate': 4.1209809576655976e-05, 'n_estimators': 625, 'min_child_samples': 53, 'min_child_weight': 0.003497645303346737, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020065727631514195, 'reg_lambda': 0.0008093937329101348}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:43,730] Trial 211 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 351, 'max_depth': 2, 'learning_rate': 0.021637315849697306, 'n_estimators': 639, 'min_child_samples': 61, 'min_child_weight': 0.0014615368011456048, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0032079344808957555, 'reg_lambda': 0.0006237092322696269}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:44,170] Trial 212 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 329, 'max_depth': 5, 'learning_rate': 0.01604911331507071, 'n_estimators': 587, 'min_child_samples': 59, 'min_child_weight': 0.0025170047577909257, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004812085349578372, 'reg_lambda': 0.001137326833297732}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:44,578] Trial 213 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 320, 'max_depth': 4, 'learning_rate': 0.042038705038451994, 'n_estimators': 618, 'min_child_samples': 62, 'min_child_weight': 0.0016708370129839903, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003176930927100289, 'reg_lambda': 3.413474711933255e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:44,916] Trial 214 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 273, 'max_depth': 2, 'learning_rate': 0.010945229005210288, 'n_estimators': 604, 'min_child_samples': 66, 'min_child_weight': 0.0008467130724510762, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004028351298166694, 'reg_lambda': 1.7442901068426176e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:45,524] Trial 215 finished with value: 0.828254477109439 and parameters: {'num_leaves': 343, 'max_depth': 9, 'learning_rate': 0.0064436136609081615, 'n_estimators': 655, 'min_child_samples': 68, 'min_child_weight': 0.0044098100169970905, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025896553710707325, 'reg_lambda': 1.0516899104073498e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:45,963] Trial 216 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 290, 'max_depth': 6, 'learning_rate': 0.02363426773531087, 'n_estimators': 526, 'min_child_samples': 57, 'min_child_weight': 0.0011445296605065215, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006305124135900075, 'reg_lambda': 0.00020996715451439876}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:46,413] Trial 217 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 353, 'max_depth': 4, 'learning_rate': 1.874848042452725e-07, 'n_estimators': 576, 'min_child_samples': 64, 'min_child_weight': 0.0028989059164297296, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018962555730608138, 'reg_lambda': 2.164620938977422e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:46,731] Trial 218 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 337, 'max_depth': 2, 'learning_rate': 0.017032896104545392, 'n_estimators': 552, 'min_child_samples': 59, 'min_child_weight': 0.0019340622562202352, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0037442404907247246, 'reg_lambda': 0.0005149206356710198}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:47,279] Trial 219 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 314, 'max_depth': 7, 'learning_rate': 0.004210774443199584, 'n_estimators': 630, 'min_child_samples': 62, 'min_child_weight': 0.0023795913508701675, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.005072225199565315, 'reg_lambda': 0.0017988401283696837}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:47,896] Trial 220 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 253, 'max_depth': 9, 'learning_rate': 0.010502106299132946, 'n_estimators': 676, 'min_child_samples': 67, 'min_child_weight': 0.00365535278018801, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012492552533310522, 'reg_lambda': 1.4392316635609468e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:48,235] Trial 221 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 308, 'max_depth': 2, 'learning_rate': 4.005445569681036e-06, 'n_estimators': 630, 'min_child_samples': 60, 'min_child_weight': 0.00428755855500011, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002957468352385035, 'reg_lambda': 0.0006328872557244374}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:48,660] Trial 222 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 324, 'max_depth': 4, 'learning_rate': 0.025440957937376534, 'n_estimators': 642, 'min_child_samples': 61, 'min_child_weight': 0.006319587441226917, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002984032103649496, 'reg_lambda': 0.0008732968752608813}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:49,255] Trial 223 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 301, 'max_depth': 108, 'learning_rate': 0.01948902839372929, 'n_estimators': 601, 'min_child_samples': 64, 'min_child_weight': 0.0035610001429629053, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0036317371911906275, 'reg_lambda': 0.00039645608676375026}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:49,639] Trial 224 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 344, 'max_depth': 5, 'learning_rate': 0.03351439154242056, 'n_estimators': 498, 'min_child_samples': 98, 'min_child_weight': 0.002839101889810314, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002203231446404238, 'reg_lambda': 0.0011030844792296818}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:50,189] Trial 225 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 317, 'max_depth': 6, 'learning_rate': 0.01348946485990014, 'n_estimators': 659, 'min_child_samples': 70, 'min_child_weight': 0.005596270106413318, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.006924239273429588, 'reg_lambda': 0.0005767568524050828}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:50,526] Trial 226 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 326, 'max_depth': 2, 'learning_rate': 0.007450891896919708, 'n_estimators': 608, 'min_child_samples': 63, 'min_child_weight': 0.001657229764685202, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004565204603865783, 'reg_lambda': 0.0007841992469540177}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:50,857] Trial 227 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 330, 'max_depth': 2, 'learning_rate': 0.007119515516846831, 'n_estimators': 591, 'min_child_samples': 65, 'min_child_weight': 0.001708726700726057, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00488734458460506, 'reg_lambda': 0.0008195536364831681}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:51,270] Trial 228 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 365, 'max_depth': 4, 'learning_rate': 0.00635645240648314, 'n_estimators': 579, 'min_child_samples': 65, 'min_child_weight': 0.0010175471444273262, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005581246688732979, 'reg_lambda': 0.000820521164441661}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:51,797] Trial 229 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 330, 'max_depth': 7, 'learning_rate': 0.00825287329278315, 'n_estimators': 600, 'min_child_samples': 67, 'min_child_weight': 0.0013265420988730397, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.015806965600223263, 'reg_lambda': 2.2189750949157852e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:52,124] Trial 230 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 353, 'max_depth': 2, 'learning_rate': 0.005085504654583439, 'n_estimators': 547, 'min_child_samples': 63, 'min_child_weight': 0.0017282797624553637, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008120838530572211, 'reg_lambda': 0.0003678147818748448}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:52,468] Trial 231 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 336, 'max_depth': 2, 'learning_rate': 0.009548598862864072, 'n_estimators': 617, 'min_child_samples': 63, 'min_child_weight': 0.0020253741427720133, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004877632759517283, 'reg_lambda': 0.0012911919869548227}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:52,917] Trial 232 finished with value: 0.8422205989773557 and parameters: {'num_leaves': 327, 'max_depth': 5, 'learning_rate': 0.012293627498280234, 'n_estimators': 587, 'min_child_samples': 65, 'min_child_weight': 0.0014474407300325896, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004023898791142275, 'reg_lambda': 0.0007872454024923678}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:53,366] Trial 233 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 324, 'max_depth': 5, 'learning_rate': 0.006837815441567266, 'n_estimators': 568, 'min_child_samples': 65, 'min_child_weight': 0.0008055014645020097, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0045392826785633405, 'reg_lambda': 0.0007796836367740834}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:53,833] Trial 234 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 344, 'max_depth': 6, 'learning_rate': 0.01148462389214741, 'n_estimators': 585, 'min_child_samples': 69, 'min_child_weight': 0.0012722453965165793, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0040275623289864945, 'reg_lambda': 0.0005277814685341342}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:54,408] Trial 235 finished with value: 0.8058318352269737 and parameters: {'num_leaves': 342, 'max_depth': 10, 'learning_rate': 0.011782231248741625, 'n_estimators': 588, 'min_child_samples': 69, 'min_child_weight': 0.0012491131589086968, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006178189314430659, 'reg_lambda': 0.0005017463260241554}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:54,874] Trial 236 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 350, 'max_depth': 7, 'learning_rate': 0.013717972997656412, 'n_estimators': 536, 'min_child_samples': 67, 'min_child_weight': 0.0015176957532713124, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004432948690449054, 'reg_lambda': 8.127744937200861e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:55,312] Trial 237 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 361, 'max_depth': 5, 'learning_rate': 0.01028234166205514, 'n_estimators': 566, 'min_child_samples': 71, 'min_child_weight': 0.0010292593921745663, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025664798071164466, 'reg_lambda': 1.5889284451720702e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:55,882] Trial 238 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 345, 'max_depth': 9, 'learning_rate': 0.004116086484002713, 'n_estimators': 590, 'min_child_samples': 69, 'min_child_weight': 0.0016421596837570944, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1.6961517453538093e-05, 'reg_lambda': 0.00019112950727238315}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:56,332] Trial 239 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 371, 'max_depth': 5, 'learning_rate': 0.01666714915855612, 'n_estimators': 608, 'min_child_samples': 66, 'min_child_weight': 0.3498091546908221, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003973303330629785, 'reg_lambda': 3.0178831116418852e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:56,925] Trial 240 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 332, 'max_depth': 13, 'learning_rate': 0.006322067988143949, 'n_estimators': 557, 'min_child_samples': 64, 'min_child_weight': 0.0008704936700446748, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007398346095240222, 'reg_lambda': 0.00029310241414498626}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:57,348] Trial 241 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 286, 'max_depth': 4, 'learning_rate': 0.008777992335987974, 'n_estimators': 613, 'min_child_samples': 62, 'min_child_weight': 0.001197575058063668, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028189597611408715, 'reg_lambda': 0.0006581198383763955}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:57,684] Trial 242 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 318, 'max_depth': 2, 'learning_rate': 0.008075037468535667, 'n_estimators': 594, 'min_child_samples': 65, 'min_child_weight': 0.0017144381362509946, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003766612547465445, 'reg_lambda': 0.0008706659461974374}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:58,132] Trial 243 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 322, 'max_depth': 6, 'learning_rate': 0.012263345971891979, 'n_estimators': 579, 'min_child_samples': 67, 'min_child_weight': 0.001285505484089592, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004757407758823501, 'reg_lambda': 9.78999457051637}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:58,471] Trial 244 finished with value: 0.7955601764400089 and parameters: {'num_leaves': 339, 'max_depth': 2, 'learning_rate': 0.003876695241909352, 'n_estimators': 595, 'min_child_samples': 65, 'min_child_weight': 0.0017334688524282013, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0037171993567546475, 'reg_lambda': 0.0009736561051569586}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:58,861] Trial 245 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 353, 'max_depth': 4, 'learning_rate': 0.008440828598177545, 'n_estimators': 518, 'min_child_samples': 68, 'min_child_weight': 2.1296499928416116e-05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021764544340571856, 'reg_lambda': 0.0009404727761421677}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:59,404] Trial 246 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 329, 'max_depth': 7, 'learning_rate': 0.0001031578297832012, 'n_estimators': 572, 'min_child_samples': 64, 'min_child_weight': 0.0007497459527395299, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005725472980256133, 'reg_lambda': 0.0015102742199886274}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:33:59,851] Trial 247 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 296, 'max_depth': 4, 'learning_rate': 0.005702554271396167, 'n_estimators': 615, 'min_child_samples': 66, 'min_child_weight': 0.008596220374796933, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017002741445681314, 'reg_lambda': 0.0005432626859717917}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:00,181] Trial 248 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 381, 'max_depth': 2, 'learning_rate': 0.017071489266212048, 'n_estimators': 543, 'min_child_samples': 63, 'min_child_weight': 0.0014783381117637207, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0027346736208425045, 'reg_lambda': 2.0722838089068918e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:00,507] Trial 249 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 357, 'max_depth': 2, 'learning_rate': 0.01777086675578559, 'n_estimators': 543, 'min_child_samples': 63, 'min_child_weight': 0.0014447181582469674, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002560889109491476, 'reg_lambda': 0.005166779871586946}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:01,129] Trial 250 finished with value: 0.814519979719652 and parameters: {'num_leaves': 374, 'max_depth': 48, 'learning_rate': 0.0026842962099678236, 'n_estimators': 593, 'min_child_samples': 58, 'min_child_weight': 0.0020352922052263656, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003968337060608925, 'reg_lambda': 0.00012098764427976565}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:01,447] Trial 251 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 344, 'max_depth': 2, 'learning_rate': 0.015266295990173671, 'n_estimators': 507, 'min_child_samples': 70, 'min_child_weight': 0.0026711293429374267, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0056799494408199085, 'reg_lambda': 0.0004240092704269866}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:01,994] Trial 252 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 402, 'max_depth': 8, 'learning_rate': 0.024848536786767024, 'n_estimators': 533, 'min_child_samples': 51, 'min_child_weight': 0.0015777677001270047, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019443813657397135, 'reg_lambda': 0.0007363525535918669}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:02,513] Trial 253 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 387, 'max_depth': 6, 'learning_rate': 0.00898208029376081, 'n_estimators': 621, 'min_child_samples': 60, 'min_child_weight': 0.003199153638047643, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.009518605935698223, 'reg_lambda': 4.2862233371146386e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:02,938] Trial 254 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 334, 'max_depth': 4, 'learning_rate': 0.012973179462429534, 'n_estimators': 591, 'min_child_samples': 55, 'min_child_weight': 0.0018184972090885885, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.0028465882753275504, 'reg_lambda': 1.407453894939981e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:03,294] Trial 255 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 413, 'max_depth': 2, 'learning_rate': 0.005292321509397942, 'n_estimators': 648, 'min_child_samples': 72, 'min_child_weight': 0.0024781592532919236, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0037408931192062125, 'reg_lambda': 2.3410459033264986e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:03,643] Trial 256 finished with value: 0.824887818514042 and parameters: {'num_leaves': 434, 'max_depth': 2, 'learning_rate': 0.006322367620873471, 'n_estimators': 648, 'min_child_samples': 70, 'min_child_weight': 0.002707146075090397, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004106660467451207, 'reg_lambda': 2.7407454802097015e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:04,062] Trial 257 finished with value: 0.828254477109439 and parameters: {'num_leaves': 361, 'max_depth': 2, 'learning_rate': 0.0048737057580151896, 'n_estimators': 612, 'min_child_samples': 68, 'min_child_weight': 0.002452863011562279, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006925586556417553, 'reg_lambda': 1.0211571482767685e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:04,736] Trial 258 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 446, 'max_depth': 7, 'learning_rate': 0.007600894316795723, 'n_estimators': 733, 'min_child_samples': 72, 'min_child_weight': 0.0020775050101864245, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004856276503706942, 'reg_lambda': 0.0020569581825103252}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:05,406] Trial 259 finished with value: 0.7840892754456584 and parameters: {'num_leaves': 383, 'max_depth': 125, 'learning_rate': 0.019648723169439265, 'n_estimators': 666, 'min_child_samples': 62, 'min_child_weight': 0.004692783901445919, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0034418928605579138, 'reg_lambda': 1.8842486895514785e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:05,853] Trial 260 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 350, 'max_depth': 4, 'learning_rate': 0.0035153178588208816, 'n_estimators': 645, 'min_child_samples': 65, 'min_child_weight': 0.0013839102354885019, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.012805505193799725, 'reg_lambda': 0.0011813641253506906}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:06,421] Trial 261 finished with value: 0.7981467213347979 and parameters: {'num_leaves': 409, 'max_depth': 8, 'learning_rate': 0.03307199871625648, 'n_estimators': 575, 'min_child_samples': 53, 'min_child_weight': 0.006811979844226535, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0037624492623525817, 'reg_lambda': 0.0008546425899065093}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:06,771] Trial 262 finished with value: 0.828254477109439 and parameters: {'num_leaves': 369, 'max_depth': 2, 'learning_rate': 0.005015809025305169, 'n_estimators': 629, 'min_child_samples': 63, 'min_child_weight': 0.003281731460373663, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0026042096330947343, 'reg_lambda': 2.4744150217552294e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:07,218] Trial 263 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 318, 'max_depth': 5, 'learning_rate': 0.010790617388577476, 'n_estimators': 600, 'min_child_samples': 59, 'min_child_weight': 0.001100832249105799, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005568447901214082, 'reg_lambda': 1.9546484394296835e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:07,856] Trial 264 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 408, 'max_depth': 66, 'learning_rate': 0.016567849407211475, 'n_estimators': 554, 'min_child_samples': 49, 'min_child_weight': 0.0016739234597731656, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004468413172690338, 'reg_lambda': 0.0005481552552176362}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:08,474] Trial 265 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 476, 'max_depth': 87, 'learning_rate': 0.0025715111724712533, 'n_estimators': 616, 'min_child_samples': 67, 'min_child_weight': 0.004113728793771553, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003005372827577735, 'reg_lambda': 3.806801303161255e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:09,160] Trial 266 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 335, 'max_depth': 9, 'learning_rate': 0.007871656753191202, 'n_estimators': 695, 'min_child_samples': 56, 'min_child_weight': 0.0022623716744329596, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007816399966201263, 'reg_lambda': 1.2919148808264e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:09,835] Trial 267 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 325, 'max_depth': 96, 'learning_rate': 0.025578392286766047, 'n_estimators': 645, 'min_child_samples': 61, 'min_child_weight': 0.0006381504262507079, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002310700520083952, 'reg_lambda': 0.0015543485499024006}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:10,254] Trial 268 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 278, 'max_depth': 4, 'learning_rate': 0.013086457188132564, 'n_estimators': 587, 'min_child_samples': 64, 'min_child_weight': 0.0018495696465216647, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005709550724435488, 'reg_lambda': 0.0010763131789984209}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:10,683] Trial 269 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 420, 'max_depth': 6, 'learning_rate': 0.04349299297551792, 'n_estimators': 490, 'min_child_samples': 72, 'min_child_weight': 0.005338804893892296, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0035895878048622337, 'reg_lambda': 0.0007462528936907234}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:11,057] Trial 270 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 344, 'max_depth': 2, 'learning_rate': 0.006252406772942343, 'n_estimators': 674, 'min_child_samples': 68, 'min_child_weight': 0.0013262391247405567, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0046070774983744895, 'reg_lambda': 2.4736884205589143e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:11,440] Trial 271 finished with value: 0.8050772180423282 and parameters: {'num_leaves': 260, 'max_depth': 2, 'learning_rate': 0.00362968430807184, 'n_estimators': 685, 'min_child_samples': 66, 'min_child_weight': 0.0031697086202634446, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006789266821252856, 'reg_lambda': 2.480633111519145e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:11,806] Trial 272 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 353, 'max_depth': 2, 'learning_rate': 0.005438028168949183, 'n_estimators': 668, 'min_child_samples': 62, 'min_child_weight': 0.0024341755815500796, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004751117501801288, 'reg_lambda': 1.4846123916348006e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:12,177] Trial 273 finished with value: 0.824887818514042 and parameters: {'num_leaves': 361, 'max_depth': 2, 'learning_rate': 0.005085570775289375, 'n_estimators': 706, 'min_child_samples': 47, 'min_child_weight': 0.0025126796830503423, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.010303007812610777, 'reg_lambda': 1.4829369852175228e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:12,535] Trial 274 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 379, 'max_depth': 2, 'learning_rate': 0.005925020983163749, 'n_estimators': 673, 'min_child_samples': 62, 'min_child_weight': 0.0035873385762406956, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002949674054096742, 'reg_lambda': 1.7379509016245682e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:12,887] Trial 275 finished with value: 0.7742931543489272 and parameters: {'num_leaves': 379, 'max_depth': 2, 'learning_rate': 0.0023172352968026683, 'n_estimators': 673, 'min_child_samples': 62, 'min_child_weight': 0.004065493966572327, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002115219661416804, 'reg_lambda': 2.2791739904791406e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:13,255] Trial 276 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 370, 'max_depth': 2, 'learning_rate': 0.004126072849111609, 'n_estimators': 710, 'min_child_samples': 60, 'min_child_weight': 0.0031627736220733588, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001494432393905862, 'reg_lambda': 1.6603800414434354e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:13,702] Trial 277 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 351, 'max_depth': 4, 'learning_rate': 0.005814300454810674, 'n_estimators': 668, 'min_child_samples': 65, 'min_child_weight': 0.002452883710175186, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028036567974078865, 'reg_lambda': 3.142704710563019e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:14,181] Trial 278 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 360, 'max_depth': 4, 'learning_rate': 0.0031453319877365283, 'n_estimators': 692, 'min_child_samples': 68, 'min_child_weight': 0.0036770402893759853, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004842783814045582, 'reg_lambda': 1.2392974068454964e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:14,817] Trial 279 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 214, 'max_depth': 11, 'learning_rate': 0.0067201957160644135, 'n_estimators': 659, 'min_child_samples': 63, 'min_child_weight': 0.004655296879257813, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0029998031249941393, 'reg_lambda': 1.6653248325210544e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:15,185] Trial 280 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 329, 'max_depth': 2, 'learning_rate': 0.008098272641443511, 'n_estimators': 653, 'min_child_samples': 61, 'min_child_weight': 0.0019941578960083364, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00534286160933607, 'reg_lambda': 2.090835490606317e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:15,770] Trial 281 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 311, 'max_depth': 7, 'learning_rate': 0.004735792883777157, 'n_estimators': 674, 'min_child_samples': 66, 'min_child_weight': 0.0010753404248266118, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001920700028379299, 'reg_lambda': 1.120280818940261e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:16,249] Trial 282 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 393, 'max_depth': 4, 'learning_rate': 0.006412841017795261, 'n_estimators': 752, 'min_child_samples': 58, 'min_child_weight': 0.002951316163473125, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.007704891900610874, 'reg_lambda': 0.0032157475138975874}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:16,873] Trial 283 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 341, 'max_depth': 113, 'learning_rate': 0.00922223835039201, 'n_estimators': 643, 'min_child_samples': 70, 'min_child_weight': 0.001523158600983552, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0034186907611227866, 'reg_lambda': 3.0368561287731965e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:17,540] Trial 284 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 350, 'max_depth': 7, 'learning_rate': 0.0014573519157626389, 'n_estimators': 715, 'min_child_samples': 64, 'min_child_weight': 0.002245784411734654, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002476141295317521, 'reg_lambda': 1.5726620690461073e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:18,178] Trial 285 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 188, 'max_depth': 106, 'learning_rate': 0.0038716512507030905, 'n_estimators': 684, 'min_child_samples': 67, 'min_child_weight': 0.0038750868694748582, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0057342199388396835, 'reg_lambda': 2.2667217206628285e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:18,531] Trial 286 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 378, 'max_depth': 2, 'learning_rate': 0.008008707993481702, 'n_estimators': 623, 'min_child_samples': 62, 'min_child_weight': 0.0009329305912458035, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004028092098640549, 'reg_lambda': 4.027274150002646e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:18,958] Trial 287 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 324, 'max_depth': 5, 'learning_rate': 0.00330401276889525, 'n_estimators': 472, 'min_child_samples': 59, 'min_child_weight': 0.005504090368484582, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003004637393854793, 'reg_lambda': 1.4221745292445993e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:19,945] Trial 288 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 334, 'max_depth': 9, 'learning_rate': 0.005608002880611124, 'n_estimators': 794, 'min_child_samples': 25, 'min_child_weight': 0.002512229210153906, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004587142690753243, 'reg_lambda': 1.869707020221322e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:20,310] Trial 289 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 448, 'max_depth': 2, 'learning_rate': 0.010609865212907507, 'n_estimators': 657, 'min_child_samples': 65, 'min_child_weight': 0.0014726005541335354, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00938527854277973, 'reg_lambda': 2.6458208887240414e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:20,770] Trial 290 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 417, 'max_depth': 5, 'learning_rate': 0.00211695815778013, 'n_estimators': 530, 'min_child_samples': 68, 'min_child_weight': 0.0031949112565991047, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.021522108586235433, 'reg_lambda': 5.5495496819354126e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:21,375] Trial 291 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 365, 'max_depth': 76, 'learning_rate': 0.006430624245360682, 'n_estimators': 630, 'min_child_samples': 73, 'min_child_weight': 0.0017512405486353952, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017712043106114397, 'reg_lambda': 1.0522003447846651e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:21,896] Trial 292 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 357, 'max_depth': 7, 'learning_rate': 0.008988277136560186, 'n_estimators': 558, 'min_child_samples': 63, 'min_child_weight': 0.001252711135793015, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006242338587557401, 'reg_lambda': 1.871525866790463e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:22,325] Trial 293 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 317, 'max_depth': 4, 'learning_rate': 0.004541132122379206, 'n_estimators': 599, 'min_child_samples': 71, 'min_child_weight': 0.0008131520623360691, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024011915799169213, 'reg_lambda': 0.0014094770699934127}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:22,956] Trial 294 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 236, 'max_depth': 119, 'learning_rate': 0.016173326952791507, 'n_estimators': 644, 'min_child_samples': 61, 'min_child_weight': 0.0021844134250591776, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0036314638828220634, 'reg_lambda': 3.52595710203004e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:23,307] Trial 295 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 345, 'max_depth': 2, 'learning_rate': 0.011131474395116015, 'n_estimators': 609, 'min_child_samples': 65, 'min_child_weight': 0.006986787971965082, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004687882736811007, 'reg_lambda': 1.3286492812985623e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:23,846] Trial 296 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 334, 'max_depth': 10, 'learning_rate': 0.006964692236214449, 'n_estimators': 518, 'min_child_samples': 69, 'min_child_weight': 0.004803276288641996, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007225303985254256, 'reg_lambda': 0.0010432510802475272}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:24,398] Trial 297 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 304, 'max_depth': 6, 'learning_rate': 0.028255955002341494, 'n_estimators': 670, 'min_child_samples': 60, 'min_child_weight': 0.0035013597517914467, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.013099438186642796, 'reg_lambda': 2.439074766394188e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:24,822] Trial 298 finished with value: 0.7254253358625067 and parameters: {'num_leaves': 352, 'max_depth': 4, 'learning_rate': 0.7292731693027812, 'n_estimators': 548, 'min_child_samples': 63, 'min_child_weight': 0.0027398883154166327, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011967530381635492, 'reg_lambda': 5.9779606358383}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:25,181] Trial 299 finished with value: 0.8246851893910718 and parameters: {'num_leaves': 322, 'max_depth': 2, 'learning_rate': 0.012348676291412116, 'n_estimators': 626, 'min_child_samples': 95, 'min_child_weight': 0.0019186342412136751, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0026619742048712633, 'reg_lambda': 1.587641066746435e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:25,773] Trial 300 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 168, 'max_depth': 70, 'learning_rate': 0.018895138176923863, 'n_estimators': 603, 'min_child_samples': 66, 'min_child_weight': 0.0006706064790468104, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003747263158953783, 'reg_lambda': 1.0132711347541388e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:26,457] Trial 301 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 369, 'max_depth': 8, 'learning_rate': 1.1904335276371326e-05, 'n_estimators': 728, 'min_child_samples': 67, 'min_child_weight': 0.0013739433020061914, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021973945570469724, 'reg_lambda': 0.0020579345259812724}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:27,023] Trial 302 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 339, 'max_depth': 5, 'learning_rate': 0.0030366302834498255, 'n_estimators': 697, 'min_child_samples': 58, 'min_child_weight': 0.0011684736917946558, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005824983555720039, 'reg_lambda': 0.14010325698007817}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:27,371] Trial 303 finished with value: 0.828254477109439 and parameters: {'num_leaves': 326, 'max_depth': 2, 'learning_rate': 0.005273042285482347, 'n_estimators': 570, 'min_child_samples': 64, 'min_child_weight': 0.0020777611227592073, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0032432051872074096, 'reg_lambda': 0.0012682433894439266}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:27,946] Trial 304 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 346, 'max_depth': 7, 'learning_rate': 0.007786126436305341, 'n_estimators': 642, 'min_child_samples': 61, 'min_child_weight': 0.004269642387279043, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015552131150526787, 'reg_lambda': 7.216655812636247e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:28,570] Trial 305 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 381, 'max_depth': 12, 'learning_rate': 0.010602951237284235, 'n_estimators': 618, 'min_child_samples': 62, 'min_child_weight': 0.0030649264421001555, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004739314431916525, 'reg_lambda': 2.0622768101368737e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:28,937] Trial 306 finished with value: 0.828254477109439 and parameters: {'num_leaves': 399, 'max_depth': 4, 'learning_rate': 0.021312774761855457, 'n_estimators': 497, 'min_child_samples': 65, 'min_child_weight': 0.0009784320736371764, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.0029430498109648206, 'reg_lambda': 0.0008654405968415651}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:29,301] Trial 307 finished with value: 0.8202977117191788 and parameters: {'num_leaves': 313, 'max_depth': 2, 'learning_rate': 0.015086937254471418, 'n_estimators': 662, 'min_child_samples': 70, 'min_child_weight': 0.00041103127743726084, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004048418664679304, 'reg_lambda': 3.442655009352075e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:29,804] Trial 308 finished with value: 0.7753721396489734 and parameters: {'num_leaves': 361, 'max_depth': 6, 'learning_rate': 0.06392998551937389, 'n_estimators': 602, 'min_child_samples': 68, 'min_child_weight': 0.0015404225227173165, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019610818239852055, 'reg_lambda': 1.4471582836326862e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:30,399] Trial 309 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 336, 'max_depth': 39, 'learning_rate': 0.004573262587718074, 'n_estimators': 572, 'min_child_samples': 59, 'min_child_weight': 0.0025828342426323695, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.005855670373246941, 'reg_lambda': 0.006048012127710206}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:30,860] Trial 310 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 355, 'max_depth': 9, 'learning_rate': 0.009243990216514543, 'n_estimators': 426, 'min_child_samples': 64, 'min_child_weight': 0.00589926282094783, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008838298155698261, 'reg_lambda': 2.7743617858539446e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:31,270] Trial 311 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 328, 'max_depth': 4, 'learning_rate': 0.006204686636485237, 'n_estimators': 536, 'min_child_samples': 73, 'min_child_weight': 0.0016777586167823304, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025760656380391773, 'reg_lambda': 0.319810735555217}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:31,855] Trial 312 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 346, 'max_depth': 6, 'learning_rate': 0.003039678325492768, 'n_estimators': 679, 'min_child_samples': 62, 'min_child_weight': 0.0005112249867884373, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0035420455630800264, 'reg_lambda': 0.0006696403591596874}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:32,082] Trial 313 finished with value: 0.8003283337405159 and parameters: {'num_leaves': 299, 'max_depth': 2, 'learning_rate': 0.0359553709428202, 'n_estimators': 66, 'min_child_samples': 67, 'min_child_weight': 0.0038062599485664114, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00441134921660589, 'reg_lambda': 0.0016611183412579295}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:32,522] Trial 314 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 318, 'max_depth': 4, 'learning_rate': 0.013304081394169444, 'n_estimators': 629, 'min_child_samples': 60, 'min_child_weight': 0.002136677918728674, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007180150475631919, 'reg_lambda': 0.008575193509438386}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:33,086] Trial 315 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 340, 'max_depth': 9, 'learning_rate': 0.020284080609561213, 'n_estimators': 560, 'min_child_samples': 57, 'min_child_weight': 0.0012674211843668275, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0029002209791641324, 'reg_lambda': 0.1873339505760032}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:33,447] Trial 316 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 367, 'max_depth': 2, 'learning_rate': 0.008207931141778589, 'n_estimators': 644, 'min_child_samples': 64, 'min_child_weight': 0.002676082184324138, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002067877020403586, 'reg_lambda': 0.00035289425231295013}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:34,022] Trial 317 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 58, 'max_depth': 82, 'learning_rate': 0.00432821326826227, 'n_estimators': 586, 'min_child_samples': 66, 'min_child_weight': 0.004639887603802912, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.015860323335470945, 'reg_lambda': 1.930218407653286e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:34,526] Trial 318 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 355, 'max_depth': 6, 'learning_rate': 0.01178472384335125, 'n_estimators': 617, 'min_child_samples': 71, 'min_child_weight': 0.001010078061258128, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004849772789249768, 'reg_lambda': 0.0009330493560598823}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:34,943] Trial 319 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 434, 'max_depth': 5, 'learning_rate': 0.026376629215694447, 'n_estimators': 508, 'min_child_samples': 69, 'min_child_weight': 0.0018647719383152466, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003635817327010747, 'reg_lambda': 4.500015740940385e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:35,790] Trial 320 finished with value: 0.7806140834712263 and parameters: {'num_leaves': 330, 'max_depth': 8, 'learning_rate': 0.00044651915444336916, 'n_estimators': 658, 'min_child_samples': 62, 'min_child_weight': 0.0032548946293486864, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.001431187305482129, 'reg_lambda': 0.003807062833041845}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:36,173] Trial 321 finished with value: 0.8050772180423282 and parameters: {'num_leaves': 388, 'max_depth': 2, 'learning_rate': 0.00597915745809777, 'n_estimators': 457, 'min_child_samples': 63, 'min_child_weight': 0.0023747422389461814, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005910001455298222, 'reg_lambda': 1.313606491812059e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:36,604] Trial 322 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 344, 'max_depth': 4, 'learning_rate': 0.015234027839241325, 'n_estimators': 602, 'min_child_samples': 66, 'min_child_weight': 0.001457691701721987, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002465505834800209, 'reg_lambda': 0.00116724901370378}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:37,194] Trial 323 finished with value: 0.8111432515980821 and parameters: {'num_leaves': 313, 'max_depth': 53, 'learning_rate': 0.0009249136019123449, 'n_estimators': 541, 'min_child_samples': 60, 'min_child_weight': 0.005506882060521646, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008375833545608185, 'reg_lambda': 2.3688083352472613e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:37,789] Trial 324 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 377, 'max_depth': 7, 'learning_rate': 0.008274146435610433, 'n_estimators': 697, 'min_child_samples': 68, 'min_child_weight': 0.0006824663752859778, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004553583386766073, 'reg_lambda': 1.7683422539184275e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:38,276] Trial 325 finished with value: 0.8319050339617852 and parameters: {'num_leaves': 331, 'max_depth': 12, 'learning_rate': 0.001900744361833334, 'n_estimators': 574, 'min_child_samples': 91, 'min_child_weight': 0.007281891607036021, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.003346749299464435, 'reg_lambda': 0.00045349929691369177}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:38,934] Trial 326 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 352, 'max_depth': 60, 'learning_rate': 0.00018341606400649349, 'n_estimators': 641, 'min_child_samples': 65, 'min_child_weight': 0.001758813792075774, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019005707965431458, 'reg_lambda': 0.000723339060290622}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:39,346] Trial 327 finished with value: 0.828254477109439 and parameters: {'num_leaves': 309, 'max_depth': 2, 'learning_rate': 0.0036733080466269806, 'n_estimators': 821, 'min_child_samples': 62, 'min_child_weight': 0.0008863325280599062, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.010777302572000626, 'reg_lambda': 2.7391961804441852e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:39,829] Trial 328 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 245, 'max_depth': 5, 'learning_rate': 0.011205647082414455, 'n_estimators': 620, 'min_child_samples': 89, 'min_child_weight': 0.003805571883082812, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005708007897007765, 'reg_lambda': 0.002098679033841853}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:40,508] Trial 329 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 364, 'max_depth': 10, 'learning_rate': 0.01110984537203304, 'n_estimators': 676, 'min_child_samples': 57, 'min_child_weight': 0.0037186823797768767, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.006000741343799003, 'reg_lambda': 0.002371823918307024}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:40,984] Trial 330 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 201, 'max_depth': 5, 'learning_rate': 0.017362335369522527, 'n_estimators': 621, 'min_child_samples': 54, 'min_child_weight': 0.002847817172951607, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.004677920083166602, 'reg_lambda': 0.001625424384343541}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:41,577] Trial 331 finished with value: 0.828254477109439 and parameters: {'num_leaves': 410, 'max_depth': 7, 'learning_rate': 0.006813413773701716, 'n_estimators': 652, 'min_child_samples': 64, 'min_child_weight': 0.004897097659540177, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006967933325482637, 'reg_lambda': 0.00326227058035681}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:41,821] Trial 332 finished with value: 0.8202977117191788 and parameters: {'num_leaves': 289, 'max_depth': 4, 'learning_rate': 0.14727996357163306, 'n_estimators': 110, 'min_child_samples': 59, 'min_child_weight': 0.003921413406899682, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0036575719935121524, 'reg_lambda': 0.001229983780197095}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:42,176] Trial 333 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 226, 'max_depth': 2, 'learning_rate': 0.011039145199186692, 'n_estimators': 588, 'min_child_samples': 71, 'min_child_weight': 0.003229506318878428, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0028942455046022473, 'reg_lambda': 0.0006397278906310493}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:42,645] Trial 334 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 339, 'max_depth': 5, 'learning_rate': 0.023502395556417, 'n_estimators': 611, 'min_child_samples': 67, 'min_child_weight': 0.006372599037869976, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005048921214765826, 'reg_lambda': 0.0009142841059626518}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:43,335] Trial 335 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 349, 'max_depth': 8, 'learning_rate': 0.005101861295703009, 'n_estimators': 625, 'min_child_samples': 39, 'min_child_weight': 0.002299568023728638, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004183032473796407, 'reg_lambda': 0.0017878023457457465}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:43,794] Trial 336 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 323, 'max_depth': 4, 'learning_rate': 0.008093643469282662, 'n_estimators': 661, 'min_child_samples': 61, 'min_child_weight': 0.004259305890381889, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1.1791754911297365, 'reg_lambda': 1.2587729527234996e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:44,150] Trial 337 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 336, 'max_depth': 2, 'learning_rate': 0.034500610954293874, 'n_estimators': 589, 'min_child_samples': 44, 'min_child_weight': 0.0028044668913326594, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023474029914266168, 'reg_lambda': 0.002473831496875811}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:44,779] Trial 338 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 373, 'max_depth': 10, 'learning_rate': 0.014547763618763136, 'n_estimators': 633, 'min_child_samples': 64, 'min_child_weight': 0.002129848124774542, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0032126055062242816, 'reg_lambda': 1.7382073721944447e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:45,244] Trial 339 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 323, 'max_depth': 7, 'learning_rate': 0.00937644946861993, 'n_estimators': 554, 'min_child_samples': 100, 'min_child_weight': 0.003382942056667598, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006744872470367806, 'reg_lambda': 1.0019738591211745e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:45,652] Trial 340 finished with value: 0.7843572540630146 and parameters: {'num_leaves': 355, 'max_depth': 5, 'learning_rate': 0.051037242364444374, 'n_estimators': 480, 'min_child_samples': 66, 'min_child_weight': 0.0017250704816790096, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011429226989675238, 'reg_lambda': 0.001237282910244297}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:46,037] Trial 341 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 247, 'max_depth': 2, 'learning_rate': 0.018278059596594756, 'n_estimators': 687, 'min_child_samples': 63, 'min_child_weight': 0.002575836860271823, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00561445494498579, 'reg_lambda': 2.3067363051555793e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:46,541] Trial 342 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 300, 'max_depth': 6, 'learning_rate': 0.005841889066770885, 'n_estimators': 597, 'min_child_samples': 69, 'min_child_weight': 0.005578942399342457, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004013829107602858, 'reg_lambda': 0.00026748909657720466}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:46,996] Trial 343 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 331, 'max_depth': 4, 'learning_rate': 0.01244005497890074, 'n_estimators': 643, 'min_child_samples': 61, 'min_child_weight': 0.007556398094269199, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001601419696294067, 'reg_lambda': 3.485661667541086e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:47,531] Trial 344 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 344, 'max_depth': 9, 'learning_rate': 0.008373111067332609, 'n_estimators': 528, 'min_child_samples': 74, 'min_child_weight': 0.0013548409892317848, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002500553003993726, 'reg_lambda': 0.0008450839359807775}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:47,872] Trial 345 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 359, 'max_depth': 2, 'learning_rate': 0.025289611086416443, 'n_estimators': 567, 'min_child_samples': 59, 'min_child_weight': 0.004336685573756688, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0034604645615012577, 'reg_lambda': 0.0005944578516933724}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:48,480] Trial 346 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 311, 'max_depth': 7, 'learning_rate': 0.003947437264682481, 'n_estimators': 673, 'min_child_samples': 65, 'min_child_weight': 0.0021487131937128878, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008649600192096693, 'reg_lambda': 1.7145659616282984e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:49,085] Trial 347 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 146, 'max_depth': 13, 'learning_rate': 0.005932706905447653, 'n_estimators': 616, 'min_child_samples': 68, 'min_child_weight': 0.0031760598408089257, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005226343448844054, 'reg_lambda': 0.0015925009141548618}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:49,560] Trial 348 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 366, 'max_depth': 4, 'learning_rate': 0.01569702228799062, 'n_estimators': 716, 'min_child_samples': 63, 'min_child_weight': 0.0018540528688728265, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002670531791662204, 'reg_lambda': 1.3088673708569962e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:49,938] Trial 349 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 456, 'max_depth': 2, 'learning_rate': 0.010486030911794479, 'n_estimators': 607, 'min_child_samples': 56, 'min_child_weight': 0.06457653933453016, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.003913683080552142, 'reg_lambda': 0.0009797271816503934}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:50,519] Trial 350 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 425, 'max_depth': 6, 'learning_rate': 0.0024200281239388473, 'n_estimators': 663, 'min_child_samples': 71, 'min_child_weight': 0.009559706453676053, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006698528229360498, 'reg_lambda': 2.1939194001368312e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:51,463] Trial 351 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 270, 'max_depth': 10, 'learning_rate': 0.007313366583529395, 'n_estimators': 645, 'min_child_samples': 19, 'min_child_weight': 0.0026136134010401302, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001825607568921565, 'reg_lambda': 0.00042234331172022205}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:51,904] Trial 352 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 395, 'max_depth': 5, 'learning_rate': 0.020967481788457244, 'n_estimators': 572, 'min_child_samples': 61, 'min_child_weight': 0.0014543665387160723, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004729042139359498, 'reg_lambda': 0.0020977714989289663}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:52,251] Trial 353 finished with value: 0.8422205989773557 and parameters: {'num_leaves': 339, 'max_depth': 2, 'learning_rate': 0.013724809945209285, 'n_estimators': 547, 'min_child_samples': 66, 'min_child_weight': 0.004933005789565029, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0032706478069067244, 'reg_lambda': 4.9505536269105865e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:52,723] Trial 354 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 320, 'max_depth': 8, 'learning_rate': 0.032292122732966985, 'n_estimators': 517, 'min_child_samples': 93, 'min_child_weight': 0.004984614962773461, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0033231541097111825, 'reg_lambda': 4.110577114304156e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:53,154] Trial 355 finished with value: 0.8338679303851168 and parameters: {'num_leaves': 178, 'max_depth': 4, 'learning_rate': 0.016341111444334547, 'n_estimators': 544, 'min_child_samples': 47, 'min_child_weight': 0.0061730527642192895, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021364817030603603, 'reg_lambda': 9.07995990325931e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:53,500] Trial 356 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 338, 'max_depth': 2, 'learning_rate': 0.01253343357014188, 'n_estimators': 545, 'min_child_samples': 67, 'min_child_weight': 0.0010969224912293029, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.005074893260601653, 'reg_lambda': 2.7362578083224434e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:54,024] Trial 357 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 332, 'max_depth': 6, 'learning_rate': 0.024991794396214385, 'n_estimators': 581, 'min_child_samples': 51, 'min_child_weight': 0.0017755035056337203, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007841723577893207, 'reg_lambda': 6.150966845784127e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:54,428] Trial 358 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 500, 'max_depth': 4, 'learning_rate': 0.009651750056491602, 'n_estimators': 516, 'min_child_samples': 69, 'min_child_weight': 0.007919087255078254, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004215378075694222, 'reg_lambda': 0.000184666417214886}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:54,970] Trial 359 finished with value: 0.711253728645033 and parameters: {'num_leaves': 345, 'max_depth': 7, 'learning_rate': 0.41597144502274797, 'n_estimators': 559, 'min_child_samples': 65, 'min_child_weight': 0.0003516843834712143, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003012383388125329, 'reg_lambda': 0.0012604628644608006}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:55,576] Trial 360 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 323, 'max_depth': 11, 'learning_rate': 0.01633194048061404, 'n_estimators': 600, 'min_child_samples': 67, 'min_child_weight': 0.004271541245781761, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00606850818399189, 'reg_lambda': 4.3212328565345584e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:55,908] Trial 361 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 351, 'max_depth': 2, 'learning_rate': 0.041896125983639294, 'n_estimators': 499, 'min_child_samples': 70, 'min_child_weight': 0.0012985712515753152, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023025808764494684, 'reg_lambda': 5.067663300678401e-05}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:56,368] Trial 362 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 302, 'max_depth': 5, 'learning_rate': 0.012036886342676306, 'n_estimators': 575, 'min_child_samples': 72, 'min_child_weight': 0.002396724749652928, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004223659831103731, 'reg_lambda': 0.0006021727751725041}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:56,912] Trial 363 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 285, 'max_depth': 9, 'learning_rate': 0.019623708673670817, 'n_estimators': 559, 'min_child_samples': 73, 'min_child_weight': 0.005264680709155879, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0036185431478175083, 'reg_lambda': 0.0005945448190251907}. Best is trial 123 with value: 0.8422205989773557.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:57,371] Trial 364 finished with value: 0.8424571599211106 and parameters: {'num_leaves': 295, 'max_depth': 5, 'learning_rate': 0.012253253872578281, 'n_estimators': 578, 'min_child_samples': 72, 'min_child_weight': 0.0020351979689098615, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001467890210066738, 'reg_lambda': 0.0004256023946792249}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:57,944] Trial 365 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 302, 'max_depth': 12, 'learning_rate': 0.026808707854369115, 'n_estimators': 576, 'min_child_samples': 73, 'min_child_weight': 0.0020936770162304115, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009405444163080401, 'reg_lambda': 0.0003198849319235135}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:58,429] Trial 366 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 292, 'max_depth': 7, 'learning_rate': 0.013997614855164193, 'n_estimators': 544, 'min_child_samples': 72, 'min_child_weight': 0.0029689681214816787, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017662345573853265, 'reg_lambda': 0.0004381708200402138}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:58,889] Trial 367 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 297, 'max_depth': 5, 'learning_rate': 0.011897431175562287, 'n_estimators': 582, 'min_child_samples': 77, 'min_child_weight': 0.003779891451811721, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011633341832219138, 'reg_lambda': 0.00037975593581526026}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:34:59,465] Trial 368 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 282, 'max_depth': 14, 'learning_rate': 1.6240487065646884e-06, 'n_estimators': 572, 'min_child_samples': 75, 'min_child_weight': 0.003809379863343654, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012300901205745452, 'reg_lambda': 0.00024235394835669865}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:00,001] Trial 369 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 300, 'max_depth': 9, 'learning_rate': 0.012519033873377336, 'n_estimators': 529, 'min_child_samples': 77, 'min_child_weight': 0.01176612930741809, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008580406383823686, 'reg_lambda': 0.0003070212216837605}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:00,501] Trial 370 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 295, 'max_depth': 6, 'learning_rate': 0.02008263147849406, 'n_estimators': 586, 'min_child_samples': 70, 'min_child_weight': 0.004597148875139731, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012443997318988876, 'reg_lambda': 0.0003369845387207001}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:00,949] Trial 371 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 308, 'max_depth': 5, 'learning_rate': 0.03150935853818025, 'n_estimators': 558, 'min_child_samples': 53, 'min_child_weight': 0.0063499186580524515, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.0014127068064462092, 'reg_lambda': 0.0005469911719286181}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:01,462] Trial 372 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 288, 'max_depth': 8, 'learning_rate': 0.01142642688849042, 'n_estimators': 589, 'min_child_samples': 89, 'min_child_weight': 0.003299714322233128, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001592772968039272, 'reg_lambda': 0.0004912803981948015}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:02,222] Trial 373 finished with value: 0.7843572540630146 and parameters: {'num_leaves': 308, 'max_depth': 11, 'learning_rate': 0.019202400987150026, 'n_estimators': 601, 'min_child_samples': 33, 'min_child_weight': 0.0038771457686251555, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012844857852246294, 'reg_lambda': 0.0007699180151226921}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:02,653] Trial 374 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 275, 'max_depth': 5, 'learning_rate': 0.06957583566425979, 'n_estimators': 567, 'min_child_samples': 77, 'min_child_weight': 0.0017338153667715399, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009797081158433242, 'reg_lambda': 0.00046502060768821183}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:03,117] Trial 375 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 293, 'max_depth': 5, 'learning_rate': 0.013873076208780085, 'n_estimators': 583, 'min_child_samples': 74, 'min_child_weight': 0.005309402129793208, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002130187033097889, 'reg_lambda': 0.0007038749958336043}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:03,600] Trial 376 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 313, 'max_depth': 7, 'learning_rate': 0.009121472857214673, 'n_estimators': 535, 'min_child_samples': 76, 'min_child_weight': 0.002929696253804734, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017936119936169416, 'reg_lambda': 0.0009419274523336605}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:04,005] Trial 377 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 302, 'max_depth': 4, 'learning_rate': 0.025583273532679928, 'n_estimators': 555, 'min_child_samples': 71, 'min_child_weight': 0.002138817887687252, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002648411104130798, 'reg_lambda': 0.00037693256214793336}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:04,602] Trial 378 finished with value: 0.7799872591586683 and parameters: {'num_leaves': 316, 'max_depth': 9, 'learning_rate': 0.045522174705131875, 'n_estimators': 607, 'min_child_samples': 66, 'min_child_weight': 0.007795985793556741, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0022276657818416992, 'reg_lambda': 0.0006172609267713189}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:05,070] Trial 379 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 293, 'max_depth': 5, 'learning_rate': 0.01572889520246322, 'n_estimators': 588, 'min_child_samples': 64, 'min_child_weight': 0.00046779073161046827, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028830244060255275, 'reg_lambda': 0.0007548863042074944}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:05,620] Trial 380 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 280, 'max_depth': 8, 'learning_rate': 0.019987293869332762, 'n_estimators': 520, 'min_child_samples': 64, 'min_child_weight': 0.0005010000881741717, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016000390778132547, 'reg_lambda': 0.0001394852955673451}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:06,016] Trial 381 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 268, 'max_depth': 5, 'learning_rate': 0.014497915588171291, 'n_estimators': 436, 'min_child_samples': 74, 'min_child_weight': 0.0004275355530165536, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.0028935939287932123, 'reg_lambda': 0.0004970352361440265}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:06,635] Trial 382 finished with value: 0.788723176958471 and parameters: {'num_leaves': 285, 'max_depth': 10, 'learning_rate': 0.03243849532129347, 'n_estimators': 577, 'min_child_samples': 58, 'min_child_weight': 0.000384343175499227, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002733916984631782, 'reg_lambda': 0.0007833226234057579}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:07,103] Trial 383 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 293, 'max_depth': 7, 'learning_rate': 0.010821060916419071, 'n_estimators': 471, 'min_child_samples': 69, 'min_child_weight': 0.0003063146235285692, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.00100475778124187, 'reg_lambda': 0.0002558874218761256}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:07,593] Trial 384 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 304, 'max_depth': 4, 'learning_rate': 0.01731543414675394, 'n_estimators': 542, 'min_child_samples': 63, 'min_child_weight': 0.004384363707246876, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0022252483326013787, 'reg_lambda': 0.00019753582823458016}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:08,459] Trial 385 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 259, 'max_depth': 12, 'learning_rate': 0.025687285095574268, 'n_estimators': 608, 'min_child_samples': 66, 'min_child_weight': 0.0007233453242149469, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001697443692543896, 'reg_lambda': 2.635619500311401}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:08,942] Trial 386 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 294, 'max_depth': 5, 'learning_rate': 0.012701886580282777, 'n_estimators': 561, 'min_child_samples': 49, 'min_child_weight': 0.000557255316665489, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003148811065092132, 'reg_lambda': 0.0003885682179418064}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:09,577] Trial 387 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 276, 'max_depth': 7, 'learning_rate': 2.9958256263939366e-06, 'n_estimators': 622, 'min_child_samples': 60, 'min_child_weight': 0.0035263480064660854, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005983986532234077, 'reg_lambda': 0.0010865749317788915}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:10,042] Trial 388 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 303, 'max_depth': 4, 'learning_rate': 0.010701638106617808, 'n_estimators': 592, 'min_child_samples': 72, 'min_child_weight': 0.006475750637162653, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021176274644867537, 'reg_lambda': 0.000611014765290117}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:10,404] Trial 389 finished with value: 0.8246851893910718 and parameters: {'num_leaves': 326, 'max_depth': 2, 'learning_rate': 0.01876102359893564, 'n_estimators': 567, 'min_child_samples': 64, 'min_child_weight': 0.0027578132071026944, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003844651660665686, 'reg_lambda': 0.0015021633910705656}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:10,955] Trial 390 finished with value: 0.7845881595881596 and parameters: {'num_leaves': 316, 'max_depth': 44, 'learning_rate': 0.03762623539425817, 'n_estimators': 497, 'min_child_samples': 68, 'min_child_weight': 0.00043772610581588805, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.010550184477503917, 'reg_lambda': 0.0007247285532273899}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:11,514] Trial 391 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 332, 'max_depth': 10, 'learning_rate': 0.008205083458154095, 'n_estimators': 530, 'min_child_samples': 62, 'min_child_weight': 0.00031958686516075327, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002750680261192404, 'reg_lambda': 0.002922720130912795}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:12,024] Trial 392 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 286, 'max_depth': 6, 'learning_rate': 0.015065192088933246, 'n_estimators': 618, 'min_child_samples': 66, 'min_child_weight': 0.16103372211430544, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00816687792311261, 'reg_lambda': 0.0009973148497977315}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:12,458] Trial 393 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 307, 'max_depth': 4, 'learning_rate': 0.02491936892201882, 'n_estimators': 587, 'min_child_samples': 70, 'min_child_weight': 0.004969176470308589, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005187627413916865, 'reg_lambda': 0.004331300373390511}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:13,048] Trial 394 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 157, 'max_depth': 8, 'learning_rate': 3.773592265313428e-08, 'n_estimators': 555, 'min_child_samples': 60, 'min_child_weight': 0.0006171539950920292, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012670208442626114, 'reg_lambda': 0.00039002277098098355}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:13,671] Trial 395 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 323, 'max_depth': 15, 'learning_rate': 0.010101850802141269, 'n_estimators': 605, 'min_child_samples': 64, 'min_child_weight': 0.0037535172445191645, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0038079278475826677, 'reg_lambda': 0.0013380906085229056}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:13,993] Trial 396 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 294, 'max_depth': 2, 'learning_rate': 2.0827725834980763e-07, 'n_estimators': 407, 'min_child_samples': 55, 'min_child_weight': 0.00233973962889638, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002014088523618056, 'reg_lambda': 0.000524970748240207}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:14,439] Trial 397 finished with value: 0.828254477109439 and parameters: {'num_leaves': 337, 'max_depth': 5, 'learning_rate': 0.015415694403316782, 'n_estimators': 577, 'min_child_samples': 98, 'min_child_weight': 0.002828789147744764, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.002956398091092037, 'reg_lambda': 0.0008391164799950349}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:15,008] Trial 398 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 134, 'max_depth': 7, 'learning_rate': 0.008899070389529352, 'n_estimators': 596, 'min_child_samples': 58, 'min_child_weight': 0.0011535459796926707, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0006780140280012775, 'reg_lambda': 0.1426561262189373}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:15,379] Trial 399 finished with value: 0.828254477109439 and parameters: {'num_leaves': 311, 'max_depth': 2, 'learning_rate': 0.02036117893486099, 'n_estimators': 629, 'min_child_samples': 86, 'min_child_weight': 0.001581262159909531, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.006691567847807419, 'reg_lambda': 0.0006613442704097683}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:15,806] Trial 400 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 331, 'max_depth': 4, 'learning_rate': 0.007361693354096582, 'n_estimators': 542, 'min_child_samples': 75, 'min_child_weight': 0.009458593653255812, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004552517924650784, 'reg_lambda': 0.0021631540153732387}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:16,354] Trial 401 finished with value: 0.8018018018018018 and parameters: {'num_leaves': 322, 'max_depth': 10, 'learning_rate': 0.0143878560348929, 'n_estimators': 516, 'min_child_samples': 67, 'min_child_weight': 0.0008313905632526218, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024681992644240555, 'reg_lambda': 0.00011384224987344337}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:16,773] Trial 402 finished with value: 0.8115146396396395 and parameters: {'num_leaves': 273, 'max_depth': 5, 'learning_rate': 0.04157739529356097, 'n_estimators': 450, 'min_child_samples': 63, 'min_child_weight': 0.005718697857730466, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0037488321059936133, 'reg_lambda': 0.0011305819421545667}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:17,140] Trial 403 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 340, 'max_depth': 2, 'learning_rate': 0.010780577985471666, 'n_estimators': 574, 'min_child_samples': 65, 'min_child_weight': 0.0019905232508269414, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014513954994076995, 'reg_lambda': 0.00029894457448167647}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:17,687] Trial 404 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 300, 'max_depth': 7, 'learning_rate': 0.025317120462772832, 'n_estimators': 620, 'min_child_samples': 79, 'min_child_weight': 0.003673841600334744, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0055569765539215474, 'reg_lambda': 0.0017317364600772439}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:18,071] Trial 405 finished with value: 0.788723176958471 and parameters: {'num_leaves': 283, 'max_depth': 4, 'learning_rate': 0.09869655935647037, 'n_estimators': 486, 'min_child_samples': 72, 'min_child_weight': 0.003015386286934216, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0034546368881934668, 'reg_lambda': 0.0006088172467647356}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:18,657] Trial 406 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 359, 'max_depth': 8, 'learning_rate': 0.007428039910686755, 'n_estimators': 599, 'min_child_samples': 68, 'min_child_weight': 0.004588942168251238, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005004714957937672, 'reg_lambda': 0.00045086899459150463}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:19,011] Trial 407 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 312, 'max_depth': 2, 'learning_rate': 0.013296005914859424, 'n_estimators': 548, 'min_child_samples': 61, 'min_child_weight': 0.00153561341665629, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018798192096263309, 'reg_lambda': 0.0008800563434013461}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:19,531] Trial 408 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 115, 'max_depth': 6, 'learning_rate': 0.019029907227509087, 'n_estimators': 631, 'min_child_samples': 70, 'min_child_weight': 0.0023146963459600677, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007096505440599876, 'reg_lambda': 0.0011244830760718991}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:19,983] Trial 409 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 87, 'max_depth': 4, 'learning_rate': 0.009268524041323032, 'n_estimators': 573, 'min_child_samples': 63, 'min_child_weight': 0.007385151533337377, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028847361687838967, 'reg_lambda': 6.547179672661526e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:20,617] Trial 410 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 347, 'max_depth': 11, 'learning_rate': 0.004414058670837473, 'n_estimators': 604, 'min_child_samples': 65, 'min_child_weight': 0.001130675640183409, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004293670042859469, 'reg_lambda': 0.0013977532142165094}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:20,977] Trial 411 finished with value: 0.8018018018018018 and parameters: {'num_leaves': 327, 'max_depth': 2, 'learning_rate': 0.22921262111832025, 'n_estimators': 553, 'min_child_samples': 60, 'min_child_weight': 0.8696567877176214, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024661476283817743, 'reg_lambda': 0.10416553889747548}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:21,473] Trial 412 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 318, 'max_depth': 6, 'learning_rate': 0.02669928275727132, 'n_estimators': 587, 'min_child_samples': 67, 'min_child_weight': 0.0020457967298468482, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0032742047925214935, 'reg_lambda': 0.0005228615565443151}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:22,045] Trial 413 finished with value: 0.8058318352269737 and parameters: {'num_leaves': 338, 'max_depth': 9, 'learning_rate': 0.012153634199447216, 'n_estimators': 529, 'min_child_samples': 62, 'min_child_weight': 0.003467767278740796, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005590550918818372, 'reg_lambda': 0.0003617561988266945}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:22,488] Trial 414 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 265, 'max_depth': 4, 'learning_rate': 0.006458458179419085, 'n_estimators': 616, 'min_child_samples': 73, 'min_child_weight': 0.00271895386927822, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016593133394912278, 'reg_lambda': 0.0007828841103714775}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:23,045] Trial 415 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 305, 'max_depth': 7, 'learning_rate': 0.017970458569704317, 'n_estimators': 563, 'min_child_samples': 56, 'min_child_weight': 0.004474849175123798, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.01000890357002324, 'reg_lambda': 0.010840053299391667}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:23,413] Trial 416 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 244, 'max_depth': 2, 'learning_rate': 0.05865612249976275, 'n_estimators': 581, 'min_child_samples': 69, 'min_child_weight': 0.00022943340460436214, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004257060242619736, 'reg_lambda': 0.0006069779171097841}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:23,934] Trial 417 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 292, 'max_depth': 5, 'learning_rate': 0.03428644492052516, 'n_estimators': 507, 'min_child_samples': 8, 'min_child_weight': 0.006139656124226233, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00230601948525065, 'reg_lambda': 0.00018004129828652252}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:24,580] Trial 418 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 349, 'max_depth': 13, 'learning_rate': 0.008484290290650379, 'n_estimators': 626, 'min_child_samples': 65, 'min_child_weight': 0.0014730899210962198, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009749347610735257, 'reg_lambda': 0.0017502157091637046}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:25,207] Trial 419 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 331, 'max_depth': 9, 'learning_rate': 0.013444755185805912, 'n_estimators': 593, 'min_child_samples': 59, 'min_child_weight': 0.0005200429490747267, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031426774586333136, 'reg_lambda': 0.0010892360519023847}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:25,670] Trial 420 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 360, 'max_depth': 4, 'learning_rate': 0.004526899856987706, 'n_estimators': 608, 'min_child_samples': 63, 'min_child_weight': 0.0019064030580916455, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007527914147671825, 'reg_lambda': 0.00024333985496146707}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:25,944] Trial 421 finished with value: 0.7742931543489272 and parameters: {'num_leaves': 318, 'max_depth': 2, 'learning_rate': 0.006985023075050628, 'n_estimators': 221, 'min_child_samples': 75, 'min_child_weight': 0.0025134786875547375, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 2.330804761165502e-05, 'reg_lambda': 0.21677713751441838}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:26,446] Trial 422 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 368, 'max_depth': 6, 'learning_rate': 0.0101229189350988, 'n_estimators': 631, 'min_child_samples': 95, 'min_child_weight': 0.000994541646765455, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004097736686002826, 'reg_lambda': 0.014625964524917486}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:26,941] Trial 423 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 298, 'max_depth': 7, 'learning_rate': 0.0208282336921219, 'n_estimators': 541, 'min_child_samples': 71, 'min_child_weight': 0.003385851331094746, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020147922734735173, 'reg_lambda': 0.0004443668540277611}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:27,380] Trial 424 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 339, 'max_depth': 4, 'learning_rate': 0.015683781122784787, 'n_estimators': 560, 'min_child_samples': 52, 'min_child_weight': 0.0051769183036614996, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0058175113051683195, 'reg_lambda': 0.0007728039907257127}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:27,716] Trial 425 finished with value: 0.824887818514042 and parameters: {'num_leaves': 284, 'max_depth': 2, 'learning_rate': 0.010833403974942795, 'n_estimators': 421, 'min_child_samples': 66, 'min_child_weight': 0.00028362012078785205, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 6.892940762455534, 'reg_lambda': 0.0009742928494141915}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:28,286] Trial 426 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 330, 'max_depth': 10, 'learning_rate': 0.006107055636273779, 'n_estimators': 581, 'min_child_samples': 61, 'min_child_weight': 0.0012846727142963356, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 3.057291299877388, 'reg_lambda': 8.273826278085229e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:28,769] Trial 427 finished with value: 0.8018018018018018 and parameters: {'num_leaves': 348, 'max_depth': 5, 'learning_rate': 0.02595157243041085, 'n_estimators': 608, 'min_child_samples': 68, 'min_child_weight': 0.0007488018342236154, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001420534145679813, 'reg_lambda': 0.30298627581038956}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:29,259] Trial 428 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 307, 'max_depth': 8, 'learning_rate': 0.01456786258647348, 'n_estimators': 467, 'min_child_samples': 64, 'min_child_weight': 0.0041760934405431485, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0030732944848909224, 'reg_lambda': 0.0014958722447303355}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:29,617] Trial 429 finished with value: 0.7700534385316994 and parameters: {'num_leaves': 320, 'max_depth': 2, 'learning_rate': 0.003213702907392403, 'n_estimators': 514, 'min_child_samples': 58, 'min_child_weight': 0.001792920067811293, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004412560473642579, 'reg_lambda': 0.0006254726487709732}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:30,229] Trial 430 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 354, 'max_depth': 5, 'learning_rate': 6.739820932553264e-05, 'n_estimators': 637, 'min_child_samples': 62, 'min_child_weight': 0.00243319820558372, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024015792191209007, 'reg_lambda': 0.17842590259273447}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:30,812] Trial 431 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 335, 'max_depth': 7, 'learning_rate': 0.008686550827571159, 'n_estimators': 569, 'min_child_samples': 50, 'min_child_weight': 0.0031412932919651208, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007959641311406815, 'reg_lambda': 0.002119312396093022}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:31,188] Trial 432 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 343, 'max_depth': 2, 'learning_rate': 0.03939071358722717, 'n_estimators': 594, 'min_child_samples': 66, 'min_child_weight': 0.001612747591463368, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003480284614911025, 'reg_lambda': 0.007077802939836376}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:31,766] Trial 433 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 253, 'max_depth': 31, 'learning_rate': 1.0491731277426028e-05, 'n_estimators': 540, 'min_child_samples': 69, 'min_child_weight': 0.0004138959619402085, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005580340568646802, 'reg_lambda': 0.00033593134382130105}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:32,434] Trial 434 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 277, 'max_depth': 11, 'learning_rate': 0.02013562440070322, 'n_estimators': 614, 'min_child_samples': 54, 'min_child_weight': 0.0063058407414239735, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0027209285403298786, 'reg_lambda': 1.0123990535836343e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:32,910] Trial 435 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 313, 'max_depth': 4, 'learning_rate': 0.00562653005591445, 'n_estimators': 641, 'min_child_samples': 64, 'min_child_weight': 0.004022621482896602, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.5284776600533633, 'reg_lambda': 0.0007672152150011897}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:33,415] Trial 436 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 327, 'max_depth': 6, 'learning_rate': 0.011219690905899894, 'n_estimators': 582, 'min_child_samples': 73, 'min_child_weight': 0.0021310539894576984, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00425265605518573, 'reg_lambda': 0.0029017360804186043}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:33,654] Trial 437 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 125, 'max_depth': 4, 'learning_rate': 0.007759695978405909, 'n_estimators': 13, 'min_child_samples': 61, 'min_child_weight': 0.0029659825263797933, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011963371505235504, 'reg_lambda': 0.0005349850120887801}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:34,211] Trial 438 finished with value: 0.780204207675669 and parameters: {'num_leaves': 298, 'max_depth': 9, 'learning_rate': 0.029451645058948397, 'n_estimators': 534, 'min_child_samples': 67, 'min_child_weight': 0.0052893902122100175, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0019487091550912927, 'reg_lambda': 0.0012027239901402722}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:34,570] Trial 439 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 369, 'max_depth': 2, 'learning_rate': 0.015550605127013705, 'n_estimators': 556, 'min_child_samples': 57, 'min_child_weight': 0.0009260378337881558, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0064355776157015085, 'reg_lambda': 1.2984828372618448e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:35,131] Trial 440 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 356, 'max_depth': 7, 'learning_rate': 0.011714895994630553, 'n_estimators': 597, 'min_child_samples': 71, 'min_child_weight': 0.01323356955268001, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00046401039845801896, 'reg_lambda': 3.0445880189327362e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:35,607] Trial 441 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 69, 'max_depth': 4, 'learning_rate': 0.004195206339707468, 'n_estimators': 623, 'min_child_samples': 60, 'min_child_weight': 0.00930592367858705, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0035014878093810025, 'reg_lambda': 0.0009278332626428962}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:36,211] Trial 442 finished with value: 0.8018018018018018 and parameters: {'num_leaves': 337, 'max_depth': 13, 'learning_rate': 0.018632201341126066, 'n_estimators': 563, 'min_child_samples': 63, 'min_child_weight': 0.001251126026003207, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0049356063157746, 'reg_lambda': 0.11279170284307438}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:36,555] Trial 443 finished with value: 0.8159077066429673 and parameters: {'num_leaves': 213, 'max_depth': 2, 'learning_rate': 0.007021539436491123, 'n_estimators': 488, 'min_child_samples': 76, 'min_child_weight': 0.0027209210419723816, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.011907153388437858, 'reg_lambda': 4.365955440059255}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:37,081] Trial 444 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 288, 'max_depth': 6, 'learning_rate': 0.009484572497253074, 'n_estimators': 610, 'min_child_samples': 65, 'min_child_weight': 0.0017962948239335745, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002470211458700188, 'reg_lambda': 0.00042021848266564994}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:37,710] Trial 445 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 325, 'max_depth': 9, 'learning_rate': 0.024556140835820882, 'n_estimators': 644, 'min_child_samples': 69, 'min_child_weight': 0.0006268270930632585, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016970437648213977, 'reg_lambda': 1.565843367173923e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:38,199] Trial 446 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 95, 'max_depth': 5, 'learning_rate': 0.005256817688469843, 'n_estimators': 581, 'min_child_samples': 67, 'min_child_weight': 0.003658236147875213, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003351228096798882, 'reg_lambda': 0.0007153057185617634}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:38,563] Trial 447 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 179, 'max_depth': 2, 'learning_rate': 9.47826349936905e-07, 'n_estimators': 531, 'min_child_samples': 63, 'min_child_weight': 0.00034594493209264205, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005105859644118745, 'reg_lambda': 1.999643738403806e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:39,050] Trial 448 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 307, 'max_depth': 7, 'learning_rate': 0.014419912016456123, 'n_estimators': 445, 'min_child_samples': 59, 'min_child_weight': 0.0022836814520432536, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.009279345561270544, 'reg_lambda': 0.0013424340919024988}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:39,557] Trial 449 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 348, 'max_depth': 4, 'learning_rate': 0.0029118893100193275, 'n_estimators': 589, 'min_child_samples': 66, 'min_child_weight': 0.004636255943473951, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025831605126442276, 'reg_lambda': 0.0002625591513005116}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:39,976] Trial 450 finished with value: 0.820490132990133 and parameters: {'num_leaves': 362, 'max_depth': 2, 'learning_rate': 0.009191903921629717, 'n_estimators': 552, 'min_child_samples': 88, 'min_child_weight': 0.0014674615423401513, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.003979233557545417, 'reg_lambda': 4.8189303252327874e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:40,543] Trial 451 finished with value: 0.7837837837837838 and parameters: {'num_leaves': 317, 'max_depth': 11, 'learning_rate': 0.042857538004740216, 'n_estimators': 629, 'min_child_samples': 92, 'min_child_weight': 0.00769263480228249, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.0018710820142789123, 'reg_lambda': 0.0005101505433368611}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:40,996] Trial 452 finished with value: 0.8292828261332198 and parameters: {'num_leaves': 382, 'max_depth': 5, 'learning_rate': 0.018545774776946456, 'n_estimators': 511, 'min_child_samples': 47, 'min_child_weight': 0.0010977682373747818, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006733115791808374, 'reg_lambda': 3.506930084815849e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:41,654] Trial 453 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 340, 'max_depth': 37, 'learning_rate': 0.012897901392408364, 'n_estimators': 607, 'min_child_samples': 71, 'min_child_weight': 0.0032348996835858354, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0029990452193821553, 'reg_lambda': 0.004731352027616769}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:42,260] Trial 454 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 327, 'max_depth': 8, 'learning_rate': 0.006441617196680542, 'n_estimators': 570, 'min_child_samples': 62, 'min_child_weight': 0.002082644198405723, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004388022306832966, 'reg_lambda': 0.0008975267438652413}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:42,734] Trial 455 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 299, 'max_depth': 4, 'learning_rate': 0.004464116685118011, 'n_estimators': 596, 'min_child_samples': 65, 'min_child_weight': 0.0024570086099881313, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001328273085717746, 'reg_lambda': 0.00182154685006855}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:43,132] Trial 456 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 271, 'max_depth': 2, 'learning_rate': 0.9783316529259753, 'n_estimators': 649, 'min_child_samples': 74, 'min_child_weight': 0.0014753034808297494, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.000802361211372544, 'reg_lambda': 0.0006115881453172059}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:43,721] Trial 457 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 202, 'max_depth': 7, 'learning_rate': 0.026537691564989238, 'n_estimators': 619, 'min_child_samples': 60, 'min_child_weight': 0.004193171368139374, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002229027823990791, 'reg_lambda': 0.14741142449107153}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:44,186] Trial 458 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 350, 'max_depth': 5, 'learning_rate': 0.010273280616192999, 'n_estimators': 550, 'min_child_samples': 78, 'min_child_weight': 0.005541004520008122, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00318722119999053, 'reg_lambda': 0.00114977001470749}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:44,787] Trial 459 finished with value: 0.8014869384434602 and parameters: {'num_leaves': 313, 'max_depth': 16, 'learning_rate': 0.015895233568423445, 'n_estimators': 575, 'min_child_samples': 68, 'min_child_weight': 0.0008524164680708176, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.005770740850890473, 'reg_lambda': 0.0003725793103823051}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:45,124] Trial 460 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 373, 'max_depth': 9, 'learning_rate': 0.008141298014450531, 'n_estimators': 161, 'min_child_samples': 64, 'min_child_weight': 0.002942953272710201, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004241433636814228, 'reg_lambda': 1.8045116125207494e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:45,510] Trial 461 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 35, 'max_depth': 2, 'learning_rate': 0.032479017789454626, 'n_estimators': 630, 'min_child_samples': 57, 'min_child_weight': 0.000502265232375123, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.007892213616000211, 'reg_lambda': 1.3584480478395634e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:45,960] Trial 462 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 291, 'max_depth': 5, 'learning_rate': 0.02061630263816374, 'n_estimators': 524, 'min_child_samples': 83, 'min_child_weight': 0.0019398652753953077, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0026595115259393535, 'reg_lambda': 0.00015336747509209176}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:46,540] Trial 463 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 337, 'max_depth': 7, 'learning_rate': 0.012367396426245023, 'n_estimators': 598, 'min_child_samples': 62, 'min_child_weight': 0.003746076265075778, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015327921372401206, 'reg_lambda': 0.4881872492394297}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:46,997] Trial 464 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 359, 'max_depth': 4, 'learning_rate': 0.006462190251590046, 'n_estimators': 567, 'min_child_samples': 70, 'min_child_weight': 0.0017219174012431328, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003623501491871967, 'reg_lambda': 0.0007958845416748652}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:47,396] Trial 465 finished with value: 0.8050772180423282 and parameters: {'num_leaves': 326, 'max_depth': 2, 'learning_rate': 0.004271732722984842, 'n_estimators': 654, 'min_child_samples': 67, 'min_child_weight': 0.007154730784994242, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005511639976077507, 'reg_lambda': 0.0005372855644761036}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:48,017] Trial 466 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 230, 'max_depth': 12, 'learning_rate': 0.012470827497947527, 'n_estimators': 581, 'min_child_samples': 64, 'min_child_weight': 0.00019359489652609778, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020695707062325028, 'reg_lambda': 0.2691345978570773}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:48,696] Trial 467 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 345, 'max_depth': 103, 'learning_rate': 0.0080509455798735, 'n_estimators': 620, 'min_child_samples': 61, 'min_child_weight': 0.0026805803105483285, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003153940080803929, 'reg_lambda': 0.001438714923308567}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:49,174] Trial 468 finished with value: 0.8246851893910718 and parameters: {'num_leaves': 307, 'max_depth': 6, 'learning_rate': 0.018329925366385866, 'n_estimators': 493, 'min_child_samples': 54, 'min_child_weight': 0.0011648885928713117, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004304519125599468, 'reg_lambda': 0.00011260722677493145}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:49,799] Trial 469 finished with value: 0.7753721396489734 and parameters: {'num_leaves': 331, 'max_depth': 10, 'learning_rate': 0.05343279066266611, 'n_estimators': 546, 'min_child_samples': 65, 'min_child_weight': 0.00513332207148456, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010188226356613239, 'reg_lambda': 0.003662698262091952}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:50,270] Trial 470 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 261, 'max_depth': 4, 'learning_rate': 0.010718029120932867, 'n_estimators': 607, 'min_child_samples': 73, 'min_child_weight': 0.0034333031840338263, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0058298807257701115, 'reg_lambda': 2.8814675041072647e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:50,621] Trial 471 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 22, 'max_depth': 2, 'learning_rate': 0.029422702693526887, 'n_estimators': 464, 'min_child_samples': 69, 'min_child_weight': 0.0022661484410015573, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.09776028342097495, 'reg_lambda': 0.0009562921651393048}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:51,278] Trial 472 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 280, 'max_depth': 8, 'learning_rate': 0.005785477235811815, 'n_estimators': 634, 'min_child_samples': 59, 'min_child_weight': 0.0014351927068749482, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023537270257596617, 'reg_lambda': 0.002714037930410378}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:51,798] Trial 473 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 139, 'max_depth': 5, 'learning_rate': 0.003095183428385231, 'n_estimators': 590, 'min_child_samples': 63, 'min_child_weight': 0.004651644710514838, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007561875582147836, 'reg_lambda': 2.2646575606792e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:52,177] Trial 474 finished with value: 0.8246851893910718 and parameters: {'num_leaves': 320, 'max_depth': 2, 'learning_rate': 0.015535424464979622, 'n_estimators': 560, 'min_child_samples': 67, 'min_child_weight': 0.0019478045559755339, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0035272929321329273, 'reg_lambda': 0.000296295045619834}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:52,666] Trial 475 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 344, 'max_depth': 6, 'learning_rate': 0.02101048297625223, 'n_estimators': 536, 'min_child_samples': 61, 'min_child_weight': 0.0028883206401104687, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016956539862395808, 'reg_lambda': 0.0006034021891871201}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:53,251] Trial 476 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 297, 'max_depth': 9, 'learning_rate': 0.00870276000515837, 'n_estimators': 605, 'min_child_samples': 72, 'min_child_weight': 0.0006700305553731506, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004804376312238923, 'reg_lambda': 6.836824336695369}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:53,701] Trial 477 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 162, 'max_depth': 4, 'learning_rate': 0.014226104518866267, 'n_estimators': 580, 'min_child_samples': 66, 'min_child_weight': 0.001032746170440359, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028523168952283525, 'reg_lambda': 6.154220598481193e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:54,319] Trial 478 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 356, 'max_depth': 7, 'learning_rate': 0.0055969348152141545, 'n_estimators': 656, 'min_child_samples': 76, 'min_child_weight': 0.006625791898484069, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004403777198874277, 'reg_lambda': 0.00041362498784254206}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:54,685] Trial 479 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 336, 'max_depth': 2, 'learning_rate': 0.009110170703959107, 'n_estimators': 514, 'min_child_samples': 63, 'min_child_weight': 0.003864359489995793, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002245055065403545, 'reg_lambda': 1.261817804449661e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:55,191] Trial 480 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 310, 'max_depth': 5, 'learning_rate': 0.02502001643520384, 'n_estimators': 623, 'min_child_samples': 52, 'min_child_weight': 0.0015697197105004812, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0065923126437373875, 'reg_lambda': 0.0010101261346496485}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:55,816] Trial 481 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 321, 'max_depth': 56, 'learning_rate': 0.003973801311579655, 'n_estimators': 595, 'min_child_samples': 69, 'min_child_weight': 0.024144478697728494, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.009684680957517594, 'reg_lambda': 0.0007730964389446992}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:56,212] Trial 482 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 285, 'max_depth': 4, 'learning_rate': 0.012722564680691615, 'n_estimators': 412, 'min_child_samples': 58, 'min_child_weight': 0.00027300186227807987, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0034455069379553515, 'reg_lambda': 0.0019232461030070703}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:56,811] Trial 483 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 348, 'max_depth': 8, 'learning_rate': 0.0074660305301787805, 'n_estimators': 556, 'min_child_samples': 65, 'min_child_weight': 0.0024273193220163613, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001307049504695079, 'reg_lambda': 1.868903297915111e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:57,166] Trial 484 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 363, 'max_depth': 2, 'learning_rate': 0.01909853634421329, 'n_estimators': 438, 'min_child_samples': 71, 'min_child_weight': 0.003371861997930859, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005091514286046622, 'reg_lambda': 0.0004459123988929934}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:57,849] Trial 485 finished with value: 0.788723176958471 and parameters: {'num_leaves': 303, 'max_depth': 11, 'learning_rate': 0.03275757998078428, 'n_estimators': 642, 'min_child_samples': 62, 'min_child_weight': 0.000443158442062556, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028689838665980766, 'reg_lambda': 0.8528543940769985}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:58,448] Trial 486 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 374, 'max_depth': 6, 'learning_rate': 3.276161897168665e-05, 'n_estimators': 573, 'min_child_samples': 68, 'min_child_weight': 0.0013242045735734865, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001997447699432459, 'reg_lambda': 0.0012868578734448633}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:59,123] Trial 487 finished with value: 0.8058318352269737 and parameters: {'num_leaves': 334, 'max_depth': 14, 'learning_rate': 0.010415953796719921, 'n_estimators': 613, 'min_child_samples': 55, 'min_child_weight': 0.010052076459401359, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.0034716251392993207, 'reg_lambda': 3.0645679456599236e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:35:59,591] Trial 488 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 320, 'max_depth': 4, 'learning_rate': 0.002402243813419342, 'n_estimators': 530, 'min_child_samples': 60, 'min_child_weight': 0.0019388517168376107, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006804875554962961, 'reg_lambda': 0.0006501911502985538}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:00,008] Trial 489 finished with value: 0.828254477109439 and parameters: {'num_leaves': 344, 'max_depth': 2, 'learning_rate': 0.005133186138550481, 'n_estimators': 595, 'min_child_samples': 64, 'min_child_weight': 0.005564628874958183, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024696766307828726, 'reg_lambda': 1.475557990515863e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:00,623] Trial 490 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 79, 'max_depth': 8, 'learning_rate': 0.015540571303350653, 'n_estimators': 561, 'min_child_samples': 45, 'min_child_weight': 0.000843133867477033, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00430382473935579, 'reg_lambda': 0.0010722239023062319}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:01,209] Trial 491 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 292, 'max_depth': 6, 'learning_rate': 0.006870153815474093, 'n_estimators': 633, 'min_child_samples': 66, 'min_child_weight': 0.002711134861087358, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001627852077961909, 'reg_lambda': 0.19617754260165843}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:01,674] Trial 492 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 330, 'max_depth': 4, 'learning_rate': 0.010630407446869005, 'n_estimators': 581, 'min_child_samples': 62, 'min_child_weight': 0.00412366494759296, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00010680420289649372, 'reg_lambda': 0.0015700745406480947}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:02,209] Trial 493 finished with value: 0.788723176958471 and parameters: {'num_leaves': 387, 'max_depth': 62, 'learning_rate': 0.07667483284351506, 'n_estimators': 484, 'min_child_samples': 75, 'min_child_weight': 0.0023104506815116205, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005489686974616349, 'reg_lambda': 9.080072107413174e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:02,613] Trial 494 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 314, 'max_depth': 2, 'learning_rate': 0.02291803635378623, 'n_estimators': 655, 'min_child_samples': 67, 'min_child_weight': 0.0017045790640309428, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.0028268832365570483, 'reg_lambda': 2.1340729586238455e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:03,218] Trial 495 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 363, 'max_depth': 10, 'learning_rate': 0.014355793234117651, 'n_estimators': 547, 'min_child_samples': 70, 'min_child_weight': 0.00035346523793818496, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0035072508792941257, 'reg_lambda': 0.0008001431723178298}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:03,840] Trial 496 finished with value: 0.7974449198985706 and parameters: {'num_leaves': 339, 'max_depth': 27, 'learning_rate': 0.04755442682561397, 'n_estimators': 618, 'min_child_samples': 80, 'min_child_weight': 0.003214801547213225, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.012646806958551008, 'reg_lambda': 1.7138513855113773}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:04,454] Trial 497 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 354, 'max_depth': 6, 'learning_rate': 0.008207033941961173, 'n_estimators': 600, 'min_child_samples': 41, 'min_child_weight': 0.0011454691833441375, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004466807897025972, 'reg_lambda': 3.888695147569982e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:04,889] Trial 498 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 301, 'max_depth': 4, 'learning_rate': 0.0038711468878827506, 'n_estimators': 501, 'min_child_samples': 64, 'min_child_weight': 0.004554630801569872, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008971876168733411, 'reg_lambda': 0.00023146256018805424}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:05,473] Trial 499 finished with value: 0.7843572540630146 and parameters: {'num_leaves': 52, 'max_depth': 8, 'learning_rate': 0.03158440091454087, 'n_estimators': 567, 'min_child_samples': 57, 'min_child_weight': 0.006330468243831085, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020924516386789473, 'reg_lambda': 0.000516253946642579}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:05,841] Trial 500 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 272, 'max_depth': 2, 'learning_rate': 0.019318527462584736, 'n_estimators': 526, 'min_child_samples': 60, 'min_child_weight': 0.0005956935295981566, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011748569029306414, 'reg_lambda': 0.12894455638287836}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:06,422] Trial 501 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 322, 'max_depth': 7, 'learning_rate': 0.012547821474611443, 'n_estimators': 633, 'min_child_samples': 72, 'min_child_weight': 0.008346882231989683, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.006518741213431375, 'reg_lambda': 0.0024503571001394716}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:06,916] Trial 502 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 352, 'max_depth': 5, 'learning_rate': 0.00674455347751687, 'n_estimators': 585, 'min_child_samples': 65, 'min_child_weight': 0.0023272161396661155, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.000708880332734447, 'reg_lambda': 0.0003746693902490859}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:07,314] Trial 503 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 327, 'max_depth': 2, 'learning_rate': 0.010499929305441372, 'n_estimators': 616, 'min_child_samples': 62, 'min_child_weight': 0.0014770841901390994, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003987682650179611, 'reg_lambda': 1.1676640371613609e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:07,911] Trial 504 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 289, 'max_depth': 11, 'learning_rate': 0.01933508919931212, 'n_estimators': 557, 'min_child_samples': 68, 'min_child_weight': 0.0031208656045832502, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0026517951781806306, 'reg_lambda': 0.0006515946022707059}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:08,431] Trial 505 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 336, 'max_depth': 5, 'learning_rate': 0.0061337106462076635, 'n_estimators': 602, 'min_child_samples': 50, 'min_child_weight': 0.0018183168591262503, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.005089987744652852, 'reg_lambda': 1.7336689280043464e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:09,042] Trial 506 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 314, 'max_depth': 9, 'learning_rate': 0.014582372474907151, 'n_estimators': 575, 'min_child_samples': 59, 'min_child_weight': 0.00410099885320153, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016140199444841274, 'reg_lambda': 0.0010221749427222183}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:09,532] Trial 507 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 305, 'max_depth': 4, 'learning_rate': 0.009526044812268389, 'n_estimators': 659, 'min_child_samples': 66, 'min_child_weight': 0.002748277598563967, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0033298575858121933, 'reg_lambda': 1.0157969035238776e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:09,931] Trial 508 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 366, 'max_depth': 2, 'learning_rate': 0.00012219343778081818, 'n_estimators': 547, 'min_child_samples': 63, 'min_child_weight': 0.0010692697569402712, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020800599469432404, 'reg_lambda': 5.081145263935835e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:10,555] Trial 509 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 279, 'max_depth': 7, 'learning_rate': 0.004630707494208202, 'n_estimators': 631, 'min_child_samples': 70, 'min_child_weight': 0.005258891729116038, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003948851513173171, 'reg_lambda': 2.829330863503442e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:11,068] Trial 510 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 348, 'max_depth': 5, 'learning_rate': 0.024529055325682614, 'n_estimators': 591, 'min_child_samples': 74, 'min_child_weight': 0.0021213251814575615, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002636507564621786, 'reg_lambda': 0.00029828319826322234}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:11,493] Trial 511 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 114, 'max_depth': 2, 'learning_rate': 0.03764007684673126, 'n_estimators': 683, 'min_child_samples': 61, 'min_child_weight': 0.001456214543481388, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005606559959611111, 'reg_lambda': 0.0007867783282945587}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:12,026] Trial 512 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 329, 'max_depth': 7, 'learning_rate': 0.007942583053607706, 'n_estimators': 514, 'min_child_samples': 64, 'min_child_weight': 0.0007603026694513078, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007105423365884212, 'reg_lambda': 0.07261264919739156}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:12,507] Trial 513 finished with value: 0.7864739620595648 and parameters: {'num_leaves': 401, 'max_depth': 4, 'learning_rate': 0.001800532860724638, 'n_estimators': 614, 'min_child_samples': 97, 'min_child_weight': 0.039185379037378, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0032443914534877813, 'reg_lambda': 0.0013416172905259516}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:13,003] Trial 514 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 148, 'max_depth': 13, 'learning_rate': 0.013567763076895126, 'n_estimators': 534, 'min_child_samples': 90, 'min_child_weight': 0.003900678523235444, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009996847546108836, 'reg_lambda': 0.0004715909350261493}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:13,728] Trial 515 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 340, 'max_depth': 9, 'learning_rate': 0.0031641369090282603, 'n_estimators': 744, 'min_child_samples': 68, 'min_child_weight': 0.0031053770967007905, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.004453380127753681, 'reg_lambda': 0.35487206042869845}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:14,130] Trial 516 finished with value: 0.833675692499222 and parameters: {'num_leaves': 298, 'max_depth': 2, 'learning_rate': 0.01891607365714947, 'n_estimators': 645, 'min_child_samples': 56, 'min_child_weight': 0.001873516036319108, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018361094877327308, 'reg_lambda': 2.3512240604339286e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:14,652] Trial 517 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 312, 'max_depth': 6, 'learning_rate': 0.005265668516138133, 'n_estimators': 572, 'min_child_samples': 66, 'min_child_weight': 0.0025226528807977796, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0026495361587504903, 'reg_lambda': 1.244345339277723}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:15,126] Trial 518 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 63, 'max_depth': 4, 'learning_rate': 0.010880925501818347, 'n_estimators': 595, 'min_child_samples': 72, 'min_child_weight': 0.006420534224072092, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008987715206764344, 'reg_lambda': 0.00018592876028383835}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:15,653] Trial 519 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 344, 'max_depth': 6, 'learning_rate': 0.02566788261293838, 'n_estimators': 617, 'min_child_samples': 64, 'min_child_weight': 0.00497938587963355, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.3280689097295467, 'reg_lambda': 1.5914046591464706e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:16,298] Trial 520 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 373, 'max_depth': 51, 'learning_rate': 0.007879345549861864, 'n_estimators': 555, 'min_child_samples': 61, 'min_child_weight': 0.00052481561444971, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0036571330866746157, 'reg_lambda': 0.002134039799213797}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:16,674] Trial 521 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 324, 'max_depth': 2, 'learning_rate': 1.1818470665309528e-07, 'n_estimators': 472, 'min_child_samples': 77, 'min_child_weight': 0.0014335682475668373, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005271409998402839, 'reg_lambda': 0.0006495718333931475}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:17,344] Trial 522 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 355, 'max_depth': 10, 'learning_rate': 0.015487673080617971, 'n_estimators': 579, 'min_child_samples': 58, 'min_child_weight': 0.0035914485904135957, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014893988077231122, 'reg_lambda': 0.0009266102733039615}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:17,845] Trial 523 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 10, 'max_depth': 5, 'learning_rate': 0.010561581460843935, 'n_estimators': 639, 'min_child_samples': 70, 'min_child_weight': 0.0009155434271360553, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023482207988016713, 'reg_lambda': 0.24978266155123788}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:18,458] Trial 524 finished with value: 0.5750344939534129 and parameters: {'num_leaves': 88, 'max_depth': 7, 'learning_rate': 0.00028191586142502906, 'n_estimators': 599, 'min_child_samples': 67, 'min_child_weight': 0.0018938810960772124, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0031390056368163356, 'reg_lambda': 0.0014154802218813627}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:18,812] Trial 525 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 334, 'max_depth': 2, 'learning_rate': 0.006393391879303028, 'n_estimators': 428, 'min_child_samples': 62, 'min_child_weight': 0.00037039834076817136, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004762541674907138, 'reg_lambda': 0.000358891913637962}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:19,247] Trial 526 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 100, 'max_depth': 4, 'learning_rate': 0.05203336637049678, 'n_estimators': 538, 'min_child_samples': 65, 'min_child_weight': 0.0024951890837677385, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006393372581908542, 'reg_lambda': 0.00047749701050319826}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:19,759] Trial 527 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 261, 'max_depth': 47, 'learning_rate': 0.01496597546746575, 'n_estimators': 399, 'min_child_samples': 60, 'min_child_weight': 0.0013028438255119827, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003878905026248482, 'reg_lambda': 0.15198620958536455}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:20,450] Trial 528 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 307, 'max_depth': 7, 'learning_rate': 0.004055244305403159, 'n_estimators': 668, 'min_child_samples': 53, 'min_child_weight': 0.0045464456424892654, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020098883813368983, 'reg_lambda': 0.0007606333502657231}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:20,857] Trial 529 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 290, 'max_depth': 9, 'learning_rate': 0.031915338859830826, 'n_estimators': 262, 'min_child_samples': 69, 'min_child_weight': 0.0033844216963317096, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.003061482801705845, 'reg_lambda': 0.001117989461946624}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:21,333] Trial 530 finished with value: 0.8292828261332198 and parameters: {'num_leaves': 354, 'max_depth': 4, 'learning_rate': 0.02009958035135348, 'n_estimators': 565, 'min_child_samples': 29, 'min_child_weight': 0.0022493624539673706, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008202013340138247, 'reg_lambda': 2.1418135477550816e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:21,738] Trial 531 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 314, 'max_depth': 2, 'learning_rate': 0.009166450396787963, 'n_estimators': 609, 'min_child_samples': 64, 'min_child_weight': 0.00792159828171952, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0051591059482558295, 'reg_lambda': 0.02991893417185871}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:22,196] Trial 532 finished with value: 0.8422205989773557 and parameters: {'num_leaves': 362, 'max_depth': 5, 'learning_rate': 0.012462624648033042, 'n_estimators': 499, 'min_child_samples': 85, 'min_child_weight': 0.001185914452366598, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001235828633401132, 'reg_lambda': 1.433675148375718e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:22,718] Trial 533 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 380, 'max_depth': 12, 'learning_rate': 0.01904533940791538, 'n_estimators': 501, 'min_child_samples': 84, 'min_child_weight': 0.001001135821984394, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008758561553912638, 'reg_lambda': 1.3274865019417243e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:23,228] Trial 534 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 368, 'max_depth': 9, 'learning_rate': 0.012403953593912241, 'n_estimators': 493, 'min_child_samples': 86, 'min_child_weight': 0.0007532365841494011, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009463658051430284, 'reg_lambda': 1.5221717376638033e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:23,732] Trial 535 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 366, 'max_depth': 17, 'learning_rate': 0.029001110037511033, 'n_estimators': 471, 'min_child_samples': 81, 'min_child_weight': 0.0010724499317835044, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005813126129801946, 'reg_lambda': 1.253201386467539e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:24,239] Trial 536 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 392, 'max_depth': 7, 'learning_rate': 0.014136489696940422, 'n_estimators': 522, 'min_child_samples': 86, 'min_child_weight': 0.0011855305887622778, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012612904999009418, 'reg_lambda': 1.8226732835609567e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:24,696] Trial 537 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 382, 'max_depth': 5, 'learning_rate': 0.023051540210403357, 'n_estimators': 510, 'min_child_samples': 93, 'min_child_weight': 0.000246057410961592, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016700248441764804, 'reg_lambda': 2.668956492692084e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:25,278] Trial 538 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 359, 'max_depth': 69, 'learning_rate': 0.010469777310583748, 'n_estimators': 541, 'min_child_samples': 78, 'min_child_weight': 0.0004315396433577827, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007962677133276862, 'reg_lambda': 1.61232900216866e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:25,770] Trial 539 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 375, 'max_depth': 10, 'learning_rate': 0.016416667110438835, 'n_estimators': 450, 'min_child_samples': 84, 'min_child_weight': 0.00604539780690597, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.0010976802615891052, 'reg_lambda': 1.0275215052682316e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:26,220] Trial 540 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 359, 'max_depth': 5, 'learning_rate': 0.04491144386284354, 'n_estimators': 493, 'min_child_samples': 88, 'min_child_weight': 0.004633086274260253, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0013481015736271785, 'reg_lambda': 1.3743248338385436e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:26,856] Trial 541 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 191, 'max_depth': 8, 'learning_rate': 0.008349586119131284, 'n_estimators': 700, 'min_child_samples': 87, 'min_child_weight': 0.0006773407610511631, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017024053592258378, 'reg_lambda': 2.0210881447134623e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:27,331] Trial 542 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 353, 'max_depth': 5, 'learning_rate': 0.021893201522249797, 'n_estimators': 525, 'min_child_samples': 75, 'min_child_weight': 0.002894485271700405, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002266988840386528, 'reg_lambda': 3.0491972556544616e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:27,856] Trial 543 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 370, 'max_depth': 12, 'learning_rate': 0.012146874131003087, 'n_estimators': 453, 'min_child_samples': 73, 'min_child_weight': 0.0016697412363791066, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012090636122872743, 'reg_lambda': 3.656451741120956e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:28,228] Trial 544 finished with value: 0.8094043185704923 and parameters: {'num_leaves': 344, 'max_depth': 2, 'learning_rate': 0.005603460024823369, 'n_estimators': 474, 'min_child_samples': 59, 'min_child_weight': 0.00030845006487671906, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025677733458446556, 'reg_lambda': 7.48945398739075e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:28,829] Trial 545 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 273, 'max_depth': 7, 'learning_rate': 0.03346605469256029, 'n_estimators': 653, 'min_child_samples': 71, 'min_child_weight': 0.0008760860033357398, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019476158748322533, 'reg_lambda': 2.0135073570753306e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:29,311] Trial 546 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 284, 'max_depth': 4, 'learning_rate': 0.007453497446348786, 'n_estimators': 624, 'min_child_samples': 89, 'min_child_weight': 0.4914919187865478, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014422776443668009, 'reg_lambda': 0.09419885648924563}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:29,804] Trial 547 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 347, 'max_depth': 6, 'learning_rate': 0.015800259985294364, 'n_estimators': 429, 'min_child_samples': 62, 'min_child_weight': 0.0035867773015102944, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0029511643385446043, 'reg_lambda': 2.3853813500082795e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:30,195] Trial 548 finished with value: 0.824887818514042 and parameters: {'num_leaves': 363, 'max_depth': 2, 'learning_rate': 0.0102235220417126, 'n_estimators': 560, 'min_child_samples': 91, 'min_child_weight': 0.001243678845636578, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0003033806147297502, 'reg_lambda': 1.5980174707278656e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:30,731] Trial 549 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 339, 'max_depth': 9, 'learning_rate': 0.023344594243717966, 'n_estimators': 545, 'min_child_samples': 90, 'min_child_weight': 0.00524263743017746, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003805842570355339, 'reg_lambda': 5.161224918131628e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:31,191] Trial 550 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 296, 'max_depth': 4, 'learning_rate': 0.005143422367504709, 'n_estimators': 577, 'min_child_samples': 82, 'min_child_weight': 0.0005332587542000256, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002491316383830975, 'reg_lambda': 0.19521197145248753}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:31,914] Trial 551 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 356, 'max_depth': 14, 'learning_rate': 0.013612047535127928, 'n_estimators': 646, 'min_child_samples': 56, 'min_child_weight': 0.002158143354744865, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003720882599022664, 'reg_lambda': 1.0046482988075363e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:32,437] Trial 552 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 377, 'max_depth': 7, 'learning_rate': 0.008812828966546568, 'n_estimators': 513, 'min_child_samples': 74, 'min_child_weight': 0.00423002219128306, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021305793072044187, 'reg_lambda': 4.0090409004109895e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:32,922] Trial 553 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 127, 'max_depth': 4, 'learning_rate': 0.017167013973980346, 'n_estimators': 610, 'min_child_samples': 68, 'min_child_weight': 0.01175139003151762, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002984756807462043, 'reg_lambda': 0.0002587047396101808}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:33,318] Trial 554 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 250, 'max_depth': 2, 'learning_rate': 0.00689366716405731, 'n_estimators': 588, 'min_child_samples': 63, 'min_child_weight': 0.002803496857595032, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.006552198572997744, 'reg_lambda': 0.00011522776253469}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:33,935] Trial 555 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 45, 'max_depth': 11, 'learning_rate': 0.0027996824848138366, 'n_estimators': 628, 'min_child_samples': 79, 'min_child_weight': 0.001579959556692357, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015972020236138325, 'reg_lambda': 0.005842701247451088}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:34,643] Trial 556 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 348, 'max_depth': 88, 'learning_rate': 0.011900491480953498, 'n_estimators': 682, 'min_child_samples': 66, 'min_child_weight': 0.006831053052703312, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0043999141213506045, 'reg_lambda': 0.0017316321260013635}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:35,154] Trial 557 finished with value: 0.7843572540630146 and parameters: {'num_leaves': 333, 'max_depth': 6, 'learning_rate': 0.034407907544164375, 'n_estimators': 567, 'min_child_samples': 60, 'min_child_weight': 0.003187846203634227, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021207299994659527, 'reg_lambda': 0.0035176306274594046}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:35,599] Trial 558 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 320, 'max_depth': 4, 'learning_rate': 0.02365188466834638, 'n_estimators': 529, 'min_child_samples': 72, 'min_child_weight': 0.002116076517324767, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003155252951340276, 'reg_lambda': 1.336833786108403e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:36,217] Trial 559 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 282, 'max_depth': 8, 'learning_rate': 0.00393794559176539, 'n_estimators': 661, 'min_child_samples': 95, 'min_child_weight': 0.0013784401351071343, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.010876696776530272, 'reg_lambda': 0.0005929216851860188}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:36,619] Trial 560 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 388, 'max_depth': 2, 'learning_rate': 0.009944165692532285, 'n_estimators': 600, 'min_child_samples': 51, 'min_child_weight': 0.003625721507519968, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010898063949767332, 'reg_lambda': 1.8986031023635827e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:37,116] Trial 561 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 363, 'max_depth': 5, 'learning_rate': 0.019346491635946317, 'n_estimators': 550, 'min_child_samples': 58, 'min_child_weight': 0.008686741991727087, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004156651624948641, 'reg_lambda': 0.0003386531620626399}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:37,778] Trial 562 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 300, 'max_depth': 9, 'learning_rate': 0.006193121713665012, 'n_estimators': 637, 'min_child_samples': 69, 'min_child_weight': 0.0009862353914339866, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00556885868614673, 'reg_lambda': 2.6770134095147854e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:38,174] Trial 563 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 77, 'max_depth': 2, 'learning_rate': 0.07576748845655056, 'n_estimators': 582, 'min_child_samples': 63, 'min_child_weight': 0.002572180119722071, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025123082218756186, 'reg_lambda': 0.00015549582027460523}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:38,692] Trial 564 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 342, 'max_depth': 6, 'learning_rate': 0.01468227007655279, 'n_estimators': 615, 'min_child_samples': 66, 'min_child_weight': 0.001723519705758726, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.0006181321346417285, 'reg_lambda': 0.018880725057617224}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:39,132] Trial 565 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 353, 'max_depth': 4, 'learning_rate': 0.010993330575111553, 'n_estimators': 487, 'min_child_samples': 48, 'min_child_weight': 0.005483445720233039, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0035554055191796396, 'reg_lambda': 0.00044194006658161385}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:39,819] Trial 566 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 330, 'max_depth': 74, 'learning_rate': 0.007690531821764765, 'n_estimators': 566, 'min_child_samples': 61, 'min_child_weight': 0.003952298623845067, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016694626719714902, 'reg_lambda': 0.002107131428355347}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:40,299] Trial 567 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 290, 'max_depth': 7, 'learning_rate': 0.02892970905230393, 'n_estimators': 455, 'min_child_samples': 77, 'min_child_weight': 0.0020194541323709197, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.00651900011136664, 'reg_lambda': 0.0011644018068651698}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:40,706] Trial 568 finished with value: 0.8424571599211106 and parameters: {'num_leaves': 312, 'max_depth': 2, 'learning_rate': 0.016628413083250287, 'n_estimators': 591, 'min_child_samples': 64, 'min_child_weight': 0.001293627513225961, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004673642174512069, 'reg_lambda': 1.5477112243568726e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:41,321] Trial 569 finished with value: 0.7845881595881596 and parameters: {'num_leaves': 301, 'max_depth': 10, 'learning_rate': 0.046332694824289276, 'n_estimators': 550, 'min_child_samples': 67, 'min_child_weight': 0.000770102413712653, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0030406706724093045, 'reg_lambda': 1.2138858461256862e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:41,910] Trial 570 finished with value: 0.7971407701137431 and parameters: {'num_leaves': 305, 'max_depth': 5, 'learning_rate': 0.023168054978908614, 'n_estimators': 718, 'min_child_samples': 70, 'min_child_weight': 0.0006353443805256559, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019907516747812207, 'reg_lambda': 1.821622820372365e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:42,377] Trial 571 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 292, 'max_depth': 2, 'learning_rate': 0.017580154672830754, 'n_estimators': 586, 'min_child_samples': 65, 'min_child_weight': 0.001079093551712884, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005173325203290818, 'reg_lambda': 2.404148748935221e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:42,892] Trial 572 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 278, 'max_depth': 7, 'learning_rate': 0.03636383107467146, 'n_estimators': 517, 'min_child_samples': 68, 'min_child_weight': 0.0012605186534126597, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0076103025529117236, 'reg_lambda': 1.62190607873313e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:43,485] Trial 573 finished with value: 0.7524326798760307 and parameters: {'num_leaves': 266, 'max_depth': 33, 'learning_rate': 0.1263031198367462, 'n_estimators': 535, 'min_child_samples': 73, 'min_child_weight': 0.1519626622318061, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004304518356479932, 'reg_lambda': 1.2862339928270068e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:43,971] Trial 574 finished with value: 0.8338679303851168 and parameters: {'num_leaves': 316, 'max_depth': 4, 'learning_rate': 0.017132650103563272, 'n_estimators': 568, 'min_child_samples': 16, 'min_child_weight': 0.00047861570864781794, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025295532016601785, 'reg_lambda': 1.6210927755271457e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:44,378] Trial 575 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 369, 'max_depth': 2, 'learning_rate': 0.025506537297708503, 'n_estimators': 597, 'min_child_samples': 64, 'min_child_weight': 0.005910978343295191, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014266777333257134, 'reg_lambda': 1.0489129671541865e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:44,995] Trial 576 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 314, 'max_depth': 8, 'learning_rate': 0.01327829002289323, 'n_estimators': 583, 'min_child_samples': 62, 'min_child_weight': 0.004179491626672959, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0036735116260259363, 'reg_lambda': 2.2701660409809316e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:45,646] Trial 577 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 108, 'max_depth': 12, 'learning_rate': 0.01643050529331491, 'n_estimators': 627, 'min_child_samples': 66, 'min_child_weight': 0.0008741660517844369, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002804976571017908, 'reg_lambda': 3.184865825518841e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:46,133] Trial 578 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 239, 'max_depth': 5, 'learning_rate': 0.010662668563052586, 'n_estimators': 550, 'min_child_samples': 88, 'min_child_weight': 0.002768035669747362, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.005288197824189262, 'reg_lambda': 1.574634987651332e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:46,838] Trial 579 finished with value: 0.7799872591586683 and parameters: {'num_leaves': 219, 'max_depth': 117, 'learning_rate': 0.025194239394922175, 'n_estimators': 608, 'min_child_samples': 55, 'min_child_weight': 0.0012593470002666815, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002004722473830334, 'reg_lambda': 1.9829543641854078e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:47,287] Trial 580 finished with value: 0.8202977117191788 and parameters: {'num_leaves': 296, 'max_depth': 4, 'learning_rate': 0.013218460185610308, 'n_estimators': 496, 'min_child_samples': 60, 'min_child_weight': 0.007176393211271295, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.8347453906350394, 'reg_lambda': 3.23233229298985e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:47,968] Trial 581 finished with value: 0.8115146396396395 and parameters: {'num_leaves': 306, 'max_depth': 81, 'learning_rate': 0.01997805497019961, 'n_estimators': 665, 'min_child_samples': 71, 'min_child_weight': 0.0031983566752536658, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010445405559120703, 'reg_lambda': 0.00866395885740663}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:48,371] Trial 582 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 344, 'max_depth': 2, 'learning_rate': 0.039113602471405336, 'n_estimators': 572, 'min_child_samples': 92, 'min_child_weight': 0.004980302820554712, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 3.8800681529103024e-05, 'reg_lambda': 1.345080476291098e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:48,994] Trial 583 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 382, 'max_depth': 7, 'learning_rate': 0.009565491970303014, 'n_estimators': 643, 'min_child_samples': 64, 'min_child_weight': 0.0016016565628017058, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0035996467027064054, 'reg_lambda': 0.11920990799929905}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:49,491] Trial 584 finished with value: 0.816975101113675 and parameters: {'num_leaves': 335, 'max_depth': 42, 'learning_rate': 0.0011542937312518967, 'n_estimators': 440, 'min_child_samples': 85, 'min_child_weight': 0.00034986039691243284, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008248055994603461, 'reg_lambda': 0.00021377752369063934}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:50,107] Trial 585 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 361, 'max_depth': 10, 'learning_rate': 0.004991912825227042, 'n_estimators': 532, 'min_child_samples': 75, 'min_child_weight': 0.0020432541861166915, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0026310881128703933, 'reg_lambda': 0.16095579641383065}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:50,742] Trial 586 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 172, 'max_depth': 23, 'learning_rate': 0.013030525310902432, 'n_estimators': 600, 'min_child_samples': 69, 'min_child_weight': 0.00019276948249361708, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.013384318818530324, 'reg_lambda': 2.591990918138573e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:51,176] Trial 587 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 284, 'max_depth': 5, 'learning_rate': 0.007984663180473433, 'n_estimators': 414, 'min_child_samples': 67, 'min_child_weight': 0.002450290278970495, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.17279111809709344, 'reg_lambda': 4.2296137151199655e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:51,571] Trial 588 finished with value: 0.8202977117191788 and parameters: {'num_leaves': 323, 'max_depth': 2, 'learning_rate': 0.01925967828555805, 'n_estimators': 553, 'min_child_samples': 58, 'min_child_weight': 0.0009300030074587823, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1.0404408925942122e-05, 'reg_lambda': 1.9377107548035745e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:52,229] Trial 589 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 351, 'max_depth': 6, 'learning_rate': 1.976986434166774e-05, 'n_estimators': 628, 'min_child_samples': 62, 'min_child_weight': 0.003784674412973305, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.06814118014449681, 'reg_lambda': 0.0026523161674499884}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:52,796] Trial 590 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 308, 'max_depth': 8, 'learning_rate': 0.02970996447642968, 'n_estimators': 508, 'min_child_samples': 64, 'min_child_weight': 0.001409918130328927, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.000818799665580812, 'reg_lambda': 1.2589475693539127e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:53,272] Trial 591 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 370, 'max_depth': 4, 'learning_rate': 0.012142887259238778, 'n_estimators': 576, 'min_child_samples': 72, 'min_child_weight': 0.003011108315687299, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0046977076732279, 'reg_lambda': 1.551360497297269e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:53,653] Trial 592 finished with value: 0.828254477109439 and parameters: {'num_leaves': 339, 'max_depth': 2, 'learning_rate': 0.006790896080801512, 'n_estimators': 480, 'min_child_samples': 66, 'min_child_weight': 0.0005800649645130743, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006347283873008673, 'reg_lambda': 1.0466678118117592e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:54,289] Trial 593 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 354, 'max_depth': 6, 'learning_rate': 0.017186789452424894, 'n_estimators': 691, 'min_child_samples': 53, 'min_child_weight': 0.004705210433040844, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013891727729397059, 'reg_lambda': 2.1620948145887035e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:54,915] Trial 594 finished with value: 0.7164228878579989 and parameters: {'num_leaves': 325, 'max_depth': 9, 'learning_rate': 0.28312635569290306, 'n_estimators': 611, 'min_child_samples': 69, 'min_child_weight': 0.0018084284867812726, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00346357671266277, 'reg_lambda': 0.35126735905193496}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:55,398] Trial 595 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 31, 'max_depth': 4, 'learning_rate': 0.009833562629450635, 'n_estimators': 594, 'min_child_samples': 61, 'min_child_weight': 0.0025082948640144384, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017727890747953126, 'reg_lambda': 0.2579086479766058}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:55,793] Trial 596 finished with value: 0.828254477109439 and parameters: {'num_leaves': 273, 'max_depth': 2, 'learning_rate': 0.00547539364102416, 'n_estimators': 561, 'min_child_samples': 65, 'min_child_weight': 0.0011411277275559454, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023958036622488605, 'reg_lambda': 0.0015691429732627436}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:56,662] Trial 597 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 297, 'max_depth': 12, 'learning_rate': 0.025875985300220335, 'n_estimators': 887, 'min_child_samples': 63, 'min_child_weight': 0.006043769380566939, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004127677694776011, 'reg_lambda': 0.0003143723980221917}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:57,146] Trial 598 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 360, 'max_depth': 6, 'learning_rate': 4.061244036076248e-07, 'n_estimators': 380, 'min_child_samples': 68, 'min_child_weight': 0.003433517558076293, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.005755348834896231, 'reg_lambda': 0.0005099567597179205}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:57,445] Trial 599 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 313, 'max_depth': 4, 'learning_rate': 0.04811191713342641, 'n_estimators': 97, 'min_child_samples': 60, 'min_child_weight': 0.009493468066489479, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0030733852472751336, 'reg_lambda': 8.461603748336224e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:58,090] Trial 600 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 96, 'max_depth': 9, 'learning_rate': 0.014524274005318803, 'n_estimators': 645, 'min_child_samples': 71, 'min_child_weight': 0.0002758902277077347, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.004563114395129123, 'reg_lambda': 2.7037424612460148e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:58,492] Trial 601 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 69, 'max_depth': 2, 'learning_rate': 5.844819747189211e-06, 'n_estimators': 539, 'min_child_samples': 57, 'min_child_weight': 0.00041052615040692664, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.010030195274482083, 'reg_lambda': 3.3017892414761665}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:59,078] Trial 602 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 342, 'max_depth': 7, 'learning_rate': 0.009911735937394132, 'n_estimators': 589, 'min_child_samples': 75, 'min_child_weight': 0.004492407162646901, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021083820151099227, 'reg_lambda': 1.4918903252537273e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:36:59,594] Trial 603 finished with value: 0.7840892754456584 and parameters: {'num_leaves': 290, 'max_depth': 5, 'learning_rate': 0.06568528628053519, 'n_estimators': 621, 'min_child_samples': 80, 'min_child_weight': 0.01547832810913808, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031869517656688147, 'reg_lambda': 3.519437689356148e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:00,115] Trial 604 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 135, 'max_depth': 4, 'learning_rate': 1.1719807823253311e-08, 'n_estimators': 517, 'min_child_samples': 63, 'min_child_weight': 0.001480111239635532, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006802629044628845, 'reg_lambda': 0.0006114390819843811}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:00,526] Trial 605 finished with value: 0.7955601764400089 and parameters: {'num_leaves': 155, 'max_depth': 2, 'learning_rate': 0.004157052176157453, 'n_estimators': 582, 'min_child_samples': 67, 'min_child_weight': 0.00073460912204656, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012041315766930956, 'reg_lambda': 0.0009817963671664037}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:01,118] Trial 606 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 331, 'max_depth': 15, 'learning_rate': 0.021167066303541024, 'n_estimators': 467, 'min_child_samples': 59, 'min_child_weight': 0.0026601462341716772, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0040537262113934935, 'reg_lambda': 1.9244274317295198e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:01,810] Trial 607 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 374, 'max_depth': 8, 'learning_rate': 0.007482400523737672, 'n_estimators': 672, 'min_child_samples': 65, 'min_child_weight': 4.052527813214486e-05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024236069586544584, 'reg_lambda': 6.47045470962837e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:02,344] Trial 608 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 320, 'max_depth': 6, 'learning_rate': 0.014353477920922111, 'n_estimators': 558, 'min_child_samples': 73, 'min_child_weight': 0.0019356323174891622, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017439405808512506, 'reg_lambda': 1.0081939500195726e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:02,995] Trial 609 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 120, 'max_depth': 10, 'learning_rate': 0.03453936333858594, 'n_estimators': 613, 'min_child_samples': 62, 'min_child_weight': 0.0037987089955426982, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00492024985143326, 'reg_lambda': 0.00043281464793528714}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:03,515] Trial 610 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 349, 'max_depth': 4, 'learning_rate': 0.0021966640160997787, 'n_estimators': 637, 'min_child_samples': 69, 'min_child_weight': 0.0009444008690432659, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.002800619975928048, 'reg_lambda': 0.0018343246605960382}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:03,926] Trial 611 finished with value: 0.824887818514042 and parameters: {'num_leaves': 304, 'max_depth': 2, 'learning_rate': 0.010357291553080978, 'n_estimators': 537, 'min_child_samples': 6, 'min_child_weight': 0.007382761724678126, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1.8930114048030082, 'reg_lambda': 2.1838737230445924e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:04,512] Trial 612 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 401, 'max_depth': 7, 'learning_rate': 0.020351970078979466, 'n_estimators': 571, 'min_child_samples': 65, 'min_child_weight': 0.0021677837432108136, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00358741189088767, 'reg_lambda': 0.5337501027590568}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:05,055] Trial 613 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 336, 'max_depth': 5, 'learning_rate': 0.006852649455579576, 'n_estimators': 657, 'min_child_samples': 90, 'min_child_weight': 0.0031677662071157285, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0074223502793586615, 'reg_lambda': 0.17617318448901306}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:05,475] Trial 614 finished with value: 0.7955601764400089 and parameters: {'num_leaves': 365, 'max_depth': 2, 'learning_rate': 0.003321136472320744, 'n_estimators': 610, 'min_child_samples': 77, 'min_child_weight': 0.0051243488970531565, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005559659936369376, 'reg_lambda': 1.4126701810189448e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:06,140] Trial 615 finished with value: 0.7974449198985706 and parameters: {'num_leaves': 284, 'max_depth': 11, 'learning_rate': 0.013139529769469346, 'n_estimators': 589, 'min_child_samples': 61, 'min_child_weight': 0.0013092025306007118, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001504730757072371, 'reg_lambda': 5.270619581312731e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:06,670] Trial 616 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 391, 'max_depth': 5, 'learning_rate': 0.026844713359538235, 'n_estimators': 630, 'min_child_samples': 55, 'min_child_weight': 0.0016947338029259244, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021132290319107287, 'reg_lambda': 0.0013089167390836977}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:07,207] Trial 617 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 349, 'max_depth': 7, 'learning_rate': 0.009007691911947497, 'n_estimators': 502, 'min_child_samples': 67, 'min_child_weight': 0.0027018512039917323, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003759987644247529, 'reg_lambda': 0.0008841838894019065}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:07,599] Trial 618 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 325, 'max_depth': 2, 'learning_rate': 0.005340280630743232, 'n_estimators': 547, 'min_child_samples': 50, 'min_child_weight': 0.0022926287935711703, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028261086644324816, 'reg_lambda': 0.000618082017653038}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:08,243] Trial 619 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 311, 'max_depth': 9, 'learning_rate': 0.01680124904092574, 'n_estimators': 601, 'min_child_samples': 71, 'min_child_weight': 0.004039004713379921, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004632907048048442, 'reg_lambda': 0.0007482806974734214}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:08,763] Trial 620 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 358, 'max_depth': 5, 'learning_rate': 0.010856513404321411, 'n_estimators': 568, 'min_child_samples': 63, 'min_child_weight': 0.0010692294061100062, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00285953582457747, 'reg_lambda': 2.7640965583448413e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:09,261] Trial 621 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 56, 'max_depth': 4, 'learning_rate': 0.01664127533557803, 'n_estimators': 586, 'min_child_samples': 64, 'min_child_weight': 0.0059666877291858385, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008661538004566635, 'reg_lambda': 0.0003357878368914401}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:09,821] Trial 622 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 257, 'max_depth': 7, 'learning_rate': 0.007628807250808363, 'n_estimators': 526, 'min_child_samples': 82, 'min_child_weight': 0.0015344610897047068, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.005798484523755319, 'reg_lambda': 0.00013869865644071592}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:10,638] Trial 623 finished with value: 0.7756126662376662 and parameters: {'num_leaves': 296, 'max_depth': 13, 'learning_rate': 0.029658719736514894, 'n_estimators': 651, 'min_child_samples': 43, 'min_child_weight': 0.0032739914761761094, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019596371015656, 'reg_lambda': 0.07986801499775481}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:11,085] Trial 624 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 339, 'max_depth': 2, 'learning_rate': 0.012502549900735488, 'n_estimators': 704, 'min_child_samples': 58, 'min_child_weight': 0.0006050448795939661, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0008294781713412584, 'reg_lambda': 1.8581412410285925e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:11,686] Trial 625 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 328, 'max_depth': 5, 'learning_rate': 0.004504802801923121, 'n_estimators': 625, 'min_child_samples': 46, 'min_child_weight': 0.002081027216954613, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0037248626152828097, 'reg_lambda': 0.0023405113130559405}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:12,298] Trial 626 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 318, 'max_depth': 8, 'learning_rate': 0.020997674038583818, 'n_estimators': 566, 'min_child_samples': 70, 'min_child_weight': 0.0007916998384256304, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024394688698237796, 'reg_lambda': 0.00020831472964728497}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:12,679] Trial 627 finished with value: 0.824887818514042 and parameters: {'num_leaves': 205, 'max_depth': 2, 'learning_rate': 0.007949873572117126, 'n_estimators': 459, 'min_child_samples': 38, 'min_child_weight': 0.004474763238017227, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010834550221982826, 'reg_lambda': 0.0011461772678929708}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:13,225] Trial 628 finished with value: 0.7848413764691776 and parameters: {'num_leaves': 346, 'max_depth': 4, 'learning_rate': 0.0006668300080964702, 'n_estimators': 604, 'min_child_samples': 66, 'min_child_weight': 0.001337293067707751, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014403846316938876, 'reg_lambda': 1.2708502046304383e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:13,885] Trial 629 finished with value: 0.7799872591586683 and parameters: {'num_leaves': 84, 'max_depth': 125, 'learning_rate': 0.03804253012253192, 'n_estimators': 547, 'min_child_samples': 60, 'min_child_weight': 0.0030786480152949582, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004642462635559824, 'reg_lambda': 3.547947067256969e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:14,808] Trial 630 finished with value: 0.7884424718940626 and parameters: {'num_leaves': 377, 'max_depth': 11, 'learning_rate': 0.013199215930912724, 'n_estimators': 585, 'min_child_samples': 23, 'min_child_weight': 0.0004324734756493216, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0004984735567009414, 'reg_lambda': 0.055392904829394476}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:15,493] Trial 631 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 278, 'max_depth': 92, 'learning_rate': 0.005700959223585148, 'n_estimators': 676, 'min_child_samples': 74, 'min_child_weight': 0.0077027227121971706, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031816071227519947, 'reg_lambda': 0.004445918437229106}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:16,115] Trial 632 finished with value: 0.8159077066429673 and parameters: {'num_leaves': 308, 'max_depth': 7, 'learning_rate': 0.022359064485221933, 'n_estimators': 623, 'min_child_samples': 62, 'min_child_weight': 0.001914672405614547, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0065499135774522805, 'reg_lambda': 0.0005453172809995006}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:16,621] Trial 633 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 360, 'max_depth': 4, 'learning_rate': 0.010998958613516813, 'n_estimators': 647, 'min_child_samples': 68, 'min_child_weight': 0.005361037926759693, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.004009571426759079, 'reg_lambda': 1.7074057308622477e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:16,991] Trial 634 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 332, 'max_depth': 2, 'learning_rate': 0.01732195765911273, 'n_estimators': 440, 'min_child_samples': 65, 'min_child_weight': 0.0037946228765454153, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017801976550176955, 'reg_lambda': 0.2384889634861265}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:17,507] Trial 635 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 339, 'max_depth': 97, 'learning_rate': 0.007743325550488242, 'n_estimators': 398, 'min_child_samples': 67, 'min_child_weight': 0.0010694978699910974, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011962430923702597, 'reg_lambda': 0.23624089499989298}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:18,022] Trial 636 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 354, 'max_depth': 9, 'learning_rate': 0.003102659072638263, 'n_estimators': 438, 'min_child_samples': 65, 'min_child_weight': 0.0027556032551982585, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.0014440545436851485, 'reg_lambda': 0.4075525155057733}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:18,508] Trial 637 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 336, 'max_depth': 6, 'learning_rate': 0.016201888607274017, 'n_estimators': 465, 'min_child_samples': 70, 'min_child_weight': 6.908704224834714e-05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020059175736359437, 'reg_lambda': 0.29366619248421433}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:18,881] Trial 638 finished with value: 0.820490132990133 and parameters: {'num_leaves': 267, 'max_depth': 2, 'learning_rate': 0.009494045027535557, 'n_estimators': 423, 'min_child_samples': 66, 'min_child_weight': 0.010681163468329001, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00173257730511597, 'reg_lambda': 0.17495911781634146}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:19,356] Trial 639 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 352, 'max_depth': 5, 'learning_rate': 0.005120922382317578, 'n_estimators': 487, 'min_child_samples': 68, 'min_child_weight': 0.00014197796200402107, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0006770511784764516, 'reg_lambda': 0.21319545768330936}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:19,742] Trial 640 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 369, 'max_depth': 2, 'learning_rate': 0.014084437921181917, 'n_estimators': 411, 'min_child_samples': 72, 'min_child_weight': 0.0003192093226078037, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016738793106145131, 'reg_lambda': 0.3070272770388244}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:20,248] Trial 641 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 333, 'max_depth': 8, 'learning_rate': 0.006755010592742426, 'n_estimators': 429, 'min_child_samples': 87, 'min_child_weight': 0.004312380232381627, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0009477378040008369, 'reg_lambda': 0.43045090460662033}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:20,716] Trial 642 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 347, 'max_depth': 5, 'learning_rate': 0.018819192910468067, 'n_estimators': 443, 'min_child_samples': 64, 'min_child_weight': 0.006623135821802853, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012055218692782737, 'reg_lambda': 0.2539694605331255}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:21,159] Trial 643 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 327, 'max_depth': 4, 'learning_rate': 0.010783520591983056, 'n_estimators': 454, 'min_child_samples': 66, 'min_child_weight': 0.0016790194219200136, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024165979946257792, 'reg_lambda': 0.13489306035305612}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:21,745] Trial 644 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 291, 'max_depth': 20, 'learning_rate': 0.02827170734220885, 'n_estimators': 479, 'min_child_samples': 69, 'min_child_weight': 0.0035591272101754908, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019786667522260822, 'reg_lambda': 0.1316350863315235}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:22,368] Trial 645 finished with value: 0.7756126662376662 and parameters: {'num_leaves': 361, 'max_depth': 10, 'learning_rate': 0.058386705703220805, 'n_estimators': 517, 'min_child_samples': 64, 'min_child_weight': 0.0023486590154230013, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025541122466355365, 'reg_lambda': 0.17974580529892922}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:22,858] Trial 646 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 384, 'max_depth': 7, 'learning_rate': 0.014163719583735485, 'n_estimators': 411, 'min_child_samples': 67, 'min_child_weight': 0.001283223027144006, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003055326648070888, 'reg_lambda': 0.012098792407229528}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:23,243] Trial 647 finished with value: 0.8202977117191788 and parameters: {'num_leaves': 342, 'max_depth': 2, 'learning_rate': 0.009174010682167317, 'n_estimators': 441, 'min_child_samples': 76, 'min_child_weight': 0.005086383652228694, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.011597989047301884, 'reg_lambda': 0.10922320725024952}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:23,770] Trial 648 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 319, 'max_depth': 5, 'learning_rate': 0.004063734408638758, 'n_estimators': 558, 'min_child_samples': 63, 'min_child_weight': 0.0008834795900216813, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013709531174458435, 'reg_lambda': 2.4290169233094372e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:24,236] Trial 649 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 301, 'max_depth': 2, 'learning_rate': 0.020800228115408263, 'n_estimators': 762, 'min_child_samples': 73, 'min_child_weight': 0.0005330578158900651, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005147829209754671, 'reg_lambda': 1.6316745540806876e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:24,844] Trial 650 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 345, 'max_depth': 7, 'learning_rate': 6.388074289496028e-05, 'n_estimators': 538, 'min_child_samples': 70, 'min_child_weight': 0.0017432070243526096, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017609708248148067, 'reg_lambda': 1.2350275848276067e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:25,450] Trial 651 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 331, 'max_depth': 14, 'learning_rate': 0.006127348808478723, 'n_estimators': 503, 'min_child_samples': 65, 'min_child_weight': 0.002291096085798186, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00786931410887496, 'reg_lambda': 2.5382140044825663e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:25,874] Trial 652 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 366, 'max_depth': 4, 'learning_rate': 0.012555667164188718, 'n_estimators': 393, 'min_child_samples': 52, 'min_child_weight': 0.003908637107446756, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0032455213197790963, 'reg_lambda': 0.22599636932240066}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:26,494] Trial 653 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 42, 'max_depth': 8, 'learning_rate': 0.03389280048558542, 'n_estimators': 579, 'min_child_samples': 62, 'min_child_weight': 0.00021934881993978736, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023109572275708864, 'reg_lambda': 4.2165608955472555e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:26,998] Trial 654 finished with value: 0.833675692499222 and parameters: {'num_leaves': 356, 'max_depth': 5, 'learning_rate': 0.008289091392944184, 'n_estimators': 524, 'min_child_samples': 68, 'min_child_weight': 0.0029163390576795512, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0040974604158731465, 'reg_lambda': 0.001737533095607379}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:27,588] Trial 655 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 338, 'max_depth': 10, 'learning_rate': 0.017246530579458005, 'n_estimators': 473, 'min_child_samples': 65, 'min_child_weight': 0.005792223025789987, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005454468588298106, 'reg_lambda': 0.002983581229405185}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:27,938] Trial 656 finished with value: 0.8424571599211106 and parameters: {'num_leaves': 284, 'max_depth': 2, 'learning_rate': 0.025378988034231154, 'n_estimators': 288, 'min_child_samples': 71, 'min_child_weight': 0.0007159616244371987, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0022884140718983973, 'reg_lambda': 1.0228132425887887e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:28,350] Trial 657 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 267, 'max_depth': 2, 'learning_rate': 0.039140291408540355, 'n_estimators': 552, 'min_child_samples': 74, 'min_child_weight': 0.0005981128156459457, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009860368813239884, 'reg_lambda': 1.0126034957939286e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:28,771] Trial 658 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 279, 'max_depth': 6, 'learning_rate': 0.04622601957853171, 'n_estimators': 322, 'min_child_samples': 72, 'min_child_weight': 0.000813345408929343, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018808222479499827, 'reg_lambda': 1.2105039772359429e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:29,151] Trial 659 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 283, 'max_depth': 4, 'learning_rate': 0.027471960653127844, 'n_estimators': 297, 'min_child_samples': 71, 'min_child_weight': 0.0007068481232908667, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.0013759313259643245, 'reg_lambda': 1.0730011422795446e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:29,574] Trial 660 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 289, 'max_depth': 11, 'learning_rate': 0.023849005399263528, 'n_estimators': 246, 'min_child_samples': 70, 'min_child_weight': 0.000688889366490729, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025272979736869062, 'reg_lambda': 1.2998343213647059e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:29,901] Trial 661 finished with value: 0.8246851893910718 and parameters: {'num_leaves': 272, 'max_depth': 2, 'learning_rate': 0.02849372152821924, 'n_estimators': 158, 'min_child_samples': 75, 'min_child_weight': 0.00048153433675232745, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003349987610676522, 'reg_lambda': 1.0400832742373354e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:30,273] Trial 662 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 258, 'max_depth': 7, 'learning_rate': 0.06451087620419493, 'n_estimators': 195, 'min_child_samples': 73, 'min_child_weight': 0.00036743760749640233, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016478086325179067, 'reg_lambda': 0.6903470194142033}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:30,614] Trial 663 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 294, 'max_depth': 4, 'learning_rate': 0.018775843922397777, 'n_estimators': 192, 'min_child_samples': 78, 'min_child_weight': 0.0005050004994575681, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0007784289680943078, 'reg_lambda': 1.5261741253186075e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:31,272] Trial 664 finished with value: 0.780204207675669 and parameters: {'num_leaves': 287, 'max_depth': 9, 'learning_rate': 0.042894243462145674, 'n_estimators': 597, 'min_child_samples': 69, 'min_child_weight': 0.0008414010873900256, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006318365856183439, 'reg_lambda': 0.3395041222361056}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:31,807] Trial 665 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 246, 'max_depth': 6, 'learning_rate': 0.01690067795217725, 'n_estimators': 565, 'min_child_samples': 71, 'min_child_weight': 1.2688402269991748e-05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021780421128825274, 'reg_lambda': 1.481656335515915e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:32,173] Trial 666 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 280, 'max_depth': 2, 'learning_rate': 0.024436712189758028, 'n_estimators': 369, 'min_child_samples': 68, 'min_child_weight': 0.0006323544624215921, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.017925964558543145, 'reg_lambda': 0.0002908568523783475}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:32,685] Trial 667 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 303, 'max_depth': 5, 'learning_rate': 0.013297593523623195, 'n_estimators': 539, 'min_child_samples': 67, 'min_child_weight': 0.001048215661469786, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00959667042898506, 'reg_lambda': 1.6077931782675207e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:33,039] Trial 668 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 301, 'max_depth': 12, 'learning_rate': 0.01196892257783548, 'n_estimators': 128, 'min_child_samples': 70, 'min_child_weight': 0.0010344383517874962, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.010039251609388258, 'reg_lambda': 1.869808413541924e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:33,531] Trial 669 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 308, 'max_depth': 9, 'learning_rate': 0.011037532193985948, 'n_estimators': 362, 'min_child_samples': 67, 'min_child_weight': 0.0008917546976438891, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.011163008529518377, 'reg_lambda': 1.006331253610987e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:34,061] Trial 670 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 299, 'max_depth': 7, 'learning_rate': 0.014561093287390536, 'n_estimators': 501, 'min_child_samples': 72, 'min_child_weight': 0.0011396639842202831, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008830837564500212, 'reg_lambda': 1.6065127812199748e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:34,578] Trial 671 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 232, 'max_depth': 5, 'learning_rate': 0.008028787053212956, 'n_estimators': 527, 'min_child_samples': 68, 'min_child_weight': 0.0006759453491265754, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.009770429651068219, 'reg_lambda': 1.993518022824109e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:35,007] Trial 672 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 312, 'max_depth': 9, 'learning_rate': 0.005324378262336809, 'n_estimators': 286, 'min_child_samples': 94, 'min_child_weight': 0.0009256069202350786, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.015112140048497789, 'reg_lambda': 1.4113913901799981e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:35,428] Trial 673 finished with value: 0.8246851893910718 and parameters: {'num_leaves': 104, 'max_depth': 5, 'learning_rate': 0.01154658724787039, 'n_estimators': 332, 'min_child_samples': 76, 'min_child_weight': 0.001032816547661595, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.016828584094504998, 'reg_lambda': 1.5580478318826516e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:35,974] Trial 674 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 374, 'max_depth': 7, 'learning_rate': 0.0163469100678683, 'n_estimators': 521, 'min_child_samples': 69, 'min_child_weight': 0.0007203745660080813, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007234660924809722, 'reg_lambda': 1.3498531213020054e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:36,591] Trial 675 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 189, 'max_depth': 13, 'learning_rate': 0.00866425681863925, 'n_estimators': 549, 'min_child_samples': 66, 'min_child_weight': 0.001236049115341108, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007737456118710387, 'reg_lambda': 1.2394329340778799e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:36,994] Trial 676 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 307, 'max_depth': 4, 'learning_rate': 0.02058790659506409, 'n_estimators': 350, 'min_child_samples': 71, 'min_child_weight': 0.0004242108317073777, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006349239645400363, 'reg_lambda': 1.6812906273698527e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:37,491] Trial 677 finished with value: 0.8176107141624382 and parameters: {'num_leaves': 319, 'max_depth': 4, 'learning_rate': 0.0016277906314092368, 'n_estimators': 504, 'min_child_samples': 66, 'min_child_weight': 0.0005588512612652463, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.00506589048476444, 'reg_lambda': 2.1914169503350067e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:38,284] Trial 678 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 477, 'max_depth': 11, 'learning_rate': 0.006543149217111437, 'n_estimators': 855, 'min_child_samples': 85, 'min_child_weight': 0.0008451086044214413, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.012767898996443762, 'reg_lambda': 0.15391176763958697}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:38,827] Trial 679 finished with value: 0.7704375758850468 and parameters: {'num_leaves': 20, 'max_depth': 7, 'learning_rate': 0.09901087493600315, 'n_estimators': 541, 'min_child_samples': 73, 'min_child_weight': 0.00137638341271984, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004495423822114892, 'reg_lambda': 1.014368923265531e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:39,234] Trial 680 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 294, 'max_depth': 2, 'learning_rate': 4.7586059059626926e-08, 'n_estimators': 525, 'min_child_samples': 68, 'min_child_weight': 0.0011025187657583983, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007358072283290016, 'reg_lambda': 1.9398019258814937e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:39,817] Trial 681 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 91, 'max_depth': 6, 'learning_rate': 0.003402184104733258, 'n_estimators': 537, 'min_child_samples': 64, 'min_child_weight': 0.0012291408447285474, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010581243107090708, 'reg_lambda': 2.8406709033433347e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:40,126] Trial 682 finished with value: 0.8148130709106318 and parameters: {'num_leaves': 351, 'max_depth': 9, 'learning_rate': 0.013664926567401089, 'n_estimators': 37, 'min_child_samples': 74, 'min_child_weight': 0.000504094761970701, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005755810565419444, 'reg_lambda': 9.822859406948742e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:40,488] Trial 683 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 118, 'max_depth': 4, 'learning_rate': 0.01048645260794068, 'n_estimators': 210, 'min_child_samples': 67, 'min_child_weight': 0.0007029636772430265, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003584924436574715, 'reg_lambda': 0.000422513070565668}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:40,908] Trial 684 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 323, 'max_depth': 2, 'learning_rate': 0.027963395653204492, 'n_estimators': 570, 'min_child_samples': 70, 'min_child_weight': 0.0014877606339180518, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00945042122214354, 'reg_lambda': 1.2548082783948476e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:41,317] Trial 685 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 364, 'max_depth': 6, 'learning_rate': 0.016057664935974943, 'n_estimators': 271, 'min_child_samples': 63, 'min_child_weight': 0.0009363014303794037, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.004437046587389374, 'reg_lambda': 0.19063393928952793}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:41,977] Trial 686 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 301, 'max_depth': 17, 'learning_rate': 0.006502521554386825, 'n_estimators': 553, 'min_child_samples': 65, 'min_child_weight': 0.0010695599006793845, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014394221949980157, 'reg_lambda': 0.04346293142907721}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:42,373] Trial 687 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 312, 'max_depth': 4, 'learning_rate': 0.010352693925975097, 'n_estimators': 312, 'min_child_samples': 91, 'min_child_weight': 0.000402838236760182, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.002568074052734875, 'reg_lambda': 2.4853651307356457e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:42,982] Trial 688 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 63, 'max_depth': 8, 'learning_rate': 0.004440036358834053, 'n_estimators': 510, 'min_child_samples': 61, 'min_child_weight': 0.0007855508893032359, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001966104492595271, 'reg_lambda': 0.09605199574895269}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:43,389] Trial 689 finished with value: 0.820490132990133 and parameters: {'num_leaves': 389, 'max_depth': 2, 'learning_rate': 0.019059501713155708, 'n_estimators': 494, 'min_child_samples': 83, 'min_child_weight': 0.0002922849842820616, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0036188473970500995, 'reg_lambda': 1.8438560762915685e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:44,277] Trial 690 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 378, 'max_depth': 37, 'learning_rate': 0.007728657824445705, 'n_estimators': 916, 'min_child_samples': 69, 'min_child_weight': 0.001473187344896655, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.024727596886534958, 'reg_lambda': 6.65139360581102e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:44,905] Trial 691 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 327, 'max_depth': 6, 'learning_rate': 0.012476973245141338, 'n_estimators': 572, 'min_child_samples': 66, 'min_child_weight': 0.0005891272377023809, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005453616901425988, 'reg_lambda': 0.02494203442877043}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:45,586] Trial 692 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 141, 'max_depth': 11, 'learning_rate': 0.03323779553789297, 'n_estimators': 528, 'min_child_samples': 63, 'min_child_weight': 0.0016765381590793643, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00117240624537938, 'reg_lambda': 0.0002583918487603672}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:46,124] Trial 693 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 279, 'max_depth': 4, 'learning_rate': 0.002283533189077064, 'n_estimators': 606, 'min_child_samples': 72, 'min_child_weight': 0.0012048619796839104, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002892800851564357, 'reg_lambda': 0.24226916466766837}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:46,769] Trial 694 finished with value: 0.7981467213347979 and parameters: {'num_leaves': 347, 'max_depth': 8, 'learning_rate': 0.022994783610647603, 'n_estimators': 582, 'min_child_samples': 67, 'min_child_weight': 0.0009562354588489193, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004361239531463262, 'reg_lambda': 1.013791678405471e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:47,110] Trial 695 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 267, 'max_depth': 2, 'learning_rate': 0.016152843579686344, 'n_estimators': 226, 'min_child_samples': 76, 'min_child_weight': 0.001872912180854871, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.006879549327169157, 'reg_lambda': 1.4131383791328303e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:47,639] Trial 696 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 357, 'max_depth': 5, 'learning_rate': 0.009351525007247778, 'n_estimators': 555, 'min_child_samples': 61, 'min_child_weight': 0.0003581582900855468, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.002282181601540863, 'reg_lambda': 0.0008673367625883692}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:48,252] Trial 697 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 291, 'max_depth': 9, 'learning_rate': 0.005620643170939107, 'n_estimators': 540, 'min_child_samples': 70, 'min_child_weight': 0.0013819675381206542, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.00160646587131381, 'reg_lambda': 0.00037981309109787914}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:48,654] Trial 698 finished with value: 0.7981467213347979 and parameters: {'num_leaves': 337, 'max_depth': 2, 'learning_rate': 0.5231210405865588, 'n_estimators': 485, 'min_child_samples': 64, 'min_child_weight': 0.00351378274382647, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003214168486295608, 'reg_lambda': 0.0001734729146362218}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:49,218] Trial 699 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 75, 'max_depth': 6, 'learning_rate': 0.013616042671543078, 'n_estimators': 589, 'min_child_samples': 74, 'min_child_weight': 0.002848451494875483, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.013873154554625735, 'reg_lambda': 3.358575601948509e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:49,734] Trial 700 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 315, 'max_depth': 4, 'learning_rate': 0.022835514182878675, 'n_estimators': 612, 'min_child_samples': 88, 'min_child_weight': 0.0007746573127417727, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007382770178771359, 'reg_lambda': 1.716344187764312e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:50,356] Trial 701 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 369, 'max_depth': 7, 'learning_rate': 0.00821894782292173, 'n_estimators': 566, 'min_child_samples': 65, 'min_child_weight': 0.0004578166132563783, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004228920199531087, 'reg_lambda': 0.0005361284294487508}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:50,978] Trial 702 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 307, 'max_depth': 64, 'learning_rate': 0.010779846092181954, 'n_estimators': 512, 'min_child_samples': 68, 'min_child_weight': 0.0023355183897616687, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008543055160345632, 'reg_lambda': 2.2300927428329612e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:51,427] Trial 703 finished with value: 0.7955601764400089 and parameters: {'num_leaves': 328, 'max_depth': 2, 'learning_rate': 0.004018128698361259, 'n_estimators': 597, 'min_child_samples': 79, 'min_child_weight': 0.0016343884944407252, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0055511604419835265, 'reg_lambda': 1.3112503307868484e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:52,094] Trial 704 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 345, 'max_depth': 10, 'learning_rate': 0.03566328157121163, 'n_estimators': 561, 'min_child_samples': 62, 'min_child_weight': 0.004215887884798449, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002736916484844411, 'reg_lambda': 0.0007305123992767061}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:52,662] Trial 705 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 298, 'max_depth': 5, 'learning_rate': 0.014004346681694198, 'n_estimators': 625, 'min_child_samples': 71, 'min_child_weight': 0.001126275102567006, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019932986200964535, 'reg_lambda': 4.817822609666891e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:53,185] Trial 706 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 356, 'max_depth': 4, 'learning_rate': 0.006246490660443831, 'n_estimators': 542, 'min_child_samples': 33, 'min_child_weight': 0.0006261395716336672, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0036955274014839976, 'reg_lambda': 0.00012666910261924382}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:53,892] Trial 707 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 286, 'max_depth': 13, 'learning_rate': 0.021074822341475046, 'n_estimators': 580, 'min_child_samples': 59, 'min_child_weight': 0.0021900581791668788, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00137457878774432, 'reg_lambda': 2.9996443877472652e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:54,526] Trial 708 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 319, 'max_depth': 7, 'learning_rate': 0.009773959906054328, 'n_estimators': 608, 'min_child_samples': 66, 'min_child_weight': 0.003279771513294622, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.00579273825898026, 'reg_lambda': 0.000992469045299323}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:55,172] Trial 709 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 332, 'max_depth': 111, 'learning_rate': 0.016381634137853145, 'n_estimators': 533, 'min_child_samples': 63, 'min_child_weight': 0.0014667380085472172, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025728963324886133, 'reg_lambda': 2.453349655569452}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:55,593] Trial 710 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 275, 'max_depth': 2, 'learning_rate': 0.05033984717166262, 'n_estimators': 572, 'min_child_samples': 67, 'min_child_weight': 0.0025833457629202993, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009378331608869273, 'reg_lambda': 2.106769013150335e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:55,991] Trial 711 finished with value: 0.8422205989773557 and parameters: {'num_leaves': 348, 'max_depth': 5, 'learning_rate': 0.0273196729711125, 'n_estimators': 250, 'min_child_samples': 69, 'min_child_weight': 0.0009167034115073145, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.004515196339735714, 'reg_lambda': 0.007024180774223145}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:56,507] Trial 712 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 350, 'max_depth': 11, 'learning_rate': 0.030329887178732508, 'n_estimators': 383, 'min_child_samples': 71, 'min_child_weight': 0.0006722185469477892, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.03686113178083239, 'reg_lambda': 1.468455510130994e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:56,955] Trial 713 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 362, 'max_depth': 15, 'learning_rate': 0.04428263903566598, 'n_estimators': 252, 'min_child_samples': 69, 'min_child_weight': 0.001003605775492863, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.011084512872488067, 'reg_lambda': 0.005349850780728481}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:57,371] Trial 714 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 343, 'max_depth': 9, 'learning_rate': 0.062180657512390235, 'n_estimators': 218, 'min_child_samples': 73, 'min_child_weight': 0.0008785385051753949, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.008535436340623996, 'reg_lambda': 0.007401038167145203}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:57,791] Trial 715 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 367, 'max_depth': 7, 'learning_rate': 0.030224692874748136, 'n_estimators': 258, 'min_child_samples': 69, 'min_child_weight': 0.0008263967351662966, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.006773671283946632, 'reg_lambda': 0.03401419526229049}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:58,148] Trial 716 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 339, 'max_depth': 6, 'learning_rate': 0.023334513618664253, 'n_estimators': 144, 'min_child_samples': 73, 'min_child_weight': 0.0012017818565603871, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.005528820239758549, 'reg_lambda': 1.0064629056432543e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:58,604] Trial 717 finished with value: 0.8122888649204439 and parameters: {'num_leaves': 351, 'max_depth': 10, 'learning_rate': 0.002715641039040003, 'n_estimators': 278, 'min_child_samples': 71, 'min_child_weight': 0.0005006075718320563, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.004501290957542283, 'reg_lambda': 0.12905776591537052}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:59,083] Trial 718 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 332, 'max_depth': 5, 'learning_rate': 0.03705382522583523, 'n_estimators': 467, 'min_child_samples': 68, 'min_child_weight': 0.0010179776175034843, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.004104277617787713, 'reg_lambda': 0.3085657355597128}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:59,526] Trial 719 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 355, 'max_depth': 8, 'learning_rate': 0.00017164993579227663, 'n_estimators': 251, 'min_child_samples': 70, 'min_child_weight': 0.0007315096555366875, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.007618460653588846, 'reg_lambda': 0.013486029671218792}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:37:59,911] Trial 720 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 374, 'max_depth': 4, 'learning_rate': 0.018756863405558606, 'n_estimators': 200, 'min_child_samples': 72, 'min_child_weight': 0.0013877803687166, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.003129726312862587, 'reg_lambda': 0.42818513382238377}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:00,491] Trial 721 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 341, 'max_depth': 8, 'learning_rate': 0.005591557985210218, 'n_estimators': 519, 'min_child_samples': 77, 'min_child_weight': 0.0006211558403523239, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017971249635377264, 'reg_lambda': 0.009200649648667146}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:00,899] Trial 722 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 168, 'max_depth': 4, 'learning_rate': 0.012341280520525487, 'n_estimators': 277, 'min_child_samples': 68, 'min_child_weight': 0.0011663462266088968, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.005332589476484606, 'reg_lambda': 0.0004358570252881555}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:01,282] Trial 723 finished with value: 0.8101760010156956 and parameters: {'num_leaves': 385, 'max_depth': 45, 'learning_rate': 0.007843705837939346, 'n_estimators': 170, 'min_child_samples': 97, 'min_child_weight': 0.0017114789839191204, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.00019220919979960385, 'reg_lambda': 0.004207267373829664}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:01,867] Trial 724 finished with value: 0.7974449198985706 and parameters: {'num_leaves': 323, 'max_depth': 12, 'learning_rate': 0.024144002665509607, 'n_estimators': 485, 'min_child_samples': 74, 'min_child_weight': 0.0009266500870353391, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.004008465845104621, 'reg_lambda': 0.007167837434967303}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:02,218] Trial 725 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 2, 'max_depth': 2, 'learning_rate': 0.01598610574104921, 'n_estimators': 290, 'min_child_samples': 67, 'min_child_weight': 0.0019511693673575003, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.00234289936089321, 'reg_lambda': 0.020994711645286372}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:02,875] Trial 726 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 349, 'max_depth': 57, 'learning_rate': 0.009854872447630059, 'n_estimators': 546, 'min_child_samples': 70, 'min_child_weight': 0.001340439998709519, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013495016968936774, 'reg_lambda': 1.8396542023961807e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:03,294] Trial 727 finished with value: 0.8141433939473363 and parameters: {'num_leaves': 130, 'max_depth': 6, 'learning_rate': 0.00495207497408178, 'n_estimators': 237, 'min_child_samples': 66, 'min_child_weight': 0.00047578281167728024, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031784802115296254, 'reg_lambda': 0.011163030532531992}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:03,673] Trial 728 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 361, 'max_depth': 4, 'learning_rate': 0.1554455711495629, 'n_estimators': 235, 'min_child_samples': 65, 'min_child_weight': 0.0009235232470935719, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004901349493250009, 'reg_lambda': 2.3983684348227372e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:04,261] Trial 729 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 334, 'max_depth': 9, 'learning_rate': 0.013015886323956736, 'n_estimators': 505, 'min_child_samples': 75, 'min_child_weight': 0.001881456121995105, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006401478815440395, 'reg_lambda': 0.00024912818943185}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:04,675] Trial 730 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 346, 'max_depth': 6, 'learning_rate': 0.007358494548637711, 'n_estimators': 239, 'min_child_samples': 69, 'min_child_weight': 0.0007996533285967365, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.010933126948288952, 'reg_lambda': 0.1989792079367556}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:05,114] Trial 731 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 396, 'max_depth': 2, 'learning_rate': 0.028549828119331273, 'n_estimators': 561, 'min_child_samples': 72, 'min_child_weight': 0.000381989742262921, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005666692253262793, 'reg_lambda': 0.00035688216304911153}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:05,746] Trial 732 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 320, 'max_depth': 5, 'learning_rate': 2.760253660504497e-06, 'n_estimators': 584, 'min_child_samples': 67, 'min_child_weight': 0.0011833588695478671, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.001793952191866215, 'reg_lambda': 1.313334628844824e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:06,209] Trial 733 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 360, 'max_depth': 8, 'learning_rate': 0.01847412076825766, 'n_estimators': 301, 'min_child_samples': 65, 'min_child_weight': 0.0005568026559378891, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028624310197570206, 'reg_lambda': 3.596235980032721e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:06,643] Trial 734 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 331, 'max_depth': 2, 'learning_rate': 0.010469878961540125, 'n_estimators': 555, 'min_child_samples': 70, 'min_child_weight': 0.0015714043447845468, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001063289469955614, 'reg_lambda': 1.1232757596557257}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:07,197] Trial 735 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 371, 'max_depth': 5, 'learning_rate': 0.0033117551081207745, 'n_estimators': 530, 'min_child_samples': 64, 'min_child_weight': 0.34754903807650067, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0041846059042274855, 'reg_lambda': 0.016178294755268247}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:07,639] Trial 736 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 341, 'max_depth': 11, 'learning_rate': 0.019739580647988673, 'n_estimators': 263, 'min_child_samples': 89, 'min_child_weight': 0.00246302035872758, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00792022790278561, 'reg_lambda': 1.8196294300277033e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:08,259] Trial 737 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 313, 'max_depth': 7, 'learning_rate': 0.03620696879551744, 'n_estimators': 589, 'min_child_samples': 61, 'min_child_weight': 0.0028976106169283193, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0022066028563354273, 'reg_lambda': 0.0005276607375169801}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:08,759] Trial 738 finished with value: 0.7843572540630146 and parameters: {'num_leaves': 348, 'max_depth': 4, 'learning_rate': 0.07843053942545411, 'n_estimators': 599, 'min_child_samples': 68, 'min_child_weight': 0.0007170794579379208, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0035014795835845744, 'reg_lambda': 1.329543209037947e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:09,172] Trial 739 finished with value: 0.5717338465832442 and parameters: {'num_leaves': 326, 'max_depth': 2, 'learning_rate': 0.0003775296890626254, 'n_estimators': 455, 'min_child_samples': 81, 'min_child_weight': 0.0003200212975575041, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005331326855012696, 'reg_lambda': 0.16455137394752914}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:09,776] Trial 740 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 358, 'max_depth': 7, 'learning_rate': 0.007441608714566639, 'n_estimators': 571, 'min_child_samples': 92, 'min_child_weight': 0.0020240088318802547, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.002663717481651156, 'reg_lambda': 2.4847680448602274e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:10,271] Trial 741 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 109, 'max_depth': 4, 'learning_rate': 0.014148105791299666, 'n_estimators': 515, 'min_child_samples': 85, 'min_child_weight': 0.0013727460481023745, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018474228940170117, 'reg_lambda': 1.616301803315831e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:10,913] Trial 742 finished with value: 0.7753721396489734 and parameters: {'num_leaves': 376, 'max_depth': 14, 'learning_rate': 0.05358036195676096, 'n_estimators': 548, 'min_child_samples': 72, 'min_child_weight': 0.0010566683348087627, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.006449648251711703, 'reg_lambda': 0.09929941059300774}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:11,875] Trial 743 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 340, 'max_depth': 10, 'learning_rate': 0.004373616751633778, 'n_estimators': 961, 'min_child_samples': 63, 'min_child_weight': 0.0035637658437094604, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003930421074834915, 'reg_lambda': 0.07258062024286677}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:12,277] Trial 744 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 308, 'max_depth': 2, 'learning_rate': 0.024495014740835663, 'n_estimators': 421, 'min_child_samples': 75, 'min_child_weight': 0.0017559677374407205, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014306519412407557, 'reg_lambda': 0.0006367636860480006}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:12,689] Trial 745 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 354, 'max_depth': 6, 'learning_rate': 0.01149882174539291, 'n_estimators': 221, 'min_child_samples': 67, 'min_child_weight': 0.002988084254657845, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003154973842593501, 'reg_lambda': 7.421814380849315e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:13,302] Trial 746 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 321, 'max_depth': 8, 'learning_rate': 0.006879672553678179, 'n_estimators': 486, 'min_child_samples': 65, 'min_child_weight': 0.0023467793156349763, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004831532228293473, 'reg_lambda': 1.039467783665022e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:13,977] Trial 747 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 333, 'max_depth': 103, 'learning_rate': 0.016544272482547497, 'n_estimators': 572, 'min_child_samples': 70, 'min_child_weight': 0.0005887264106652477, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021633343306008356, 'reg_lambda': 0.005494435883562019}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:14,413] Trial 748 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 365, 'max_depth': 4, 'learning_rate': 0.008870929542364805, 'n_estimators': 346, 'min_child_samples': 60, 'min_child_weight': 0.00025529749613441435, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.009768177911681405, 'reg_lambda': 3.0896054317332564e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:14,867] Trial 749 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 305, 'max_depth': 2, 'learning_rate': 0.012605886907793356, 'n_estimators': 617, 'min_child_samples': 69, 'min_child_weight': 0.0011344093842498126, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001110129116396968, 'reg_lambda': 2.043539299968543e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:15,442] Trial 750 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 298, 'max_depth': 5, 'learning_rate': 0.025759295046796468, 'n_estimators': 620, 'min_child_samples': 71, 'min_child_weight': 0.0009721183097745022, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009885696967582404, 'reg_lambda': 0.25570464452731284}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:15,895] Trial 751 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 304, 'max_depth': 2, 'learning_rate': 0.01940484525249016, 'n_estimators': 625, 'min_child_samples': 69, 'min_child_weight': 0.0008239044623821701, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00040222103930083773, 'reg_lambda': 3.928396691844762e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:16,576] Trial 752 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 312, 'max_depth': 7, 'learning_rate': 0.03997388464439362, 'n_estimators': 610, 'min_child_samples': 73, 'min_child_weight': 0.001306369612324568, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007339496825977956, 'reg_lambda': 0.0003152103112141963}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:17,272] Trial 753 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 300, 'max_depth': 10, 'learning_rate': 0.014749563095306471, 'n_estimators': 638, 'min_child_samples': 69, 'min_child_weight': 0.0010213128422238435, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007094569297615415, 'reg_lambda': 7.469065628969379}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:17,770] Trial 754 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 311, 'max_depth': 4, 'learning_rate': 0.01358066586066122, 'n_estimators': 531, 'min_child_samples': 71, 'min_child_weight': 0.0007459929004727948, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014387012241170898, 'reg_lambda': 2.179473112112483e-05}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:18,329] Trial 755 finished with value: 0.8159077066429673 and parameters: {'num_leaves': 153, 'max_depth': 6, 'learning_rate': 0.0306478053458557, 'n_estimators': 600, 'min_child_samples': 78, 'min_child_weight': 0.0012964863174805353, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.001125792240241349, 'reg_lambda': 0.00018608297574626852}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:18,744] Trial 756 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 315, 'max_depth': 2, 'learning_rate': 0.020934024091234422, 'n_estimators': 508, 'min_child_samples': 68, 'min_child_weight': 0.001132723107305698, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012706920650242795, 'reg_lambda': 0.00046301406356563527}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:19,166] Trial 757 finished with value: 0.8159077066429673 and parameters: {'num_leaves': 316, 'max_depth': 2, 'learning_rate': 0.0465583745485054, 'n_estimators': 505, 'min_child_samples': 68, 'min_child_weight': 0.0009477926741727898, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.000764038586536391, 'reg_lambda': 0.0009233238948487925}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:19,762] Trial 758 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 307, 'max_depth': 9, 'learning_rate': 0.025988953976911398, 'n_estimators': 481, 'min_child_samples': 70, 'min_child_weight': 0.0011997778489524077, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009083446017789455, 'reg_lambda': 0.00042683077401673596}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:20,255] Trial 759 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 300, 'max_depth': 5, 'learning_rate': 0.021883109504550097, 'n_estimators': 462, 'min_child_samples': 72, 'min_child_weight': 0.0008154975945257338, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001103065411861495, 'reg_lambda': 0.0002835268885799664}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:20,831] Trial 760 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 317, 'max_depth': 8, 'learning_rate': 0.03395992672731297, 'n_estimators': 500, 'min_child_samples': 68, 'min_child_weight': 0.0011327929698532896, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012264881071916104, 'reg_lambda': 0.0004230512436973707}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:21,479] Trial 761 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 291, 'max_depth': 12, 'learning_rate': 0.02168337112341042, 'n_estimators': 516, 'min_child_samples': 67, 'min_child_weight': 0.0015020564067046013, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0006203708394240789, 'reg_lambda': 0.0005560341355060252}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:21,958] Trial 762 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 309, 'max_depth': 4, 'learning_rate': 0.08853176473253394, 'n_estimators': 493, 'min_child_samples': 69, 'min_child_weight': 0.042590507057336115, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013211922597048972, 'reg_lambda': 0.0007053609574250466}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:22,385] Trial 763 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 322, 'max_depth': 2, 'learning_rate': 0.016455087779609374, 'n_estimators': 526, 'min_child_samples': 74, 'min_child_weight': 0.000628817924259154, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005141002660942893, 'reg_lambda': 0.0003038643209659998}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:22,935] Trial 764 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 302, 'max_depth': 6, 'learning_rate': 0.032939486358893315, 'n_estimators': 545, 'min_child_samples': 72, 'min_child_weight': 0.0010866056157021332, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010911123553462535, 'reg_lambda': 0.0004746437939567065}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:23,412] Trial 765 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 315, 'max_depth': 4, 'learning_rate': 0.05336824469191393, 'n_estimators': 473, 'min_child_samples': 67, 'min_child_weight': 0.0014566864468169235, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009186843785736311, 'reg_lambda': 0.0002278722687614233}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:23,968] Trial 766 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 325, 'max_depth': 7, 'learning_rate': 0.018363771519451316, 'n_estimators': 506, 'min_child_samples': 70, 'min_child_weight': 0.000825756807460419, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017468614591729212, 'reg_lambda': 0.0006443833408013186}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:24,400] Trial 767 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 296, 'max_depth': 2, 'learning_rate': 0.012274496350752302, 'n_estimators': 535, 'min_child_samples': 66, 'min_child_weight': 0.0015527238343201872, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008664412002789735, 'reg_lambda': 0.000325522687763438}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:24,943] Trial 768 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 306, 'max_depth': 9, 'learning_rate': 0.021096787170950548, 'n_estimators': 429, 'min_child_samples': 69, 'min_child_weight': 0.001126080305642989, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016510254381363145, 'reg_lambda': 0.0004721118713933929}. Best is trial 364 with value: 0.8424571599211106.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:25,478] Trial 769 finished with value: 0.8468468468468469 and parameters: {'num_leaves': 293, 'max_depth': 5, 'learning_rate': 0.012725472211138492, 'n_estimators': 550, 'min_child_samples': 73, 'min_child_weight': 0.0008830758141012929, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001155887520163899, 'reg_lambda': 0.0007569327227101199}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:26,109] Trial 770 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 293, 'max_depth': 28, 'learning_rate': 0.026566582975144068, 'n_estimators': 519, 'min_child_samples': 74, 'min_child_weight': 0.0006663762122391682, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008568782860517407, 'reg_lambda': 0.0008213470965992868}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:26,450] Trial 771 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 286, 'max_depth': 13, 'learning_rate': 0.0158023107238745, 'n_estimators': 78, 'min_child_samples': 76, 'min_child_weight': 0.000886039290754626, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005926680807993134, 'reg_lambda': 0.0006576624726473538}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:27,076] Trial 772 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 296, 'max_depth': 11, 'learning_rate': 0.04094924115609182, 'n_estimators': 548, 'min_child_samples': 76, 'min_child_weight': 0.0005335901453704415, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012679813036660125, 'reg_lambda': 0.0005907223334310661}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:27,659] Trial 773 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 290, 'max_depth': 8, 'learning_rate': 0.012428424883112263, 'n_estimators': 532, 'min_child_samples': 72, 'min_child_weight': 0.0007218923842381914, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011284284273576533, 'reg_lambda': 0.0007556603436707642}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:28,299] Trial 774 finished with value: 0.7974449198985706 and parameters: {'num_leaves': 180, 'max_depth': 16, 'learning_rate': 0.018985101082169088, 'n_estimators': 551, 'min_child_samples': 73, 'min_child_weight': 0.0009002679366274357, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013607870293181154, 'reg_lambda': 0.00042779793547838}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:28,918] Trial 775 finished with value: 0.788723176958471 and parameters: {'num_leaves': 306, 'max_depth': 78, 'learning_rate': 0.030829916604138072, 'n_estimators': 509, 'min_child_samples': 75, 'min_child_weight': 0.001143335268968402, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008751403500291398, 'reg_lambda': 0.0011475736788332924}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:29,488] Trial 776 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 283, 'max_depth': 6, 'learning_rate': 0.012676474622327339, 'n_estimators': 564, 'min_child_samples': 71, 'min_child_weight': 0.0004257266466366244, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015865395937051804, 'reg_lambda': 0.0008294859681406025}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:30,106] Trial 777 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 306, 'max_depth': 10, 'learning_rate': 0.023036737286832285, 'n_estimators': 529, 'min_child_samples': 79, 'min_child_weight': 0.0009936438888267915, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011250700008618927, 'reg_lambda': 0.0005505078303448997}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:30,624] Trial 778 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 289, 'max_depth': 5, 'learning_rate': 0.015968977306656598, 'n_estimators': 494, 'min_child_samples': 73, 'min_child_weight': 0.0007292993129432675, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015622532671183188, 'reg_lambda': 0.0003560018489592773}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:31,186] Trial 779 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 266, 'max_depth': 9, 'learning_rate': 0.02549447008539746, 'n_estimators': 452, 'min_child_samples': 74, 'min_child_weight': 0.0005834142543492417, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015186832009020626, 'reg_lambda': 0.00019407138667686607}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:31,752] Trial 780 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 277, 'max_depth': 12, 'learning_rate': 0.01736213948595668, 'n_estimators': 472, 'min_child_samples': 76, 'min_child_weight': 0.0007101867457974298, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007773292689647099, 'reg_lambda': 0.00037109643423397924}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:32,307] Trial 781 finished with value: 0.7981467213347979 and parameters: {'num_leaves': 284, 'max_depth': 7, 'learning_rate': 0.03879002050854196, 'n_estimators': 492, 'min_child_samples': 73, 'min_child_weight': 0.0004992560118239946, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010189895709609154, 'reg_lambda': 0.0003536352637598441}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:32,837] Trial 782 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 291, 'max_depth': 6, 'learning_rate': 0.01738740762418447, 'n_estimators': 482, 'min_child_samples': 74, 'min_child_weight': 0.0007825474232069842, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.001497607306761208, 'reg_lambda': 0.0002550147199372725}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:33,425] Trial 783 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 296, 'max_depth': 9, 'learning_rate': 0.030212264662479504, 'n_estimators': 499, 'min_child_samples': 72, 'min_child_weight': 0.000584869001989915, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001222193842737108, 'reg_lambda': 0.0004895731838686282}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:33,911] Trial 784 finished with value: 0.8424571599211106 and parameters: {'num_leaves': 274, 'max_depth': 5, 'learning_rate': 0.012267394538402098, 'n_estimators': 441, 'min_child_samples': 75, 'min_child_weight': 0.0008507289070630819, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001584305561301711, 'reg_lambda': 0.00040907228462840794}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:34,453] Trial 785 finished with value: 0.8018018018018018 and parameters: {'num_leaves': 255, 'max_depth': 11, 'learning_rate': 0.02197910094955204, 'n_estimators': 457, 'min_child_samples': 78, 'min_child_weight': 0.0007836155686449212, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.0006788849867637445, 'reg_lambda': 0.00035259665225590087}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:34,981] Trial 786 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 267, 'max_depth': 15, 'learning_rate': 0.01490973903051646, 'n_estimators': 396, 'min_child_samples': 77, 'min_child_weight': 0.0006464793717100407, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016421855105113795, 'reg_lambda': 0.00025841578756484115}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:35,520] Trial 787 finished with value: 0.7971407701137431 and parameters: {'num_leaves': 284, 'max_depth': 8, 'learning_rate': 0.0617916362847812, 'n_estimators': 433, 'min_child_samples': 76, 'min_child_weight': 0.0007926532465583091, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012629725736725778, 'reg_lambda': 0.00034588108810713837}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:36,035] Trial 788 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 277, 'max_depth': 6, 'learning_rate': 0.015330777185517595, 'n_estimators': 443, 'min_child_samples': 80, 'min_child_weight': 0.0010924702802184495, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016183060912842867, 'reg_lambda': 0.000219821143694001}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:36,606] Trial 789 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 275, 'max_depth': 11, 'learning_rate': 0.02453995620598292, 'n_estimators': 464, 'min_child_samples': 76, 'min_child_weight': 0.0009017250048124104, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010106072709623883, 'reg_lambda': 0.0004495333179752196}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:37,132] Trial 790 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 285, 'max_depth': 8, 'learning_rate': 0.013285182373853692, 'n_estimators': 408, 'min_child_samples': 74, 'min_child_weight': 0.0004681728117515976, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018400566837368402, 'reg_lambda': 0.0004413423228416595}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:37,639] Trial 791 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 266, 'max_depth': 5, 'learning_rate': 0.0376289036231971, 'n_estimators': 492, 'min_child_samples': 77, 'min_child_weight': 0.0009556983659697879, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0004516094358366492, 'reg_lambda': 0.0003106359824698298}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:38,142] Trial 792 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 286, 'max_depth': 6, 'learning_rate': 0.010881924747311778, 'n_estimators': 416, 'min_child_samples': 73, 'min_child_weight': 0.0007590950726772213, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001284218548236808, 'reg_lambda': 0.0005285075123244218}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:38,692] Trial 793 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 273, 'max_depth': 9, 'learning_rate': 0.020871463844062067, 'n_estimators': 435, 'min_child_samples': 71, 'min_child_weight': 0.0006167490985250327, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009545760878452683, 'reg_lambda': 0.0005826926975967247}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:39,249] Trial 794 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 257, 'max_depth': 13, 'learning_rate': 0.01153044711119385, 'n_estimators': 449, 'min_child_samples': 75, 'min_child_weight': 0.00121502300507662, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017833602447918256, 'reg_lambda': 0.00015722074344530905}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:39,766] Trial 795 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 296, 'max_depth': 5, 'learning_rate': 0.028393032117041927, 'n_estimators': 469, 'min_child_samples': 78, 'min_child_weight': 0.0008818851187516442, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001971287194084746, 'reg_lambda': 0.0002250172383817576}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:40,246] Trial 796 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 292, 'max_depth': 4, 'learning_rate': 0.017811494902187797, 'n_estimators': 476, 'min_child_samples': 72, 'min_child_weight': 0.000406655420944337, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008053139176591177, 'reg_lambda': 0.00041753940470056947}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:40,806] Trial 797 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 300, 'max_depth': 7, 'learning_rate': 7.73128343549297e-06, 'n_estimators': 476, 'min_child_samples': 75, 'min_child_weight': 0.0005545026069771699, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014509855147349726, 'reg_lambda': 0.5627895596261993}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:41,291] Trial 798 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 274, 'max_depth': 4, 'learning_rate': 0.012135619840225372, 'n_estimators': 455, 'min_child_samples': 71, 'min_child_weight': 0.001131354598733504, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020165832658571793, 'reg_lambda': 0.0003007452799085049}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:41,837] Trial 799 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 284, 'max_depth': 50, 'learning_rate': 0.01922841864606833, 'n_estimators': 419, 'min_child_samples': 74, 'min_child_weight': 0.0006850507655318549, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011139544014287038, 'reg_lambda': 0.0003623171282386934}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:42,406] Trial 800 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 302, 'max_depth': 10, 'learning_rate': 0.04859964249697693, 'n_estimators': 501, 'min_child_samples': 81, 'min_child_weight': 0.0009861894164174948, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015466721344407275, 'reg_lambda': 0.0005534652097593417}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:42,943] Trial 801 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 292, 'max_depth': 7, 'learning_rate': 0.010760907070464768, 'n_estimators': 441, 'min_child_samples': 71, 'min_child_weight': 0.0013775561977197584, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0022410731787620296, 'reg_lambda': 0.0006647596379794191}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:43,436] Trial 802 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 52, 'max_depth': 4, 'learning_rate': 0.030364340479961883, 'n_estimators': 488, 'min_child_samples': 73, 'min_child_weight': 0.0009762915095863648, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019708367519335767, 'reg_lambda': 0.000275274389509816}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:44,031] Trial 803 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 280, 'max_depth': 8, 'learning_rate': 0.015180850802944887, 'n_estimators': 514, 'min_child_samples': 70, 'min_child_weight': 0.000482540633395357, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007351337042870101, 'reg_lambda': 0.0004007700487841557}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:44,502] Trial 804 finished with value: 0.8246851893910718 and parameters: {'num_leaves': 304, 'max_depth': 4, 'learning_rate': 0.02102523536064314, 'n_estimators': 383, 'min_child_samples': 36, 'min_child_weight': 0.0007341341867663802, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012268294396186024, 'reg_lambda': 0.14101124937889725}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:44,967] Trial 805 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 310, 'max_depth': 6, 'learning_rate': 0.010168979487730228, 'n_estimators': 315, 'min_child_samples': 73, 'min_child_weight': 0.001283715320530892, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0003165521845828017, 'reg_lambda': 0.0004981496362922445}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:45,528] Trial 806 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 293, 'max_depth': 10, 'learning_rate': 0.01643639605979153, 'n_estimators': 451, 'min_child_samples': 70, 'min_child_weight': 0.0009877329062207888, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015472642022576297, 'reg_lambda': 0.1997135327988021}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:45,879] Trial 807 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 270, 'max_depth': 2, 'learning_rate': 0.029148162789525863, 'n_estimators': 185, 'min_child_samples': 72, 'min_child_weight': 0.0003271162157315658, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008906822583563724, 'reg_lambda': 0.00015358098254827953}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:46,408] Trial 808 finished with value: 0.8468468468468469 and parameters: {'num_leaves': 300, 'max_depth': 5, 'learning_rate': 0.011933335728289465, 'n_estimators': 514, 'min_child_samples': 79, 'min_child_weight': 0.0006506522570580279, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021837351218001, 'reg_lambda': 0.00011075657628057122}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:46,995] Trial 809 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 286, 'max_depth': 25, 'learning_rate': 0.009946021046944168, 'n_estimators': 483, 'min_child_samples': 78, 'min_child_weight': 0.0005509588792548797, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014348906933298947, 'reg_lambda': 0.00012082134581832122}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:47,634] Trial 810 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 297, 'max_depth': 12, 'learning_rate': 0.03803814174764731, 'n_estimators': 505, 'min_child_samples': 77, 'min_child_weight': 0.0006560905401659244, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002041874230807758, 'reg_lambda': 9.557203867164721e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:48,256] Trial 811 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 304, 'max_depth': 8, 'learning_rate': 0.02130319223032615, 'n_estimators': 465, 'min_child_samples': 83, 'min_child_weight': 0.0004172539977352622, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001365752103407741, 'reg_lambda': 0.00010232318406335226}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:48,858] Trial 812 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 295, 'max_depth': 14, 'learning_rate': 0.014862770007506822, 'n_estimators': 521, 'min_child_samples': 79, 'min_child_weight': 0.0005575634730042989, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011257943430242057, 'reg_lambda': 6.236544153433461e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:49,397] Trial 813 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 278, 'max_depth': 9, 'learning_rate': 0.02587459978427615, 'n_estimators': 429, 'min_child_samples': 80, 'min_child_weight': 0.0007692420905934481, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019905995523348645, 'reg_lambda': 6.177083515913232e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:49,955] Trial 814 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 243, 'max_depth': 6, 'learning_rate': 0.010123713593246738, 'n_estimators': 494, 'min_child_samples': 80, 'min_child_weight': 0.0006751735815951057, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001965354765182103, 'reg_lambda': 0.0001150655164875524}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:50,431] Trial 815 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 289, 'max_depth': 5, 'learning_rate': 0.014719609297436946, 'n_estimators': 404, 'min_child_samples': 86, 'min_child_weight': 0.0008569309430413242, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009568618297306767, 'reg_lambda': 7.520145607025403e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:50,884] Trial 816 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 261, 'max_depth': 10, 'learning_rate': 0.04254729161837986, 'n_estimators': 259, 'min_child_samples': 77, 'min_child_weight': 0.00038963979204215604, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016226736054062482, 'reg_lambda': 7.9867848341438e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:51,447] Trial 817 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 302, 'max_depth': 7, 'learning_rate': 0.02223131754800588, 'n_estimators': 519, 'min_child_samples': 76, 'min_child_weight': 0.0005086251726019813, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024187149298813522, 'reg_lambda': 0.00018726078575723355}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:51,962] Trial 818 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 310, 'max_depth': 4, 'learning_rate': 0.013275088436841085, 'n_estimators': 540, 'min_child_samples': 79, 'min_child_weight': 0.0008803372711344903, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005591911319553084, 'reg_lambda': 5.470448222683978e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:52,519] Trial 819 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 284, 'max_depth': 7, 'learning_rate': 0.009375606166684487, 'n_estimators': 477, 'min_child_samples': 76, 'min_child_weight': 0.0011330461795176691, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011631904402851952, 'reg_lambda': 9.915309990542469e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:53,018] Trial 820 finished with value: 0.7974449198985706 and parameters: {'num_leaves': 300, 'max_depth': 4, 'learning_rate': 0.06561334546696976, 'n_estimators': 507, 'min_child_samples': 75, 'min_child_weight': 0.0006791979011276734, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002340266451555271, 'reg_lambda': 0.00013050522559196159}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:53,574] Trial 821 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 314, 'max_depth': 12, 'learning_rate': 0.01746225006023445, 'n_estimators': 442, 'min_child_samples': 82, 'min_child_weight': 0.001117268926306465, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015911161841479593, 'reg_lambda': 0.00021509257008535168}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:54,235] Trial 822 finished with value: 0.8071179781643625 and parameters: {'num_leaves': 292, 'max_depth': 9, 'learning_rate': 0.026033395548223166, 'n_estimators': 560, 'min_child_samples': 74, 'min_child_weight': 0.0008637789940233178, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.000667483590583283, 'reg_lambda': 4.5998825447875257e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:54,735] Trial 823 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 278, 'max_depth': 5, 'learning_rate': 0.012879755759258016, 'n_estimators': 465, 'min_child_samples': 87, 'min_child_weight': 0.00048312033368956336, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023847567688100027, 'reg_lambda': 7.235952015115738e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:55,176] Trial 824 finished with value: 0.8202977117191788 and parameters: {'num_leaves': 309, 'max_depth': 2, 'learning_rate': 0.019191044314332006, 'n_estimators': 527, 'min_child_samples': 78, 'min_child_weight': 0.0012997682826499746, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1.6118054438139954e-05, 'reg_lambda': 0.000318684544185462}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:55,759] Trial 825 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 224, 'max_depth': 7, 'learning_rate': 0.009787656124917271, 'n_estimators': 550, 'min_child_samples': 82, 'min_child_weight': 0.000610961381322947, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012107163539024648, 'reg_lambda': 0.32286421976167595}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:56,174] Trial 826 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 78, 'max_depth': 4, 'learning_rate': 0.038932107744232634, 'n_estimators': 288, 'min_child_samples': 75, 'min_child_weight': 0.001408425188741852, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016834191840816436, 'reg_lambda': 0.00027509527989872333}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:56,758] Trial 827 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 93, 'max_depth': 60, 'learning_rate': 2.9260572456990926e-07, 'n_estimators': 492, 'min_child_samples': 74, 'min_child_weight': 0.00031819743805149936, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001975556079267091, 'reg_lambda': 5.068653305534868e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:57,327] Trial 828 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 291, 'max_depth': 6, 'learning_rate': 0.01614610046546736, 'n_estimators': 573, 'min_child_samples': 78, 'min_child_weight': 0.0007466727861482073, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009393069758505382, 'reg_lambda': 0.00013594278407692682}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:57,733] Trial 829 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 38, 'max_depth': 10, 'learning_rate': 0.008677933013310489, 'n_estimators': 210, 'min_child_samples': 90, 'min_child_weight': 0.0010016549028855977, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.002326424213833509, 'reg_lambda': 0.0003610958899399127}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:58,183] Trial 830 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 406, 'max_depth': 2, 'learning_rate': 0.025239980436610483, 'n_estimators': 542, 'min_child_samples': 72, 'min_child_weight': 0.001241045401521032, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013520714969082594, 'reg_lambda': 0.0002301094442438879}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:58,821] Trial 831 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 272, 'max_depth': 19, 'learning_rate': 0.011777379792643247, 'n_estimators': 515, 'min_child_samples': 75, 'min_child_weight': 0.0004286870354429934, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016977647072374568, 'reg_lambda': 0.2244240502746131}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:38:59,476] Trial 832 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 302, 'max_depth': 8, 'learning_rate': 0.019112847599372925, 'n_estimators': 575, 'min_child_samples': 70, 'min_child_weight': 0.0008811219690642853, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 5.7287850761261226e-05, 'reg_lambda': 0.000445319493880895}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:00,026] Trial 833 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 314, 'max_depth': 5, 'learning_rate': 2.490405981755045e-05, 'n_estimators': 448, 'min_child_samples': 73, 'min_child_weight': 0.0015026557539357863, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009331381267195087, 'reg_lambda': 0.00018024703509831547}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:00,665] Trial 834 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 282, 'max_depth': 67, 'learning_rate': 0.028562629703976515, 'n_estimators': 551, 'min_child_samples': 80, 'min_child_weight': 0.0006553078017091883, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023873100090731516, 'reg_lambda': 0.00036918927755756625}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:01,146] Trial 835 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 68, 'max_depth': 4, 'learning_rate': 0.012445206105955255, 'n_estimators': 420, 'min_child_samples': 85, 'min_child_weight': 0.0010120436663852794, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001248453424144935, 'reg_lambda': 8.656675092316562e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:01,710] Trial 836 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 295, 'max_depth': 7, 'learning_rate': 0.00849515966085316, 'n_estimators': 485, 'min_child_samples': 84, 'min_child_weight': 0.0005632061698630358, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025198046826492085, 'reg_lambda': 0.10575319143952962}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:02,407] Trial 837 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 257, 'max_depth': 11, 'learning_rate': 0.016283233620473465, 'n_estimators': 582, 'min_child_samples': 77, 'min_child_weight': 0.0012841754834743734, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007335368997669685, 'reg_lambda': 0.16206521951445904}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:02,867] Trial 838 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 124, 'max_depth': 2, 'learning_rate': 0.053419419647885415, 'n_estimators': 534, 'min_child_samples': 69, 'min_child_weight': 0.0008061756293133033, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017437618363878226, 'reg_lambda': 0.00027409408684296214}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:03,417] Trial 839 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 317, 'max_depth': 5, 'learning_rate': 0.03533358628247271, 'n_estimators': 560, 'min_child_samples': 72, 'min_child_weight': 0.0003599133184977887, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012877812501582689, 'reg_lambda': 0.0004970841684908488}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:04,056] Trial 840 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 300, 'max_depth': 33, 'learning_rate': 0.021620006410105624, 'n_estimators': 502, 'min_child_samples': 69, 'min_child_weight': 0.0015741527366596394, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002591340094960003, 'reg_lambda': 0.29009235332984407}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:04,660] Trial 841 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 290, 'max_depth': 8, 'learning_rate': 0.012984902089449062, 'n_estimators': 521, 'min_child_samples': 74, 'min_child_weight': 0.0010694801748091947, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019382865914694682, 'reg_lambda': 0.4042259155792063}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:05,243] Trial 842 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 143, 'max_depth': 40, 'learning_rate': 0.00876655949214852, 'n_estimators': 459, 'min_child_samples': 71, 'min_child_weight': 0.00046870622228825307, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009740945853815845, 'reg_lambda': 0.0035634945393494422}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:05,653] Trial 843 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 269, 'max_depth': 4, 'learning_rate': 0.01575899883256121, 'n_estimators': 242, 'min_child_samples': 42, 'min_child_weight': 0.0006850471799672851, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00161398832271298, 'reg_lambda': 0.061723954957910665}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:06,345] Trial 844 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 314, 'max_depth': 13, 'learning_rate': 0.029920497313362132, 'n_estimators': 574, 'min_child_samples': 69, 'min_child_weight': 0.00025585263925948393, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025346089085872105, 'reg_lambda': 0.0005963608108111532}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:06,823] Trial 845 finished with value: 0.7884424718940626 and parameters: {'num_leaves': 281, 'max_depth': 85, 'learning_rate': 0.0891607329039406, 'n_estimators': 272, 'min_child_samples': 75, 'min_child_weight': 0.000918479728053418, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001426024825200695, 'reg_lambda': 0.010094331709730658}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:07,282] Trial 846 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 307, 'max_depth': 2, 'learning_rate': 0.00910247498785982, 'n_estimators': 592, 'min_child_samples': 71, 'min_child_weight': 0.0012513856882211565, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005346490266667816, 'reg_lambda': 5.520525176354414e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:07,861] Trial 847 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 99, 'max_depth': 7, 'learning_rate': 0.018974776572822386, 'n_estimators': 558, 'min_child_samples': 88, 'min_child_weight': 0.0005739494035053065, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020701612377013513, 'reg_lambda': 0.00014525556173416182}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:08,450] Trial 848 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 287, 'max_depth': 10, 'learning_rate': 0.012470563402694522, 'n_estimators': 479, 'min_child_samples': 77, 'min_child_weight': 0.0015703034947377975, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011673230574220752, 'reg_lambda': 0.0004086149915622377}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:08,989] Trial 849 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 300, 'max_depth': 5, 'learning_rate': 0.024003338135955034, 'n_estimators': 534, 'min_child_samples': 68, 'min_child_weight': 0.0007997361128817364, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0026174591386662906, 'reg_lambda': 0.00026372329479408134}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:09,448] Trial 850 finished with value: 0.820490132990133 and parameters: {'num_leaves': 320, 'max_depth': 2, 'learning_rate': 0.009082748337148333, 'n_estimators': 590, 'min_child_samples': 73, 'min_child_weight': 0.001045926256899061, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 4.297332177901737, 'reg_lambda': 0.12011705651074697}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:09,976] Trial 851 finished with value: 0.7893478279020448 and parameters: {'num_leaves': 306, 'max_depth': 6, 'learning_rate': 0.04977356688454921, 'n_estimators': 430, 'min_child_samples': 68, 'min_child_weight': 0.0012811937247238466, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018084554828297812, 'reg_lambda': 9.128891088797922e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:10,550] Trial 852 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 252, 'max_depth': 9, 'learning_rate': 0.015185890002181918, 'n_estimators': 514, 'min_child_samples': 81, 'min_child_weight': 0.0008159036744409213, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008266621934147589, 'reg_lambda': 0.0006814208906041878}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:11,066] Trial 853 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 276, 'max_depth': 4, 'learning_rate': 0.03460909461953573, 'n_estimators': 561, 'min_child_samples': 76, 'min_child_weight': 0.00148744590737603, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028551638507265825, 'reg_lambda': 0.0004218087145768441}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:11,621] Trial 854 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 27, 'max_depth': 7, 'learning_rate': 0.020081445545743485, 'n_estimators': 542, 'min_child_samples': 93, 'min_child_weight': 0.0004965679846900403, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020490168506731164, 'reg_lambda': 0.017808034878899884}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:12,035] Trial 855 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 291, 'max_depth': 2, 'learning_rate': 0.011692484789655896, 'n_estimators': 401, 'min_child_samples': 71, 'min_child_weight': 0.0006761415317965507, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014082117672263048, 'reg_lambda': 0.00031210222766450864}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:12,556] Trial 856 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 320, 'max_depth': 5, 'learning_rate': 0.009010043036227893, 'n_estimators': 506, 'min_child_samples': 83, 'min_child_weight': 0.0009558605194846607, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028705554064829344, 'reg_lambda': 0.2244095089800907}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:13,070] Trial 857 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 114, 'max_depth': 9, 'learning_rate': 0.025187062020446065, 'n_estimators': 379, 'min_child_samples': 73, 'min_child_weight': 0.0003711153131954225, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.30916386559551945, 'reg_lambda': 0.0001700052919993152}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:13,676] Trial 858 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 498, 'max_depth': 15, 'learning_rate': 0.015810727557507433, 'n_estimators': 459, 'min_child_samples': 67, 'min_child_weight': 0.0016134215932308892, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010087940233523738, 'reg_lambda': 0.02635192572189815}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:14,215] Trial 859 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 86, 'max_depth': 4, 'learning_rate': 0.007442296547317458, 'n_estimators': 583, 'min_child_samples': 70, 'min_child_weight': 0.0011299297445408493, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015347858524581194, 'reg_lambda': 0.0005211398728985254}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:14,783] Trial 860 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 301, 'max_depth': 7, 'learning_rate': 0.012416467396369651, 'n_estimators': 494, 'min_child_samples': 72, 'min_child_weight': 0.0007289697383193725, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.002183764732152745, 'reg_lambda': 0.0006906509381466168}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:15,479] Trial 861 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 313, 'max_depth': 12, 'learning_rate': 0.022047257908970285, 'n_estimators': 605, 'min_child_samples': 75, 'min_child_weight': 0.0011723551760129194, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0006427449162347437, 'reg_lambda': 0.00020288561989466344}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:15,934] Trial 862 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 461, 'max_depth': 2, 'learning_rate': 0.037054870739978076, 'n_estimators': 528, 'min_child_samples': 78, 'min_child_weight': 0.0006062063292018276, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002820056451805025, 'reg_lambda': 0.04464023515564238}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:16,419] Trial 863 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 282, 'max_depth': 5, 'learning_rate': 0.00719211674266744, 'n_estimators': 343, 'min_child_samples': 68, 'min_child_weight': 0.0009503278528403523, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.0011483010333553166, 'reg_lambda': 0.0003549754714078546}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:17,095] Trial 864 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 264, 'max_depth': 9, 'learning_rate': 0.0169672730627029, 'n_estimators': 564, 'min_child_samples': 70, 'min_child_weight': 0.001571698167212279, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00172900527337943, 'reg_lambda': 0.0005067971184126586}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:17,602] Trial 865 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 295, 'max_depth': 4, 'learning_rate': 0.012615941179099893, 'n_estimators': 473, 'min_child_samples': 67, 'min_child_weight': 0.0005057538819252096, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002957077773779755, 'reg_lambda': 0.005410691713587787}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:18,058] Trial 866 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 310, 'max_depth': 2, 'learning_rate': 0.02484362952574098, 'n_estimators': 548, 'min_child_samples': 73, 'min_child_weight': 0.0002962682742543939, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002147368522385972, 'reg_lambda': 4.1585130140406985e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:18,631] Trial 867 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 288, 'max_depth': 7, 'learning_rate': 0.008993141992906723, 'n_estimators': 592, 'min_child_samples': 69, 'min_child_weight': 0.0007996980623719169, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 6.901338222019948, 'reg_lambda': 6.350354974767127e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:19,218] Trial 868 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 321, 'max_depth': 6, 'learning_rate': 0.015985348975766485, 'n_estimators': 440, 'min_child_samples': 75, 'min_child_weight': 0.0011787986965882224, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008795922627309401, 'reg_lambda': 0.19109350339066608}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:19,752] Trial 869 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 303, 'max_depth': 11, 'learning_rate': 0.029454374121514214, 'n_estimators': 233, 'min_child_samples': 66, 'min_child_weight': 0.0017126650204307265, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001515403285639542, 'reg_lambda': 0.13997535449108037}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:20,365] Trial 870 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 276, 'max_depth': 4, 'learning_rate': 0.0114182910764846, 'n_estimators': 575, 'min_child_samples': 79, 'min_child_weight': 2.588838712378947e-05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.020516915387050926, 'reg_lambda': 0.0007007422990275296}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:20,845] Trial 871 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 295, 'max_depth': 2, 'learning_rate': 0.019108506967259277, 'n_estimators': 612, 'min_child_samples': 71, 'min_child_weight': 0.00043458122191813927, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0030692577446064947, 'reg_lambda': 9.542482418916456e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:21,497] Trial 872 finished with value: 0.779732673850321 and parameters: {'num_leaves': 316, 'max_depth': 74, 'learning_rate': 0.049351024241144514, 'n_estimators': 521, 'min_child_samples': 73, 'min_child_weight': 0.000971630909455667, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021836613502119093, 'reg_lambda': 0.00026193311849058285}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:22,076] Trial 873 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 305, 'max_depth': 7, 'learning_rate': 0.007395208456829471, 'n_estimators': 497, 'min_child_samples': 68, 'min_child_weight': 0.0006005508093267807, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012066251823846636, 'reg_lambda': 0.07880758229674589}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:22,671] Trial 874 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 287, 'max_depth': 5, 'learning_rate': 9.236965738642584e-08, 'n_estimators': 539, 'min_child_samples': 70, 'min_child_weight': 0.0014332137825933062, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0030948155922394453, 'reg_lambda': 0.0008644005438781817}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:23,278] Trial 875 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 14, 'max_depth': 9, 'learning_rate': 0.012859617175340687, 'n_estimators': 566, 'min_child_samples': 77, 'min_child_weight': 0.0017592912386612807, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00173127460708875, 'reg_lambda': 0.00043145310680563805}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:23,740] Trial 876 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 159, 'max_depth': 2, 'learning_rate': 0.030502882608780174, 'n_estimators': 593, 'min_child_samples': 89, 'min_child_weight': 0.0008210646498322518, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010647630123452522, 'reg_lambda': 0.25331297990161433}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:24,318] Trial 877 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 323, 'max_depth': 6, 'learning_rate': 0.016937656790142544, 'n_estimators': 543, 'min_child_samples': 67, 'min_child_weight': 0.001288808461144248, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023378390947838452, 'reg_lambda': 0.0003466282034748655}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:24,863] Trial 878 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 273, 'max_depth': 4, 'learning_rate': 0.010137089705382267, 'n_estimators': 614, 'min_child_samples': 74, 'min_child_weight': 0.001016112388067172, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014601790562843876, 'reg_lambda': 0.00011631905148178008}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:25,420] Trial 879 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 309, 'max_depth': 9, 'learning_rate': 0.02348495198563043, 'n_estimators': 465, 'min_child_samples': 72, 'min_child_weight': 0.12165795388267586, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.000708862388967413, 'reg_lambda': 0.0005708243217342417}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:25,994] Trial 880 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 298, 'max_depth': 6, 'learning_rate': 0.007257941073727045, 'n_estimators': 518, 'min_child_samples': 66, 'min_child_weight': 0.0007145759556322652, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.002119192168232521, 'reg_lambda': 3.553187983217827e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:26,692] Trial 881 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 265, 'max_depth': 53, 'learning_rate': 0.01303606040305431, 'n_estimators': 579, 'min_child_samples': 69, 'min_child_weight': 0.0012977251568189365, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003408193095985722, 'reg_lambda': 6.985718895546685e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:27,357] Trial 882 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 284, 'max_depth': 12, 'learning_rate': 0.0394151677371413, 'n_estimators': 556, 'min_child_samples': 81, 'min_child_weight': 0.0018865697066386335, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001281495749745634, 'reg_lambda': 0.0004076289956436121}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:27,801] Trial 883 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 324, 'max_depth': 2, 'learning_rate': 0.019798312467459174, 'n_estimators': 499, 'min_child_samples': 20, 'min_child_weight': 0.0006042291371037761, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002788498057762235, 'reg_lambda': 0.0081323698762623}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:28,353] Trial 884 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 295, 'max_depth': 8, 'learning_rate': 0.009516720666807744, 'n_estimators': 419, 'min_child_samples': 76, 'min_child_weight': 0.00037302171308715515, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0019253422610061007, 'reg_lambda': 0.3401385193497673}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:28,838] Trial 885 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 312, 'max_depth': 4, 'learning_rate': 0.006070409109358389, 'n_estimators': 442, 'min_child_samples': 71, 'min_child_weight': 0.0009721344151050897, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009018040042787752, 'reg_lambda': 0.16327660987714543}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:29,385] Trial 886 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 49, 'max_depth': 6, 'learning_rate': 0.015970448591270576, 'n_estimators': 484, 'min_child_samples': 68, 'min_child_weight': 0.0004788165739206489, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.003397081087433888, 'reg_lambda': 0.782975406659717}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:29,867] Trial 887 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 209, 'max_depth': 2, 'learning_rate': 0.02847868619641431, 'n_estimators': 595, 'min_child_samples': 87, 'min_child_weight': 1.7448758080989496e-05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.05171688820726823, 'reg_lambda': 0.0007117779877329756}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:30,975] Trial 888 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 135, 'max_depth': 10, 'learning_rate': 0.01094630462627687, 'n_estimators': 634, 'min_child_samples': 14, 'min_child_weight': 0.00022133834596642748, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017264017531381298, 'reg_lambda': 0.00029068300178562484}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:31,345] Trial 889 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 299, 'max_depth': 4, 'learning_rate': 0.07385751197023492, 'n_estimators': 139, 'min_child_samples': 66, 'min_child_weight': 0.0007805076647451497, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.002645896848239501, 'reg_lambda': 4.699110828581226e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:31,705] Trial 890 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 302, 'max_depth': 4, 'learning_rate': 0.12689015842751136, 'n_estimators': 126, 'min_child_samples': 65, 'min_child_weight': 0.0009082946954935628, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.003001083711185098, 'reg_lambda': 5.7301136146962105e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:32,101] Trial 891 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 291, 'max_depth': 2, 'learning_rate': 0.10361575691959214, 'n_estimators': 312, 'min_child_samples': 95, 'min_child_weight': 0.0007203663750320491, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00043995886942535685, 'reg_lambda': 4.0387335784868746e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:32,493] Trial 892 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 280, 'max_depth': 7, 'learning_rate': 0.11253980780522527, 'n_estimators': 138, 'min_child_samples': 66, 'min_child_weight': 0.0010803626934324172, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.003767705149511631, 'reg_lambda': 6.142649454072944e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:32,957] Trial 893 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 305, 'max_depth': 4, 'learning_rate': 0.16607580069220654, 'n_estimators': 381, 'min_child_samples': 66, 'min_child_weight': 0.0008001404336375523, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024834004820279646, 'reg_lambda': 4.682563310340447e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:33,289] Trial 894 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 314, 'max_depth': 5, 'learning_rate': 0.3153195370057265, 'n_estimators': 20, 'min_child_samples': 84, 'min_child_weight': 0.0012612939718936417, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031330205096506917, 'reg_lambda': 3.802247992449801e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:33,642] Trial 895 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 297, 'max_depth': 17, 'learning_rate': 0.10139565718841424, 'n_estimators': 61, 'min_child_samples': 79, 'min_child_weight': 0.0010567175306961446, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.0024570342364871067, 'reg_lambda': 8.54504695463854e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:34,167] Trial 896 finished with value: 0.788723176958471 and parameters: {'num_leaves': 325, 'max_depth': 8, 'learning_rate': 0.08441379431386817, 'n_estimators': 357, 'min_child_samples': 65, 'min_child_weight': 0.2589566390625915, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.003684714526145468, 'reg_lambda': 5.1604419870316286e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:34,518] Trial 897 finished with value: 0.824887818514042 and parameters: {'num_leaves': 290, 'max_depth': 2, 'learning_rate': 0.08354400864401311, 'n_estimators': 122, 'min_child_samples': 45, 'min_child_weight': 0.0015035680746585316, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013355113249684078, 'reg_lambda': 3.1446094617516286e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:34,935] Trial 898 finished with value: 0.8275562882304457 and parameters: {'num_leaves': 307, 'max_depth': 6, 'learning_rate': 0.006270113002347461, 'n_estimators': 172, 'min_child_samples': 68, 'min_child_weight': 0.0008618358881037178, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017474202132336213, 'reg_lambda': 5.490579316071931e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:35,386] Trial 899 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 282, 'max_depth': 4, 'learning_rate': 0.2075507323112498, 'n_estimators': 335, 'min_child_samples': 91, 'min_child_weight': 0.0018853601219100873, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007291067976479558, 'reg_lambda': 7.692241421494637e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:36,047] Trial 900 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 314, 'max_depth': 8, 'learning_rate': 0.04793984979760676, 'n_estimators': 571, 'min_child_samples': 75, 'min_child_weight': 0.0007299788090211326, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.001011396705025897, 'reg_lambda': 2.5820455419315524e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:36,772] Trial 901 finished with value: 0.7622616940165399 and parameters: {'num_leaves': 272, 'max_depth': 13, 'learning_rate': 0.061201542219774016, 'n_estimators': 608, 'min_child_samples': 67, 'min_child_weight': 0.001240858517916629, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023491854540950564, 'reg_lambda': 4.616027866915311e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:37,176] Trial 902 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 295, 'max_depth': 2, 'learning_rate': 0.05809091257036416, 'n_estimators': 329, 'min_child_samples': 65, 'min_child_weight': 0.000996650251112357, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0040304625143965465, 'reg_lambda': 0.003125915487421823}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:37,593] Trial 903 finished with value: 0.7704375758850468 and parameters: {'num_leaves': 302, 'max_depth': 124, 'learning_rate': 0.21980116634507119, 'n_estimators': 151, 'min_child_samples': 77, 'min_child_weight': 0.0014901586331724508, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014208122298629822, 'reg_lambda': 3.3311317247291134e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:37,939] Trial 904 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 320, 'max_depth': 5, 'learning_rate': 0.06109277120869489, 'n_estimators': 54, 'min_child_samples': 70, 'min_child_weight': 0.0006252272501366185, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003038188903402326, 'reg_lambda': 0.00021323877806146127}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:38,370] Trial 905 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 288, 'max_depth': 10, 'learning_rate': 0.03361684521171584, 'n_estimators': 167, 'min_child_samples': 73, 'min_child_weight': 0.0008437572001487523, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021732178956960797, 'reg_lambda': 2.935797062497488e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:39,000] Trial 906 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 306, 'max_depth': 7, 'learning_rate': 0.020140630928875018, 'n_estimators': 557, 'min_child_samples': 65, 'min_child_weight': 0.0012672480924994483, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017847953022240037, 'reg_lambda': 0.00010562009334702607}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:39,513] Trial 907 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 329, 'max_depth': 4, 'learning_rate': 0.012163326583684856, 'n_estimators': 539, 'min_child_samples': 71, 'min_child_weight': 0.0018443646191498022, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.001101950790414285, 'reg_lambda': 7.471330898947812e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:40,009] Trial 908 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 280, 'max_depth': 2, 'learning_rate': 0.008391200223623966, 'n_estimators': 585, 'min_child_samples': 67, 'min_child_weight': 0.001125707597789442, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0036760548702377675, 'reg_lambda': 0.00053627734546528}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:40,513] Trial 909 finished with value: 0.7753721396489734 and parameters: {'num_leaves': 391, 'max_depth': 7, 'learning_rate': 0.1342749812747304, 'n_estimators': 361, 'min_child_samples': 69, 'min_child_weight': 0.0007292024825002326, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002657503465445556, 'reg_lambda': 0.00034630829963309154}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:40,909] Trial 910 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 414, 'max_depth': 11, 'learning_rate': 0.07044565160938987, 'n_estimators': 120, 'min_child_samples': 73, 'min_child_weight': 0.0005995198906289394, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015580050664595864, 'reg_lambda': 1.5729983108035743}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:41,324] Trial 911 finished with value: 0.828254477109439 and parameters: {'num_leaves': 297, 'max_depth': 5, 'learning_rate': 0.04401053222513884, 'n_estimators': 197, 'min_child_samples': 75, 'min_child_weight': 0.0015288220657638002, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008317603841668207, 'reg_lambda': 0.00014184732342172854}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:41,813] Trial 912 finished with value: 0.8159077066429673 and parameters: {'num_leaves': 246, 'max_depth': 2, 'learning_rate': 0.015903796447938323, 'n_estimators': 626, 'min_child_samples': 80, 'min_child_weight': 0.0008863334070531318, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00200445338600849, 'reg_lambda': 0.000742654061765235}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:42,194] Trial 913 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 313, 'max_depth': 8, 'learning_rate': 0.024573982125837224, 'n_estimators': 89, 'min_child_samples': 64, 'min_child_weight': 0.00108882535575415, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.0037706528869626403, 'reg_lambda': 4.896752855383893e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:42,547] Trial 914 finished with value: 0.8154468935434523 and parameters: {'num_leaves': 329, 'max_depth': 5, 'learning_rate': 0.009838255001192267, 'n_estimators': 44, 'min_child_samples': 31, 'min_child_weight': 0.0017099670814461425, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001249650936740236, 'reg_lambda': 0.0009039008527217866}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:43,080] Trial 915 finished with value: 0.824887818514042 and parameters: {'num_leaves': 263, 'max_depth': 4, 'learning_rate': 0.015159184541886006, 'n_estimators': 526, 'min_child_samples': 40, 'min_child_weight': 0.0013700395586745465, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.002658004229791387, 'reg_lambda': 0.0005330781912116129}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:43,770] Trial 916 finished with value: 0.7794923301680058 and parameters: {'num_leaves': 286, 'max_depth': 8, 'learning_rate': 0.0005577656353321081, 'n_estimators': 559, 'min_child_samples': 67, 'min_child_weight': 0.0008266991658357848, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.0006334399322111466, 'reg_lambda': 0.0004115983222628024}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:44,250] Trial 917 finished with value: 0.824887818514042 and parameters: {'num_leaves': 302, 'max_depth': 2, 'learning_rate': 0.0059627647997687935, 'n_estimators': 600, 'min_child_samples': 71, 'min_child_weight': 0.0006644249867056617, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001984964370143925, 'reg_lambda': 3.820758954910457e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:44,613] Trial 918 finished with value: 0.7847823906380608 and parameters: {'num_leaves': 273, 'max_depth': 10, 'learning_rate': 0.5486867759730796, 'n_estimators': 158, 'min_child_samples': 69, 'min_child_weight': 0.0010281950760160723, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 2.735840761992717, 'reg_lambda': 0.013733060209743221}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:45,205] Trial 919 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 317, 'max_depth': 6, 'learning_rate': 0.028155781036036234, 'n_estimators': 572, 'min_child_samples': 76, 'min_child_weight': 0.001843020538619702, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003352441644825997, 'reg_lambda': 0.0005846807376640014}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:45,600] Trial 920 finished with value: 0.780204207675669 and parameters: {'num_leaves': 290, 'max_depth': 4, 'learning_rate': 0.30901232925480815, 'n_estimators': 177, 'min_child_samples': 65, 'min_child_weight': 0.0012735711657204454, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015240876121584467, 'reg_lambda': 5.022993581159071}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:46,188] Trial 921 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 326, 'max_depth': 6, 'learning_rate': 0.02017078181696485, 'n_estimators': 544, 'min_child_samples': 73, 'min_child_weight': 0.000869042771751457, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025875421507067405, 'reg_lambda': 0.0011094531215218944}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:46,942] Trial 922 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 309, 'max_depth': 14, 'learning_rate': 6.964615171797009e-07, 'n_estimators': 654, 'min_child_samples': 78, 'min_child_weight': 0.0006169377874383727, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011633293511277242, 'reg_lambda': 0.00027143272943453475}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:47,326] Trial 923 finished with value: 0.7777756850927582 and parameters: {'num_leaves': 296, 'max_depth': 2, 'learning_rate': 0.012468256858193494, 'n_estimators': 103, 'min_child_samples': 86, 'min_child_weight': 0.002008221798566459, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 0.003993169467429237, 'reg_lambda': 0.0041128844619104}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:48,136] Trial 924 finished with value: 0.5672468331150966 and parameters: {'num_leaves': 280, 'max_depth': 10, 'learning_rate': 0.00024898247342464413, 'n_estimators': 584, 'min_child_samples': 48, 'min_child_weight': 0.0010260353659650098, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004534478472671262, 'reg_lambda': 0.00016993057235914285}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:48,518] Trial 925 finished with value: 0.8171238954412691 and parameters: {'num_leaves': 319, 'max_depth': 30, 'learning_rate': 0.009037006428978136, 'n_estimators': 80, 'min_child_samples': 68, 'min_child_weight': 0.0005418905013294564, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018838644563548225, 'reg_lambda': 2.7012725520910776e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:48,909] Trial 926 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 302, 'max_depth': 6, 'learning_rate': 0.0378117423815206, 'n_estimators': 110, 'min_child_samples': 64, 'min_child_weight': 0.0013134068473082277, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009281204633262626, 'reg_lambda': 0.0004669162202127175}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:49,434] Trial 927 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 309, 'max_depth': 4, 'learning_rate': 0.020787751468579415, 'n_estimators': 524, 'min_child_samples': 82, 'min_child_weight': 0.0007498891528686738, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0028199829381796524, 'reg_lambda': 6.876310497185047e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:51,339] Trial 928 finished with value: 0.7794400238895547 and parameters: {'num_leaves': 332, 'max_depth': 97, 'learning_rate': 0.007063017421090241, 'n_estimators': 615, 'min_child_samples': 9, 'min_child_weight': 0.0016276411847979165, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013286711204204128, 'reg_lambda': 0.0007678286681420894}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:52,283] Trial 929 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 289, 'max_depth': 8, 'learning_rate': 0.01381429675418947, 'n_estimators': 639, 'min_child_samples': 71, 'min_child_weight': 0.0011613972504390493, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021899175893487464, 'reg_lambda': 0.0065956657969883405}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:52,746] Trial 930 finished with value: 0.8159077066429673 and parameters: {'num_leaves': 271, 'max_depth': 2, 'learning_rate': 0.016134957537247467, 'n_estimators': 555, 'min_child_samples': 74, 'min_child_weight': 0.0009344764546833278, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.012854935748692306, 'reg_lambda': 2.2536873854828395e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:53,356] Trial 931 finished with value: 0.7350866998032943 and parameters: {'num_leaves': 231, 'max_depth': 5, 'learning_rate': 0.7711958034523552, 'n_estimators': 599, 'min_child_samples': 66, 'min_child_weight': 0.0006984788373067168, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0035946549281739566, 'reg_lambda': 0.0003813326850458391}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:54,050] Trial 932 finished with value: 0.7578801894678183 and parameters: {'num_leaves': 297, 'max_depth': 9, 'learning_rate': 0.18496179808286123, 'n_estimators': 574, 'min_child_samples': 68, 'min_child_weight': 0.0005329594540042027, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0016359694607443733, 'reg_lambda': 4.433691011607522e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:54,436] Trial 933 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 321, 'max_depth': 4, 'learning_rate': 0.01049864707945214, 'n_estimators': 141, 'min_child_samples': 72, 'min_child_weight': 0.0013778076302985802, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00276601740087388, 'reg_lambda': 0.0002275794863679314}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:55,035] Trial 934 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 258, 'max_depth': 7, 'learning_rate': 0.029481604207356887, 'n_estimators': 541, 'min_child_samples': 70, 'min_child_weight': 0.0018212729597866357, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004627396860257205, 'reg_lambda': 1.0111918312383311e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:55,488] Trial 935 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 284, 'max_depth': 2, 'learning_rate': 0.005603132019907504, 'n_estimators': 518, 'min_child_samples': 66, 'min_child_weight': 0.000959594546659399, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010305180940693823, 'reg_lambda': 0.0006673882732959487}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:56,194] Trial 936 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 310, 'max_depth': 107, 'learning_rate': 2.279254877217475e-08, 'n_estimators': 594, 'min_child_samples': 75, 'min_child_weight': 0.0008082340647367606, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.002292967604105263, 'reg_lambda': 0.00011668740504840254}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:56,862] Trial 937 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 197, 'max_depth': 12, 'learning_rate': 5.296995756726041e-05, 'n_estimators': 615, 'min_child_samples': 89, 'min_child_weight': 0.0020776697827955457, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.015833963584604493, 'reg_lambda': 1.8797348917945568e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:57,443] Trial 938 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 331, 'max_depth': 5, 'learning_rate': 0.018177816693778107, 'n_estimators': 562, 'min_child_samples': 63, 'min_child_weight': 0.0011799970978439466, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005506146959858752, 'reg_lambda': 0.000989974506432507}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:57,945] Trial 939 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 298, 'max_depth': 8, 'learning_rate': 0.010775098217772302, 'n_estimators': 299, 'min_child_samples': 69, 'min_child_weight': 0.0015494406457244917, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0015680619948967376, 'reg_lambda': 3.1934335541035e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:58,405] Trial 940 finished with value: 0.8334547119166025 and parameters: {'num_leaves': 317, 'max_depth': 2, 'learning_rate': 0.024668163143997467, 'n_estimators': 506, 'min_child_samples': 72, 'min_child_weight': 0.0006961205497543729, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0035077013901332332, 'reg_lambda': 0.000513154676049336}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:58,988] Trial 941 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 381, 'max_depth': 6, 'learning_rate': 0.008074937248270912, 'n_estimators': 536, 'min_child_samples': 77, 'min_child_weight': 0.000496931614409094, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020512188966797344, 'reg_lambda': 0.00031464230745102353}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:59,340] Trial 942 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 277, 'max_depth': 11, 'learning_rate': 0.040894426366901944, 'n_estimators': 29, 'min_child_samples': 64, 'min_child_weight': 0.0010901428619379352, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007869011465549214, 'reg_lambda': 1.5673664835248107e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:39:59,897] Trial 943 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 305, 'max_depth': 4, 'learning_rate': 0.013937751944016231, 'n_estimators': 580, 'min_child_samples': 74, 'min_child_weight': 0.0013580502945376677, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004719996685753611, 'reg_lambda': 8.658572588941172e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:00,674] Trial 944 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 290, 'max_depth': 7, 'learning_rate': 0.02284462456861383, 'n_estimators': 807, 'min_child_samples': 67, 'min_child_weight': 0.0009024185289461423, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002984235628876618, 'reg_lambda': 0.0014069336491249228}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:01,244] Trial 945 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 401, 'max_depth': 4, 'learning_rate': 0.012187466927454637, 'n_estimators': 624, 'min_child_samples': 70, 'min_child_weight': 0.0015951422341998003, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001089687257152821, 'reg_lambda': 0.00042279451275175717}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:01,965] Trial 946 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 438, 'max_depth': 22, 'learning_rate': 0.008643914077586877, 'n_estimators': 561, 'min_child_samples': 66, 'min_child_weight': 0.0021270292382916255, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013648542669675728, 'reg_lambda': 6.169822050616588e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:02,857] Trial 947 finished with value: 0.7884424718940626 and parameters: {'num_leaves': 327, 'max_depth': 9, 'learning_rate': 0.017658660463544952, 'n_estimators': 604, 'min_child_samples': 26, 'min_child_weight': 0.0006180080927844883, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0018022864876232113, 'reg_lambda': 2.343053661107631e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:03,322] Trial 948 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 315, 'max_depth': 2, 'learning_rate': 0.03221262917255079, 'n_estimators': 539, 'min_child_samples': 80, 'min_child_weight': 0.0008336259674697301, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002506771574266668, 'reg_lambda': 0.0006449457461348773}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:03,947] Trial 949 finished with value: 0.77581499024798 and parameters: {'num_leaves': 267, 'max_depth': 6, 'learning_rate': 0.06683640749022576, 'n_estimators': 652, 'min_child_samples': 69, 'min_child_weight': 0.001035682832917532, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003640603676518012, 'reg_lambda': 0.000917393685227955}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:04,719] Trial 950 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 297, 'max_depth': 5, 'learning_rate': 0.006859325458050302, 'n_estimators': 935, 'min_child_samples': 76, 'min_child_weight': 0.00044410335184124565, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.006287333666136944, 'reg_lambda': 0.0024895908808872636}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:05,107] Trial 951 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 285, 'max_depth': 2, 'learning_rate': 0.01416558431130517, 'n_estimators': 210, 'min_child_samples': 72, 'min_child_weight': 0.001190059336143246, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017292280833065736, 'reg_lambda': 1.2295880940004733e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:05,475] Trial 952 finished with value: 0.8188643188643188 and parameters: {'num_leaves': 308, 'max_depth': 116, 'learning_rate': 0.020297617415579155, 'n_estimators': 69, 'min_child_samples': 64, 'min_child_weight': 0.0007033704614320463, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002833887911715894, 'reg_lambda': 0.00031115450592143713}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:06,105] Trial 953 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 334, 'max_depth': 36, 'learning_rate': 0.005328281843965899, 'n_estimators': 576, 'min_child_samples': 92, 'min_child_weight': 0.0014922696983722668, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004494276832625674, 'reg_lambda': 0.0002383940917489703}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:06,673] Trial 954 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 298, 'max_depth': 10, 'learning_rate': 0.010888539224061508, 'n_estimators': 399, 'min_child_samples': 67, 'min_child_weight': 0.0021836820935231217, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012152545712630126, 'reg_lambda': 0.0005262906370936283}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:07,263] Trial 955 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 321, 'max_depth': 7, 'learning_rate': 0.03179946518538125, 'n_estimators': 519, 'min_child_samples': 84, 'min_child_weight': 0.0005510105566646847, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.0022714597543916503, 'reg_lambda': 4.57560125872985e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:07,987] Trial 956 finished with value: 0.8018018018018018 and parameters: {'num_leaves': 288, 'max_depth': 14, 'learning_rate': 0.016040750022572707, 'n_estimators': 632, 'min_child_samples': 74, 'min_child_weight': 0.000851386793248309, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008399040554189702, 'reg_lambda': 1.399117519541049e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:08,440] Trial 957 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 305, 'max_depth': 71, 'learning_rate': 1.2758160664339388e-06, 'n_estimators': 187, 'min_child_samples': 70, 'min_child_weight': 0.001084491261482407, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005644535338222886, 'reg_lambda': 0.0003630134038367924}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:08,986] Trial 958 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 315, 'max_depth': 4, 'learning_rate': 0.052083647103885515, 'n_estimators': 591, 'min_child_samples': 78, 'min_child_weight': 0.0016957822850574016, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001509894560563303, 'reg_lambda': 3.0884024699487834e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:09,669] Trial 959 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 274, 'max_depth': 8, 'learning_rate': 0.008058255436595026, 'n_estimators': 549, 'min_child_samples': 65, 'min_child_weight': 0.02569089841715878, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003417623037440561, 'reg_lambda': 0.00016886437261722369}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:10,051] Trial 960 finished with value: 0.8094043185704923 and parameters: {'num_leaves': 330, 'max_depth': 2, 'learning_rate': 0.024028280018826762, 'n_estimators': 97, 'min_child_samples': 68, 'min_child_weight': 0.0014115509939099365, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021351154792457346, 'reg_lambda': 0.0007987266532926554}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:10,560] Trial 961 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 294, 'max_depth': 6, 'learning_rate': 0.011806653180099932, 'n_estimators': 370, 'min_child_samples': 63, 'min_child_weight': 0.0007229748255949492, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004227385410179683, 'reg_lambda': 1.8370104443059384e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:11,258] Trial 962 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 280, 'max_depth': 42, 'learning_rate': 0.018762388529476128, 'n_estimators': 566, 'min_child_samples': 71, 'min_child_weight': 0.0010511693599745905, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012665601786289173, 'reg_lambda': 0.0006010363347895089}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:11,929] Trial 963 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 385, 'max_depth': 11, 'learning_rate': 0.010263556515582648, 'n_estimators': 493, 'min_child_samples': 66, 'min_child_weight': 0.002068461367173073, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0031009958509894383, 'reg_lambda': 0.0004390478648462464}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:12,570] Trial 964 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 306, 'max_depth': 89, 'learning_rate': 0.042305630189036644, 'n_estimators': 510, 'min_child_samples': 73, 'min_child_weight': 0.0005824380507996023, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.008751990160884973, 'reg_lambda': 2.3726580099372424e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:13,132] Trial 965 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 255, 'max_depth': 4, 'learning_rate': 0.02537552682243672, 'n_estimators': 610, 'min_child_samples': 69, 'min_child_weight': 0.0008567960914917617, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001736508901245703, 'reg_lambda': 0.00010427488995360235}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:13,797] Trial 966 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 336, 'max_depth': 8, 'learning_rate': 0.014759299602430031, 'n_estimators': 531, 'min_child_samples': 63, 'min_child_weight': 0.0004324949980183264, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.13644080361278174, 'reg_lambda': 3.629699658694666e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:14,286] Trial 967 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 323, 'max_depth': 2, 'learning_rate': 0.006836973300447904, 'n_estimators': 593, 'min_child_samples': 76, 'min_child_weight': 0.0012501874833512323, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002535273483292238, 'reg_lambda': 1.0059571282375499e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:14,858] Trial 968 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 288, 'max_depth': 5, 'learning_rate': 0.0049380620825049595, 'n_estimators': 552, 'min_child_samples': 72, 'min_child_weight': 0.0009781502750616595, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.7845390658461047, 'reg_lambda': 0.001118297449766784}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:15,466] Trial 969 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 301, 'max_depth': 6, 'learning_rate': 0.01944708483511609, 'n_estimators': 578, 'min_child_samples': 67, 'min_child_weight': 0.0017395549196753603, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010326555545374034, 'reg_lambda': 1.636934881537087e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:16,174] Trial 970 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 239, 'max_depth': 93, 'learning_rate': 0.013807619772424397, 'n_estimators': 638, 'min_child_samples': 82, 'min_child_weight': 0.0007441145060067709, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.005512360573490273, 'reg_lambda': 0.534427711038857}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:16,843] Trial 971 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 309, 'max_depth': 9, 'learning_rate': 0.009468771986563767, 'n_estimators': 507, 'min_child_samples': 70, 'min_child_weight': 0.0012831065879787078, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0038444635186311304, 'reg_lambda': 6.804569407245129e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:17,409] Trial 972 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 266, 'max_depth': 4, 'learning_rate': 0.03333323202981176, 'n_estimators': 618, 'min_child_samples': 74, 'min_child_weight': 0.0005803599760875368, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021375570215027757, 'reg_lambda': 0.00030572052248165966}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:17,871] Trial 973 finished with value: 0.833675692499222 and parameters: {'num_leaves': 318, 'max_depth': 2, 'learning_rate': 0.024761638396794274, 'n_estimators': 531, 'min_child_samples': 37, 'min_child_weight': 0.0008965320265812699, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00674679649546675, 'reg_lambda': 0.031666722078041984}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:18,551] Trial 974 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 294, 'max_depth': 12, 'learning_rate': 0.01289456143122908, 'n_estimators': 563, 'min_child_samples': 79, 'min_child_weight': 4.911089618073048e-05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0029204792645158763, 'reg_lambda': 0.004626564675407351}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:18,888] Trial 975 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 280, 'max_depth': 7, 'learning_rate': 0.006700041536435528, 'n_estimators': 10, 'min_child_samples': 65, 'min_child_weight': 0.0022426062273737907, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007911505540236418, 'reg_lambda': 0.0007637678168761384}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:19,453] Trial 976 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 338, 'max_depth': 4, 'learning_rate': 0.01712176571589427, 'n_estimators': 603, 'min_child_samples': 87, 'min_child_weight': 0.0016664125988455584, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001439763881213207, 'reg_lambda': 1.3069154225821375e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:20,160] Trial 977 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 313, 'max_depth': 9, 'learning_rate': 0.009050989244495107, 'n_estimators': 547, 'min_child_samples': 68, 'min_child_weight': 0.0011892435522571994, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00481136941447317, 'reg_lambda': 0.00022505810669428802}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:20,778] Trial 978 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 326, 'max_depth': 6, 'learning_rate': 0.04196737736436993, 'n_estimators': 660, 'min_child_samples': 71, 'min_child_weight': 0.00035423200428764685, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.0018376043976407624, 'reg_lambda': 0.0005533954388556408}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:21,241] Trial 979 finished with value: 0.8378378378378378 and parameters: {'num_leaves': 301, 'max_depth': 2, 'learning_rate': 0.022500545775347044, 'n_estimators': 484, 'min_child_samples': 63, 'min_child_weight': 0.0014619302296789728, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011217932829556425, 'reg_lambda': 0.0014093214476332927}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:21,798] Trial 980 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 218, 'max_depth': 4, 'learning_rate': 0.011425152992257676, 'n_estimators': 575, 'min_child_samples': 66, 'min_child_weight': 0.0007152993710223057, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005745878199921747, 'reg_lambda': 1.9365052816136533e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:22,418] Trial 981 finished with value: 0.7794400238895547 and parameters: {'num_leaves': 289, 'max_depth': 7, 'learning_rate': 0.08510379583179102, 'n_estimators': 591, 'min_child_samples': 73, 'min_child_weight': 0.0009852385309688208, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 0.0036480731244896776, 'reg_lambda': 0.0003741639375791942}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:22,916] Trial 982 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 338, 'max_depth': 2, 'learning_rate': 1.4342509942742568e-05, 'n_estimators': 524, 'min_child_samples': 77, 'min_child_weight': 0.0022835554393862358, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002572326974831103, 'reg_lambda': 5.5325736223921863e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:23,673] Trial 983 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 272, 'max_depth': 10, 'learning_rate': 0.01754357883481731, 'n_estimators': 616, 'min_child_samples': 68, 'min_child_weight': 0.00047999464811099296, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001419710751319161, 'reg_lambda': 0.00046716733891196023}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:24,158] Trial 984 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 301, 'max_depth': 5, 'learning_rate': 0.03072036869729826, 'n_estimators': 549, 'min_child_samples': 75, 'min_child_weight': 0.0010827396765532866, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 9.322752176415893, 'reg_lambda': 2.3224384412197796e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:24,852] Trial 985 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 325, 'max_depth': 6, 'learning_rate': 9.695119522776046e-05, 'n_estimators': 583, 'min_child_samples': 70, 'min_child_weight': 0.0007555076539222444, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001920660691132478, 'reg_lambda': 0.00014222361368277303}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:25,437] Trial 986 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 285, 'max_depth': 4, 'learning_rate': 0.005153699802423464, 'n_estimators': 641, 'min_child_samples': 90, 'min_child_weight': 0.0013771570025269766, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0029893669809065975, 'reg_lambda': 0.010467148248279292}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:26,100] Trial 987 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 423, 'max_depth': 48, 'learning_rate': 0.008819325714367922, 'n_estimators': 496, 'min_child_samples': 65, 'min_child_weight': 0.0006073977408669979, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.004777452631998906, 'reg_lambda': 0.0009536391091378689}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:26,769] Trial 988 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 312, 'max_depth': 16, 'learning_rate': 0.013209125321222327, 'n_estimators': 510, 'min_child_samples': 72, 'min_child_weight': 0.0018411168290330244, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.011400444173995572, 'reg_lambda': 4.3110074000430375e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:27,298] Trial 989 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 294, 'max_depth': 8, 'learning_rate': 0.021385236793037176, 'n_estimators': 322, 'min_child_samples': 62, 'min_child_weight': 0.0008006925757235907, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.000883448237683444, 'reg_lambda': 0.0006295012927693411}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:27,779] Trial 990 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 373, 'max_depth': 2, 'learning_rate': 0.008281542074833078, 'n_estimators': 561, 'min_child_samples': 67, 'min_child_weight': 0.0011193097375177808, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.007187098886592735, 'reg_lambda': 2.9850322642696076e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:28,470] Trial 991 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 277, 'max_depth': 12, 'learning_rate': 2.628926596714113e-06, 'n_estimators': 532, 'min_child_samples': 69, 'min_child_weight': 0.0014174994401145585, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0021248535293237787, 'reg_lambda': 1.0126942567241395e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:29,078] Trial 992 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 393, 'max_depth': 5, 'learning_rate': 0.013417757702462675, 'n_estimators': 620, 'min_child_samples': 74, 'min_child_weight': 0.000950304163814998, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00373003955988041, 'reg_lambda': 0.001844917687091406}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:29,826] Trial 993 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 340, 'max_depth': 9, 'learning_rate': 0.03310826280666392, 'n_estimators': 599, 'min_child_samples': 64, 'min_child_weight': 0.00045987373299032606, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014147062664130816, 'reg_lambda': 8.668733063375573e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:30,303] Trial 994 finished with value: 0.8290706763944796 and parameters: {'num_leaves': 315, 'max_depth': 2, 'learning_rate': 0.019879226549493333, 'n_estimators': 567, 'min_child_samples': 71, 'min_child_weight': 0.002494687464205301, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0025526380819585193, 'reg_lambda': 1.4985743973562511e-05}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:30,839] Trial 995 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 307, 'max_depth': 7, 'learning_rate': 0.06026118698020208, 'n_estimators': 391, 'min_child_samples': 76, 'min_child_weight': 0.0018876746032920764, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.001733463852085978, 'reg_lambda': 0.0003084793197069285}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:31,360] Trial 996 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 294, 'max_depth': 4, 'learning_rate': 0.01021805443473726, 'n_estimators': 477, 'min_child_samples': 79, 'min_child_weight': 0.0006307351195560149, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.030494050647118784, 'reg_lambda': 0.00021168100866603517}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:32,046] Trial 997 finished with value: 0.7971407701137431 and parameters: {'num_leaves': 328, 'max_depth': 100, 'learning_rate': 0.016006167125348976, 'n_estimators': 540, 'min_child_samples': 66, 'min_child_weight': 0.0008581861958864924, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.005437471927258117, 'reg_lambda': 3.805909607047602}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:32,654] Trial 998 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 303, 'max_depth': 6, 'learning_rate': 0.025388283786157206, 'n_estimators': 584, 'min_child_samples': 69, 'min_child_weight': 0.0011519390786852513, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0010496496995009061, 'reg_lambda': 0.02252933626137012}. Best is trial 769 with value: 0.8468468468468469.\n","/tmp/ipykernel_34/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","/tmp/ipykernel_34/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","[I 2024-04-02 06:40:33,382] Trial 999 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 285, 'max_depth': 9, 'learning_rate': 0.011773870703614409, 'n_estimators': 635, 'min_child_samples': 72, 'min_child_weight': 0.001710285464435365, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00318871723770556, 'reg_lambda': 0.003272151822971199}. Best is trial 769 with value: 0.8468468468468469.\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 992, number of negative: 784\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000601 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 567\n","[LightGBM] [Info] Number of data points in the train set: 1776, number of used features: 13\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558559 -> initscore=0.235314\n","[LightGBM] [Info] Start training from score 0.235314\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Model Accuracy: 0.833333\n","Model F1 Score: 0.832880\n"]}],"source":["from tabnanny import verbose\n","import optuna\n","from lightgbm import LGBMClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def objective(trial):\n","    param = {\n","        'num_leaves': trial.suggest_int('num_leaves', 2, 500),\n","        'max_depth': trial.suggest_int('max_depth', 2, 128),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0,log=True),\n","        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n","        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n","        'min_child_weight': trial.suggest_float('min_child_weight', 1e-5, 1,log=True),\n","        'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n","        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 10,log=True),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 10,log=True)\n","    }\n","    model = LGBMClassifier(**param,verbose=-1)\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_val)\n","    accuracy = f1_score(y_val, preds, average=\"weighted\")\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=1000)\n","\n","# Best hyperparameters\n","best_params = study.best_params\n","\n","# Fit the model with best hyperparameters\n","best_model = LGBMClassifier(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","# Make predictions \n","preds = best_model.predict(X_test)\n","\n","# Check the accuracy and F1 score of the model\n","print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n","print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T06:40:33.656537Z","iopub.status.busy":"2024-04-02T06:40:33.655631Z","iopub.status.idle":"2024-04-02T06:40:33.686107Z","shell.execute_reply":"2024-04-02T06:40:33.684688Z","shell.execute_reply.started":"2024-04-02T06:40:33.656503Z"},"trusted":true},"outputs":[],"source":["pickle.dump(best_model, open(\"LGBM\", 'wb'))"]},{"cell_type":"code","execution_count":58,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-02T06:40:33.688299Z","iopub.status.busy":"2024-04-02T06:40:33.687909Z","iopub.status.idle":"2024-04-02T07:10:47.208168Z","shell.execute_reply":"2024-04-02T07:10:47.205864Z","shell.execute_reply.started":"2024-04-02T06:40:33.688267Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-04-02 06:40:33,697] A new study created in memory with name: no-name-f873f0d3-9df4-41dc-8fd0-f84458ca436e\n","[I 2024-04-02 06:40:37,684] Trial 0 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 1273, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8200743962047155.\n","[I 2024-04-02 06:40:41,229] Trial 1 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 1085, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.8338679303851168.\n","[I 2024-04-02 06:40:44,919] Trial 2 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1135, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 2 with value: 0.8380669565842438.\n","[I 2024-04-02 06:40:45,347] Trial 3 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 153, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 2 with value: 0.8380669565842438.\n","[I 2024-04-02 06:40:45,908] Trial 4 finished with value: 0.838267940547261 and parameters: {'n_estimators': 173, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 4 with value: 0.838267940547261.\n","[I 2024-04-02 06:40:46,683] Trial 5 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 297, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 4 with value: 0.838267940547261.\n","[I 2024-04-02 06:40:48,565] Trial 6 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 601, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 4 with value: 0.838267940547261.\n","[I 2024-04-02 06:40:51,087] Trial 7 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 710, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 4 with value: 0.838267940547261.\n","[I 2024-04-02 06:40:52,091] Trial 8 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 341, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:40:55,302] Trial 9 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 982, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:40:56,895] Trial 10 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 471, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:40:57,313] Trial 11 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 126, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:40:58,231] Trial 12 finished with value: 0.8036745872848512 and parameters: {'n_estimators': 403, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:00,483] Trial 13 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 818, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:01,312] Trial 14 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 285, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:05,581] Trial 15 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1476, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:08,436] Trial 16 finished with value: 0.7030580753764145 and parameters: {'n_estimators': 1446, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:11,843] Trial 17 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 1333, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:14,488] Trial 18 finished with value: 0.833675692499222 and parameters: {'n_estimators': 804, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:18,581] Trial 19 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 1496, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:21,652] Trial 20 finished with value: 0.824887818514042 and parameters: {'n_estimators': 931, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:23,428] Trial 21 finished with value: 0.8340317486530564 and parameters: {'n_estimators': 538, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:24,065] Trial 22 finished with value: 0.8319050339617852 and parameters: {'n_estimators': 249, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8426661956073721.\n","[I 2024-04-02 06:41:25,122] Trial 23 finished with value: 0.847063236774008 and parameters: {'n_estimators': 349, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:27,299] Trial 24 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 632, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:28,773] Trial 25 finished with value: 0.833675692499222 and parameters: {'n_estimators': 492, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:29,988] Trial 26 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 359, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:32,079] Trial 27 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 703, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:34,878] Trial 28 finished with value: 0.838267940547261 and parameters: {'n_estimators': 940, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:38,486] Trial 29 finished with value: 0.8366322730604221 and parameters: {'n_estimators': 1231, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:39,707] Trial 30 finished with value: 0.8329250675208845 and parameters: {'n_estimators': 430, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:40,097] Trial 31 finished with value: 0.8250604918234916 and parameters: {'n_estimators': 102, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:40,872] Trial 32 finished with value: 0.838267940547261 and parameters: {'n_estimators': 252, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:41,541] Trial 33 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 196, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 23 with value: 0.847063236774008.\n","[I 2024-04-02 06:41:42,597] Trial 34 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 357, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:43,638] Trial 35 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 346, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:46,644] Trial 36 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 1126, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:48,538] Trial 37 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 561, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:49,638] Trial 38 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 358, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:51,552] Trial 39 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 672, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:52,944] Trial 40 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 503, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:53,609] Trial 41 finished with value: 0.820651992198384 and parameters: {'n_estimators': 185, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:54,485] Trial 42 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 302, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:55,145] Trial 43 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 200, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:56,487] Trial 44 finished with value: 0.847253054961302 and parameters: {'n_estimators': 425, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:57,837] Trial 45 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 440, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:41:59,830] Trial 46 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 582, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:00,834] Trial 47 finished with value: 0.8036745872848512 and parameters: {'n_estimators': 411, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:03,765] Trial 48 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 1035, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:07,653] Trial 49 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1288, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:08,669] Trial 50 finished with value: 0.847063236774008 and parameters: {'n_estimators': 323, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:09,602] Trial 51 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 305, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:10,765] Trial 52 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 370, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:11,519] Trial 53 finished with value: 0.824887818514042 and parameters: {'n_estimators': 238, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:13,056] Trial 54 finished with value: 0.8294656263406263 and parameters: {'n_estimators': 478, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:13,496] Trial 55 finished with value: 0.8329250675208845 and parameters: {'n_estimators': 149, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:15,602] Trial 56 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 746, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:20,645] Trial 57 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1399, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:21,767] Trial 58 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 321, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:26,091] Trial 59 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 1372, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:29,423] Trial 60 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 877, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:34,723] Trial 61 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1475, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:39,662] Trial 62 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1426, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:44,534] Trial 63 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1417, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:49,228] Trial 64 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1376, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:53,533] Trial 65 finished with value: 0.838267940547261 and parameters: {'n_estimators': 1235, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:42:58,321] Trial 66 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1401, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:02,505] Trial 67 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 1184, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:06,953] Trial 68 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1316, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:12,058] Trial 69 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1455, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:17,075] Trial 70 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1463, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:22,231] Trial 71 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1402, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:26,978] Trial 72 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1339, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:32,156] Trial 73 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1480, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:36,916] Trial 74 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1350, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:41,218] Trial 75 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1260, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:45,618] Trial 76 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1171, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:50,635] Trial 77 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1415, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:54,847] Trial 78 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1298, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:43:56,181] Trial 79 finished with value: 0.847063236774008 and parameters: {'n_estimators': 371, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:01,202] Trial 80 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1497, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:06,107] Trial 81 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1387, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:10,943] Trial 82 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1349, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:15,695] Trial 83 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1429, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:16,673] Trial 84 finished with value: 0.847063236774008 and parameters: {'n_estimators': 269, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:18,615] Trial 85 finished with value: 0.847253054961302 and parameters: {'n_estimators': 523, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:20,466] Trial 86 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 515, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:22,652] Trial 87 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 632, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:24,850] Trial 88 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 624, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:26,703] Trial 89 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 526, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:28,628] Trial 90 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 551, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:30,459] Trial 91 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 521, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:32,062] Trial 92 finished with value: 0.833675692499222 and parameters: {'n_estimators': 464, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:34,365] Trial 93 finished with value: 0.847063236774008 and parameters: {'n_estimators': 656, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:35,947] Trial 94 finished with value: 0.847063236774008 and parameters: {'n_estimators': 451, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:38,408] Trial 95 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 735, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:40,616] Trial 96 finished with value: 0.833675692499222 and parameters: {'n_estimators': 597, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:42,051] Trial 97 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 395, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:43,311] Trial 98 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 388, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:44,768] Trial 99 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 408, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:46,603] Trial 100 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 495, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:48,516] Trial 101 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 519, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:50,081] Trial 102 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 419, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:52,096] Trial 103 finished with value: 0.847063236774008 and parameters: {'n_estimators': 566, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:53,965] Trial 104 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 531, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:55,412] Trial 105 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 438, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:57,618] Trial 106 finished with value: 0.847063236774008 and parameters: {'n_estimators': 632, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:44:59,335] Trial 107 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 474, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:01,481] Trial 108 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 578, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:04,099] Trial 109 finished with value: 0.838267940547261 and parameters: {'n_estimators': 789, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:06,289] Trial 110 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 683, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:07,498] Trial 111 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 330, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:08,801] Trial 112 finished with value: 0.838267940547261 and parameters: {'n_estimators': 391, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:13,798] Trial 113 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1437, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:14,608] Trial 114 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 228, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:16,157] Trial 115 finished with value: 0.847063236774008 and parameters: {'n_estimators': 499, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:17,236] Trial 116 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 286, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:18,511] Trial 117 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 341, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:21,603] Trial 118 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1023, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:23,241] Trial 119 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 451, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:26,056] Trial 120 finished with value: 0.847063236774008 and parameters: {'n_estimators': 850, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:27,191] Trial 121 finished with value: 0.847063236774008 and parameters: {'n_estimators': 369, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:28,155] Trial 122 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 305, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:29,427] Trial 123 finished with value: 0.838267940547261 and parameters: {'n_estimators': 420, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:33,282] Trial 124 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1337, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:34,360] Trial 125 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 352, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:38,357] Trial 126 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 1465, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:40,358] Trial 127 finished with value: 0.847063236774008 and parameters: {'n_estimators': 547, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:41,612] Trial 128 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 396, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:42,589] Trial 129 finished with value: 0.838267940547261 and parameters: {'n_estimators': 266, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:44,625] Trial 130 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 602, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:49,601] Trial 131 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1389, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:54,655] Trial 132 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1417, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:45:59,389] Trial 133 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1363, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:04,821] Trial 134 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1481, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:10,309] Trial 135 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1499, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:15,687] Trial 136 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1441, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:20,515] Trial 137 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1322, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:22,064] Trial 138 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 476, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:26,499] Trial 139 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1261, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:27,715] Trial 140 finished with value: 0.838267940547261 and parameters: {'n_estimators': 319, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:32,703] Trial 141 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1398, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:37,525] Trial 142 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1404, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:42,532] Trial 143 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1375, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:46,875] Trial 144 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1304, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:51,596] Trial 145 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1399, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:46:56,575] Trial 146 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1451, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:01,064] Trial 147 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1278, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:06,044] Trial 148 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1432, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:11,089] Trial 149 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1432, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:16,240] Trial 150 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1457, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:21,165] Trial 151 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1427, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:25,891] Trial 152 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1363, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:30,767] Trial 153 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1401, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:35,665] Trial 154 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1405, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:40,652] Trial 155 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1450, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:45,262] Trial 156 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1333, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:50,441] Trial 157 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1470, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:55,127] Trial 158 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1411, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:47:59,873] Trial 159 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1355, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:04,653] Trial 160 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1383, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:09,718] Trial 161 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1439, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:14,846] Trial 162 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1486, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:19,786] Trial 163 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1424, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:24,156] Trial 164 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1248, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:29,036] Trial 165 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1391, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:34,102] Trial 166 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1457, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:38,890] Trial 167 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1338, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:43,291] Trial 168 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1312, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:48,181] Trial 169 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1429, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:52,992] Trial 170 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1364, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:48:57,841] Trial 171 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1401, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:01,916] Trial 172 finished with value: 0.7294704035020937 and parameters: {'n_estimators': 1494, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:03,737] Trial 173 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 515, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:08,792] Trial 174 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1447, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:13,273] Trial 175 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1203, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:14,851] Trial 176 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 435, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:18,851] Trial 177 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1081, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:24,117] Trial 178 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1463, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:28,939] Trial 179 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1388, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:33,273] Trial 180 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 1374, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:38,073] Trial 181 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1414, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:41,434] Trial 182 finished with value: 0.847063236774008 and parameters: {'n_estimators': 924, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:46,210] Trial 183 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1399, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:50,954] Trial 184 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1349, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:53,271] Trial 185 finished with value: 0.847063236774008 and parameters: {'n_estimators': 545, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:49:55,449] Trial 186 finished with value: 0.847063236774008 and parameters: {'n_estimators': 611, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:00,018] Trial 187 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1279, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:04,651] Trial 188 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1317, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:09,190] Trial 189 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1333, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:13,909] Trial 190 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1299, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:18,336] Trial 191 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1262, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:22,942] Trial 192 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1285, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:27,840] Trial 193 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1364, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:32,664] Trial 194 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1444, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:36,895] Trial 195 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1210, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:41,528] Trial 196 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1320, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:46,531] Trial 197 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1420, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:51,431] Trial 198 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1419, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:50:56,269] Trial 199 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1382, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:01,596] Trial 200 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1500, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:06,474] Trial 201 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1425, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:11,465] Trial 202 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1428, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:16,483] Trial 203 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1470, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:21,353] Trial 204 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1405, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:23,898] Trial 205 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 718, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:26,647] Trial 206 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 774, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:31,461] Trial 207 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1375, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:36,395] Trial 208 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1447, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:41,204] Trial 209 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1391, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:46,204] Trial 210 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1422, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:51,254] Trial 211 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1466, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:51:56,137] Trial 212 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1436, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:01,040] Trial 213 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1347, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:05,939] Trial 214 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1418, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:10,898] Trial 215 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1389, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:15,825] Trial 216 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1434, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:20,440] Trial 217 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1355, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:25,437] Trial 218 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1466, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:30,547] Trial 219 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1404, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:34,910] Trial 220 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1291, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:39,759] Trial 221 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1406, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:44,541] Trial 222 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1384, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:46,902] Trial 223 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 667, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:52,024] Trial 224 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1443, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:52:56,577] Trial 225 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1329, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:01,654] Trial 226 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1424, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:06,453] Trial 227 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1367, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:11,688] Trial 228 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1482, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:16,505] Trial 229 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1403, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:21,543] Trial 230 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1454, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:24,031] Trial 231 finished with value: 0.847063236774008 and parameters: {'n_estimators': 704, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:29,010] Trial 232 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1420, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:33,930] Trial 233 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1384, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:38,315] Trial 234 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 1346, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:40,994] Trial 235 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 750, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:43,925] Trial 236 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 820, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:46,457] Trial 237 finished with value: 0.847063236774008 and parameters: {'n_estimators': 711, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:51,656] Trial 238 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1439, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:53:56,358] Trial 239 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1405, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:00,862] Trial 240 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1315, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:03,587] Trial 241 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 766, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:05,927] Trial 242 finished with value: 0.847063236774008 and parameters: {'n_estimators': 635, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:08,624] Trial 243 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 776, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:11,689] Trial 244 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 832, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:16,133] Trial 245 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1265, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:18,739] Trial 246 finished with value: 0.847063236774008 and parameters: {'n_estimators': 740, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:23,953] Trial 247 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1465, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:26,262] Trial 248 finished with value: 0.847063236774008 and parameters: {'n_estimators': 648, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:28,811] Trial 249 finished with value: 0.847063236774008 and parameters: {'n_estimators': 717, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:33,640] Trial 250 finished with value: 0.838267940547261 and parameters: {'n_estimators': 1374, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:38,385] Trial 251 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1421, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:39,798] Trial 252 finished with value: 0.847063236774008 and parameters: {'n_estimators': 375, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:42,814] Trial 253 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 877, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:45,231] Trial 254 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 687, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:47,366] Trial 255 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 589, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:52,470] Trial 256 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1437, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:54:57,361] Trial 257 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1393, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:01,489] Trial 258 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1146, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:06,824] Trial 259 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1488, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:09,653] Trial 260 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 800, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:14,254] Trial 261 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1367, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:18,173] Trial 262 finished with value: 0.7707518596312068 and parameters: {'n_estimators': 1411, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:23,343] Trial 263 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1453, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:28,091] Trial 264 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1349, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:32,989] Trial 265 finished with value: 0.838267940547261 and parameters: {'n_estimators': 1390, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:37,273] Trial 266 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1240, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:42,015] Trial 267 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1306, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:47,003] Trial 268 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1441, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:52,216] Trial 269 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1479, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:55:57,119] Trial 270 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1418, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:01,562] Trial 271 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 1380, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:06,285] Trial 272 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1340, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:11,785] Trial 273 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1465, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:16,528] Trial 274 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1421, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:18,572] Trial 275 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 572, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:19,807] Trial 276 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 345, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:24,931] Trial 277 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1498, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:29,858] Trial 278 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1400, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:34,550] Trial 279 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1362, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:36,294] Trial 280 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 487, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:41,198] Trial 281 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1446, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:45,699] Trial 282 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1275, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:50,686] Trial 283 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1430, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:52,212] Trial 284 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 404, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:54,924] Trial 285 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 763, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:56:58,734] Trial 286 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 1394, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:03,563] Trial 287 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1331, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:08,550] Trial 288 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1460, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:13,531] Trial 289 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1419, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:16,259] Trial 290 finished with value: 0.847063236774008 and parameters: {'n_estimators': 791, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:20,825] Trial 291 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1368, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:25,376] Trial 292 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1314, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:27,995] Trial 293 finished with value: 0.847063236774008 and parameters: {'n_estimators': 723, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:31,483] Trial 294 finished with value: 0.847063236774008 and parameters: {'n_estimators': 973, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:33,677] Trial 295 finished with value: 0.838267940547261 and parameters: {'n_estimators': 684, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:38,473] Trial 296 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 1392, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:43,428] Trial 297 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1467, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:48,556] Trial 298 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1445, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:52,991] Trial 299 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1353, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:57:57,884] Trial 300 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1407, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:02,353] Trial 301 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1224, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:07,326] Trial 302 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1429, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:12,008] Trial 303 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1377, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:13,404] Trial 304 finished with value: 0.8275562882304457 and parameters: {'n_estimators': 448, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:15,628] Trial 305 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 617, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:19,912] Trial 306 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 1476, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:22,883] Trial 307 finished with value: 0.847063236774008 and parameters: {'n_estimators': 852, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:27,409] Trial 308 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1281, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:28,541] Trial 309 finished with value: 0.838267940547261 and parameters: {'n_estimators': 301, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:30,521] Trial 310 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 547, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:35,230] Trial 311 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1333, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:40,078] Trial 312 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1434, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:43,729] Trial 313 finished with value: 0.838267940547261 and parameters: {'n_estimators': 1094, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:48,856] Trial 314 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1405, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:54,282] Trial 315 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1500, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:58:56,633] Trial 316 finished with value: 0.847063236774008 and parameters: {'n_estimators': 657, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:01,407] Trial 317 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1370, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:06,291] Trial 318 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1408, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:07,989] Trial 319 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 516, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:09,353] Trial 320 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 362, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:14,255] Trial 321 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1466, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:18,826] Trial 322 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1306, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:23,954] Trial 323 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1447, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:28,560] Trial 324 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1352, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:33,437] Trial 325 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1388, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:38,366] Trial 326 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1423, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:38,998] Trial 327 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 149, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:40,498] Trial 328 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 390, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:43,049] Trial 329 finished with value: 0.847063236774008 and parameters: {'n_estimators': 737, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:47,787] Trial 330 finished with value: 0.838267940547261 and parameters: {'n_estimators': 1448, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:49,016] Trial 331 finished with value: 0.847063236774008 and parameters: {'n_estimators': 325, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:54,196] Trial 332 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1391, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 06:59:58,806] Trial 333 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1357, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:03,668] Trial 334 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 1422, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:05,743] Trial 335 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 578, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:10,440] Trial 336 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1327, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:14,827] Trial 337 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1247, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:19,915] Trial 338 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1464, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:25,127] Trial 339 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1380, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:30,082] Trial 340 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1433, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:32,848] Trial 341 finished with value: 0.847063236774008 and parameters: {'n_estimators': 804, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:36,792] Trial 342 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1406, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:41,941] Trial 343 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1484, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:43,574] Trial 344 finished with value: 0.838267940547261 and parameters: {'n_estimators': 432, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:47,964] Trial 345 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1294, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:52,684] Trial 346 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1351, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:00:54,534] Trial 347 finished with value: 0.838267940547261 and parameters: {'n_estimators': 473, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:00,193] Trial 348 finished with value: 0.824887818514042 and parameters: {'n_estimators': 1450, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:05,167] Trial 349 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1394, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:10,107] Trial 350 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1416, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:12,870] Trial 351 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 769, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:17,158] Trial 352 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1380, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:17,640] Trial 353 finished with value: 0.833675692499222 and parameters: {'n_estimators': 106, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:22,204] Trial 354 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1316, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:24,618] Trial 355 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 688, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:25,453] Trial 356 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 216, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:28,074] Trial 357 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 616, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:33,177] Trial 358 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1437, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:38,203] Trial 359 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1472, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:39,145] Trial 360 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 260, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:43,766] Trial 361 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1361, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:46,902] Trial 362 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 895, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:51,363] Trial 363 finished with value: 0.838267940547261 and parameters: {'n_estimators': 1394, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:01:55,810] Trial 364 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1264, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:00,976] Trial 365 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1500, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:05,497] Trial 366 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 1443, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:07,795] Trial 367 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 647, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:09,630] Trial 368 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 499, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:14,558] Trial 369 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1408, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:18,673] Trial 370 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1177, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:23,415] Trial 371 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 1339, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:28,237] Trial 372 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1420, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:33,634] Trial 373 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1452, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:35,169] Trial 374 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 413, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:37,808] Trial 375 finished with value: 0.847063236774008 and parameters: {'n_estimators': 839, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:42,461] Trial 376 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1370, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:44,278] Trial 377 finished with value: 0.838267940547261 and parameters: {'n_estimators': 530, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:45,600] Trial 378 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 356, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:49,135] Trial 379 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1021, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:54,387] Trial 380 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1474, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:02:59,333] Trial 381 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1414, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:04,086] Trial 382 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1327, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:08,813] Trial 383 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1379, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:11,040] Trial 384 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 594, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:15,474] Trial 385 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1287, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:17,714] Trial 386 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 719, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:22,692] Trial 387 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1421, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:27,337] Trial 388 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 1453, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:31,839] Trial 389 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1360, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:37,003] Trial 390 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1397, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:42,054] Trial 391 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1428, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:47,028] Trial 392 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1460, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:48,997] Trial 393 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 558, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:53,814] Trial 394 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1382, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:55,367] Trial 395 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 453, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:03:56,494] Trial 396 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 289, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:01,689] Trial 397 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1481, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:02,970] Trial 398 finished with value: 0.847063236774008 and parameters: {'n_estimators': 378, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:07,685] Trial 399 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1335, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:10,469] Trial 400 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 780, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:15,588] Trial 401 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1430, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:19,972] Trial 402 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1305, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:24,873] Trial 403 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1401, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:27,616] Trial 404 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 746, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:32,121] Trial 405 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1353, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:33,388] Trial 406 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 337, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:38,619] Trial 407 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1445, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:41,060] Trial 408 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 677, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:45,874] Trial 409 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 1499, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:50,633] Trial 410 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1383, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:04:55,477] Trial 411 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1410, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:00,480] Trial 412 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1449, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:05,218] Trial 413 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1365, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:10,530] Trial 414 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1408, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:14,755] Trial 415 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1236, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:19,949] Trial 416 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1474, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:24,266] Trial 417 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 1333, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:29,224] Trial 418 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1422, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:34,044] Trial 419 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1382, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:37,869] Trial 420 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1283, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:43,024] Trial 421 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1440, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:45,223] Trial 422 finished with value: 0.847063236774008 and parameters: {'n_estimators': 635, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:50,092] Trial 423 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1398, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:55,254] Trial 424 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1464, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:05:59,763] Trial 425 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1306, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:02,717] Trial 426 finished with value: 0.847063236774008 and parameters: {'n_estimators': 802, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:07,409] Trial 427 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1353, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:09,198] Trial 428 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 475, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:14,321] Trial 429 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1436, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:15,774] Trial 430 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 405, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:20,671] Trial 431 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1378, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:23,008] Trial 432 finished with value: 0.847063236774008 and parameters: {'n_estimators': 714, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:28,193] Trial 433 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1421, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:33,352] Trial 434 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1477, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:37,792] Trial 435 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1259, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:43,051] Trial 436 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1399, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:44,877] Trial 437 finished with value: 0.838267940547261 and parameters: {'n_estimators': 503, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:49,375] Trial 438 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1343, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:51,578] Trial 439 finished with value: 0.847063236774008 and parameters: {'n_estimators': 602, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:56,484] Trial 440 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1444, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:06:57,742] Trial 441 finished with value: 0.833675692499222 and parameters: {'n_estimators': 313, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:02,570] Trial 442 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1366, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:04,735] Trial 443 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 759, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:08,880] Trial 444 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1212, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:13,777] Trial 445 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1396, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:15,772] Trial 446 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 548, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:20,694] Trial 447 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1471, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:25,218] Trial 448 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1323, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:30,122] Trial 449 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1433, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:34,983] Trial 450 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1418, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:37,850] Trial 451 finished with value: 0.847063236774008 and parameters: {'n_estimators': 819, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:39,220] Trial 452 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 371, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:39,982] Trial 453 finished with value: 0.838267940547261 and parameters: {'n_estimators': 173, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:43,595] Trial 454 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 1378, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:46,924] Trial 455 finished with value: 0.847063236774008 and parameters: {'n_estimators': 880, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:52,240] Trial 456 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1499, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:57,311] Trial 457 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1458, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:07:59,650] Trial 458 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 653, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:02,137] Trial 459 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 698, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:03,646] Trial 460 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 435, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:08,404] Trial 461 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1424, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:13,246] Trial 462 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1363, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:18,263] Trial 463 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1300, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:20,334] Trial 464 finished with value: 0.847063236774008 and parameters: {'n_estimators': 575, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:24,946] Trial 465 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1399, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:29,303] Trial 466 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1455, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:34,088] Trial 467 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1344, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:38,860] Trial 468 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1418, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:43,396] Trial 469 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 1387, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:48,475] Trial 470 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1441, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:51,395] Trial 471 finished with value: 0.847063236774008 and parameters: {'n_estimators': 734, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:08:55,711] Trial 472 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1278, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:00,301] Trial 473 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1324, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:04,292] Trial 474 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1134, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:09,271] Trial 475 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1407, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:14,021] Trial 476 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1364, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:18,846] Trial 477 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 1429, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:24,126] Trial 478 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1461, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:29,147] Trial 479 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1483, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:30,444] Trial 480 finished with value: 0.847063236774008 and parameters: {'n_estimators': 351, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:33,690] Trial 481 finished with value: 0.847063236774008 and parameters: {'n_estimators': 947, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:35,546] Trial 482 finished with value: 0.838267940547261 and parameters: {'n_estimators': 517, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:39,304] Trial 483 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1074, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:44,139] Trial 484 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1399, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:48,942] Trial 485 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1368, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:53,596] Trial 486 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1338, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:55,107] Trial 487 finished with value: 0.847063236774008 and parameters: {'n_estimators': 399, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:09:57,676] Trial 488 finished with value: 0.8428480422561916 and parameters: {'n_estimators': 788, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:03,138] Trial 489 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 1448, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:07,894] Trial 490 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1386, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:09,283] Trial 491 finished with value: 0.7988362849853958 and parameters: {'n_estimators': 458, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:14,201] Trial 492 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1418, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:16,626] Trial 493 finished with value: 0.847063236774008 and parameters: {'n_estimators': 672, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:21,555] Trial 494 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1468, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:26,448] Trial 495 finished with value: 0.847063236774008 and parameters: {'n_estimators': 1314, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:31,770] Trial 496 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1431, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:36,215] Trial 497 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 1258, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:41,246] Trial 498 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1406, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n","[I 2024-04-02 07:10:46,123] Trial 499 finished with value: 0.8514596079256185 and parameters: {'n_estimators': 1363, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 34 with value: 0.8514596079256185.\n"]},{"name":"stdout","output_type":"stream","text":["Model Accuracy: 0.806306\n","Model F1 Score: 0.803979\n"]}],"source":["import optuna\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def objective(trial):\n","    param = {\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n","        'max_depth': trial.suggest_int('max_depth', 2, 32),\n","        'min_samples_split': trial.suggest_int('min_samples_split', 2, 5),\n","        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n","        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n","        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n","        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy'])\n","    }\n","    model = ExtraTreesClassifier(**param)\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_val)\n","    accuracy = f1_score(y_val, preds, average=\"weighted\")\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=500)\n","\n","# Best hyperparameters\n","best_params = study.best_params\n","\n","# Fit the model with best hyperparameters\n","best_model = ExtraTreesClassifier(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","# Make predictions \n","preds = best_model.predict(X_test)\n","\n","# Check the accuracy and F1 score of the model\n","print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n","print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:10:47.213957Z","iopub.status.busy":"2024-04-02T07:10:47.213426Z","iopub.status.idle":"2024-04-02T07:10:47.276387Z","shell.execute_reply":"2024-04-02T07:10:47.274878Z","shell.execute_reply.started":"2024-04-02T07:10:47.213916Z"},"trusted":true},"outputs":[],"source":["pickle.dump(best_model, open(\"ET\", 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import optuna\n","from xgboost import XGBClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def objective(trial):\n","    param = {\n","        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n","        'max_depth': trial.suggest_int('max_depth', 2, 32),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0,log=True),\n","        'gamma': trial.suggest_float('gamma', 0.1, 1),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n","        'subsample': trial.suggest_float('subsample', 0.5, 1, step=0.1),\n","        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1, step=0.1),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 10,log=True),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 10,log=True)\n","    }\n","    model = XGBClassifier(**param)\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_val)\n","    accuracy = f1_score(y_val, preds,average=\"weighted\")\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=1000)\n","\n","# Best hyperparameters\n","best_params = study.best_params\n","\n","# Fit the model with best hyperparameters\n","best_model = XGBClassifier(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","# Make predictions \n","preds = best_model.predict(X_test)\n","\n","# Check the accuracy and F1 score of the model\n","print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n","print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:43:28.282830Z","iopub.status.busy":"2024-04-02T07:43:28.282299Z","iopub.status.idle":"2024-04-02T07:43:28.318550Z","shell.execute_reply":"2024-04-02T07:43:28.317304Z","shell.execute_reply.started":"2024-04-02T07:43:28.282791Z"},"trusted":true},"outputs":[],"source":["pickle.dump(best_model, open(\"XGB\", 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import pickle"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:43:47.915898Z","iopub.status.busy":"2024-04-02T07:43:47.914458Z","iopub.status.idle":"2024-04-02T07:43:49.350935Z","shell.execute_reply":"2024-04-02T07:43:49.349770Z","shell.execute_reply.started":"2024-04-02T07:43:47.915837Z"},"trusted":true},"outputs":[],"source":["\n","lr=pickle.load(open('LR', 'rb'))\n","gb=pickle.load(open(\"GB\", 'rb'))\n","rf=pickle.load(open(\"RF\", 'rb'))\n","lgbm=pickle.load(open(\"LGBM\", 'rb'))\n","et=pickle.load(open(\"ET\", 'rb'))\n","xgb=pickle.load(open(\"XGB\", 'rb'))\n"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:43:56.832561Z","iopub.status.busy":"2024-04-02T07:43:56.831378Z","iopub.status.idle":"2024-04-02T07:43:56.856716Z","shell.execute_reply":"2024-04-02T07:43:56.855459Z","shell.execute_reply.started":"2024-04-02T07:43:56.832513Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<catboost.core.CatBoostClassifier at 0x78a048153e80>"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["cb=CatBoostClassifier()\n","cb.load_model(\"CB\")\n"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:44:00.366152Z","iopub.status.busy":"2024-04-02T07:44:00.364891Z","iopub.status.idle":"2024-04-02T07:44:00.709556Z","shell.execute_reply":"2024-04-02T07:44:00.708000Z","shell.execute_reply.started":"2024-04-02T07:44:00.366074Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8558558558558559\n","\n","\n","0.869481880258512\n","\n","\n","0.7646839416736325\n","\n","\n","0.8007504396232122\n","\n","\n","0.8015217677784167\n","\n","\n","0.8607401118837822\n","\n","\n","0.8337415991457823\n","\n","\n","0.8344981412639405\n","\n","\n","0.8468468468468469\n","\n","\n","0.8337865851516111\n","\n","\n","0.8420184890773126\n","\n","\n","0.8086339665287035\n","\n","\n","0.8476590226590227\n","\n","\n","0.8034218126172148\n","\n","\n"]}],"source":["p1=cb.predict(X_val)\n","print(f1_score(p1,y_val,average=\"weighted\"))\n","print(\"\\n\")\n","p2=cb.predict(X_test)\n","print(f1_score(p2,y_test,average=\"weighted\"))\n","print(\"\\n\")\n","\n","p1=lr.predict(X_val)\n","print(f1_score(p1,y_val,average=\"weighted\"))\n","print(\"\\n\")\n","p2=lr.predict(X_test)\n","print(f1_score(p2,y_test,average=\"weighted\"))\n","print(\"\\n\")\n","\n","p1=gb.predict(X_val)\n","print(f1_score(p1,y_val,average=\"weighted\"))\n","print(\"\\n\")\n","p2=gb.predict(X_test)\n","print(f1_score(p2,y_test,average=\"weighted\"))\n","print(\"\\n\")\n","\n","p1=rf.predict(X_val)\n","print(f1_score(p1,y_val,average=\"weighted\"))\n","print(\"\\n\")\n","p2=rf.predict(X_test)\n","print(f1_score(p2,y_test,average=\"weighted\"))\n","print(\"\\n\")\n","\n","p1=lgbm.predict(X_val)\n","print(f1_score(p1,y_val,average=\"weighted\"))\n","print(\"\\n\")\n","p2=lgbm.predict(X_test)\n","print(f1_score(p2,y_test,average=\"weighted\"))\n","print(\"\\n\")\n","\n","p1=et.predict(X_val)\n","print(f1_score(p1,y_val,average=\"weighted\"))\n","print(\"\\n\")\n","p2=et.predict(X_test)\n","print(f1_score(p2,y_test,average=\"weighted\"))\n","print(\"\\n\")\n","\n","p1=xgb.predict(X_val)\n","print(f1_score(p1,y_val,average=\"weighted\"))\n","print(\"\\n\")\n","p2=xgb.predict(X_test)\n","print(f1_score(p2,y_test,average=\"weighted\"))\n","print(\"\\n\")"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:44:11.851126Z","iopub.status.busy":"2024-04-02T07:44:11.850510Z","iopub.status.idle":"2024-04-02T07:44:12.193602Z","shell.execute_reply":"2024-04-02T07:44:12.192248Z","shell.execute_reply.started":"2024-04-02T07:44:11.851067Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Ensemble Weights: [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n"," 0.14285714]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.48      0.47      0.48        91\n","         1.0       0.64      0.65      0.64       131\n","\n","    accuracy                           0.58       222\n","   macro avg       0.56      0.56      0.56       222\n","weighted avg       0.58      0.58      0.58       222\n","\n","Precision: 0.639098\n","Recall: 0.648855\n","F1 Score: 0.643939\n"]}],"source":["from scipy.optimize import minimize\n","from sklearn.metrics import f1_score\n","import numpy as np\n","\n","preds_cb = cb.predict(X_val)\n","preds_lr = lr.predict(X_val)\n","preds_gb = gb.predict(X_val)\n","preds_rf = rf.predict(X_val)\n","preds_lgbm = lgbm.predict(X_val)\n","preds_et = et.predict(X_val)\n","preds_xgb = xgb.predict(X_val)\n","\n","# Stack predictions\n","preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n","\n","def loss_func(weights):\n","    \n","    final_prediction = np.average(preds, axis=0, weights=weights)\n","    final_prediction = [1 if prob > 0.5 else 0 for prob in final_prediction]\n","    return 1 - f1_score(y_val, final_prediction, average='weighted')\n","\n","# The algorithm needs a starting value, let's start with equal weights\n","starting_values = [1/7,1/7,1/7,1/7,1/7,1/7,1/7]\n","\n","# Our weights are bound between 0 and 1\n","bounds = [(0, 1)]*7\n","\n","# We want our weights to sum to 1\n","cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n","\n","# We use 'SLSQP' as our solver, SLSQP stands for Sequential Least Squares Programming\n","res = minimize(loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n","\n","print('Ensemble Weights: {weights}'.format(weights=res['x']))\n","\n","from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n","\n","# Get the predictions from each model on the test set\n","preds_cb = cb.predict(X_test)\n","preds_lr = lr.predict(X_test)\n","preds_gb = gb.predict(X_test)\n","preds_rf = rf.predict(X_val)\n","preds_lgbm = lgbm.predict(X_val)\n","preds_et = et.predict(X_val)\n","preds_xgb = xgb.predict(X_val)\n","\n","# Stack the predictions together\n","preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n","\n","# Calculate the weighted average of predictions\n","final_preds = np.average(preds, axis=0, weights=res['x'])\n","\n","# Convert probabilities to class labels\n","final_preds = [1 if prob > 0.5 else 0 for prob in final_preds]\n","\n","# Print the classification report\n","print(classification_report(y_test, final_preds))\n","\n","# Print Precision, Recall and F1 Score\n","print(\"Precision: %f\" % precision_score(y_test, final_preds))\n","print(\"Recall: %f\" % recall_score(y_test, final_preds))\n","print(\"F1 Score: %f\" % f1_score(y_test, final_preds))\n","\n"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:44:17.274224Z","iopub.status.busy":"2024-04-02T07:44:17.273172Z","iopub.status.idle":"2024-04-02T07:44:17.445095Z","shell.execute_reply":"2024-04-02T07:44:17.443658Z","shell.execute_reply.started":"2024-04-02T07:44:17.274166Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.81      0.80      0.80        93\n","           1       0.85      0.87      0.86       129\n","\n","    accuracy                           0.84       222\n","   macro avg       0.83      0.83      0.83       222\n","weighted avg       0.84      0.84      0.84       222\n","\n","Precision: 0.854962\n","Recall: 0.868217\n","F1 Score: 0.861538\n"]}],"source":["preds_cb = cb.predict(X_val)\n","preds_lr = lr.predict(X_val)\n","preds_gb = gb.predict(X_val)\n","preds_rf = rf.predict(X_val)\n","preds_lgbm = lgbm.predict(X_val)\n","preds_et = et.predict(X_val)\n","preds_xgb = xgb.predict(X_val)\n","# Stack the predictions together\n","preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n","\n","# Calculate the weighted average of predictions\n","final_preds = np.average(preds, axis=0, weights=res['x'])\n","\n","# Convert probabilities to class labels\n","final_preds = [1 if prob > 0.5 else 0 for prob in final_preds]\n","\n","# Print the classification report\n","print(classification_report(y_val, final_preds))\n","\n","# Print Precision, Recall and F1 Score\n","print(\"Precision: %f\" % precision_score(y_val, final_preds))\n","print(\"Recall: %f\" % recall_score(y_val, final_preds))\n","print(\"F1 Score: %f\" % f1_score(y_val, final_preds))\n"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:44:22.303450Z","iopub.status.busy":"2024-04-02T07:44:22.302939Z","iopub.status.idle":"2024-04-02T07:44:22.699166Z","shell.execute_reply":"2024-04-02T07:44:22.697774Z","shell.execute_reply.started":"2024-04-02T07:44:22.303394Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Ensemble Weights: [0.2842193  0.11092116 0.20387251 0.28665253 0.09220049 0.01538497\n"," 0.00674904]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.43      0.43      0.43        91\n","         1.0       0.60      0.60      0.60       131\n","\n","    accuracy                           0.53       222\n","   macro avg       0.52      0.52      0.52       222\n","weighted avg       0.53      0.53      0.53       222\n","\n","Precision: 0.603053\n","Recall: 0.603053\n","F1 Score: 0.603053\n"]}],"source":["from scipy.optimize import minimize\n","from sklearn.metrics import accuracy_score, f1_score\n","import numpy as np\n","\n","preds_cb = cb.predict(X_val)\n","preds_lr = lr.predict(X_val)\n","preds_gb = gb.predict(X_val)\n","preds_rf = rf.predict(X_val)\n","preds_lgbm = lgbm.predict(X_val)\n","preds_et = et.predict(X_val)\n","preds_xgb = xgb.predict(X_val)\n","# Stack predictions\n","preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n","\n","def loss_func(weights):\n","    \n","    final_prediction = np.average(preds, axis=0, weights=weights)\n","    # Convert probabilities to class labels\n","    final_prediction = [1 if prob > 0.5 else 0 for prob in final_prediction]\n","    return 1 - f1_score(y_val, final_prediction, average='weighted')\n","\n","# Our weights are bound between 0 and 1\n","bounds = [(0, 1)]*7\n","\n","# We want our weights to sum to 1\n","cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n","\n","# Number of random starting points\n","num_starts = 10\n","\n","best_score = np.inf\n","best_weights = None\n","\n","# Perform optimization with several randomly chosen starting points\n","for _ in range(num_starts):\n","    # Randomly choose starting weights\n","    values = np.random.rand(7)\n","    starting_values = values / np.sum(values)\n","\n","    res = minimize(loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n","\n","    if res.fun < best_score:\n","        best_score = res.fun\n","        best_weights = res.x\n","\n","# Calculate the weighted average of predictions\n","final_preds = np.average(preds, axis=0, weights=best_weights)\n","\n","# Convert probabilities to class labels\n","final_preds = [1 if prob > 0.5 else 0 for prob in final_preds]\n","\n","print('Best Ensemble Weights: {weights}'.format(weights=best_weights))\n","\n","print(classification_report(y_test, final_preds))\n","\n","# Print Precision, Recall and F1 Score\n","print(\"Precision: %f\" % precision_score(y_test, final_preds))\n","print(\"Recall: %f\" % recall_score(y_test, final_preds))\n","print(\"F1 Score: %f\" % f1_score(y_test, final_preds))\n"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:44:27.838985Z","iopub.status.busy":"2024-04-02T07:44:27.838446Z","iopub.status.idle":"2024-04-02T07:44:28.013954Z","shell.execute_reply":"2024-04-02T07:44:28.012538Z","shell.execute_reply.started":"2024-04-02T07:44:27.838941Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.82      0.81      0.82        93\n","           1       0.86      0.88      0.87       129\n","\n","    accuracy                           0.85       222\n","   macro avg       0.84      0.84      0.84       222\n","weighted avg       0.85      0.85      0.85       222\n","\n","Precision: 0.862595\n","Recall: 0.875969\n","F1 Score: 0.869231\n"]}],"source":["preds_cb = cb.predict(X_val)\n","preds_lr = lr.predict(X_val)\n","preds_gb = gb.predict(X_val)\n","preds_rf = rf.predict(X_val)\n","preds_lgbm = lgbm.predict(X_val)\n","preds_et = et.predict(X_val)\n","preds_xgb = xgb.predict(X_val)\n","# Stack the predictions together\n","preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n","\n","# Calculate the weighted average of predictions\n","final_preds = np.average(preds, axis=0, weights=best_weights)\n","\n","# Convert probabilities to class labels\n","final_preds = [1 if prob > 0.5 else 0 for prob in final_preds]\n","\n","# Print the classification report\n","print(classification_report(y_val, final_preds))\n","\n","# Print Precision, Recall and F1 Score\n","print(\"Precision: %f\" % precision_score(y_val, final_preds))\n","print(\"Recall: %f\" % recall_score(y_val, final_preds))\n","print(\"F1 Score: %f\" % f1_score(y_val, final_preds))\n"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T07:44:36.651470Z","iopub.status.busy":"2024-04-02T07:44:36.650929Z","iopub.status.idle":"2024-04-02T07:44:36.823856Z","shell.execute_reply":"2024-04-02T07:44:36.822372Z","shell.execute_reply.started":"2024-04-02T07:44:36.651426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Disagreement Measure between cb and lr: 0.14414414414414414\n","Correlation of Errors between cb and lr: 0.5603411444311519\n","Disagreement Measure between cb and gb: 0.09009009009009009\n","Correlation of Errors between cb and gb: 0.6967489613206035\n","Disagreement Measure between cb and rf: 0.03153153153153153\n","Correlation of Errors between cb and rf: 0.8832505754016562\n","Disagreement Measure between cb and lgbm: 0.04504504504504504\n","Correlation of Errors between cb and lgbm: 0.8225794275109579\n","Disagreement Measure between cb and et: 0.04054054054054054\n","Correlation of Errors between cb and et: 0.8430274536955765\n","Disagreement Measure between cb and xgb: 0.036036036036036036\n","Correlation of Errors between cb and xgb: 0.8581903153634214\n","Disagreement Measure between lr and gb: 0.16216216216216217\n","Correlation of Errors between lr and gb: 0.5254334065751518\n","Disagreement Measure between lr and rf: 0.13063063063063063\n","Correlation of Errors between lr and rf: 0.6088339125177527\n","Disagreement Measure between lr and lgbm: 0.13513513513513514\n","Correlation of Errors between lr and lgbm: 0.5917254695001163\n","Disagreement Measure between lr and et: 0.15765765765765766\n","Correlation of Errors between lr and et: 0.5195603228146611\n","Disagreement Measure between lr and xgb: 0.14414414414414414\n","Correlation of Errors between lr and xgb: 0.5621924087471861\n","Disagreement Measure between gb and rf: 0.1036036036036036\n","Correlation of Errors between gb and rf: 0.6569344101227068\n","Disagreement Measure between gb and lgbm: 0.07207207207207207\n","Correlation of Errors between gb and lgbm: 0.761222517468996\n","Disagreement Measure between gb and et: 0.0945945945945946\n","Correlation of Errors between gb and et: 0.6841126419086412\n","Disagreement Measure between gb and xgb: 0.08108108108108109\n","Correlation of Errors between gb and xgb: 0.7298464686613246\n","Disagreement Measure between rf and lgbm: 0.05855855855855856\n","Correlation of Errors between rf and lgbm: 0.7831133910418329\n","Disagreement Measure between rf and et: 0.036036036036036036\n","Correlation of Errors between rf and et: 0.86788028873177\n","Disagreement Measure between rf and xgb: 0.03153153153153153\n","Correlation of Errors between rf and xgb: 0.8837993984614975\n","Disagreement Measure between lgbm and et: 0.07657657657657657\n","Correlation of Errors between lgbm and et: 0.7084054215418493\n","Disagreement Measure between lgbm and xgb: 0.036036036036036036\n","Correlation of Errors between lgbm and xgb: 0.8610763454317898\n","Disagreement Measure between et and xgb: 0.06756756756756757\n","Correlation of Errors between et and xgb: 0.7427279888884858\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","import numpy as np\n","\n","models = [cb, lr, gb,rf,lgbm,et,xgb]\n","model_names = ['cb', 'lr', 'gb', 'rf', 'lgbm','et','xgb']\n","\n","# Get the predictions from each model on the validation set\n","preds = [model.predict(X_val) for model in models]\n","\n","# Calculate Disagreement Measure and Correlation of Errors\n","for i in range(len(models)):\n","    for j in range(i+1, len(models)):\n","        # Disagreement Measure\n","        disagree = np.mean(preds[i] != preds[j])\n","        print(f'Disagreement Measure between {model_names[i]} and {model_names[j]}: {disagree}')\n","        \n","        # Correlation of Errors\n","        errors_i = preds[i] != y_val\n","        errors_j = preds[j] != y_val\n","        correlation = np.corrcoef(errors_i, errors_j)[0, 1]\n","        print(f'Correlation of Errors between {model_names[i]} and {model_names[j]}: {correlation}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# WEBAPP\n","### Store this in html file"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["<!DOCTYPE html>\n","<html>\n","<head>\n","    <title>Heart Disease Prediction</title>\n","    <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js\"></script>\n","</head>\n","<body>\n","    <h1>Heart Disease Prediction</h1>\n","    <form id=\"predict-form\">\n","        <label for=\"age\">Age:</label><br>\n","        <input type=\"number\" id=\"age\" name=\"age\"><br>\n","        <label for=\"sex\">Sex:</label><br>\n","        <select id=\"sex\" name=\"sex\">\n","            <option value=\"Male\">Male</option>\n","            <option value=\"Female\">Female</option>\n","        </select><br>\n","        <label for=\"chestPainType\">Chest Pain Type:</label><br>\n","        <select id=\"chestPainType\" name=\"chestPainType\">\n","            <option value=\"Typical angina\">Typical angina</option>\n","            <option value=\"Atypical angina\">Atypical angina</option>\n","            <option value=\"Non-anginal pain\">Non-anginal pain</option>\n","            <option value=\"Asymptomatic\">Asymptomatic</option>\n","        </select><br>\n","        <label for=\"restingBP\">Resting Blood Pressure:</label><br>\n","        <input type=\"number\" id=\"restingBP\" name=\"restingBP\"><br>\n","        <label for=\"cholesterol\">Cholesterol:</label><br>\n","        <input type=\"number\" id=\"cholesterol\" name=\"cholesterol\"><br>\n","        <label for=\"fastingBS\">Fasting Blood Sugar:</label><br>\n","        <input type=\"number\" id=\"fastingBS\" name=\"fastingBS\"><br>\n","        <label for=\"maxHR\">Maximum Heart Rate:</label><br>\n","        <input type=\"number\" id=\"maxHR\" name=\"maxHR\"><br>\n","        <label for=\"exerciseAngina\">Exercise Induced Angina:</label><br>\n","        <select id=\"exerciseAngina\" name=\"exerciseAngina\">\n","            <option value=\"Yes\">Yes</option>\n","            <option value=\"No\">No</option>\n","        </select><br>\n","        <input type=\"submit\" value=\"Predict\">\n","    </form>\n","    <p id=\"prediction\"></p>\n","\n","    <script>\n","        $(\"#predict-form\").submit(function(event) {\n","            event.preventDefault();\n","            var data = {\n","                'Age': parseInt($(\"#age\").val()),\n","                'Sex': $(\"#sex\").val(),\n","                'ChestPainType': $(\"#chestPainType\").val(),\n","                'RestingBP': parseInt($(\"#restingBP\").val()),\n","                'Cholesterol': parseInt($(\"#cholesterol\").val()),\n","                'FastingBS': parseInt($(\"#fastingBS\").val()),\n","                'MaxHR': parseInt($(\"#maxHR\").val()),\n","                'ExerciseAngina': $(\"#exerciseAngina\").val()\n","            };\n","            $.ajax({\n","                url: '/predict',\n","                method: 'POST',\n","                contentType: 'application/json',\n","                data: JSON.stringify(data),\n","                success: function(response) {\n","                    $(\"#prediction\").text('Prediction: ' + response.prediction);\n","                },\n","                error: function(response) {\n","                    $(\"#prediction\").text('Error: ' + response.responseJSON.error);\n","                }\n","            });\n","        });\n","        \n","    </script>\n","</body>\n","</html>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true}},"outputs":[],"source":["from flask import Flask, request, jsonify\n","import pickle\n","import numpy as np\n","\n","# Load the models\n","cb1 = pickle.load(open('cbheart1.pkl', 'rb'))\n","cb2 = pickle.load(open('cbheart2.pkl', 'rb'))\n","lr = pickle.load(open('LRHD_0.8F1_0.75Acc.pkl', 'rb'))\n","gb = pickle.load(open('GradBoostHeartDisease_0.82_0.82.pkl', 'rb'))\n","\n","# Define the ensemble weights\n","weights = np.array([0.25014892, 0.24990093, 0.24985107, 0.25009908])\n","\n","app = Flask(__name__)\n","def validate_input(data):\n","    # Convert input data to the format expected by the models\n","    data['Sex'] = 1 if data['Sex'].lower() == 'male' else 0\n","    chest_pain_types = ['typical angina', 'atypical angina', 'non-anginal pain', 'asymptomatic']\n","    for i, chest_pain_type in enumerate(chest_pain_types):\n","        data['ChestPainType_' + str(i)] = data['ChestPainType'].lower() == chest_pain_type\n","    del data['ChestPainType']\n","    data['FastingBS'] = 1 if data['FastingBS'] > 120 else 0\n","    data['ExerciseAngina'] = 1 if data['ExerciseAngina'].lower() == 'yes' else 0\n","\n","    # Convert the data to a flat list of features\n","    features = [data['Age'], data['Sex'], data['RestingBP'], data['Cholesterol'], data['MaxHR'], data['ExerciseAngina']] + [data['ChestPainType_' + str(i)] for i in range(4)]\n","\n","    # Define the expected data types for each feature\n","    expected_types = [int, int, int, int, int, int, bool, bool, bool, bool]\n","    constraints = [(20,80), (0,1), (0,200), (0,603), (60,202), (0,1), (False,True), (False,True), (False,True), (False,True)]\n","    \n","    # Check if the number of features is correct\n","    if len(features) != len(expected_types):\n","        return False, \"Incorrect number of features. Expected {} but got {}.\".format(len(expected_types), len(features)), None\n","    \n","    # Check the data type and constraints of each feature\n","    for i in range(len(features)):\n","        if type(features[i]) != expected_types[i]:\n","            return False, \"Incorrect data type for feature {}. Expected {} but got {}.\".format(i, expected_types[i].__name__, type(features[i]).__name__), None\n","        if features[i] < constraints[i][0] or features[i] > constraints[i][1]:\n","            return False, \"Feature {} out of bounds. Expected between {} and {} but got {}.\".format(i, constraints[i][0], constraints[i][1], features[i]), None\n","    # If all checks pass, return True and the features\n","    return True, \"Input is valid.\", features\n","\n","        \n","@app.route('/',methods=[\"GET\"])\n","def home():\n","    return app.send_static_file('index.html')\n","\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    # Get the data from the POST request\n","    data = request.get_json(force=True)\n","    is_valid, message, features = validate_input(data)\n","    if not is_valid:\n","        print(message)\n","        return jsonify({'error': message}),400\n","    # Make prediction using the models\n","    prediction1 = cb1.predict_proba([np.array(features)])\n","    prediction2 = cb2.predict_proba([np.array(features)])\n","    prediction3 = lr.predict_proba([np.array(features)])\n","    prediction4 = gb.predict_proba([np.array(features)])\n","\n","    # Compute the ensemble prediction\n","    ensemble_prediction = np.argmax(np.average(np.array([prediction1, prediction2, prediction3, prediction4]), axis=0, weights=weights))\n","\n","    # Send back to the client\n","    output = {'prediction': int(ensemble_prediction)}\n","    return jsonify(output)\n","\n","if __name__ == '__main__':\n","    app.run(port=5000, debug=True)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
